{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KSKimmon/KSKimmon/blob/main/Chawa_Heart_Attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Increase machine learning model accuracy of Cardiovascular diseases datasets"
      ],
      "metadata": {
        "id": "jRfiCR1XVNXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6330140621 Napat Chawakespong\n"
      ],
      "metadata": {
        "id": "ckTIXs9UVTHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6330348921 Palapol Suetrakoolpanich"
      ],
      "metadata": {
        "id": "q9-gGUQfV0PI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U90gTHMooUg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_rows\",None)\n",
        "from sklearn import preprocessing\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNqaY3nopi2z",
        "outputId": "990f6ed3-b8a6-4158-d3ed-45ee3dc3f03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tZsUnXhmpPIp",
        "outputId": "083ea682-9a2b-4cd7-a171-9c2eb0b60497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
              "0   40   M           ATA        140          289          0     Normal    172   \n",
              "1   49   F           NAP        160          180          0     Normal    156   \n",
              "2   37   M           ATA        130          283          0         ST     98   \n",
              "3   48   F           ASY        138          214          0     Normal    108   \n",
              "4   54   M           NAP        150          195          0     Normal    122   \n",
              "\n",
              "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
              "0              N      0.0       Up             0  \n",
              "1              N      1.0     Flat             1  \n",
              "2              N      0.0       Up             0  \n",
              "3              Y      1.5     Flat             1  \n",
              "4              N      0.0       Up             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-840cc675-ff18-402e-9c76-7ccdb08b1c2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>ChestPainType</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>RestingECG</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>ExerciseAngina</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>ST_Slope</th>\n",
              "      <th>HeartDisease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>M</td>\n",
              "      <td>ATA</td>\n",
              "      <td>140</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>172</td>\n",
              "      <td>N</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Up</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>NAP</td>\n",
              "      <td>160</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>156</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Flat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>M</td>\n",
              "      <td>ATA</td>\n",
              "      <td>130</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>ST</td>\n",
              "      <td>98</td>\n",
              "      <td>N</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Up</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>F</td>\n",
              "      <td>ASY</td>\n",
              "      <td>138</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>108</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Flat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54</td>\n",
              "      <td>M</td>\n",
              "      <td>NAP</td>\n",
              "      <td>150</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>122</td>\n",
              "      <td>N</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Up</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-840cc675-ff18-402e-9c76-7ccdb08b1c2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-840cc675-ff18-402e-9c76-7ccdb08b1c2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-840cc675-ff18-402e-9c76-7ccdb08b1c2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4ca18f6b-b3c0-4629-85bf-2fa4a23c48b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ca18f6b-b3c0-4629-85bf-2fa4a23c48b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4ca18f6b-b3c0-4629-85bf-2fa4a23c48b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/heart1.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8aoGSx-p4U_",
        "outputId": "7e84c18b-16bd-4ae8-e76d-8948518ce67a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                 int64\n",
              "Sex                object\n",
              "ChestPainType      object\n",
              "RestingBP           int64\n",
              "Cholesterol         int64\n",
              "FastingBS           int64\n",
              "RestingECG         object\n",
              "MaxHR               int64\n",
              "ExerciseAngina     object\n",
              "Oldpeak           float64\n",
              "ST_Slope           object\n",
              "HeartDisease        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPD8L38VrARq",
        "outputId": "0ac5abbe-5e1e-440e-d633-f1b133e7abb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                 int64\n",
              "Sex                string\n",
              "ChestPainType      string\n",
              "RestingBP           int64\n",
              "Cholesterol         int64\n",
              "FastingBS           int64\n",
              "RestingECG         string\n",
              "MaxHR               int64\n",
              "ExerciseAngina     string\n",
              "Oldpeak           float64\n",
              "ST_Slope           string\n",
              "HeartDisease        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "string_col = df.select_dtypes(include=\"object\").columns\n",
        "df[string_col]=df[string_col].astype(\"string\")\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BVVm3s0rJX1"
      },
      "source": [
        "Getting Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "sw3BIvr5rLl4",
        "outputId": "46f7a9aa-a3c6-44ee-b2ab-1b0a4f9f74f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              count        mean         std   min     25%    50%    75%    max\n",
              "Age           918.0   53.510893    9.432617  28.0   47.00   54.0   60.0   77.0\n",
              "RestingBP     918.0  132.396514   18.514154   0.0  120.00  130.0  140.0  200.0\n",
              "Cholesterol   918.0  198.799564  109.384145   0.0  173.25  223.0  267.0  603.0\n",
              "FastingBS     918.0    0.233115    0.423046   0.0    0.00    0.0    0.0    1.0\n",
              "MaxHR         918.0  136.809368   25.460334  60.0  120.00  138.0  156.0  202.0\n",
              "Oldpeak       918.0    0.887364    1.066570  -2.6    0.00    0.6    1.5    6.2\n",
              "HeartDisease  918.0    0.553377    0.497414   0.0    0.00    1.0    1.0    1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-929853ee-fb49-48e2-b14c-7e4c9bbccd5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>918.0</td>\n",
              "      <td>53.510893</td>\n",
              "      <td>9.432617</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.00</td>\n",
              "      <td>54.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RestingBP</th>\n",
              "      <td>918.0</td>\n",
              "      <td>132.396514</td>\n",
              "      <td>18.514154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.00</td>\n",
              "      <td>130.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cholesterol</th>\n",
              "      <td>918.0</td>\n",
              "      <td>198.799564</td>\n",
              "      <td>109.384145</td>\n",
              "      <td>0.0</td>\n",
              "      <td>173.25</td>\n",
              "      <td>223.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>603.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FastingBS</th>\n",
              "      <td>918.0</td>\n",
              "      <td>0.233115</td>\n",
              "      <td>0.423046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxHR</th>\n",
              "      <td>918.0</td>\n",
              "      <td>136.809368</td>\n",
              "      <td>25.460334</td>\n",
              "      <td>60.0</td>\n",
              "      <td>120.00</td>\n",
              "      <td>138.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oldpeak</th>\n",
              "      <td>918.0</td>\n",
              "      <td>0.887364</td>\n",
              "      <td>1.066570</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeartDisease</th>\n",
              "      <td>918.0</td>\n",
              "      <td>0.553377</td>\n",
              "      <td>0.497414</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-929853ee-fb49-48e2-b14c-7e4c9bbccd5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-929853ee-fb49-48e2-b14c-7e4c9bbccd5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-929853ee-fb49-48e2-b14c-7e4c9bbccd5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-933088e6-bd37-4a61-8371-401f983b44e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-933088e6-bd37-4a61-8371-401f983b44e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-933088e6-bd37-4a61-8371-401f983b44e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "string_col=df.select_dtypes(\"string\").columns.to_list()\n",
        "num_col=df.columns.to_list()\n",
        "#print(num_col)\n",
        "for col in string_col:\n",
        "    num_col.remove(col)\n",
        "num_col.remove(\"HeartDisease\")\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "rRL-DCoarfRD",
        "outputId": "7b40be1a-494d-4f38-da57-c2d285c38ac6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1c9a835a-9a80-449c-927e-7ca86fe89c7f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1c9a835a-9a80-449c-927e-7ca86fe89c7f\")) {                    Plotly.newPlot(                        \"1c9a835a-9a80-449c-927e-7ca86fe89c7f\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"Age\",\"RestingBP\",\"Cholesterol\",\"FastingBS\",\"MaxHR\",\"Oldpeak\",\"HeartDisease\"],\"y\":[\"Age\",\"RestingBP\",\"Cholesterol\",\"FastingBS\",\"MaxHR\",\"Oldpeak\",\"HeartDisease\"],\"z\":[[1.0,0.2543993561515428,-0.09528177118121824,0.19803906586674333,-0.3820446750319701,0.25861153601875636,0.2820385058189964],[0.2543993561515428,1.0,0.10089294207709164,0.07019333570992349,-0.11213499711298038,0.16480304317138791,0.10758898037140385],[-0.09528177118121824,0.10089294207709164,1.0,-0.2609743277657631,0.23579240300238535,0.050148109140803906,-0.2327406389270114],[0.19803906586674333,0.07019333570992349,-0.2609743277657631,1.0,-0.1314384913934405,0.05269786028732148,0.26729118611029784],[-0.3820446750319701,-0.11213499711298038,0.23579240300238535,-0.1314384913934405,1.0,-0.1606905500499244,-0.4004207694631906],[0.25861153601875636,0.16480304317138791,0.050148109140803906,0.05269786028732148,-0.1606905500499244,1.0,0.40395072206288607],[0.2820385058189964,0.10758898037140385,-0.2327406389270114,0.26729118611029784,-0.4004207694631906,0.40395072206288607,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"title\":{\"text\":\"Correlation Plot of the Heat Failure Prediction\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1c9a835a-9a80-449c-927e-7ca86fe89c7f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "px.imshow(df.corr(),title=\"Correlation Plot of the Heat Failure Prediction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "gEKSuHcNsuvI",
        "outputId": "be262419-785c-4483-bc0e-602d9b2ef41c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e788bdbe38a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HeartDisease\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Looking for Insites in Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HeartDisease\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.pairplot(df,hue=\"HeartDisease\")\n",
        "plt.title(\"Looking for Insites in Data\")\n",
        "plt.legend(\"HeartDisease\")\n",
        "plt.tight_layout()\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hiqjzbZNM-l",
        "outputId": "258135aa-119c-4591-9376-7fffabd1b699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 918 entries, 0 to 917\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Age             918 non-null    int64  \n",
            " 1   Sex             918 non-null    string \n",
            " 2   ChestPainType   918 non-null    string \n",
            " 3   RestingBP       918 non-null    int64  \n",
            " 4   Cholesterol     918 non-null    int64  \n",
            " 5   FastingBS       918 non-null    int64  \n",
            " 6   RestingECG      918 non-null    string \n",
            " 7   MaxHR           918 non-null    int64  \n",
            " 8   ExerciseAngina  918 non-null    string \n",
            " 9   Oldpeak         918 non-null    float64\n",
            " 10  ST_Slope        918 non-null    string \n",
            " 11  HeartDisease    918 non-null    int64  \n",
            "dtypes: float64(1), int64(6), string(5)\n",
            "memory usage: 86.2 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "B1LBXvj6O8XC",
        "outputId": "510d746b-6977-440d-dfff-549ebfd12d99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABmoAAAHbCAYAAADLdcWwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXwU9f0/8Nfslc212YTcHDkIIAgi3iLKKaCgglgPbItFUKvtT237tYpWQaGWWltU1CpYr3pRFBRUvAAFQREQ5FJAEiDkPjabO3t8fn9MZpNlN/ces5vX8/HwUbI7O/uebDqzM+95v9+SEEKAiIiIiIiIiIiIiIiIAk4T7ACIiIiIiIiIiIiIiIh6KyZqiIiIiIiIiIiIiIiIgoSJGiIiIiIiIiIiIiIioiBhooaIiIiIiIiIiIiIiChImKghIiIiIiIiIiIiIiIKEiZqiIiIiIiIiIiIiIiIgoSJGiIiIiIiIiIiIiIioiBhooaIiIiIiIiIiIiIiChImKghIiIiIiIiIiIiIiIKEiZqiHrgrbfewqhRoxAbGwtJknDPPfcEO6SQk5mZiczMTLfHXnnlFUiShFdeeSUoMRFReLDZbHjkkUcwaNAgREREQJIkrF27NthhBdzmzZshSRIWLlwY7FDCjiRJGDdunNtjCxcuhCRJ2Lx5c1BiIqLO4TEiONSwjwz1c4224vd2XkVEgddbji95eXmQJAm33HJLsEOhLmjrOOztvIYCj4kaCjuSJHn8FxERgczMTMyZMweHDh3yyfts374dN998M6qrq/Hb3/4WjzzyCKZOneqTdfvb//73P0ydOhXJycnQ6/Xo06cPhg0bhl/+8pd49dVXgx0eEVG7lixZ4tq///TTT20u9+STT+LRRx9Feno6/vSnP+GRRx7BGWecoYqLRArlYsvpx6yMjAzcfPPN2Lt3b7BD9LmeXCBzOBxYsWIFxo4di4SEBOj1eiQnJ+Oss87CvHnz8MEHH/g+YCIKKeF0jACAgoIC3HvvvRg2bBiioqIQGRmJAQMGYOzYsXjwwQfx888/uy0/btw4SJIUpGjDV1c/ByIKP+F0fGl9DnLZZZe1uVxeXh40Go1r2WBQfm+SJOHXv/51m8t9+eWXruXUlrT+6aefMH/+fOTk5MBoNCI6OhpZWVmYPHkyHn30URQXFwc7RFIJXbADIPKXRx55xPXvqqoq7NixA6+99hreffddbN26FWeffXaP1v/hhx9CCIHXXnsNo0eP7mG0gXPbbbdhxYoViIyMxLRp05CVlQUhBH788UesW7cOmzdvxpw5c4Ia48yZM3HRRRchLS0tqHEQkfoIIbBy5UpIkgQhBFasWIF//OMfXpddv349YmJi8Nlnn8FgMAQ40q4ZOXIkZsyYAQCwWq34+uuv8eabb+Ldd9/FF198gUsuuSS4AaqAw+HA9OnTsWHDBpjNZkybNg39+vVDU1MTDhw4gDfffBM//vgjrr766qDG+bvf/Q433ngjBgwYENQ4iHqjcDtG7N+/H2PHjkVFRQVGjBiBOXPmICEhASUlJdixYwf++te/IisrCwMHDgx2qGEtVD6HL774IqjvTxTOwu34otDpdNiyZQt++uknDBkyxOP5lStXQggBnU4Hu93u9lzfvn1x6NAhxMXFBSzW1atX4+mnn4bZbPZ4fsWKFV7jDLaNGzdi2rRpaGhowMUXX4ypU6fCZDKhoKAA27Ztw2effYbRo0cjJSUlqHEeOnQIUVFRQY2BmKihMOatxcvvf/97LF++HMuWLetxqXtBQQEAID09vUfrCaStW7dixYoV6NevH7Zv345+/fq5PW+z2VRxd0dcXFzADvZEFFo+/fRT5OXl4ZZbbsGGDRvw6quv4q9//avXk6CCggL06dNH9SdIAHD22Wd7HLfuuOMOvPDCC3jooYewadOm4ASmIm+99RY2bNiAkSNH4ssvv/Q4TtTV1eHbb78NUnQtEhMTkZiYGOwwiHqlcDtG3HPPPaioqMDChQvdbkJTHDt2DE1NTUGIrHcJlc8h2IkionAWbscXxfTp07F27VqsXLkSTzzxhNtzDocDL7/8Ms4//3wUFBTg1KlTbs/r9XqcccYZAY/1jTfewF133eX2XGVlJd59911cddVVWLNmTcBi6ozbb78dDQ0NeOWVV7zeFP3DDz8gPj4+CJG5C+RnSW1j6zPqVSZPngwAKC0t9fr8W2+9hfHjx8NsNsNoNGLo0KFYvHgxGhsbXcsoJaIvv/wyACArK8tVXpmXl+dabteuXZg1axaSk5NdbWzuvPNOFBYWerzvLbfcAkmScOzYMTzzzDM466yzEBkZ6dYfsqKiAg888ACGDh2KyMhIxMXFYeLEifj00087vf3btm0DAMyaNcsjSQPIB9rLL7/c62s//fRTXHXVVa7t6d+/P6655hp8/vnnrmWampqwfPlyXHnllcjIyEBERAQSEhIwadIkfPzxx52Os6O+y7W1tfi///s/DBgwABEREcjJycHSpUshhPBYlxACTz31FIYNGwaj0Yi+ffvid7/7HaqqqtjHmSgErVixAgAwf/583HzzzSgrK/P4Mq7sU3Nzc3H8+HG3EvjMzEwsWrQIADB+/Hi3lmOt1dXV4fHHH8fZZ5+N6OhoxMTE4OKLL8Zbb73lEVPrGTA7duzAtGnTkJCQ4HFc6Kpbb70VAPDdd995PFdVVYUHHngAQ4YMgdFoRHx8PKZMmeK2T/Zm+/btmDRpEuLi4hAbG4spU6Zg586dHsspv0Nv8bc18+bYsWO47bbbkJOTg8jISCQkJGDEiBG44447UF5eDkBuyfOb3/wGAPCb3/zG7fff0e9KOYbdcsstXpP5UVFRGD9+vNfXvvPOO5g4cSISEhJgNBqRmZmJm266yW3bq6qq8MQTT2DChAno168fDAYDkpKScPXVV2P79u3txtZaR32fy8rKcNtttyEtLQ0RERE488wzXd8pTtfY2IiFCxciOzsbERERyMrKwkMPPYTGxkb2kSbyItyOEcp+7+677/b6fHZ2tuvCijIr4MsvvwTg3g669b5i06ZNuO222zBs2DCYTCZERkZi+PDhWLRoERoaGjzeo/U+bfXq1bjgggsQFRWFhIQE3HjjjR4X7hS7du3C1KlTERsbC5PJhEmTJrW7L127di1++ctfYvDgwYiOjkZ0dDTOPfdcPP3003A6nR7Ld+b86ejRo/jFL36B+Ph4REdHY/To0fjwww/bjKEtXfkcWquoqMCDDz6I4cOHIyoqCnFxcRg5ciTuv/9+1NbWupbbtWsX7r77bowcOdJ1nBo0aBD++Mc/orKystNxdjT7c9OmTRg3bpzrM5k2bVqbbcEPHz6MWbNmefzuQn2+D1F3hdvxRXHmmWfi4osvxquvvgqbzeb23IcffoiCggLMnz/f62vbmlHT+jzihRdewIgRI2A0GpGSkoLbbrsNVVVVnYrtdFOnTkW/fv2wcuVKj+def/11NDQ0tBlrV69V/etf/4IkSZg1a5bHc59//jm0Wi1GjBiB+vr6dmMuKSnB0aNHERcX12bnmrPOOgv9+/f3eDw/Px//7//9PwwaNMh1bnXBBRfgsccec1uuq8f1tnQ0e7Mr3wG+++47TJ482eM7gJra/6kVK2qoV1EuYJ133nkez82dOxcvv/wy+vXrh1mzZsFsNuObb77BX/7yF3zxxRf47LPPoNPpcPbZZ+ORRx7B2rVrsXfvXtx9992uskvlf9evX49Zs2ZBCIHrrrsOGRkZ2LVrF55//nm8//772Lp1K7KysjxiuPvuu7FlyxZMmzYNV155JbRaLQDg+PHjGDduHPLy8nDppZdi6tSpqK2txfr16zF16lS88MILbR6QWuvTpw8A4MiRI136vT3yyCN49NFHERMTgxkzZqB///6uMs3//ve/mDRpEgD5ZOTuu+/G6NGjcfnllyMpKQmFhYVYt24drrzySqxYsQLz5s3r0nufzmazYcqUKSgoKMAVV1wBnU6HtWvX4v7770dDQ4PHXW533XUXnn/+eaSnp+O2226DwWDABx98gB07dsBms0Gv1/coHiIKnOLiYnzwwQcYPHgwRo8eDZPJhCeffBIvvvgibrjhBtdyM2bMQGZmJpYtWwZAvhMWaNlHr127Fl9++SXmzJnjNVlrsVgwYcIEfP/99zjnnHMwd+5cOJ1OfPLJJ5g9ezYOHDiAxYsXe7xu+/btePzxxzFmzBjMnTsXZWVlPrmT7vT9lMViwSWXXIKDBw/i/PPPxz333IOysjKsWrUKkydPxvPPP4/bb7/dYz3ffvstHn/8cUyaNAl33XUXjh49ivfeew9fffUVPv30U1x66aXdjrGwsBDnn38+rFYrrrzySsyaNQsNDQ3Izc3F66+/jt/97nfo06cPbrnlFpjNZrz//vu45ppr3NqQemth0JpyDDt8+HCn4xJC4De/+Q1effVVJCYm4tprr0VSUhLy8/OxadMmDBkyxPWd4NChQ3jwwQdx2WWXYdq0aYiPj8eJEyfwwQcf4OOPP8a6det6PItO+ewMBgOuu+46NDY24n//+x/mzp0LjUbjdgInhMCsWbPw4YcfYtCgQfjd734Hm82GV155BQcOHOhRHEThKByPEX369EF+fj4OHz6MCy64oN1lzWYzHnnkEbzyyis4fvy423fi1tuxdOlS/Pjjjxg9erSrFcvXX3+NhQsXYvPmza4LUKd77rnn8MEHH+Dqq6/G2LFj8e233+Kdd97B3r17sWfPHkRERLiW3bZtGyZNmoSmpiZce+21yMnJwZ49ezBu3DhMmDDBa/z3338/NBoNLrzwQvTt2xdVVVXYuHEj7r77bnz33Xd4/fXXvb6urfOnI0eO4OKLL0Z5eTmuuOIKnH322Th69ChmzJiBK664ot3f5em68jkocnNzMX78eBw/fhznnnsufvvb38LpdOLw4cP417/+hTvuuAPR0dEA5AvAa9aswdixYzFp0iQ4nU7s2rUL//znP/Hxxx/j22+/RWxsbJdiPt369evx/vvv44orrsAdd9yBgwcP4qOPPsJ3332HgwcPulWCKn8flZWVmDZtGs466ywcO3YMM2fOxJVXXtmjOIhCUTgeX1qbP38+5s6di/fffx/XXXed6/EVK1YgJiYGN910kyvJ1BX33XcfPvnkE1x11VWYPHkyNm3ahBUrVuDo0aPYuHFjl9en1Woxd+5cPProo9i5c6fbdb0VK1YgKyvLdW3qdF29VnXvvfdi48aNeO+99/Dcc8/hzjvvBAAUFRXhl7/8JYxGI1atWoXIyMh2Y46Li4NOp0NNTQ0KCws73d5/586dmDJlCioqKnDZZZfh2muvRV1dHQ4ePIiFCxfiL3/5i2vZ7h7Xu6Ir3wG++uorTJ48GQ6HA9deey0GDhyIffv2Yfz48W1+B6BWBFGYASAAiEceecT137333ivGjBkjJEkS06dPF1ar1e01L7/8sgAgZs6cKerq6tyee+SRRwQAsWzZMrfH58yZIwCI3Nxct8erq6tFQkKC0Gg04quvvnJ77m9/+5sAIC6//HKv60pPTxfHjh3z2KaxY8cKSZLEW2+95fZ4ZWWlGDlypDAajaKoqKjD301+fr6Ii4sTAMRVV10l3njjDXH48GHhdDrbfM0nn3wiAIisrCyRn5/v8fzJkydd/25oaHD7WWGxWMSZZ54p4uPjPX6/GRkZIiMjw+0x5fN4+eWXPZYFIK644gq39RQXF4u4uDgRFxcnmpqaXI9/9dVXAoAYPHiwqKysdD3e2NgoLr30UgHA472JSL0ef/xxAUD89a9/dT127rnnCkmSxJEjRzyW97Z/EaJlv75p0yav76Psk5cuXer2eH19vZgyZYqQJEl8//33rsc3bdrkOvb8+9//7tI2Kfu7OXPmeDw3b948AUBMnz7d7fHbbrtNABC33Xab2/778OHDwmQyCYPB4HZsah3fM88847autWvXCgAiJydHOBwOj9/B6ce41ut75JFHXI89/fTTXo+VQghRU1Pjts9uax/fkd27dwu9Xi8kSRK//OUvxbvvvivy8vLafc0LL7wgAIjzzz9fWCwWt+fsdrsoKChw/WyxWERpaanHOk6ePCnS0tLEGWec4fEcADF27Fi3x9r6+1I+g1tvvVXY7XbX4wcOHBBarVYMHTrUbfnXXntNABCXXnqpaGxsdD1eWVkphgwZ4vW9iXqzcDxG/PGPfxQAREpKili4cKH48ssvRVVVVbuvGTt2rGjvNP/nn3/2+t3/oYceEgDE22+/7fa48vuIjY0VP/zwg9tzN910kwAg3nnnHddjTqfTtY9au3at2/LLli1z/S5O//0ePXrUIyaHwyF+/etfCwDim2++cXuuo/Onyy+/3OtxSTnudeU41J3P4eKLL/b4e1SUlpaK+vp61895eXluxwXFypUrBQDxt7/9ze3x9s6V2jqv0mq14vPPP3d77v777/f6tzxhwgQBQDz33HNuj3/00Udd/t0RhYNwPL4o+4YHH3xQ1NTUCJPJJCZPnux6Pj8/X2i1WjFv3jwhhBB9+/b1OLbk5uZ6PY9RtqN///7i+PHjrsdtNpvrOsy3337b6ViV39uKFStEXl6e0Gg04rbbbnM9v337dgFALF68WNhsNq/XebpzraqsrEz069dPGI1GsWfPHuFwOMTEiRMFAPGf//yn0/HPmjVLABDZ2dniiSeeEN98842ora1tc/nGxkaRmZkpAIg33njD4/nTt6O7x3Vv5yptndd09juAw+EQOTk5AoD46KOP3JZ//vnn2/wOQC2YqKGwo/wf39t/w4YN87qjO/vss4VOp3O7mK+w2+2iT58+4vzzz3d7vK2LWP/9738FAHHTTTd5rMtms7l2uK0PWMq6vF3g2rNnjwAgrrvuOq/bq5xsPPvss16fP93GjRvFwIED3X4vsbGxYsqUKeL111/3OEmYPn26ACDee++9Tq2/LU8++aQAIL788ku3x7uTqPH2ZUg5idu3b5/rsVtvvVUAEK+++qrH8lu3bmWihiiEOJ1OMXDgQKHRaNySxs8884wAIO677z6P13TnJKmsrExotVpx3nnneY1D2Sf/3//9n+sx5STp7LPP7vJ2Kfu7kSNHut1ccN5557kuQP3000+u5RsbG0VUVJSIiYkR5eXlHutTvpAvWrTII77TkzEK5aLe5s2bXY91N1HzwgsvdHqbu3OR55133hGpqalux7CEhAQxY8YM8cEHH3gsP3z4cAFA7N69u8vv1drvf/97j2O3EF1P1ERFRXm9uHfZZZcJAKK6utr1mHIiePpxU4iW7xpM1BDJwvUY0dDQIObPny90Op1rnydJkhgyZIi4++67xc8//+zxmo4SNW0pLy8XAMRvfvMbt8eV38eDDz7o8ZqNGzcKAOKPf/yj6zHlO/Zll13msbzdbnedh3T2Is2uXbs8jmtCtH/+dPLkSQHIN5p5S4Aov6POHoe6+jns3LnT9Zl7O+52ltPpFCaTSYwfP97t8e4kam6++WaP9R87dkwAELNmzXI9duLEiXa/M0yaNImJGupVwvX40jpRI4QQd9xxh5AkyfXd/9FHH3VLqHQnUbNixQqP9/3Pf/4jAM+bx9rTOlEjhBBTp04VsbGxoqamRgghxNy5c4VWqxWnTp1qM1HTnrauVQkhxJYtW4RWqxVDhgwRDzzwQJv70/ZUVFSIa6+9VkiS5DqGaDQacdZZZ4kHH3zQ46br1atXCwDi6quv7tL7nK6j43pXEjWd/Q6wZcsWAcDjuCWEnMQZPHgwEzUdYOszClui1byS2tpaHDhwAPfffz9uvvlmHDhwAEuWLAEg9wDdu3cvEhMTXSWqp4uIiGizf+/pdu/eDQBeS/p0Oh0uu+wy5OXl4fvvv8eAAQPcnvdWSq/0cq6qqvKYBwC0zNvpbHzjx4/H4cOH8fXXX+PLL7/E999/j6+//hqffPIJPvnkE7z66qtYv369q3Txm2++gSRJnW73cuDAATzxxBP46quvUFhY6NETs60elp0VFxeHnJwcj8eVnp6t+zh///33AIAxY8Z4LH/RRRdBp+MukChUbNy4ET///DOmTJmCvn37uh6fPXs2/vjHP+KVV17B4sWLe9zO8LvvvoPD4fA6gwWAq3ezt31uZ9uheLN3717s3bvX7bEBAwZgy5YtbseKn376CXV1dbjkkkuQkJDgsZ4JEyZg8eLFrv1fa5deeik0Gs/xhOPGjXMdD8aOHdut+K+++mosWLAAd911Fz755BNMmTIFl1xyCYYNG+bRe7snrr/+esycORObNm3C1q1b8f3332Pr1q1Yu3Yt1q5di1//+teu/vm1tbXYv38/UlJSMGrUqE6t/+uvv8ZTTz2F7du3o6SkxGM49KlTpzyO3V0xaNAgmEwmj8dbH8NiYmIAyMcwjUaD0aNHeyzv7bhG1JuF6zEiIiICL774Ih577DFs2LAB3377LXbv3o2dO3fiqaeewosvvohVq1Zh+vTpnV5nbW0tnnrqKaxZswaHDx9GdXW123lTW9/VvbWO9vb9WzkX8nY80Wq1GDNmDH7++WeP58rLy/HEE0/go48+wrFjx9xmuLQXl7ffa+tzAG/tXpTjXmd19XP45ptvAABTpkzxetw9nc1mwwsvvIC3334bBw8eRFVVldtcnp6ePwGd//z27NkDALj44ou9xj5mzJgO5+ERhZNwPb6cbv78+fj3v/+Nl156CYsWLcJLL72Es846q0fr7ux+55VXXvGYqTNu3Lg2ZzHOnz8fGzZswNtvv41f/OIXeOeddzBt2jSkp6fDbre3GU93rlWNGTMGixYtwkMPPYTHH38cgwYNwr///e8238Ob+Ph4vPvuu8jLy8Mnn3yCnTt34rvvvsMPP/yAH374Ac8//zw2bNiA888/H0DLMaSzbTq7e1zvis5+lu1dg1POa7rSxro34lVK6hWio6NxwQUX4L333kO/fv3w97//HXfccQf69++PyspKCCFQWlrarb6bp1MGo7XVe1J53GKxeDyXmprq8ZgygPmzzz7DZ5991ub71tTUdDpGjUaDSy+91DWPQAiBzz77DHPmzMHnn3+O559/3tVP1WKxID4+vsPem4B8QJkwYQLsdjsmTpyIq6++GiaTCRqNBnv27MH777+PxsbGTsfpTVszDJSki8PhcD2mfBYpKSkey2u1Wte8AyJSvxdffBEAPIZVJiQk4KqrrsK7777r0Ve5O5R97nfffYfvvvuuzeW87XO97cM7a86cOXjllVcghEBJSQleeuklPPTQQ7jqqquwfft2REVFAejZMcbbvrB13N0d7AkAGRkZ2LFjBxYuXIgNGzbgvffeAyB/gf/Tn/6E//f//l+31306vV6PyZMnY/LkyQDk/f67776LuXPn4rXXXsPMmTMxY8YM1++g9Ul1e9asWYPrrrsORqMRl19+OQYOHIjo6GhoNBps3rwZX375ZcCPYQkJCV5vKmjrsyTqrcL9GJGSkoI5c+a45lhVVFTgz3/+M1auXIm5c+ciPz+/U/MIbDYbJkyYgB07dmD48OG44YYbkJSU5LrAuGjRojb3c972X139/g14/z1YLBacf/75yM3NxQUXXIBf//rXrv2fxWLBU0891WZc3tbXnRg6o7OfQ1ePPzfccAPWrFmD7OxsXHPNNUhNTXXdNLds2bIeH3sA331+PP5QbxPuxxfFOeecg3POOQcvv/wyLrroIhw/fhzPPPNMj9bZ2f3OK6+84jV53lai5qqrrkJKSgpWrlwJm82G2traDmc29+Ra1bXXXouHH34YTqcT8+bNc91U1VWZmZm4/fbbXbNE8/Pzceedd2LdunWYP3++K1HelWNIT47rXcFjSOAwUUO9itlsxpAhQ7B7927s3r0b/fv3R1xcHABg1KhRrjvAekJZX1FRkdfnCwsL3ZZrzdtdx8pyTz31lE8vdJ3+vpMnT8bixYsxb948bNy40W3wXXl5Oerr6ztM1ixevBj19fXYtGmTx0H18ccfx/vvv++X+Nui3LVcXFyM7Oxst+ccDgfKy8s7fQJFRMFTWlqKtWvXAgBuuukm3HTTTV6Xe/HFF3t8kqTsc++9917885//7NJrfVE5IkkSUlJSsGDBAlRWVuIf//gHHnroIVcsPTnGFBcXe32Nsq7Wr1HuovV2V5q3JBAADB06FO+88w7sdjv27t2Lzz//HM888wzuvvtuREdH49Zbb/X6up7SarW4/vrrsW/fPixevBgbN27EjBkzXCcUnb2L7C9/+QsMBgN27tyJoUOHuj13++23d+nua18wmUyoqKiA3W73SNa09VkS9Ua96RihSEhIwAsvvIBPP/0UJ06cwP79+3HOOed0+Lr3338fO3bswC233IKXX37Z7bnCwkKf3LSm/I46Oua0tnLlSuTm5uKRRx7xuJN8+/bteOqpp9p8v/bOn7oSQ3e09Tl05fizc+dOrFmzBpMmTcLHH3/str93Op34+9//7pNYO6v1+ZM3PP5Qb9Lbji+33XYb7rjjDtxxxx2IjIzEL3/5S5+styObN2/u0vJ6vR6/+c1v8Le//Q35+fno169fh9Un3b1W1dDQ4Prc4+Pj8eijj+Kaa67BkCFDuhSzN/369cPbb7+N+Ph47N27FxUVFUhISOjSMSQQx/Wu4DGk5zquwyUKM0pZnlJOHhMTgzPPPBMHDhxARUVFj9evtFfxdrCx2+3YsmULAHTqZAqQW3QBcL3On2JjYwG4t4276KKLIITAhg0bOnz90aNHkZCQ4PXOh0Bf4AJaPoutW7d6PPfNN9+0WxZLROrx6quvoqmpCeeeey5uvfVWr/8lJSXh888/R25ubofrU9qgtL77R3HBBRdAo9EEZJ/bkYcffhhJSUlYvny5a7uGDBmCqKgo7N2712vCZNOmTQC8H2O2bt3q1kpFoRyvWrcHi4+PBwCcPHnSY/mdO3e2G7dOp8O5556LP//5z3jrrbcAwHWSC7T/+++J049h0dHRGD58OIqLi722gjvd0aNHMWzYMI8kjdPp9Hoc8bdRo0bB6XRi27ZtHs8FIx4iteqtxwiNRoPo6GgA7t/d24v/6NGjAOS7g0/nq+/qyvHH2/ocDofX/ZcS16xZs3wSV+tzAG+/h65eFGyPt89BOX/75JNPvB53W1O2/eqrr/ZIyu/YsQP19fU+i7Uzzj77bABygsxb7Dz+UG/S244vs2fPRnR0NPLz8/GLX/yizUpwNZg3bx4kSUJ+fj7mzp3rtc1la929VvWHP/wBe/fuxQMPPIC3334bdXV1uOGGG3xSpQLIrTWVitjTjyEff/xxh68PxHG9K9q7BtfWeQ25Y6KGepW1a9ciNzcXer3eref7H/7wBzQ1NWHu3LleL3xVVlZ2utpmxowZSEhIwFtvveXqLalYtmwZcnNzMWnSpE73uD/vvPNw6aWX4r333sN//vMfr8vs27cPJSUlHa5LaUej9DdtraamxjWj57LLLnM9/vvf/x4A8Mc//tFrRr/1Y5mZmaioqMAPP/zgtsxLL72ETz75pMP4fO3Xv/41AGDJkiVuLX2ampqwYMGCgMdDRN2zYsUKAMBzzz2HlStXev3v9ttvhxACK1eu7HB9StvDEydOeDyXnJyMm2++GTt37sRjjz3m9UTq559/7tTJWE/Fxsbiz3/+M2w2m+sOY4PBgJtvvhnV1dX4y1/+4hHX008/Db1ej1/96lce6zty5Aiee+45t8fef/99fPnll8jJyXG1wwRael0rv3vFvn37vN7ZvGvXLq+t05S7ppTWbUD7v//2vPXWW/jss8+8XjgqKipyxdr6GKZUot5+++0e8TmdTlcFEiAfw44cOYKCggLXY0IILFy4EAcPHuxSrL6gHMMeeught1k5VVVVeOyxxwIeD5FahfMxYtGiRR59+xWrV6/Gjz/+iPj4eAwfPrxT8WdmZgLwTFQcO3YMf/7zn30S8+jRozFkyBB89dVXHncoL1++3Ot8mrbi+v777/H44493OYZ+/frh8ssvR25uLpYvX+72nHLc64qufg7nnnsuRo8ejT179mDp0qUerykvL3fNRmhr20tKSnDXXXd1KU5fGDBgAMaNG4ejR4/ihRdecHtuw4YNnE9DvUo4H1+8iY2NxYYNG7BmzRosXrzYb+/jCwMHDnTF2pnOM925VvXuu+/i+eefxyWXXIJFixZh8uTJuO+++7B3717ce++9nYqztrYWjz32WJuVJMuWLUNNTQ2GDRvm+vu46qqrkJmZiQ8++MB101tr+fn5btsF+Pe43hWXXHIJBg4ciE2bNnkkml588UXOp+kEtj6jsNW6bL62thYHDx507Sj++te/uvVGnDt3Lnbt2oXnnnsOAwcOxJQpUzBgwABUVFQgNzcXX331FX7zm990amhYTEwM/vOf/+AXv/gFxo4di1/84hcYMGAAdu3ahU8//RSpqakeX3o78uabb2LChAm49dZb8fTTT+PCCy+E2WxGfn4+fvjhB+zfvx/bt29HcnJyu+v58ccfce+99yI+Ph6XXnopBg0aBJ1Oh/z8fHz44YewWCy48MIL8bvf/c71msmTJ+Ohhx7C4sWLMXToUMyYMQP9+/dHcXExtm7diosuugivvPIKAOCee+7BJ598gjFjxuD6669HXFwcdu7cia1bt+K6667D6tWru7TdPTV27FjcdtttePHFF3HmmWdi1qxZ0Ov1WLduHeLi4pCent6pAZ9EFDybN2/G4cOHMWLEiHaHWd56661YsmQJXn75ZSxatMjrXA/F+PHjodFo8MADD2D//v2u6pGHHnoIgHwh6ciRI3j44Yfx+uuvY8yYMUhJSUFBQQEOHTqE7777Dm+99RaysrJ8u7Fe3HnnnfjHP/6B//73v7j//vsxdOhQ/O1vf8OWLVuwfPlyfPfddxg/fjzKysqwatUqVFdXY/ny5V5jmzp1Kv74xz/i448/xsiRI3H06FG89957MBqN+M9//uO2P7zmmmswaNAgvPXWW8jPz8eFF16IEydO4P3338c111yDVatWua379ddfxwsvvIAxY8Zg4MCBiI+Px88//4x169YhIiLC1U4TkAcUR0VFYdmyZSgvL3f11f7973/vtWWb4ttvv8VTTz2F1NRUjBkzxrWNubm5+PDDD1FfX49rrrnGrfXEvHnzsGXLFrz++usYNGgQrrnmGiQlJaGgoAAbN27E3LlzXd8X7r33Xtxxxx0YNWqU63jx9ddf4+DBg7jqqquwbt26Ln9+PfHrX/8ab7/9NjZs2IDhw4fj6quvhs1mw7vvvovzzz8fP/30E49h1OuF+zHiX//6FxYuXIhRo0bhvPPOQ1JSEqqqqrB7925s374dOp0O//73v13zTABg4sSJ+N///odrr70WV155JSIjI5GRkYFf/epXuOqqq5CTk4N//vOf2LdvH0aNGoUTJ05g/fr1mDZtWpcT6N5IkoSXXnoJl19+OWbNmoVrr70WOTk52LNnD7744gtMnTrVo1L/17/+NZ544gncc8892LRpEwYNGoQjR45g/fr1uPbaa/HOO+90OY5nn30WF198Me655x58+umnruPemjVrurxP787n8N///hfjxo3DggUL8O6772LcuHEQQuDIkSP49NNP8eOPPyIzMxPnn38+LrnkErz33nsYPXo0xowZg+LiYnz88ccYMmQI0tPTu7ztPfXss8/ikksuwZ133omPPvoIZ511Fo4dO4Z3330X11xzDd5//30efyjshfvxpS3ehsCrlTKvsjO6eq0qLy8P8+bNQ3x8PN58801Xxc7ixYvx1Vdf4fnnn8fEiRO9VoK2ZrPZ8PDDD2PRokW44IILcPbZZyM+Ph4VFRX4+uuvsW/fPkRHR7tdazQYDPjf//6HyZMnY/bs2XjhhRdw0UUXoaGhAYcOHcIXX3zh6g4TiON6V2g0GqxcuRJTp07F1VdfjVmzZmHgwIH44Ycf8Nlnn+GKK67Axx9/zGNIewRRmAHg8Z9WqxWpqani6quvFp9++mmbr123bp2YNm2aSEpKEnq9XqSkpIjzzz9fPPjgg+LQoUNuy86ZM0cAELm5uV7XtWPHDjFjxgyRmJgo9Hq96N+/v7jjjjvEqVOnPJbtaF1CCGG1WsWSJUvEOeecI6Kjo4XRaBSZmZniyiuvFC+88IKoqanp8HdTWloqXnrpJXHjjTeKoUOHCrPZLHQ6nUhMTBTjxo0Tzz77rGhsbPT62g8//FBMmTJFxMfHC4PBIPr16ydmzJghvvjiC7fl1q1bJy688EIRExMj4uLixOWXXy6+/PJL8fLLLwsA4uWXX3ZbPiMjQ2RkZLg91pVlFY888ogAIDZt2uT2uMPhEP/85z/FkCFDhMFgEGlpaeLOO+8UFotFxMTEiJEjR3bwWyOiYJo9e7YAIJ566qkOl7388ssFAPHee+8JIdrfZ7z++uti5MiRwmg0uo4VrTU2NopnnnlGXHzxxcJkMgmDwSD69+8vJkyYIP71r3+JsrIy17KbNm0SAMQjjzzS5e1T9ndz5sxpc5mnn35aABDXXnut67HKykpx3333iZycHGEwGERcXJyYNGmS+OSTTzxe3zq+bdu2iYkTJ4rY2FgRExMjLr/8crFjxw6v73vixAlx/fXXi/j4eGE0GsV5550n3n33Xa/b+80334g77rhDnHXWWa7lBw4cKG655Raxb98+j3V//PHH4qKLLhLR0dGu3397x0AlnuXLl4sZM2aIwYMHi9jYWKHX60Vqaqq44oorxOuvvy4cDofX1/73v/8Vl112mTCZTCIiIkJkZmaK2bNni127drkt9/LLL4uRI0eKqKgo0adPHzFjxgzxww8/tHmMASDGjh3r9lhXllW09T2gvr5e/OUvfxGZmZnCYDCIjIwMsWDBApGfny8AiGuuuabd3xlRuAv3Y8SWLVvEggULxCWXXCL69+8vDAaDiIqKEoMHDxbz5s0TP/zwg8dr7Ha7eOCBB0RWVpbQ6XQe+54TJ06I2bNni/T0dGE0GsWwYcPE0qVLhc1m69I+TQghcnNz2zyG7dy5U0yZMkXExMSImJgYMXHiRLFt27Y213fgwAFx1VVXiaSkJBEVFSXOOeccsWLFijbfozPnT0eOHBGzZs0ScXFxIioqSlx00UVi/fr1bZ5rtKU7n4MQQpSVlYn77rtPDB48WERERIi4uDgxcuRIsWDBAlFbW+tarry8XPz2t78VGRkZIiIiQmRnZ4sHHnhA1NbW9vhcqaNtbevYdOjQITFz5kyP390TTzwhAIg1a9Z08FsjCm3hfnxR9g0PPvhgp5bv27evR6zd2T93J2bluLFixYoOl1WOZd5+/529VtXU1CQuvPBCAUC8++67HuvJy8sTZrNZmM3mDs9fHA6H+Pjjj8Uf/vAHccEFF4i0tDSh0+lETEyMGDFihLj77rvbXMfx48fFb3/7W5GZmSn0er1ISEgQF1xwgViyZInbcr46rvvyO8A333wjJk2a5PEd4K677hIAxPfff9/u7603k4Ro1dCWiKiXOHLkCAYPHowbb7zRazkpERGRWn322WeYPHky7r///m61BSIiIuqOm2++GW+++SZ+/PFHnwzTJiKi3uOSSy7Bt99+i6qqKtd8N3LHWiMiCmtFRUUe8wzq6upcbXhmzpwZhKiIiIg61npejqK8vBz3338/AB7DiIjI95xOJ4qKijwe/+KLL/DOO+9g2LBhTNIQEZFXdXV1Xmd/v/LKK9i2bRsmT57MJE07OKOGiMLasmXL8NZbb2HcuHFIS0tDUVERvvjiC+Tn5+OKK67AL37xi2CHSERE5NUf/vAH7N27F6NHj0ZSUhLy8/Px8ccfo6KiArfffnu7PdOJiIi6o6mpCf3798f48eNxxhlnQKfT4cCBA/jss89gMBjw7LPPBjtEIiJSqRMnTmDUqFG4/PLLkZOTA7vdju+//x5bt26F2WzGk08+GewQVY2tz4gorH3xxRf4xz/+gT179qCiogI6nQ6DBw/G7Nmzcc8990Cv1wc7RCIiIq9WrVqF559/HgcOHIDFYoHRaMSZZ56JW2+9FbfeeiskSQp2iEREFGYcDgfuuecebNy4Efn5+airq0NiYiIuu+wy3H///Rg1alSwQyQiIpWqrKzE//3f/+HLL79EUVERGhsbkZqaikmTJuHBBx/EwIEDgx2iqjFRQ0REREREREREREREFCScUUNERERERERERERERBQkTNQQEREREREREREREREFCRM1REREREREREREREREQcJEDRERERERERERERERUZDogh1AuKmsrITdbg92GO1KSkpCaWlpsMPoMW6HunA71CeUtkWn0yE+Pj7YYaiKWo4nofJ3FCpxAozVXxir74VKnEBLrDyeeArm8SSU/oaA0IsXCL2YGa9/MV7f4fHEO7Wco3ij5r+nrgqnbQHCa3u4Leql5u3p7DGFiRofs9vtsNlswQ6jTZIkAZDjFEIEOZru43aoC7dDfcJpW3orNRxPQuXvKFTiBBirvzBW3wuVOAH3WMlTsI4nofQ3BIRevEDoxcx4/YvxUiCo4RzFm3D6ewqnbQHCa3u4LeoVLtvD1mdERERERERERERERERBwkQNERERERERERERERFRkDBRQ0REREREREREREREFCRM1BAREREREREREREREQUJEzVERERERERERERERERBwkQNERERERERERERERFRkDBRQ0REREREREREREREFCRM1BAREREREREREREREQUJEzVERERERERERERERERBwkQNERERERERERERERFRkDBRQ0REREREREREREREFCRM1BAREREREREREREREQUJEzVERERERERERERERERBwkQNERERERERERERERFRkOiCHQARha6jR7W44YZEOJ3ACy8AF14Y7IiIfG/Dhg1Yt24dLBYLMjIyMHfuXOTk5HhddvPmzXjuuefcHtPr9XjjjTcCESqRT+kOHQIuuwzxgwbB8thjcKalBTskIiIKA0II/L//9/+wa9cu/OlPf8LMmTODHRIRUdDlVuXiho9uQGVDJYYlD8O/xvwL2XHZwQ6LiAKIiRoi6rZXX41GUZEWAPDww8CGDUEOiMjHtm3bhtdeew3z58/HoEGD8OGHH2LJkiVYtmwZ4uLivL4mMjISTz31VIAjJfKxpiaYf/974OhRGI8eRXxlJcrffTfYURERUQiobKjEn776E+rsdbhxyI24ZuA1bs+/+uqreLf5mPK73/0O/fr1w/nnnx+MUImIVEEIgfu33o9TNacAADsLduL3m36P969+HzoNL90S9RZsfUZE3WK3Ax98EOn6ed8+YN8+foGg8LJ+/XpMnDgR48ePR79+/TB//nwYDAZs2rSpzddIkgSz2ez2H1GoMX78MfQHD7p+jvjmG2hzc4MYERERhYoX9r2ADcc34KtTX+GPX/0RFQ0VrufsdjueeOIJt+XffvvtQIdIRKQq7x19D1sLtsKoNeKNK95AXEQc9pTuwfM/PB/s0IgogFR3VbUrLWZOnjyJd955B7m5uSgtLcWcOXMwbdo0t2XuuusulJaWerx28uTJmDdvHgBg4cKFONjqYgQATJo0CbfddpuPtooo/OzZo0dZmRbx8Q5cfHETPvooEh9/bMSIEbZgh0bkE3a7HceOHcOMGTNcj2k0GowYMQKHDx9u83UNDQ248847IYRAVlYWbrrpJvTv37/N5W02G2y2lv/fSJKEyMhI17+DSXn/YMfRkVCJEwidWI0bN8r/uO8+NO7YgYjNmxH13nuo+dOfghtYG0Ll9wqETqyhEicQWrEShbt6ez1eP/S6288r96/EfefdBwD45ptvUFlZCbPZjBdffBHXX3891q9fj8ceewxRUVHBCpuIKKie3vM0AOCec+7B+P7j8fQVT2PO2jl4ds+zmDd8HiJ1kR2sgYjCgaoSNV1tMdPY2IiUlBRcfPHFePXVV72u8/HHH4fT6XT9fOLECSxevBgXX3yx23ITJ07EDTfc4PrZYDD4aKuIwtNPP+kBACNH2nDZZXKi5vvv+f8bCh9WqxVOp9OjIsZsNqOgoMDra9LT0/Hb3/4WGRkZqKurwwcffICHHnoI//znP9GnTx+vr1mzZg1Wr17t+jkrKwtLly5FUlKSz7alp1JTU4MdQqeESpyAymN1OoHNm+V/X3klIoYPBzZvRuzmzYh98smghtYRVf9eTxMqsYZKnEBoxUoUrj7O+xiWRgsGxA7AggsW4I4v7sDrh17Hn879E7SSFuvXrwcATJgwARdffDH69++PkydPYtu2bZg0aVKQoyciCrw8ax6OWo5CJ+kwZ9gcAMAvz/olHvz8QeTX5OOTvE8wI2dGcIMkooBQVaKmdYsZAJg/fz52796NTZs2ud3RrMjJyXFV27z55pte12kymdx+Xrt2LVJSUjBs2DC3xyMiItiehqgLfvpJ3n0MGmTHqFFNAIC9e/VwOgENmypSLzV48GAMHjzY7ed7770Xn332GW688Uavr5k5cyamT5/u+lm5I7y0tBR2u92/AXdAkiSkpqaiqKgIQoigxtKeUIkTCI1Y9Xv2ILGsDM7YWGhGj0ZpVBSSAIh9+1CUmwsYjcEO0UMo/F4VoRJrqMQJuMeq1WpVlegm6m12Fu8EAEzNnIqpmVMRo49BRUMFDpQfwFlJZ+HDDz8EIHew0Gg0uPDCC3Hy5Ens3buXiRoi6pW+OPEFAOD81PNhMsjXMDWSBtcNvg7Ldi/D/478j4kaol5CNYma7raY6ep7bNmyBdOmTfNojbBlyxZs2bIFZrMZ5557LmbNmoWIiIg216XmVjXtCZfWENyO4DtyRK6oGTLEjqFDHTAagaoqDXJzdcjJcQQ5uu4J5c/jdOG0LcFiMpmg0WhgsVjcHrdYLJ1O7Ot0OmRlZaGoqKjNZfR6PfR6vdfn1HJxVAihmljaEypxAuqOVbd7NwCg6cILYdTrYe/bF474eGgrK6E7dAi2s88OboDtUPPv9XShEmuoxAmoZ59J1JvtLd0LADg76WzoNXpclHYRPj/xObac2oIsYxb2798PABgzZoy83NlnY/Xq1dizZ0+wQiYiCiolUTNpgHuy+vrB12PZ7mX46tRXKKwtRFp0WjDCI6IAUk2ipjstZrpqx44dqK2txbhx49weHzNmDBITE5GQkIDjx4/jjTfeQEFBAf7UTh/2UGhV055waQ3B7Qieo0fl/x092oz+/YFRo4Dt24GTJ5Nx6aXBja2nQvHzaEs4bUug6XQ6ZGdnY//+/bjgggsAAE6nE/v378fUqVM7tQ6n04kTJ05g1KhR/gyVyKeqd+fBiv6IO3MEjAAgSbCNHAnt5s3Q792r6kQNEREFT5OjCQfL5dmvI5NGAgAu7XspPj/xObae2orzGs8DAKSlpblawp7dfEz5/vvvIYTgTUZE1KvU2mqxvXA7AGBi/4luz2WaMnFBygXYUbwDH+V+hFuH3xqMEIkogFSTqAmETZs24eyzz0ZCQoLb461LrAcMGID4+Hg8+uijKCoqavMip5pb1bQnlNpYtIfbEVzV1RIKCuT/byQkFKGoCDjzzFRs3w589101xo+vCXKE3ROqn4c3obYtOp1OlYnu6dOn49lnn0V2djZycnLw0UcfobGx0ZXwX758ORISEjB79mwAwOrVqzFo0CCkpqaitrYWH3zwAUpLSzFx4sR23oVIPX7+WYspa55GPSJx0YdF+Pqf8uO2s86CcfNm6H/4IbgBEhGRah2qOIQmZxPMEWZkxGYAAMaky5Uz3xZ9iz0FewAAI0aMcL1m2LBh0Ov1qKysxMmTJzFgwICAx01EFCzbC7ejydmEAbEDkGPO8Xh+csZk7CjegS/zv2SihqgXUE2ixhctZtpTWlqKH374od0qGYUy96a9RE0otKppTyi1sWgPtyM48vO1AACz2YnYWCeEkHDGGfJzP/+sC6lt8SbUPo/2hNO2BMPo0aNhtVqxatUqWCwWZGZmYsGCBa7jUllZmdudnzU1NXjhhRdgsVgQHR2N7OxsLF68GP369QvSFhB1zQvPR6FeyK1cvzmaivXrgfPPB2zNF9X0hw4FMzwiIlKx1m3PlO9Hg+MHI0YfgxpbDbb/LN81Pnz4cNdrIiIiMGTIEOzfvx8HDhxgoobID1atWuXWEQYA0tPTsWzZsuAERC77yvYBAM5POd9rReFl/S4DdgDbCreh0dGICG3bIxqIKPSpJlHjixYz7dm0aRPi4uJwzjnndLhsXl4eACA+Pr7H70sUjoqK5ERNWlrLLBolUXP0qGp2K0Q+MXXq1DaPQwsXLnT7+ZZbbsEtt9zi/6CI/KCiQoN3340CAIzWfINtzovw178Ca9YA9uxsAIAuNxcQAmBrGiIiOs2xqmMAgCHxQ1yPaSQNhvcZjm+KvsH+Mnk+TetEDQAMHDgQ+/fvR25ubuCCJepl+vfvj7/85S+unzUaTRCjIYXSLvLMPmd6fX5owlAkRSahtL4Uu4p3YXT66ECGR0QBpqo98/Tp0/HFF19g8+bNyM/Px8qVKz1azLz55puu5e12O/Ly8pCXlwe73Y6Kigrk5eV5DG12Op3YvHkzxo4dC61W6/ZcUVERVq9ejWPHjqGkpAQ7d+7Es88+i6FDhyIjI8Pv20wUioqK5F1HampLomZI8/lYbq4OTmcwoiIiop7YvDkCDU1anIW9eHvEI9BqBb79Vq6idDR/J9JYrZAqK4McKRERqdGJ6hMAgAyT+3n0mYnyBcgiST5PP/NM9wuS2c03AzBRQ+Q/Go0GZrPZ9Z/JZAp2SATgQPkBAG0najSSBpf2lYcAf3nqy4DFRUTBoapb37vaYqaiogL33Xef6+d169Zh3bp1GDZsmNtdzvv27UNZWRnGjx/v8Z46nQ779u1zzR3o06cPLrzwQlx77bV+204ihXHtWuC112CcNw/1V1wR7HA6rbBQTni2TtRkZgIGg0BDg4T8fC0GDHC08WoiIlKjPXvklq7jsQl9hphxts6GXbsM2LLFgBtvjIQjNRXaoiLocnNhO23eHxERkStRE+ueqBnRR26f6Uxxwmg0om/fvm7PZ2VlAWCihsifioqKcPvtt0Ov12Pw4MGYPXs2EhMT21zeZrPBZrO5fpYkCZGRka5/q40Skxpja4u1yYrj1ccBAMMTh3tsg/K/Y/uNxXtH38NX+V9hwQULghNsD4TiZ9MWbot6hcv2qCpRA3StxUxycjJWrVrV4TpHjhzZ5nKJiYlYtGhRl+Mk6ilNQQHi/vQnoK4O8d98A/tHH8E2cmSww+oUJVGTltZSOqPTAQMGOHD0qA55eUzUEBGFmu+/NwAAzsd3sGdm4tL0RuzaZcBXX0XgxhvrYM/KkhM1eXmwnXtukKMlIiI1EULguFW+4DjA5D5nZnhic6uzVCB7YDY0Go3bDEUmaoj8a9CgQbjzzjuRnp6OyspKrF69Gg8//DCefPJJV/LldGvWrHGba5OVlYWlS5ciKSkpUGF3S1tzptXo6PGjAIABcQMwLGuYx/PKtsyKnoW7N9+N/eX7EZMQg9iI2IDG6Suh9Nl0hNuiXqG+PapL1BD1FtEvvwxNXZ3r58g1a0ImUaPMqGldUQMAAwbYcfSoDvn5OgBNQYiMiIi6w2YDDhyQK2ouwA7YM8dgbFojli2LxdatBjidgD0rCxHbt0PXPMuPiIhIUVZfhjp7HSRI6BfTz+25QeZB0EILR4QD/Yb383itkqgpKipCXV0doqKiAhIzUW8xatQo178zMjJciZvt27djwoQJXl8zc+ZMTJ8+3fWzcpd6aWkp7Ha7fwPuBkmSkJqaiqKiIrdEsJp9eVhuZXaG+QwUFha6Hj99WzTQoG9MX5yqOYUN+zZgTN8xwQq5W0Lxs2kLt0W91L49Op2uU4luJmqIgiRiyxb5H9dfD6xaBePHH8P6yCMhMaC5paLGPVHTv7/888mTWo/XEBGRev34ox6NjRLMkgU54ijKsrMx6gwbjEagvFyLvDwtTJmZAAAt73gmIqLTKO170qLTYNAa3J7TaXSIbYqFxWCBKctzLkZ8fDzi4+NRWVmJ3Nxcjxk2RORb0dHRSE9P95jv3Jper4der/f6nBovgiqEEKqOr7UDZS3zabzF3Hpbzk0+F6dqTuG7ou9wSfolAY3TV0Lps+kIt0W9Qn17NMEOgKg3kiorod+/X/7h8cchjEbo8vOhPXYsuIF1UlGRvOs4vaKGiRoiotB08KB87845YhckAPaMDBgMwFlnyc/v26eHPUOeOaA7fjxIURKFvg0bNuCuu+7CzTffjAULFuDo0aPtLl9bW4uVK1fitttuw+zZs3H33Xdj9+7dAYqWqPNc82lMGV6f11vkC75Ssveb0jKbbwY4zmMMkd81NDSgqKjINQ+aguNAhZyoGZbg2fbsdOelnAcA2FWyy68xEVFwMVFDFAQR334LSQjYc3KA7GzYzjgDAKA/dCjIkXXM4QAqK+VdR1KS0+05ZS7NyZMs1iMiCiV5efJ+ezAOw9GnD4RJvuP5nHPk5/fv18ORng4A0LRz9yURtW3btm147bXXcN1112Hp0qXIyMjAkiVLUFVV5XV5u92OxYsXo7S0FH/4wx+wbNky3H777UhISAhw5EQdc82niR3g9fmmArktcn10vdfn05uPMQUFBX6Ijqh3e+2113Dw4EGUlJTgp59+whNPPAGNRoMxY0KrhVY4EULgWJV8o+7g+MEdLn9uijwfcnfJbjiFs4OliShU8WoqURDoD8h3TjSdey50AOxDh8KwZw/0Bw+ioVUfWDWqqtJACPlOOLPZ/QsCK2qIiELTiRPyfnsgfoYjo+VuaCVRs2+fAY65aQAAbXGxnLXXcl9P1BXr16/HxIkTMX78eADA/PnzsXv3bmzatAkzZszwWH7jxo2oqanBY489Bp1OPm1LTk4OZMhEnVZYK89X6BvT1+M5u90Oa64VOBsoFaVeX89EDZH/VFRU4KmnnkJ1dTVMJhPOOOMMLFmyBCaTZytCCoyy+jLU2mohQUL/2P4dLj8sYRiMWiMsjRYcqzqGHHNOAKIkokBjooYoCHQ//QQAsA8ZAgCwDR0qPx4CFTXl5XI1jdnsxOkta/v3l4cKFhdr0dAAGI2Bjo6IiLrj+HH5K2E2jsHRr2XQc0uiRg9HUjKEVgvJ4YCmtBTO1NRghEoUkux2O44dO+aWkNFoNBgxYgQOHz7s9TW7du3CoEGD8NJLL2Hnzp0wmUy45JJLMGPGDGg0no0RbDYbbDab62dJkhAZGen6d6Ap7xmM9+6OUIsXUFfMJXUlAIDU6FSPeIqLiyFK5H7xP1t/9hpv375ygqegoEAV2wOo6/fbGYyX2nLPPfcEOwQ6TV51HgA5uR2hjehweYPWgJFJI/Ft0bfYVbyLiRqiMMVEDVEQ6I4cAQDYB8slrvZhck9S/cGDQYupsyoq5AsD8fGe5bbx8QKRkU7U12tQXKxFRobDYxkiIlKf48fl6phsHIMj/WLX48OHAzqdgMWiQUGxAanJydAWFkJbWMhEDVEXWK1WOJ1Oj3kAZrO5zQqC4uJilJaWYsyYMXjggQdQVFSElStXwuFw4Be/+IXH8mvWrMHq1atdP2dlZWHp0qVISkry6bZ0VWqI7StCLV5AHTFX2CoAAGf0PQNpaWluz/38889Amfzvsroy6Ew6JEYlui1z5plnAgDKy8s9Xh9savj9dgXjJVK/vKo8AG3P9fLm7KSz8W3Rt/ih7AfcMOQGP0VGvcGGDRuwfPlyTJgwATNnzkRWVlawQ6JmTNQQBVpTE3TH5F6kNiVR01xZo8vPh9pLUZRETUKCZ6JGkoCUFCfy8pioISIKFdXVEioqWiVq+l7nei4iAsjKsuPIET0OH9ZhZFqaK1FjGzUqWCET9QpCCJhMJtx+++3QaDTIzs5GRUUFPvjgA6+JmpkzZ2J6qxa6yl3qpaWlsNvtAYu79funpqaiqKgIQoiAv39XhVq8gLpiPlV1CgCgb9SjsLDQ7bm9e/cCNsDQYECTsQnfHP7GNW9BYWw+/8nLy/N4fbCo6ffbGYzXt3Q6XdAT3RS+jlfLc70yTZmdfs3wxOEAgP3l+/0REvUS//3vf3H//fdDCIHvv/8e//73v/H5559jwADvM+YosJioIQowXV4eJLsdzuhoOJtL/J0JCXBGRUFTVwftqVNwDBwY5Cjb1l6iBgBSUx3Iy9OhsNCzJQcREamPUk2TqKuEyV6NiuY5AYpBg+REzdGjOjia73LWquQiGlGoMJlM0Gg0sFgsbo9bLBaPKhuF2WyGTqdza3PWt29fWCwW2O1219wahV6vh/70vrTNgnkRVAihyouwbQm1eIHgx+xwOlBaL8+eSYpM8oglPz8fABDniEMpSpFnzcM5yee4LaNU0RQXF8Nut0Orojlowf79dhXjJVI/paKmK4maEX1GAAAOlh+Ew+mAVqOe/SSFhiNHjriSNDNnzsSxY8ewd+9eLFq0CC+99FKwwyMAvJJKFGDavDwAgH3gQLkEBQAkCY7+8gA5XfOJjFp1lKhJSZGraIqL+aWBiCgUnDghX+zNQi4AwNHXfRD0oEHynfhHjjBRQ9RdOp0O2dnZ2L+/5S5Yp9OJ/fv3Y3BzhfXphgwZgqKiIjidLd+5CgsLER8f75GkIQqmioYKOIQDEiQkRXpWIJw6JVfbJOuSAQB51jyPZZKTk6HT6eBwOFBcXOzXeImIgk2ZUdOVRE12XDYidZGos9ch15rrn8AorD377LMQQmDy5MlYvnw53njjDeh0OmzYsAGbNm0KdngEJmqIAk538iQAuBIzCmV4s7b5ebXquKJGfryoiIkaIqJQkJ/f3PbMLg80d3ipqAHgVlGjYaKGqMumT5+OL774Aps3b0Z+fj5WrlyJxsZGjBs3DgCwfPlyvPnmm67lJ0+ejJqaGrzyyisoKCjA7t27sWbNGkyZMiVIW0DkXXG9nFjpE9kHOo1nElFJ1PSPkc9/jluPeyyj1WqRkpICAG3ObSIiChfdmVGj1WgxLEGeb7y/jO3PqGtOnTqFNWvWAADuvvtuSJKEM888E7/5zW8AACtWrAhmeNSMiRqiANOeOAHAS6Km+We1J2rKyztbUcPdCxFRKFAqINNRAGE0wpmQ4PZ8Tg4raoh8YfTo0fjVr36FVatW4b777kNeXh4WLFjgan1WVlaGyspK1/KJiYl48MEH8fPPP+P//u//8PLLL+OKK67AjBkzgrMBRG0oqSsBAKREpXh9Xkm8DEocBMB7RQ3Q0v5MLTNqiIj8oaqxCpWN8vG+KxU1AOfUUPe99NJLsNvtGDNmDM4++2zX43PmzAEAbN26FRUVFUGKjhSsmScKMG1zazP7aYka5WetylufVVbKCZg+fRxen09NlR9nRQ0RUWhQEuvpKJATMUpbzmY5OfJ+vaJCi9KIvkgAoC0tDXSYRGFh6tSpmDp1qtfnFi5c6PHY4MGDsWTJEj9HRdQzHSVqlBk1w9OHA4XeK2oAuf0ZICctiYjClbIPTIpMQrQ+ukuvVebU7Cvb5/O4KHwJIfDRRx8BgKuCRpGdnY1hw4bh4MGD+OSTT3DTTTcFI0RqxlveiQLM1fqsudWZwjWjprniRq2U1mfx8Wx9RkQUDpSKmjQUwpGa6vF8VJRA377NVTV18rFKw4toRETUrLhObn2WHJns8VxNTQ1qamoAAOdmnQsAKK0vRa2t1mNZJVFTUlLir1CJiIJOqSrsStszReuKGiGEL8OiMHbo0CGcPHkSRqMRY8eO9Xh++vTpAID169cHOjQ6DRM1RAGmVMx4tD5rngmgKSoKeExdYbHIuw2z2fuXAqX1WVGRBvzeQESkfiUl8n69rUQNAGRmyvv2Y1Z5SLTGagUaGgITIBERqZorURPlmagpaj63iY2NRXpCOuKN8QC8V9UkJcnHmFJWbRJRGCuoldtBKnO7umKQeRC0khaWRgtK6pnUps759NNPAQCXXnopIiMjPZ5XEjVbt251a8NLgcdEDVEASVYrNFVVADwTNc7mO8i0paVQc4bDapVb4sTFtT+jpqFB41qWiIjUq/WMGuVYdLrMTLmiJq/UBKHXAwC05eWBCZCIiFStvF4+HiRGJno8V1wsJ3FSUuS2aNnx2QCA/BrPds9M1BBRb1BQIydq0mPSu/xao86IrLgsAMBPFT/5NC4KX0qiZsqUKV6fHzhwIAYOHAi73Y7vvvsukKHRaZioIQogZfiy02yGiIpye87RfGIi2WzQqDSDLQRgtcq7DZPJe6ImMhIwm+XnlIt/RESkTnV1EqqrW1XUtJGoyciQk/DHT+jgTJQvxGl4IY2IiABUNMjDh/sY+3g8d3qiJsMst/rJr2aihoh6p8Ja+bpQWnRat14/JH4IAOBQxSGfxUThq7i4GHv37oUkSZg0aVKby1144YUAwERNkDFRQxRA2uYTFa+tZQwGOOLlVgCa5uXUpq5Ogt2uVNS0XfWTmqq0P2OihohIzYqL5a+CkZoGmGCFM8X7IOiMDLmiJjdX57qxgIkaIiICWhI1CZEJHs95JGrimhM1XipqOKOGiHoDpfVZenTXK2oA4Iz4MwAAP1WyooY69s033wAAhg8f7rohwpvzzjsPABM1wcZEDVEAKfNnHG1cCFMukGlVenJSVSUnaXQ6gcjIthM1refUEBGRepWUNLc90xRDAtqsqFFanx0/rnVV1GjLygISIxERqZsrUWP0TNQoM2pSm29Uay9Ro1xAKisr45BsIgpbSuuzblfUJMgVNUzUUGfs3LkTAHD++ee3u5zy/N69e9HAWaRBw6uoRAGkVNS0dceycoFMo9JETeu2Z1I742dSUuTWZ6yoISJSN6WiJk2cAtD2jQSZmXICvqJCi8q4AQBYUUNERIAQoiVRE9GJiprm1menak55LJvYfCOAzWaDxWLxR7hEREHV5GhCab38Hbo7M2qAltZnP1X+BKfw3pKeSKFUyCgVM23JyspCYmIimpqasG/fvkCERl4wUUMUQNqOKmqaEzVqrahREjXttT0DWlqfcUYNEZG6KfvpdMdJAG3fSBATI9Cnj7xvP6qX2y0wUUNERNW2atiFXHUZb4z3eL4rrc8iIiJgNpsBcE4NEYWn4rpiCAgYNAavVYidkWnKhEFjQL29HierT/o4QgontbW1OHjwIICOK2okSXItw/ZnwcNEDVEAadqbUYOWBI5aZ9RYLMp8mvbv2mDrMyKi0FBWJu+nU1AMZ2QkRExMm8sOGCDv2/OkLACAlhfRiIh6PaWaJkoXhUhdpMfzSqLG1fqsuaKmrL4M9fZ6j+WV9mecU0NE4aiwthCA3PZMI3XveolOo0OOOQcA259R+3bv3g2Hw4F+/fohPb3jCi6l6mbXrl3+Do3awKuoRAGkVNQ420jUOJtPTNReUWMytZ+oSUuTn2dFDRGRulVUyPv1JJTK1TTt9LXs319O1By39wUAaDijhoio1yuvLwcA9DH28XhOCOFRURNvjEeMXr4poL32Z6yoIaJw1NP5NIozEuQK9x8rfuxxTBS+lMqYjqppFGeddRYA4NChQ36LidrHRA1RALkqatpqfdacqNGUlwcspq5oSdS03/pMaY+j3KlNRETqpCRqElEGR/MxqC39+smtbU7UyhfRNJWV/g2OiIhUzzWfxksLH6vV6hpIrFTKSJKEfjH9AAD51Z7tz/r0kRM+FRUVfomXiCiYlIqa7s6nUSgVNUctR3scE4Wv3bt3A+h4Po3ijDPkBODx48dRU1Pjt7iobbyKShQoQrjaxDiaZ9Gczpkgn+Co9eJXVVXnWp8lJsrPM1FDRKRu5eWtKmo6TNTISfgTFnkGgYYX0YiIer2KxrYTNUpVTExMDCIjW9qipcXId5IX1RV5vIaJGiIKZwW1vqmoURI1P1f93OOYKHzt378fQEulTEcSEhJcrUp//JHVWsHAq6hEASJVVUGy2QAAzuaS/tM5lERNyFfUyIma+noN6urabqNDRETB1bqixtnHs21Na0qiJr9cblmjqagARPvHAyIiCm+VDfINZvHGeI/nyppbZCaedu6TGiVfBFLuLG8tofl8qFyl50NERD3hqqiJ7mFFTVxzosbyMwS/j5MXJSUlKC0thUajwdChQzv9umHDhgFg+7NgYaKGKEC0zScqTpMJiIjwuoyrokalF7+qquRdRkcVNTExAhERcvzK3dpERKQ+bomaDipqlBk1+cXyMUyy2yFVV/s3QCIiUjVlRo23iholUZN02vElNVpO1BTVsqKGiHoXX82oyYzLhEbSoNpWjZJ6dc44puA6cOAAAGDgwIFuVa0dUZI6TNQEB6+gEgWIMnS5vTuWlUSNZLdDsloDEldXWK1ydUxsbPuJGkkCEhLkZZioISJSJ4cDsFhaWp85OllRU2XVojJSvsjG9mdERL2bMqOmj9HzGNJmoqa5osZb6zOlooaJGiIKR0pFTU8TNRHaCAyIHQCAc2rIO6Xt2Zlnntml1ylzapioCQ5eQSUKEI0yn6a9O5aNRjijo+XlVVjuX13dudZnAJCYKF/Q45waIiJ1slg0EEJOwCegos22nIqoKIGEBHnfnhs7HIB6Z6oREVFgKDNqvLU+U2bUeLQ+a66oKa4r9ngNEzVEFK4cTgfKGuQEdkp0So/XNzBuIAC5/RnR6ZSKmq4malpX1LCtXuDxCipRgCiJl44uhCkVN2q8S7m2Vr6gFxPTfkUN0DKnhhU1RETqpLQ9i9dYoIe9w+MT0FJVkxclf4FX47GKiIgCx9JgAQCYI8wez3WUqPHW+owzaogoXJU3lMMpnJAgea1C7Kocszyn5mgVK2rIk5KoGT58eJdeN3DgQOj1elRXV+PUqVP+CI3awSuoRAGi7UTrM+C0OTUqU12ttD7rOKvekqjR+jUmIiLqHiWRngj5+OToRKImPb15To0+E4A6j1VERBQ4VU1VAIC4iDiP55TWZ6cnapSWP2X1ZbA5bW7PKTNqKisr4XR2fHMYEVGoUGbJ9InsA51G1+P1DTSzooa8q62tRW5uLgBg2LBhXXqtwWDAwIHy39ZPP/3k89iofUzUEAWI0vqso2HNak7U1NTIu4yYmK4karibISJSI6WiJskpt57pTEVNaqq8bz+l6Q9AnccqIiIKnKpGOVETH9F267PTZ9QkGBOg1+ghIFBS5z4EOz5eXo/D4UBVVZU/QiYiCgplf5ccmeyT9eXENVfUcEYNnUZpW5aamupxs0RnZGdnA4Ar2UOBwyuoRAGitD7raFizkqjRqrDcX6mo6Uzrs8REeRnOqCEiUqfWFTVCr4eI87wb+nSpqXJFzSlnOgAmaoiIejtLowUAEGdou6Lm9ESNRtIgOUq+UHl6+7OIiAjExsYC4JwaIgovpXVy8lrZ//WU0vosvyYf9fZ6n6yTwsPhw4cBAEOGDOnW65VEzbFjx3wWE3UOr6ASBYhGaX3W0YwalVbUOBxAba28y+hc6zP5Yp5yxzYREamLsn9ORJncllOSOnyNkqgpaJIvumkqK/0XIBERqVqDvQENjgYA3luftTWjBgBSo5rn1NS1PaeGiRoiCidK6zNfJWoSjAkwGUwAgBPWEz5ZJ4WHI0eOAABycnK69XpW1AQPr6ASBYhSIdPhjJrmO5olq9XvMXVFbW3LBbzOVNQorc9YUUNEpE4eiZpOUBI1hfVyaxq13VRARESBo8ynkSAh1hDr9lxdXR3q6+U7vL0maqKbEzW1TNQQUe/g69ZnkiQh05QJAMiz5vlknRQejh6V2+ENHjy4W69nRU3w8AoqUYBIzXcdO+M9+ze35jSbAQAai8XPEXWN0vZMrxeIiOh4ec6oISJSN4tF3j8noMJVzdmRtLTmGTVW+e49VtQQEfVeynyauIg4aCT37/xKksVgMCAmJsbjte0lapQ5NUzUEFE4URI1SVHtzy3uCiVRk2tl5QO1UCpqBg0a1K3XK4maU6dOuW66oMDgFVSiQHA6oWkehtlRokaYmi9+qa6iRt5dxMQ4O9MdxzWjprxcC9FxpzQiIgqwqqqWRI2jk4kapaKmuiECNYh2HduIiKj3URI15gizx3NKkiUhIQGSl5OH9lqfmZtvXKviMYaIwoivK2oAsKKGPNTV1eHkyZMAup+oSUhIQFxcHIQQOH78uC/Dow4wUUMUAJLVCskpJy6Uipm2uFqfqezERKmo6cx8GqCloqahQUJdXScyO0REFFBVVfK+OR6VEB3cRKCIiRGu9pen0Fd11Z9ERBQ4lkYLACDO4DmfprK54jK+jeNLexU1SqLGwmMMEYURX8+oAYDMuEwATNRQi59//hmAnGxJ6OTNeKeTJIntz4KEiRqiAFBawzijotBR3zAlUaO2u5RrapSKms4laqKiBIxGzqkhIlIrpfVZPCo7rPZsTamqOYW+kHgRjYio13IlaiI8EzWtK2q86UxFDRM1RBROSutLAfg2UZNlygIA5FXl+WydFNqUtmfdnU+jyMqS/7aYqAksXj0lCgBNJ+fTAIBQEjUqa32mVNQod1J3RJI4p4aISM1atz7r7IwaAEhNbVVRU18PNDX5JT4iIlK3qqbOtT7zpnVFjTitT3Jc8/kQW58RUbiotdWi1lYLwLetz5REzanaU2h0NPpsvRS6lERNTk5Oj9bDiprg4NVTogBQWsN0JlHj1vrM2bmkSCDU1CiJms4PnFHm1LCihohIfXxRUQOorwKUiIgCQ5lR015FTZutz5oraursdai2Vbs9x4oaIgo3ynyaSF0kovXRPltvYmQiovXRcAonTlaf9Nl6KXQpiZruzqdRKIma3NzcHsdEnacLdgCn27BhA9atWweLxYKMjAzMnTu3zSzgyZMn8c477yA3NxelpaWYM2cOpk2b5rbMqlWrsHr1arfH0tPTsWzZMtfPTU1NeO2117Bt2zbYbDaMHDkS8+bNc31BJOoppaJGdOJvymkyAQAkISBVV7sqbIKtulq+oBcb2/nkkVJRU1HBRA0RkZrU1wONjS0zauzdSNTk67MAm5yocSYl+SVOIiJSr84katqqqInSR8FkMMHaZEVxbTFMBpPrOVbUEFG4URI1KVEpkCTfzfCVJAmZpkwcKD+APGsecsw9q6Kg0KfMqOlpRc2AAQMAACdOnOhxTNR5qrp6um3bNrz22mu47rrrsHTpUmRkZGDJkiVtfkFrbGxESkoKZs+e3W5SpX///njxxRdd/z366KNuz7/66qvYtWsX/vCHP2DRokWorKzEk08+6ctNo16uK63PYDRCGI3y61TU/qw7FTVKoqasTOuXmIiIqHuUtmda2GGCtUutz9LSmitqdPKXd86pISLqnSob5XMcs8Hs8VxHiRqgpaqmsK7Q7XFW1BBRuCmplxM1SZG+v7kp05QJAMiz5vl83RRanE4njh8/DqBlxkx3KYma4uJiNDayrV6gqCpRs379ekycOBHjx49Hv379MH/+fBgMBmzatMnr8jk5OfjVr36FSy65BHq9vs31ajQamM1m138mU8vdOnV1ddi4cSPmzJmD4cOHIzs7G3feeSd++uknHD582OfbSL1TlxI1OK39mUrU1Mi7i+4kajijhohIXZS2Z2ZYIKHzxyfAfUYNwNZnRES9lVJR421GTWXz+U+7iZpWc2paUxI1rKghonBRWlcKAEiK8n2iRplTk1eV5/N1U2gpLCxEY2Mj9Ho9+vbt26N1JSQkICoqCkII5Ofn+yhC6ohqWp/Z7XYcO3YMM2bMcD2m0WgwYsSIHidMioqKcPvtt0Ov12Pw4MGYPXs2EhMTAchDkRwOB0aMGOFavm/fvkhMTMThw4cxePBgr+u02Wyw2WyunyVJQmRkpOvfaqXEpuYYOyPUtsM1oyYhwS3mtrbDGRcHbXExtFVVcKhkG+vq5Diio4VHvG1tR3y8fDGvqkoTEp9VqP1dtSectoWIfE+pqEmAfMdzd2bUFDjkC2xM1BAR9U7WJrn63xRh8niuMxU1KVEpAIDiumK3x1snapxOJzQa3vRFRKGtrKEMgH8qavrH9gcAnKhmi6reTpkn079/f+h0PbvkL0kS+vfvj59++gn5+fkYOHCgL0KkDqgmUWO1WuF0Oj1amJnNZhQUFHR7vYMGDcKdd96J9PR0VFZWYvXq1Xj44Yfx5JNPIjIyEhaLBTqdDtHR7sO84uLi2i21XrNmjdvsm6ysLCxduhRJIdKjPTU1Ndgh+ETIbEdDAwAgdsAAxKaleTztsR2JicDhw+ij1QJelg8G0VxIk5YWi7S0WK/LnL4dGRny/zY0RCEtLcqf4flUyPxddUI4bQsR+Y5SUROPSgiDASK680NNlURNka0PHNCoqvqTiIgCp7qpGgDc5ssoOlNRo1ywLKsvc3tcmVEjhIDVauXsWCIKecp+LtGY6PN1D4iVW1SdrD7p83VTaFESNT1te6ZQEjWcUxM4qknU+MuoUaNc/87IyHAlbrZv344JEyZ0e70zZ87E9OnTXT8rd62XlpbCbrd3P2A/kyQJqampKCoqghCdb2GlNqG2HQkFBYgAYNFqUV/Y0oO5re2Ij4qCEYAlN9dt+WAqK4sHYITdXoXCwjq359raDkkyAohHUVEjCgsrAhtwN4Ta31V7Qm1bdDpdyCS6icKBxSJ/b4lHpVxN04Xqu6QkJ7RaAYdDi2KkIIYzBIiIeqVqm5yoiTW438QlhOhURU2fyD4AgPL6crfHDQYDoqKiUFdXB4vFwkQNEYU8ZT+n7Pd8SamoOVlzEkJ4dkCh3iMvLw8AkJmZ6ZP1KXNqTp5kEjBQVJOoMZlM0Gg0HlUsvv5iFh0djfT0dBQVyX1wzWYz7HY7amtr3apqqqqq2n1fvV7f5lycULgoKoQIiTg7EirbITXfUeYwm73Ge/p2OJvnKElVVarZvrrm3ExkpLPNmE7fjrg4+a5ri0Wjmu3ojFD5u+qMcNoWIvIdpaImARVdansGAFqtnKwpKtLiFPpiKCtqiIh6pZqmGgBAjD7G7fHa2lo0NTUBAOLbOcYoFTWl9aUez8XFxaGuro5zaogoLJQ3NCdqjL5P1PSN6QsJEurt9SirL/PLHBwKDb6uqOnXrx8AJmoCSTXNXnU6HbKzs7F//37XY06nE/v3729zTkx3NDQ0oKioyJWEyc7Ohlarxb59+1zLFBQUoKyszKfvS72ba0ZNJy+GOZv/PtXU97+2Vt5dREd3/qK/MqNGuSBIRETqoMyocVXUdFFampyIP4W+qjpWERFRYAgh2qyoUappjEaja46rN4mRcgsg5QJma8r5envtyImIQoWr9Vmk71ufGbQGpEXLLfM5p6Z3UypqfJWoYUVN4KmmogYApk+fjmeffRbZ2dnIycnBRx99hMbGRowbNw4AsHz5ciQkJGD27NkAALvdjvz8fNe/KyoqkJeXB6PR6JrL8Nprr+G8885DYmIiKisrsWrVKmg0GowZMwYAEBUVhQkTJuC1115DTEwMoqKi8J///AeDBw9mooZ8RtNcUdPZi2GiuaJGTRe/6urk8tmoqM4nasxmeVm5oqZLnXWIiMiPlERNdypqgJY5NfnoB6nqqE9jIyIi9au318Mp5JuyYvXuiRplPk18fHy7LXiUC5beKmqYqCGicKIkpP2RqAHkOTUFtQU4WX0S56ac65f3IHVzOp04fvw4AN+1PuvfX26rxxk1gaOqRM3o0aNhtVqxatUqWCwWZGZmYsGCBa4vaWVlZW5f9CoqKnDfffe5fl63bh3WrVuHYcOGYeHCha5lnnrqKVRXV8NkMuGMM87AkiVLYDK1DDycM2cOJEnCk08+CbvdjpEjR2LevHkB2WbqBZqaoKmR2wI4O9nGz9k8QFNNA5qVRE1XKmrMZvnkrbFRQkODhMhItuAiIlIDq1Xep8ehqluJmuRkef9ejBRoqnb5NDYiIlI/a5MVAKCVtIjUuVfNdGY+DdBywbKioQIOpwNajdb1HBM1RBQuGh2Nrn2mP1qfAfKcmm+KvsHx6uN+WT+pX2FhIRoaGqDT6Vwty3pKSdSUl5ejrq4OUVFRPlkvtU1ViRoAmDp1KqZOner1OSX5okhOTsaqVavaXd8999zT4XsaDAbMmzePyRnyC6XtmZAkiOYETEeURI3GavVXWF2mJGoiI52dfk10tIBOJ2C3S6isZKKGiEgtrFa5oiYOVXB2cCHNm6QkuaJGTtSo56YCIiIKjBqbfCNarCHWo2qms4maBKP8vFM4UdlY6XaneVzz+RBn1BBRqCuvl6tpdJIOcRGduybUVQNim1tUVbNFVW+lzKfp378/dDrfXO6Pi4tDXFwcqqqqcPLkSQwZMsQn66W2cXAEkZ+5EjVxcfIE5k5QEjoaFd1B1p3WZ5LUUlXDOTVEROpRU9OziprExFYVNSo6VhERUWBUN8nzaWL0MR7PdTZRo9foER8hH4OU+Q0KVtQQUbioaJD3iX0i+0Aj+ee6SP/Y5hZVnFHTayntyXzV9kzB9meBxSunRH7W1fk0gPpanwnRvdZnABM1RERqVF0t75NNsPYoUVOCZNUcq4iIKHCqbXKiJtYQ6/FcZxM1QEv7s9MTNayoIaJwoezf/NX2DAAyTBkAWFHTmymJFCWx4it9+/YFABQUFPh0veQdr5wS+ZkrUdPJ+TSA+lqfNTQATmfXK2oAwGyWl2eihohIPZSKGhOs3Wp9lpjYqvVZXR1gs/k0PiIiUreaJrn1WXsVNfGduBGgrUQNK2qIKFyUNcj7t9btHX1Nqag5VXMKdqfdb+9D6nXypJykGzBggE/Xm56eDoCJmkDhlVMiP+tORY2r9VlVlVzOEmT19S27iq4nalhRQ0SkNlar71qfAeCcGiKiXkZpfeazipoGVtQQUXhSEtH+TNSkRKXAoDHAIRwoqi3y2/uQevmrooaJmsDilVMiP5Oa7wLrVuuzpiZIDQ3+CKtLamvlC3pGo+jsmB0XJmqIiNRFCKCmpmetz5KS5H17HaJRiyjXsY6IiHqH9lqfVTbfqNaZRE1SZBIAoLS+1O1xpRqHFTVEFOrK68sBAAnGrlexd5ZG0iA9Rr6gfqrmlN/eh9SLFTXhgVdOifxMGbLcldZnIjoaojkjoobe/8p8mshIZ5df25KokXwaExERdU9jI2Cz9az1WXS0gNHYUlXDihoiot5Fqajx1vpMSdR0pvWZMrNBuZCpUCpqmKgholBX3iDv3/xZUQMA6dHyBfX8mny/vg+pT319PUpL5RseWFET2pioIfIz5eJVVxI1kCQ4TSa31weTkqiJju56GzZW1BARqUt1dcv+OEaqhWg+3nSFJLm3P1PDsYqIiAKnxibPqOlp67OkKO8VNZxRQ0ThwtX6zOjfRE2/2H4AWFHTGynVNLGxsa7jp68oiZrCwkI4nV2/eZu6hldOifxMsloBoMsXwtzm1ASZ0vqsq/NpACA+Xt6RV1Zyd0OhacOGDbjrrrtw8803Y8GCBTh69GinXvf111/j+uuvx9///nc/R0jUNdXV8j49FlYgPg7QdG//rLQ/K0GyKo5VREQUOG1V1AghujajpvnCZVsVNfX19WhsbOxxvEREwaJU1PSJ7OPX9+kb0xcAK2p6o9bzaSTJt91sUlJSIEkSbDYbysrKOn4B9Ygu2AEQhTtNc6LG2cVEjbK8VF3t85i6Sqmo6U6ixmyWX8OKGgpF27Ztw2uvvYb58+dj0KBB+PDDD7FkyRIsW7bMdQHBm5KSErz++usYOnRoAKMl6pyezqdRtK6oUUObTqJQsGHDBqxbtw4WiwUZGRmYO3cucnJyvC67efNmPPfcc26P6fV6vPHGG4EIlahdSqLGZHA/x6murobdbgfQudZnSiug0ytqTCYTJEmCEAJVVVVITk72RdhERAHnqqjxc+uzfjFyRU1BDVtU9Tb+mk8DyN89U1JSUFRUhIKCAh6P/YxXTon8TLnLWLRzUdcbESPfnSbV1Pg8pq6qr+9Jooatzyh0rV+/HhMnTsT48ePRr18/zJ8/HwaDAZs2bWrzNU6nE8888wyuv/56fokhVbJa5X16HKogelAan5joANDc+oytaYg6pCT/r7vuOixduhQZGRlYsmQJqtpJdEZGRuLFF190/ffss88GMGKitimtz2IM7hU1Sqsyo9GIyMjIDtejXLgsqy+DEC3nGhqNxnVTTHv/HyEiUjtXRY3RvxU16TGcUdNbta6o8Ye0tDQAnFMTCKyoIfIzqbsVNbFyv2eNCipqamvlJEvPEjW+Lb8k8je73Y5jx45hxowZrsc0Gg1GjBiBw4cPt/m61atXw2QyYcKECTh06FCH72Oz2WCz2Vw/S5LkurDh67LlrlLeP9hxdCRU4gTUEatbRY3Z3GYsHcWalCQfE0qQDI31QFC3SQ2/184KlVhDJU4gdGJtnfwHgPnz52P37t3YtGmT27GmNUmSfN5rnMgXlIqaWL37jBpr87lPe5XHrSmJmgZHA2pttW6JH7PZDIvFwjk1RBSy6u31qLfXA/B/okapqDlVcwpCCNV/LyLf8WdFDQD07dsX33//PU6d4vwjf2OihsjPutv6TE0VNUrrs+jorg8OY0UNhSqr1Qqn0+lxgcxsNrd5J8mPP/6IjRs3dmkuzZo1a7B69WrXz1lZWVi6dCmSkpK6Fbc/pKamBjuETgmVOIHgxqpr/vZnghXGlBTXHVJtaSvWgQPl/y1GCmKavkdMB+sJBP4N+F6oxAmoO9buJv8bGhpw5513QgiBrKws3HTTTW3eLam2xH+oJNAUoRYvENyYlYqaWEOs2/sr1S9xcXEecXmLN8YQg0hdJOrt9ShvLEdsREvip3VFDf+GO8Z4idSnokGe2WXQGBCtj/bre6VHyxU1dfY6VDZWIsHY8ZwwCg9KosZfFTXp6fLfFitq/I+JGiI/UxI1XW59pqqKmp63Pqur06CxEYiI8GloRKpRX1+PZ555BrfffjtMXUjMzpw5E9OnT3f9rJyslpaWunq8B4skSUhNTUVRUZFbOxK1CZU4AXXEeuJEFIA4xKEKtXo9rIWFXpfrKFa93gggHsVIQUNhISrbWE8gqOH32lmhEmuoxAm4x6rValWV6FZ0J/mfnp6O3/72t8jIyEBdXR0++OADPPTQQ/jnP/+JPn0878pVa+JfzQk0b0ItXiA4Mdc56gAAWelZbgl/jUa+OSspKanNGwFOjzclJgV5ljwgCm6vSUlJcf27o5sK/CnU/iYYL5F6VDZUAgASjAl+T0oadUYkRSahtL4UBTUFTNT0Ivn5crs7JmpCHxM1RP7U0ACpoQFAN1qfKRU1KkjUKBU13UnUmEwCkiQghISqKg2Sk7telUMUDCaTCRqNxqPdhsVi8dqGpri4GKWlpVi6dKnrMeXi5o033ohly5Z5PRHV6/XQ6/VeY1DLxVEhhGpiaU+oxAkEN9bqanmfboIVTpOpwzjailWZUVOCZEhVVar43fNvwPdCJU5APftMXxk8eDAGDx7s9vO9996Lzz77DDfeeKPH8mpL/IdSsg8IvXiB4MZsqbcAABqtjSjUtCTqc3NzAcjzlQpPS+C3FW+CIQF5yMOh/EPI1GW6HjcajQCA48ePe6wrEELtb4Lx+pZOpwt6optCn1JRE2+MD8j79Y3pi9L6UuTX5GN44vCAvCcFV11dneuaRd++ff3yHkzUBA4TNUR+pFTDCElytTLrLFdFjQpan9XXdz9Ro9EAcXECFosEi4WJGgodOp0O2dnZ2L9/Py644AIAgNPpxP79+zF16lSP5dPT0/GPf/zD7bG3334bDQ0NuOWWW5CYmBiQuIk6UlPTKlHTg9kXSUny/rwYKaq4qYBIzbqa/PdGp9MhKysLRUVFXp9Xa+I/lJJ9QOjFCwQ+ZiEEqm3yfj9GH+P23sqMGlM7NwKcHq8yt6Gsrszt8djm8yGr1cq/4S5gvNSRtWvX4s0338SVV16JW265JdjhhDVXoiYicImaPaV7cKqGs0R6CyV5Ehsb6zpu+ppS1RqMmyZ6Gw6NIPIjqblHszCZ5IxFF6ipoqYnrc+AlvZnlZXc5VBomT59Or744gts3rwZ+fn5WLlyJRobGzFu3DgAwPLly/Hmm28CAAwGAwYMGOD2X3R0NIxGIwYMGACdjvdGkDpYrfK+OA5V8vGpmxITm/ftSIDd2uCT2IjCVevkv0JJ/reummmP0+nEiRMnEB8fmIs9RG2pt9fDKeRjQKze/aKQkozsbAISAJIi5aqF0vpSt8eVVrJK8oeIeu7o0aP47LPPkJGREexQegUlUROoNmR9Y+SKivya/IC8HwXfqVNyUk6pevEHpRVpaWkpnE7efO1PvGpE5EfKfJqutj0DWipqJBVU1NTVyRf1oqN7lqixWjkokkLL6NGjYbVasWrVKlgsFmRmZmLBggWuiw9lZWUcgEohx62ixtT98niz2QmtxgmHU4OyKgO/VBJ1YPr06Xj22WeRnZ2NnJwcfPTRRx7J/4SEBMyePRsAsHr1agwaNAipqamora3FBx98gNLSUkycODGIW0EEVzWNRtIgUhfp9lxV841qXZnX1yeyuaKmvsztcWUd1Sq4cY0oHDQ0NLhmar733nvBDqdXqGgMbKImPVq+WF9Yy8qH3kKpqPFX2zMASE5OBgDY7XZUVFSwW4gf8ZyayI+URE137lh2Kq3PVHBi0pMZNQAQGyu/TrmLmyiUTJ061WurMwBYuHBhu6+96667/BARUc9UV8v7YhOscMbFdXs9Gg2QmGBHcZkBpTXRSBMCYOKSqE1dTf7X1NTghRdegMViQXR0NLKzs7F48WL069cvSFtAJKtuks9PYvWxHjesKNUvcV04viitzyobK90eVxI1SvKHiHpm5cqVGDVqFM4666wOEzU2mw02m831syRJiIyMdP1bbZSY1Babq6ImMqHTsfVkW9Ji5BZVRbVFqvldqPWz6Q41bouSqElPT+9SXF3ZFoPBgMTERJSVlaG4uFiV87vU+Nl0BxM1RH6ktD7rVkWN0vpMBRU1La3PulfiaDLJr1MGWBMRUfAo++I4VEH0IFEDAH0SnSguA0ocfZDe0AARGdnxi4h6sa4k/2+55RbODiBVqrHJ5ycxBs8ZnEpSpSuJGmXItnJBU6H02mdFDVHPff3118jNzcXjjz/eqeXXrFmD1atXu37OysrC0qVLVXmBtrXU1NRgh+CmXqoHAGQlZ7nmfHRWd7ZluH04AKCkoaTL7+dvavtsekJN21JZKd/kcMYZZ3TrM+/stvTr1w9lZWWw2Wyq+9tqTU2fTXcwUUPkR67WZ924ECZUVFFTX9+ziholUVNVxYoaIqJgc6uo6cGMGgBISgHwI1CCZEhWKxM1RES9gLVJPscxGTyPId2ZUaMM2a5s8F5Rwxk1RD1TVlaGV155BQ899BAMBkOnXjNz5kxMnz7d9bNyl3ppaSnsdrtf4uwJSZKQmpqKoqIiCNG96xb+UFApVztom7SdHsTek23RN+jl960uwKmCU9BIwb8Go9bPpjvUuC1Hjx4FIN/c0Nm/MaDr29Knj1z9evDgQYwaNap7wfqRGj+b1nQ6XacS3UzUEPlRj1qfqbKipruJGrY+IyJSi5rq1jNqepaoSUyUE/HFSIGmuhrO5kGTREQUvmqamitq9G1X1HRlRo0yu+H0ihomaoh849ixY6iqqsKf//xn12NOpxOHDh3Chg0b8Oabb0KjcT9X1+v10Ov1XtenxougCiGEquJztT6LSOhyXN3ZluTIZEiQYHPaUF5fjsRI9cwSUdtn0xNq2pZTp04BkFufdSemzm5LSvN5XnFxsWq23Rs1fTbdwUQNkR9JSkVNd1qfKRU1NTWA0ykPAwiSns+oYeszIiK1qG6+3hWHqm7dSNBa60SNxAtpRES9QrWteUaNIdbjue7MqFFan50+o4atz4h8Y8SIEfjHP/7h9tjzzz+P9PR0XHPNNR5JGvKdisbmRE1zQtrf9Bo9EiMTUVpfisLaQlUlasj3hBBuM2r8KTk5GYCcqCH/YaKGyI80yoyabrQ+UypqAECqrXUlboJBSdRER3cvURMXJ7+Orc+IiIJLCKC6VgsAiIlyALqefRVUEjVlSFRFq04iIvK/tipqhBDdm1HT3Pqs3l6Pens9InWRbutgRQ1Rz0RGRmLAgAFuj0VERCA2NtbjcfIdIYSrpWOgEjUAkBad5krUjEgcEbD3pcCrrKxEQ0MDAPh9bkzrihryH141JfIjqQetzxARAdFcaiwF+eJXXZ28q2BFDRFRaGtokOBwyPvimJ4V0wAA4uNbEjWsqCEi6h2qm7xX1NTX18NmswHo2owak8EErSTfRNB6To1SUdPU1OS6EEVEFCrq7HVodDQCCGyiJjVaHqZeVFsUsPek4FCqaZKSkhAREeHX90pNlf+umKjxL1bUEPmRpgetzyBJcMbEQFtZCU1NDZw+jq2z7HagsVFpfda9KOLi5NdxRg0RUXBZrfL+XIIT0WYd6nu4voQEef9ejj7QVB/q4dqIiCgUtNX6TKmm0Wq1iIqK6vT6JElCvDEeZfVlqGysRHqM3L4lJiYGkiRBCIHq6moYjUYfbQERLVy4MNghhD1lPo1Ra3RVCgZCapR8Qb2wtvOD5Sk0KfNp+vbt6/f3YkVNYPCqKZEfKa3PRDdanwEtc2qCWVGjtD0DelJRI79OuUBIRETBoVQ2mmCFMHfv2NQaK2qIiHofpaLm9NZnrdueSVLXvvcnRMh3m7euqNFoNK6qGmXdREShQknUKHO4AiUtWm6BVVTHippwF6j5NEBLoqakpAQOh8Pv79dbMVFD5EdSTypqAIjmOTWamhqfxdRVSqJGoxHobiWlycSKGiIiNaipkffDJli7fWxqTamo4YwaIqLeo8Ymn5u0VVHTlfk0CuVCpnJhU6Ekaqp5jCGiEKPszwLZ9gxg67PeRKmoCUSiJjExERqNBk6nE+Xl5X5/v96KV02J/KhHrc8AOFVUURMdLdDFG+NcTCa5oqa6mrscIqJgUiob41DVvflpp1Eqaqpghr2qrsfrIyIi9XPNqNH7MFETISdqKhsr3R43NR+rrKzaJKIQE+xEDVufhb9AVtTodDokJiYCYPszf+JVUyI/UhI13W591lxRI6mgoqa7bc+AloqahgYJjY0+CYuIiLrBraKmm8em1uLinJCap6hZyoI1TY2IiAKppkk+N4kxtN36rKuUC5mtW58BTNQQUegKVqImPVq+aM+KmvAXyBk1QEv7s6Ii/m35CxM1RP7S0ACpoQFAzytqgtlOpq5O3k30JFETGysgSayqISIKNrcZNT5I1Oh0QFyknIGvrOT+nYioN6i2NVfU+KP1WSNbnxFReHAlaiICXFETJVfUVNuqXYl1Ck+BrKgBWhI1rKjxH55RE/mJklwRkuSqjOmqcKmo0WiAmBj59VVV3eyfRkREPaYky+NQ5ZMZNQDQJ0ZO1FRUan2yPiIiUje/tj5jRQ0RhYlgVdTEGGIQo5evJRXVsfIhXNntdldlS6Arapio8R8maoj8RGo+UREmk5yp6Aahgoqa2lolUdOzljZK+zOrlbsdIqJgaV1R46tETUJcEwCgstrgk/UREZG61djkm8h8WVGjXMi0NFrcHmeihohClVIhGOhEDQCkRacB4JyacFZcXAyn0wm9Xo+kpKSAvGdqaqrrvck/eMWUyE+U+TRK+7LucKqooiY6uvsVNQBgMrH1GRFRsLWeUSPMZp+sM94sJ+LLayN9sj4iIlIvIYSroka5Y1vhk9ZnDd5bnzFRQ0ShRqkQVPZvgZQaLV9Q55ya8KW0PUtLS4OmmzeHdxUravyPV0yJ/MTV+qwHdyyrq6Kmp4ka+UIeW58REQWPUlHjy9ZnCX3k/XtFHRM1REThrsHRAIdwAPDxjJo2Wp8p62KihohCTbBanwEtc2pYURO+Aj2fBgCSk5MBMFHjT0zUEPmJ1JxcCfWKmvp63yRqYmNZUUNEFGzKPtiXrc/MifI6yxtjANGzYwUREambtUlOmGgkDaJ0UW7P+bOipjqIN64REXVHMBM1SuszzqgJX6dOnQIQ2EQNW5/5H6+YEvmJklwRMTEdLNk2paJGCuKJSV2dvJvwVUWN1cqKGiKiYKmpaZlRI7pxIc2b+BT5OFHhjAcaGnyyTiIiUiel7VmsPhaS5P69Xql6MXXjRgDlQma1rRo2p831OFufEVEoEkK0tD6LYOsz8r1gVNQorc9KS0tht9sD9r69CRM1RH6i8WFFjSaIFTW+a30mv95q5W6HiChYquWbneXWZz5L1OgBAGVIDGqrTiIi8r8am3xeEmPwvBnNYrEAAMzdmIEWZ4iDBPm8w9JgaXmcrc+IKARV26phF/KF7GDMqFEqatj6LHwFo6KmT58+0Gq1EEKgrKwsYO/bm/CKKZGfKFUwogeJGnVU1MgnTNHRzh6thxU1RETBV10lJ81jpRqI6GifrDOhj7zOcvSBxAtpRERhrXVFzel60vpMq9EiLkJ+Xev2Z2x9RkShSNmPRemiEKkL/BxHV+szVtSELaWipm/fvgF7T61Wi6SkJABsf+YvTNQQ+YkvKmqURE0w71BWEjW+a33G3Q4RUbDUVMv79NhoB6Dxzf44Pl7ev7Oihogo/NU0ea+oaWpqQn19PYDutT4DWtoDVTZWuh5jRQ0RhaJgzqcBgNQoufVZaX2pWztJCh/BqKgBOKfG33jFlMhPfDGjxtl8t7NUUxO0Ac1KoiYykq3PiIhCXXWNvA+Oje1ZlWRrCQnyusrRh4kaIqIwZ7U1z6ExuCdjWidSupuoUS5oKnMdAPeKGqfTd8cuIiJ/Cnaipk9kH+g1eggIlNSVBCUG8p+GhgZUVsrHyrS0tIC+d3JyMgCgqIjVWv6gC3YAp9uwYQPWrVsHi8WCjIwMzJ07Fzk5OV6XPXnyJN555x3k5uaitLQUc+bMwbRp09yWWbNmDXbs2IFTp07BYDBg8ODB+OUvf+mWcVy4cCEOHjzo9rpJkybhtttu8/0GUq+haT5Z6VHrs+Ykj+RwyAOaIwNfMtvS+qxniRrlomB1NVufEREFgxBAdZ381S8mznf7YqWiphLxcFQyUUNEFM5cFTV695vRlPk0JpMJWq22W+tW5jhUNLa0PlOSPk6nE7W1ta7EDRGRmgU7UaORNEiJSkF+TT4KawvRNyZw7bHI/0pK5OSb0Wjs1ly4nkhJSQHAihp/UVWiZtu2bXjttdcwf/58DBo0CB9++CGWLFmCZcuWee1z29jYiJSUFFx88cV49dVXva7z4MGDmDJlCgYOHAiHw4G33noLixcvxj//+U8YjUbXchMnTsQNN9zg+tlgMPh+A6lXUSpqetT6rNX8AE1tLZxBSNTU1sp3X/e09VlcnPz6qipW1BARBUNdnQSnaK6oMWvQ4KP1ms1yokZAg6pSO3wz+YaIiNTINaPG4H6O05P5NApX67NWFTVGoxF6vR42mw1Wq5WJGiIKCcFO1ABAanQq8mvyOacmDClJkpSUFEhSYG+GZqLGv1R1xXT9+vWYOHEixo8fj379+mH+/PkwGAzYtGmT1+VzcnLwq1/9Cpdccgn0er3XZR588EGMGzcO/fv3R2ZmJu666y6UlZXh2LFjbstFRETAbDa7/ouKivL59lHvorR/6UlFDTQaOJv/FqUgtZPxdUWN1cqKGiKiYFAqGrWwwxgf4bP16vWAWS/fnGApcfhsvUREpD41Nu8VNUrrs+62PQNatT5rNaNGkiS39mdERKFASTgrlYLBoMypKawtDFoM5B+FhfJnqsyLCSTOqPEv1VTU2O12HDt2DDNmzHA9ptFoMGLECBw+fNhn71NXVwcAiDltbsiWLVuwZcsWmM1mnHvuuZg1axYiItq+iGGz2WCztQzkkiQJkc3VDoHOZnaFEpuaY+yMUNgO14ya2Ng24+zMdojYWKCuTq6oCcL21tfL7xkVJXq0HUpFTXW1RrWfWyj8XXVWOG0LEflGdbV8f44JVghz9+949ibBWAuLLQaVZQAbKxARhS+/VtQorc8aKtweN5lMqKiocJuDQ0SkZq6KmojgVdSkRcuzS4rqWFETblpX1AQaK2r8SzWJGqvVCqfT6dFbz2w2o6CgwCfv4XQ68corr2DIkCEYMGCA6/ExY8YgMTERCQkJOH78ON544w0UFBTgT3/6U5vrWrNmDVavXu36OSsrC0uXLkVSUpJPYvW3YGRd/UHV21FbCwDok5UFdDDcq93tiIsDiouRZDR2uB5/qK+X/zcjI7HDt29vO5R8QXW1BikpadCoqp7Pnar/rroonLaFiHpGqagxwQrRgzuevUmIqsOxaqCiouNliYgodCkVNacnapQZNT3ple+qqGnV+gxoqdJhooaIQoVaWp8BYOuzMFRUJH+mwbjew0SNf6kmURMIL730Ek6ePIlHH33U7fFJkya5/j1gwADEx8fj0UcfRVFRUZt/9DNnzsT06dNdPyt3rZeWlsJut/shet+QJAmpqakoKiqCED1rZRVMobAdKVVV0AAoaWyEo9B7qWlntqOP0QgDgIrjx9HYxnr8qaYmBYAGdXUlKCz03tKmM9shF7OlQQjg55+LEBOjvs8tFP6uOivUtkWn04VMopsoVNXUyBnyOFTB6etETUwjUAxUWry3oiUiovBgbZKTJbF6P86oaXRP1Citz5ioIaJQoYZETUqUfEG9pK4kaDGQfwSzoiY5ORkAUF5eDrvdDp2uV6UW/E41v02TyQSNRuO6E0dhsVh6dFeO4qWXXsLu3buxaNEi9OnTp91lc3JyAKDdRI1er29zLk4oXBQVQoREnB1R7XY4na7WZ86YmA5jbG87RHTzWOaamoBvqxBAba2chIyMdPZoO4xGQKsVcDgkWK09n3njT6r9u+qGcNoWIuoZZUaYCVY4e3AhzZsEUxMAoMLKRA0RUTiraWqeUWPw/YyauAj52FTVWOX2OCtqiCjUVDTKiZpgzqhJipRvhCypZ6Im3CgVNWlB6LqTkJAAjUYDp9OJiooKV+KGfEM1zYd0Oh2ys7Oxf/9+12NOpxP79+/H4MGDu71eIQReeukl7NixAw8//HCn/oDy8vIAAPHxwduhUmiTamshNV8cd542D6mrRPPrNc2Jn0BqaACEkC/s9TSxIklwVdHU1qpm10NE1GvU1LRqfebjRE282QkAqKgx+nS9RESkLtW25hk1fqio6ShRU11d3e11ExEFkpoqakrrSoMWA/mHkqgJRkWNVqt1FUCUlDAJ6GuqqagBgOnTp+PZZ59FdnY2cnJy8NFHH6GxsRHjxo0DACxfvhwJCQmYPXs2AMButyM/P9/174qKCuTl5cFoNLoqYV566SVs3boV9913HyIjI10VO1FRUTAYDCgqKsLWrVtxzjnnICYmBidOnMCrr76KoUOHIiMjI+C/AwoPUvNJhNDr5VKSHlASPVIQTkzq61sSKpGRPa/KiIlxoqpK45qTQEREgVNd7cfWZwlya8yK+kifrpeIiNSlrYoaXyRqzAYzAMDSaIEQwtVePKb5fIiJGiIKBU7hhKXRAqClpWMwJEXJFTVVTVWot9cjUsfv6eFACBHUGTUAkJiYiNLSUpSWMgnoa6pK1IwePRpWqxWrVq2CxWJBZmYmFixY4Gp9VlZW5vqyBgAVFRW47777XD+vW7cO69atw7Bhw7Bw4UIAwKeffgoArp8Vd955J8aNGwedTod9+/a5kkJ9+vTBhRdeiGuvvdav20rhTdOq7RmkniUlXBU1tbU9jqurlLZnRqOAVtvz9cXGyskeJmqIiAJP2ffKFTW+LZOPT5STQOUNPasiJSIidWuroka5IbJHiZoIMwCgydmEBkeD66IiW58RUSipaqyCU8jV5sGsqIkzxCFCG4FGRyPK6svQP7Z/0GIh36murkZ9fT2A4FTUAPKcmkOHDjFR4weqStQAwNSpUzF16lSvz52ebElOTsaqVavaXV9HzycmJmLRokVdipGoI66KmtjYDpbsmJKokYLQ+qyuTr6oFxXl9Mn6lPZpbH1GRBR4SkWNCVY4TUN8um5zkrzuiqaeH/eIiEidhBCobmpO1Bjc9/dKEqUniZpofTS0khYO4YCl0eJK1MQ2n1OxooaIQoHS9ixGHwOD1hC0OCRJQlJkEvJr8lFcV8xETZhQqmnMZjMiI4NTJZWYmAgATNT4Aa+WEvmBRknU9HA+DQA4o6MByHNvAq0lUeObYfSxsXLChxU1RESBV9O8741DFZw+nlETl6wHAFgcTNQQEYWrBkcDHEJudXl6osYXrc8kSXLNqVHaBgGcUUNEoaWiMfjzaRTJUfKcbs6pCR/BnE+jUOa/M1Hje0zUEPmBUlHjixkAwayoUVqfKZUwPdVSUcNEDRFRoFVXyslyufWZbxM1prQIAECFiAdsNp+um4iI1EGpppEgIUoX5facLxI1QEv7s6rGKtdjrKgholBS2VAJQCWJmkj5gnpxfXGQIyFfCfZ8GgBISpLnHzFR43tM1BD5gTKjxhcVNa4ZNUFtfebrihrueoiIAq3aIu+DY7V1EEajT9cdlyonaioR76oqJSKi8NK67Vnr2bFOp9OVROlpokapqGGihohClZKoiY+ID3IkrKgJR8XFctItmBU1TNT4D6+WEvmBq6LGBzNqXK3PgpKokXcRkZG+SdTExMjrqalhRQ0RUaDVWOV9sCmqCZB8ux82J2kBAA2IRENZ4Ft1EhGR/9XY5PORGL37zWhWqxVCyMeYHlfUGMwAAEuTxfWYkqhR5uAQEalZZWNzosaonkRNSV1JkCMhX2FFTXhjoobID3w5o0Y0n5gEs6LGV63PWhI13PUQEQWaUs0YG+ObfXprMTECWtgBANbCBp+vn4iIgs/aJCdKTAb39s5K27PIyEgYDD0bnK20PrM0WFyPcUYNEYWSigZ5Ro0aEjVJkfIF9ZJ6JmrCBStqwhuvlhL5gV9m1NQG/g7lltZnTp+sr6X1GStqiIgCrbpGrnqJMfk+USNJQLxGvoBXVdTk8/UTEVHw1TQ1V9QY3G9G89V8GqBV67Mm763PlModIiK1UhI1CREqmFHD1mdhR6moSUtLC1oMycny31VlZSVsnE/qU0zUEPmB5MMZNcFsfVZb69sZNWx9RkQUPNX1OgBAbM/vIfDKrJdvUqgq5Zd1IqJwVG1rnlGjd2/v7JdETasZNUpFjRACtUG4eY2IqCuUGTUJRvUkaorri4McCfmKkqgJZkWN2WyGVivfBFhWVha0OMIREzVEfqBp7p/sixk1roqaILY+832ihrseIqJAcjqBmka5HU1MvNYv7xFvkC+eVZX6pgqTiIjUJSAVNQZ5HZZGi+sxo9HouiDEOTVEpHZqan2WHCknasrqyuAU/I4e6hwOB0pK5DZ2wZxRo9Fo2P7MT3i1lMgPfFlRo6xD09AA2O09Xl9X1Nf7OlEjfzFgRQ0RUWDV1koQQt73xiTo/PIeZmMdAKCqkm1piIjCUSAqasxGs7zOVhU1kiS5tT8jIlKzykb1VNQkRiYCAOzC7qr0odBVXl4Oh8MBjUaDxMTEoMaivD8TNb7FRA2RH2iaTyCED2bUKK3PgMBX1Sitz6KjfXPRLTZWXo8y0JqIiAJDmQ2mRxMMCVF+eQ9zZCMAoKqSyXgionBU3dScqDG4J2qUKheTD859zAYzAMDSZHF7XFk3K2qISO1cFTURwa+oMWgNroRRSX1JkKOhnlLaniUlJUGn88/Nd52lzKlhosa3eLWUyA+UhIrTBxU1iIiAMMjtajQB7slcVyfvInxVURMdLVfUKAkgIiIKDCVBboIViPPPkJr4GDlRU2n1T2s1IiIKrrYSNRaLBYDcs76nvM2oAcCKGiIKCU7hVFVFDdDS/qykjomaUKckaoLZ9kzBihr/YKKGyA+UGTXCBzNqgJaqmmBV1PgqUdNSUcNEDRFRICn7XROscPqgNY03cbEOAEBVdXDv7iIiIv+osTXPqNH7b0aNOcIMwH1GDdBSUcNEDRGpmbXJ6poFo4YZNQCQHMVETbhQEjUpKSlBjoQVNf7CRA2RH7gqanyUqFHm1AQ6UVNXpyRqfDN0TknU1Ndr4HD4ZJVERNQJNTXyV744VMHpg9Y03pjj5B17ZW2EX9ZPRETB1VZFjS8TNa0raoRouVmMFTVEFAqUtmfR+mhEaNXxnTgpUh76zkRN6CsuLgbAippwxkQNka85ndA0J1R8VVGjJGoC3fqsvt63FTVK6zMAqKlhVQ0RUaBYrS0VNcJPFTXm5psGq+qNflk/EREFV1sVNT6dUdNcUeMQDtTaWs59YprPh5ioISI1q2xobnsWoY62ZwCQEiVXX3BGTehjRU34Y6KGyMdaV734ZEYNABHk1mfR0b5J1EREAAaDvC7l7m4iIvI/ZZ9rgtVvFTVxfeRjRmVDlF/WT0REwWVtak7IGNyPI0pFjS9m1Bi1Rhg08nzO1u3PlCSQkhQiIlIjpaJGLW3PACApihU14UKpqElLSwtyJC0VNSUl/LvyJV4pJfIxqfkuL6HXy5kJH1BaqEkBvoOspfWZbxI1QEtVDStqiIgCR5lRE4cq/82oSdQCACptvrlJgSgcbdiwAXfddRduvvlmLFiwAEePHu3U677++mtcf/31+Pvf/+7nCInaVtPUXFFjcN/PWywWAL5pfSZJUsucmiaL63G2PiOiUFDRKCdqEozqq6gprWflQ6hTY0VNWVlZkCMJL0zUEPmYpvV8Gsk3yQiloibQrc/8kahR5tQoFw2JiMj/appvQPZn67O4ZB0AoNLun4odolC3bds2vPbaa7juuuuwdOlSZGRkYMmSJa5qhLaUlJTg9ddfx9ChQwMUKZF31bbmGTV67zNqfNH6DHCfU6NQ1s1EDRGpmav1mYoSNcqMmuK64iBHQj2lJGrUNKOmqqoKDQ0NQY4mfDBRQ+RjrooaH82nAVpaqAW69VldnbyL8FXrMwCIiWHrMyKiQKsutwPwc+uzVLmKtNIZB6ezg4WJeqH169dj4sSJGD9+PPr164f58+fDYDBg06ZNbb7G6XTimWeewfXXX++6c5EoGIQQXitqhBCudmS+qKgBvCdqWFFDRKFASdTER6in9VlyVPMskTpW1ISyhoYGVFbKf19qqKgxm83Q6/UAgPLy8iBHEz50wQ6AKNxolESNj+bTAK1m1ASwosZuBxob5aqXyEjfXXGLiWHrMyKiQKupdAAATLo6wGDwy3vEphkBAE5oUVMNmPxTuEMUkux2O44dO4YZM2a4HtNoNBgxYgQOHz7c5utWr14Nk8mECRMm4NChQ+2+h81mg81mc/0sSRIiIyNd/w405T2D8d7dEWrxAoGNucHRALtoTvobTK73rKurg90uPx4fH99uLJ2Nt3XrM2XZ1omaQH1GofY3wXiJgq+ysTlRo6IZNUqiptpWjXp7PSJ1kUGOiLpDmQVjNBp9MhOupyRJQlJSEgoKClBSUoK+ffsGO6SwwEQNkY8pFTVOH1bUKEkfTQArapS2Z4C/Kmr4hZyIKFBqquQkeWykrYMlu8+YHAsj6tGASFiLGmGK882cNqJwYLVa4XQ6PU6szWYzCgoKvL7mxx9/xMaNGzs9l2bNmjVYvXq16+esrCwsXboUSUlJ3Y7bF9TQnqMrQi1eIDAxF9fILXMkSMgZkOO6uH7y5EkAgF6vR3Z2dqcuuncUb5o5DTgBCINwDUzOzMwEANTX1wd8iHKo/U0wXqLgqWiQZ9SoKVETq4+FUWtEg6MBJXUlyDBlBDsk6obW82nUkuBWEjWlpazW8hUmaoh8TEmm+LL1mZKokQJY6q8karRa4dObr2Nj5YuF1dVsfUZEFCjVzd1jYqIdfnsPERmJeFSiEJGoKmxAvyFM1BB1V319PZ555hncfvvtnZ77MXPmTEyfPt31s3ISX1pa6qp4CCRJkpCamoqioiII4bubfvwl1OIFAhvzz5afAQCxhljXxSIAOHLkCAB5hkzrx73pbLwGp3zycbLsJAoLCwHAVS1WUVHheszfQu1vgvH6lk6nC3qim0KPkqhJiFDPjBpJkpAclYwT1SdQUs9ETahS03wahbKPZKLGd5ioIfIxqblHsy8ralwzagLY+kxJ1ERFCfgyWc+KGiKiwFOS46YY/yVqIElI0FSh0JmOqqIm/70PUQgymUzQaDSwWCxuj1ssFq/tK4qLi1FaWoqlS5e6HlMuZN54441YtmyZx4m6Xq939Qo/XTAvggohVHkRti2hFi8QmJirm+QbxmL0MW7vpfxNx8XFdTqGjuI1G8wA5FkPynKtW58F+vMJtb8JxksUPMqMmgSjehI1AFoSNXUlwQ6Fuql1RY1aMFHje0zUEPmYq6LGlzNqgtj6zJdtz4DWiRpW1BARBUp1nRYAENu5G/O7zayrBpoAa4n/WqwRhSKdTofs7Gzs378fF1xwAQDA6XRi//79mDp1qsfy6enp+Mc//uH22Ntvv42GhgbccsstSExMDEjcRAolURNrcL8ZrapKLtmMi/PdYLK4CHldVU1VrsdOT9Sope0LEVFrFY3qa30GAMmR8pya0jpeUA9VxcVyC1JW1IQ3JmqIfMw1o6aTbSo6IzgVNXIiJTLSt4kapfUZK2qIiAKnuk6+yz46zr/73nhDDdAEWMqcfn0folA0ffp0PPvss8jOzkZOTg4++ugjNDY2Yty4cQCA5cuXIyEhAbNnz4bBYMCAAQPcXh8dHQ0AHo8TBUKNTb5hLEbvfjOaUlHjy8HGrkRNo2eixmazoaGhAZGRHIZNROoihFB1RQ0AFNcVBzkS6i5W1PQOTNQQ+Zjkj4qa5hNzKYAVNbW1La3PfEmp0GGihogocKob5H7/pnj/VjOajfVADVBVwUQN0elGjx4Nq9WKVatWwWKxIDMzEwsWLHBd4C4rK2OVAKlWWxU11ua2z52dpdQZcQY5UWNptLgei4mJgSRJEEKgurqaiRoiUh1rkxUOIbcZjo9QV0VNUmTzBfV6XlAPVUpFTVpaWpAjacFEje8xUUPkYxo/zKgJbusz315si42VEzXKvAQiIvIvhwOosRkBADEJ/v3qFx9ZDwCwVHIfT+TN1KlTvbY6A4CFCxe2+9q77rrLDxERdU4gW5+ZjWZ53a0qajQaDWJiYlBdXQ2r1Yrk5GSfvR8RkS9UNMhtz6J0UTDqjEGOxh0rakJfYWEhAFbUhDueRRP5mD8qalytz4KQqPF9RY2c+FEqdoiIyL9aVzBGJ0X49b3MMfJsmiorv2ISEYWTaltzokYfgESNwSyvu9WMGqCl/VlNAM+JiIg6q7JRnW3PACAxUp5tV1ZfFuRIqDuEEJxR00vwLJrIxzR+mFEjWs+oEb5NnLTFX63PWFFDRBRYNTXy/jYCDTD08d1NBN6YY+VEjcWq9+v7EBFRYNU0Nc+oMXifUePLRI0pQj6PsjZZ4RQt1f1KezWl3RoRkZooFTXxRnW1PQNaKmrY+iw0Wa1W1NfLnQvUWFFTU1Pjio96hq3PiHxMak7U+HRGjZKocToh1ddDREX5bN1tqa/3T6ImJkY+2eKMGgoVGzZswLp162CxWJCRkYG5c+fi/7N35+Fx1Hee+N/Vl1rdre5W65Zl67Bsg42xgXCZY0yc38YBbxYyJENg8mSXwCYZNsnM7obJwi8ZZjbMsw5JNtmF2U2GZDPsEwgeMjBj4MdkAoYA5gqHDww2tnxIllp3d0t9H/X7o/pbrbZatqQ+qqr7/XoeHqxWq+tTdqu+XfWpz+fT399f8LlvvPEGnnzySfj9fqTTabS3t+Nf/+t/jWuvvbbCURPlzMwox1s3QiW9iaAQj0c5xgcitrJuh4iIKmuhihqRNCllokbMqMnIGcwmZ+G2KWuXK3tONJM93yIi0pPpWLaipk5/FTViRs1kdBKyLHMmnsGIahqv16urGW0NDQ2w2+2IxWIYHx/HqlWrtA7J8JioISoxMUdGLuWMGocDsiRBkmVIs7MVSdREIsod2KVP1Civx0QNGcHevXvxyCOP4M4778SaNWvwzDPP4P7778ePfvSjghckXC4XPvOZz6CzsxMWiwXvvPMO/uZv/gZutxubN2+u/A4QIVfBWIlEjderHOMDEX315SYiouIsVFFTjtZndosddrMdsXQMoXhITdSIihomaohIj/RcUdNkbwIAJDIJBBNBeOu82gZES+L3+wHoq5oGACRJQnNzM4aGhpioKRH2HiIqMVFRkylhRQ0kCbLTqfyxQj2ZReszp7M8rc9EKx4iPXv66aexbds2XHfddejq6sKdd94Jm82GPXv2FHz+hg0bcNlll6Grqwvt7e24/vrr0d3djQ8//LDCkRPliIoaD4KQvd6ybsvTpGxrOl7+GwqIiKhyQgmlckYkTYRyJGrmbieQCKiPiRk1bH1GRHo0FVcSNXqcUWO32NXjKufUGI9I1OhpPo3AOTWlVdSV0r/+67/GK6+8gkQiUap4iIwtnYYpHAYAyCW+a1m0PxOvX26RiGh9ljnHM5dGtD6LxyXw0EGlVOo1KZVKYWBgABs3blQfM5lM2LhxI44cOXLOn5dlGQcOHMDw8DDWr1+/4POSySQikYj639zerpIkaf6fXuKolji1iFUkxt0IQfZ4yhqrp1kp1g4mHFX/91oLsRolzrmxlgrPc4jyzSazFTXW/JvRytH6DAA8dcrrBeNB9TGRqGFFDVU7rkHGpLY+02GiBgCa65sBcE6NEem1ogZgoqbUimp9Njo6iv/5P/8n7HY7Lr30Ulx77bXYuHFjSU+SiIxkbrVLSStqsq9nRq5ip9xERU25Wp8BSvszn6+0r0+1q9RrUigUQiaTgfeMCgSv14vh4eEFfy4SieDLX/4yUqkUTCYTvvSlL+HCCy9c8PlPPvkknnjiCfXr3t5e7Ny5U/3Aowd6vHOnEKPECVQ2VlMmBUBJ1LSu3QT4lnbyuJRYzWuV920w3YDW1gaYzUvaVNH4Hig9o8QJlDZWnucQ5ZtJZGfU2PLbOwcCAQDlq6gJxXPVM2x9RrWCa5AxiURNY53+Wp8BypyageAAxiO8oG40YkYNEzXVr6hEzY9//GMcPXoUL7/8Ml577TW8/PLL8Hq9uPrqq3HNNdegp6enRGESGYM6n8ZmA+rqSvraoqKmUq3PotHyJGosFsBuzyAWM2F21gSfL13S16fapZc1yW6344EHHkAsFsOBAwfwyCOPoK2tDRs2bCj4/Jtuugk7duxQvxYnYOPj40ilUhWJeSGSJKG9vR1+vx+yrN+kqlHiBLSJ9fQAAHTAgyBGIhEgHl/Uzy0nVqkuov758GE/Ghsrs498D5SeUeIE8mM1m80lSXTrZU0h0otCFTXxeByxWAxAGStqEqyoodrDNciYpuPZRI0OZ9QArKgxMpGo0eMNVK2trQCAsbExjSOpDkUlagCgv78f/f39+OIXv4j9+/fj5Zdfxm9/+1s8/fTT6OrqwrXXXourr74aTU1NpYiXSNfKMp8mS8yoqXzrs9JfnGlokBGLKRU1RKVUyjXJ7XbDZDKpd4oKgUBgXpXNXCaTSf0A1dPTg9OnT+Opp55aMFFjtVphtVoLfk8vF0dlWdZNLGdjlDiBysY6M6Ek/BqsMcgmE7DE7S4lVrPXCSdmEYYLgYAEr7e07TPPhe+B0jNKnEDpj5k8zyHKKVRRI+bTSJKkJlFKxWNbuPUZZ9RQLSjlGvSb3/wGv/nNb9Q73ru6unDzzTfjoosuKvdu1JSpmDKjRq+Jmpb6bOUDEzWGo+cZNc3NSgJwYoKzj0qh6ESNYDKZsHnzZmzevBnhcBg//elP8frrr+PRRx/FY489hg0bNuCGG27AxRdfXKpNEumOKZuoKfV8GiCX/KlURU04rMw0cDpLf3HG6ZQxPg51bgJRqZViTbJYLOjr68PBgwdx2WWXAQAymQwOHjyI7du3LzqWTCaDZDJZ9D4RLdfslFK52FC3uEqaYshuN7wIIAwXQiETAFZNkvHxPIdqnSzLBRM1ImEibm4pJVbUEClKsQb5fD7ceuut6OjogCzLeOmll/C9730P3/ve97By5coK7k11E4kavc+omYjygrrRsKKmdpQsUQMAH374IX73u9/hjTfewOzsLFauXIlrr70WFosFe/bswc6dO/GZz3wGf/RHf1TKzRLpRiUqaqSqqKhR7rCemWFFDZVPKdakHTt24KGHHkJfXx/6+/vx7LPPIh6PY+vWrQCABx98UD3xAZR5M6tXr0ZbWxuSySTeffddvPzyy7jjjjsqsctEBc0GleO4u778A2kzLhcaMY3T6EJgsrLVNETlxPMcqmWxdAwpWVRn5hI15ZpPA+QSNZxRQ1T8GvSxj30s7+vPf/7z+M1vfoOPPvqIiZoSkWVZnVHjq9NnooYVNcaUyWTUJIieZ9SwoqY0ik7UDA0N4Xe/+x1effVVTExMwOPx4A/+4A9w7bXX5vXNvP766/GTn/wE//zP/8wTGKpaIlEjl7j0f+5rmipUUZNL1JT+QpvLpVw0ZOszKrVSr0lbtmxBKBTCrl27EAgE0NPTg3vuuUdtfTYxMZE31DMej+Phhx/G5OQkbDYbVqxYga997WvYsmVLuXaZ6Jxmste4GlzlT5zIDQ1oxEkAQMgfR4nvCSKqKJ7nEClmE8r5hwQJDqtDfVy0PitHosZtU5IyrKihWlWuNSiTyeC1115DPB7H2rVrF3xeMpnM6wogSRLq6+vVP+uNiEmr2GaSM2pC21fvKyqOcu1Lq0OpfJiITlT070nrf5tS0mJfpqamkEqlIEkSWltbS7btUu3L3IoaLf+Nq+V9VtTZ8ze/+U2cOnUKVqsVH/vYx3DHHXdg06ZNC5Y9b9iwAS+88EIxmyTSNZFEyZQhUaO2PqvQiUk5K2pyiRq2PqPSKdeatH379gVbnd133315X99yyy245ZZblhw7UTnNZI+1rgokamC1wmMKARkxG4eJGjImnucQ5cwklfMPl9UFk5T7HZjb+qzUvHVeAEAgHlAfY6KGakU51qBTp07h3nvvRTKZhN1ux3/+z/8ZXV1dCz7/ySefxBNPPKF+3dvbi507d6p3z+uVVq2hotNRAIDD6kDfyr6SvGap9+X89PkAgKnEFDo6Okr62ouhx7Zdy1XJfRHzadra2spSAVfsvoi1ORqNoqGhAa4ydBhaCqO/z4o6e3Y6nfjyl7+MK664Ag6H45zPv/TSS/Hggw8Ws0kiXVMratj67KzY+ozKgWsSUWEzYeXjnttdmYHwjbYwEAOC46mKbI+oHLimEOWIihqXLf8cpxIVNaFErvWZuBgkEkRE1aoca1BnZyceeOABRCIRvP7663jooYfwl3/5lwsma2666Sbs2LFD/VrcpT4+Po5USn+f8SRJQnt7O/x+P2S5Mp955/pw7EMAgNfmxcjISFGvVa59kbLXeEZnRzE8PFyxygOt/21KSYt9OXjwIAClxVix7625SrkvDocDkUgE+/fvR29vb4kiXBq9v88sFsuiEt1FJWr+w3/4D3C73bDZbAW/n0gkEAqF0NysDKyqq6vTffadqBimcrY+yyZ/KtH6TJaBcFhZtJ3O0h/gxGuGw6yoodLhmkRU2EzUCgBweipzMuatiyiJmin9fUAmWiyuKUQ5IlkikieCmFEjWsKWkphRE4zPb30Wi8WQTCZhtVpLvl0iPSjHGmSxWNQ7zfv6+nDs2DE8++yz+Pf//t8XfL7Val3wd0yPF0EFWZY1iW8yOgkA8Nl9Jdt+qfelyd4EAIin4wglQvOO6eWm1b9NOVRyX+ZW1JRjm6XYl5aWFpw8eRLj4+N5rRm1YPT3WVFXSe+66y68+eabC37/97//Pe66664lveZzzz2Hu+66C7fddhvuueceHD16dMHnDg4O4vvf/z7uuusufO5zn8MzzzyzrNdMJBJ4+OGHcfvtt+MLX/gCvv/976sfOomWQlTUlLX1WQUqamIxQJZZUUPGUo41iagahOJ1AABXU2UuaHnrYwCA4HRFNkdUFlxTiHJmk9mKGmvlKmo8NuU1C1XUAGx/RtWtEmtQJpPJm0FDxZmOKx98fXafxpEsrN5Srx7HxyPjGkdDizU6OgpA3y29RKJ4bGxM40iMr6y3s6dSqQV7aBayd+9ePPLII7j55puxc+dOdHd34/7771c/AJ4pHo+jra0Nt95664J38SzmNf/u7/4Ob7/9Nv7jf/yP+Mu//EtMT0/jBz/4wZL2lQiYU1FTztZnFaioiUZzv7f19eWrqJmdZaKGKmepaxJRtZhJ2AEADU2VmRfjcSgn/aEQj/FUvbimUC2ZSSjnOA22/JvRyjmjplBFjdVqVYeZM1FDtWypa9Cjjz6KQ4cOYWxsDKdOnVK/vuaaa8oYZW2Zik0BABrtjRpHcnbN9UoV1kR0QuNIaLFERY0REjXj40wAFmvJZ+yRSASRSET9emZmBhMT83/Bw+Ew9u7du6Qy6Keffhrbtm3DddddBwC488478c4772DPnj248cYb5z2/v78f/f39AJSFZzmvGYlE8MILL+Ab3/gGLrjgAgDAn/zJn+DP/uzPcOTIEaxdu3bR8ROJJEo5KmpEO7VKtD4Tbc/s9gzM5tK/vsslEjW8wEHFKeeaRFQNUikgklYSNa7mwu0zSs3jUhI1wVBlEkNEpcI1hagwLSpqREueWDqGWCoGu0VZy9xuN6LRKBM1VHXKuQYFg0E89NBDmJ6ehsPhQHd3N+69915ceOGFpQidkEvU+Or0W1EDAC31LTgROoGxKCsfjGJu6zO9YqKmdJZ8Bv3MM8/giSeeUL/+xS9+gV/84hcLPv+P/uiPFvW6qVQKAwMDeQkZk8mEjRs34siRI0sNc9GvOTAwgHQ6jY0bN6rPWbFiBZqbm8+aqEkmk3llopIkqXf3VGog13KI2PQc42LodT9MYrCl272o2JayH6JKR5qdLft+i4oah0Mu+X4AQEODmFEj6erfUK/vq+Wopn05m3KtSUTVYm6LSVerHekKbNPrVrYSCHN2ABkL1xSiwhaqqCnnjJoGWwMkSJAhI5QIqYkal8uF0dFRtZqHqFqUcw366le/WkxotAjTMaX1md4ralrqlQvqrKgxDtH6TM+JmtbWVgBM1JTCkhM1mzZtgt1uhyzL+OUvf4mrrroKvb29ec+RJAl1dXXo6+vD6tWrF/W6oVAImUxm3oc8r9eL4eHhpYa56NcMBAKwWCxwZttKCR6P56xzap588sm8RbS3txc7d+40zBBRPZfMLYXu9iMeBwB4u7vh7ehY9I8taj+yv2eWSAQdS3jt5RgcVP7vdpuXtK3F/nusXKn8P5Gwl31flkN376siVNO+FFKuNYmoWojKxXpEYG5yVyRR4/YqyfhApA5AqgJbJCoNrilEhYmKmjMTNaKiphytz0ySCZ46DwLxAEKJEFodrXnbYkUNVRuuQcY2Fc9W1Oh4Rg2Qa302HuUFdaMwQqKGFTWls+REzdq1a9Uqk3g8jssvvxyrVq0qeWB6d9NNN2HHjh3q1+Ku9fHxcaRS+r0oIUkS2tvb4ff7Iculnz1SKXrdj5bJSVgATCaTSIyMnPP5S9kPczSKVgDyzAz8i3jtYpw8aQPQhLq6JEZGzn2nxVL/PZJJ5fWnphb3+pWi1/fVchhtXywWy7IS3VyTiM5OVNS4EUKmDBfSCvE0KtsMxuwAyt+uk6hUuKYQFRZKKNUrDdbCM2rK0foMUNqfBeIBBOIB9bGGbDtoVtRQteEaZGyiokbviRqR9GZFjTEkk0m1BaKeb8JloqZ0imoe/tnPfrZUccDtdsNkMs2rYgkEAssupV7Ma3q9XqRSKYTD4byqmmAweNbtWq1WWK2FW3oY4aKoLMuGiPNc9LYfYkZN2uVaUlyL2Y+0w6FsIx6HnEgAC7z/SiEcVv7vcCzt73ex/x4ORya7HUlX/36C3t5XxaimfTmXUq5JRNVidk6iRi7ThbQzuZuUKp5AwglZnkWVd2CkKsU1hShnNpGdUWOr3IwaAPDUeYAZIBgPqo+JRM1sBeZ2EmmFa5DxqK3P6vTd+owVNcYyPj4OWZZhtVrh8+k3CSgSNWNjnH1UrCUlakSrr8985jMwmUx5rb/O5uabbz53IBYL+vr6cPDgQVx22WUAgEwmg4MHD2L79u1LCXNJr9nX1wez2YwDBw7giiuuAAAMDw9jYmJiwfk0RAuRsnd2yQ0N53jm0okZNYCSEJIby/cBIBLJzagpB5dLed3ZWV69o+Ur55pEVC1Ck0qVrwdBZCqUqPG0KB8v07IZ4bCkHvOJ9IxrCtHCZpLZGTVzKmrS6bTafqwcM2oApaIGyFX0ALnWZ6yooWrCNcj4pmLGaH0mZtQwUWMMfr8fgDIDxmQyaRzNwubOqJHlxc26psKWlKj5+7//ewDAjTfeCJPJpH59LotdPHbs2IGHHnoIfX196O/vx7PPPot4PI6tW7cCAB588EH4fD7ceuutAIBUKoWhoSH1z1NTUzhx4gTsdrtaEnau13Q4HPj4xz+ORx55BC6XCw6HAz//+c/zyk6JFiWZhCkWAwBkypCogdUK2W6HFIvBFA4jXdZEjXJQLXeiJhzW70JD+lfuNYmoGoTHldlpboQgOzsrss06Xz2sSCAJG4JBJmrIGLimEC2sUEXN3ERJOWbUANmKGuRX1LiyN69xRg1VE65BxibLMqbj2YoauzEqaiYibH1mBEaYTwMAzc3K+yqRSJyzQxWd3ZISNY8//vhZvy7Wli1bEAqFsGvXLgQCAfT09OCee+5R/4EnJibysnJTU1O4++671a93796N3bt3Y/369bjvvvsW9ZoA8MUvfhGSJOEHP/gBUqkUNm3ahDvuuKOk+0bVT5pTfl+OihoAyDidMMdikMp8YiISNU5npiyvL143FpOQTJa1ixtVsXKvSUTVQCRqGqxRVKwHmceNRkxjDG0IBk1YsaI8awlRKXFNIVqYqKgRFS5Aru2Zw+FYsCV4sTy2bKImkUvUsKKGqhHXIGObTc4imUkCMFZFDSsf9E8kavQ8nwYA7HY7PB4PgsEgxsfHmagpQlEzasph+/btC7Y6E8kXobW1Fbt27SrqNQHAZrPhjjvuYHKGimLKJk8ydnvZMg+yywVMTuYlhcohHK5MRQ2gtD9rbOTd1kRE5SBan7ltsYptM+Ny5SVqiIjI2GYSynmOy5qrqCn3fBqgcEWNmFHDihoi0gsxn8ZutqPeUq9xNGcnEjWxdAzhZHje7DHSF9H6TO8VNYAyp0YkatasWaN1OIZV8kRNPB7Hq6++ilQqhYsuukgdKERU7USVS7mqaQBAdjoBAKZwuGzbAHIVNfX15Umg2GyAzSYjkZAQDpvQ2Jguy3aIuCZRrQsHlGqWBnuiYtuU3UpFDQAmaqiqcE2hWiUSNQ223HmOSNSU865ZUVFTaEYNEzVUa7gG6ddUXJlPo/e2ZwDgsDrgsDgQSUUwFh1jokbnjNL6DFASNUePHsX4OOcfFaOoRM3/+l//C0ePHsUPfvADAMqcmHvvvReDg4MAlDLo73znO+jt7S0+UiKdM1UgUZPJ9mQud0VNrvVZ+SpdXK4MpqbMmJ1lqS2VBtckovlmg8pxvMGRrNg2Mw0N8EI5qQgGeYwnY+KaQqSQZRmzyeyMmgIVNeWaTwMA7jrltVlRQ7WGa5CxTMWURI3e254JLfUtODlzEhPRCfR5+rQOh87CKK3PAKjJ47GxMY0jMbaibnN8//33cdlll6lfv/LKKxgcHMTXvvY1/OAHP4DX6130EDQioxMVNZlyVtSIRE2FKmrK1foMyLU/Y6KGSoVrEtF8ooW/25mq2Dblhga1oiY0UbntEpUS1xQiRTwdV2cvFKqoKWfrM6/NCwAIxAPqY0zUUC3gGmQsovVZY53+K2oAoLleGfw+HmXlg94ZrfUZAFbUFKmoRE0gEMgrt3zzzTfR19eHq6++Gl1dXdi2bRuOHj1adJBERlCJihqRqDGVvaJGOTSUs6JGvHY4zLY4VBpck4jmm51VjrGuhsrNApMdDngRAAAEx5ioIWPimkKkENU0EiQ4rU718UokakRFzdzWZyJREwqFCv4MUTXgGmQsRquoaXW0AmCixgiMVFHT2qq8r1hRU5yirpDW1dUhEokAANLpNA4dOoRNmzap37fb7er3iapdJSpq1NZnZb6DLBwWFTWZsm3D5VJemxU1VCpck4jmm4koXW4b3BU81koSvHXK71pwsnzrCFE5cU0hUogkicvqgknKXT4QiZJytj4TM2rY+oxqDdcgY5mOKxU1RknUiIqaieiExpHQ2USjUQQCAQCsqKklRc2o6evrw/PPP48NGzbg97//PaLRKD72sY+p3x8dHS3rHTZEelKRihqnchdbpVqf1dez9RkZB9ckovlCURsAoMFb2WOt1x4D4kBoWgbA4zwZD9cUIsVsQqmocdqceY+Li0der7ds2/bUKb9jcytqRGJodnYW6XQaZrO5bNsn0grXIGOZjE4CABrtxmh91lKfvaAe4QV1PROVKXa7vaw3RZQKK2pKo6iKmltuuQXBYBDf+ta38MQTT+Dyyy9Hf3+/+v0333wT69atKzpIIiOo5Iya8rc+Uy6qiWRKObD1GZUa1ySi+WZidQAAp6+oe3OWzOuIAQCCQSZpyJi4phApRJLEbc2/SFSJ1meioiaUCCEjKxWaDXPOtcJlvnmNSCtcg4xFtD5rtjdrHMnisKLGGOa2PZMk/Z9TiYqaiQm+r4pR1Fn76tWr8aMf/QiHDx+G0+nE+vXr1e+Fw2F88pOfzHuMqJpVoqJGbX1W5kSNqHIp54wa0fpsZkb/Cw4ZA9ckovlmknYAQEOzraLb9TiVwdPBkBkA25+R8XBNIVLMJJRzHDEvRqjkjBoZMmYSM/DUeWC322Gz2ZBIJDAzM2OIu4yJloprkLGIhEdTfZPGkSyOWlHDGTW65vf7ARhjPg2Qq6iZmJhgxWsRir690u1249JLL533uNPpxPXXX1/syxMZRiUrasrd+kxUuYhkSjnkKmqYqKHS4ZpElC+YUlrVuFoqnKhpSAMAQrMWAImKbpuoVLimEM2pqLHlJ0QqMaOmzlwHu9mOWDqGYDyotkJzuVyYmppCKBTCihUryrZ9Ii1xDTKOiZiSqBGVKnonEjWsqNE3kagxwnwaAPD5fJAkCZlMBlNTU2qFDS1NSfpgRKNRjI+PIxwOQ5bn34HPTD/VgorMqBGtz8o8PFO0PnM4KjGjhq3PqLS4JhEpEgkgJisVNc5We0W37fYoif5AuA5M1JCRcU2hWicSNQ22/HOcSsyoAQBvnRf+iB/BRFB9zO12Y2pqCjNlPici0hrXIGMQrc+a7MaoqBEJpbEoZ4nomWh9ZpREjcViQVNTEyYmJjA2NsZEzTIVlaiZmZnBz372M7zxxhvIZBa+8/7xxx8vZjNEhiDakYn2ZOWQcSp3RpezokaWK9P6rKFBOWaIbREVi2sSUb6ZmVwi3NXuQPmO6PN5s7NUA1E7AF5II+PhmkKkUFuf2Srf+kxs1x/xIxjPJWrEnBpR1UNUbbgGGUcyk0QgHgBgvIqaaCqKcDIMp9WpcURUiNESNYAyp2ZiYgLj42yrt1xFJWp+8pOf4O2338anPvUpnHfeeXCV8QI1kd6ZsicKchnL/+UKzKiJxYBMpvyJGrY+o1LjmkSUL5S9ptWAECSfp6KJGneTkiSKpa2IxQB7ZQt6iIrGNYVIISpZ5iZqZFlWkyTlTtSIdmdzK2pEoma2zHM7ibTCNcg4RDWNSTLBW+fVNphFclqdalvJ8eg4EzU6ZbQZNYAyp+aDDz7A2BirtZarqETNvn37cMMNN+CP//iPSxUPkWFVoqJGbX1WxoqaSCR3BzZbn5GRcE0iyjczGgcAeBBEpsLDll0+KyRkIMOEUMgEu718M8+IyoFrCpFCVNTMbX0WDoeRTiuzyCpRUQMAoXiuekbMxWFFDVUrrkHGIea8+Ow+mCRjXNuQJAkt9S0YnB3EeHQcPe4erUOiAoxaUQOAFTVFKOooUldXx55zRFlSBSpqMhWoqBGtyByODExl/JzhcikX7VhRQ6XCNYko36w/CgDwSsHKl7R4GuBFAAAQDBrjpJVoLq4pRIpCiRrR9sxms8Fe5vWlUEWNqC7gjBqqVlyDjGMyOgkAaLYbo+2Z0OJQ3l8TkQmNI6GFiESN0SpqALCipghFnTlfc801ePPNN0sVC5FxyTJMFayokcJh4Cy9aoshEiflbHs29/U5o4ZKhWsSUb7QWAIA4DaHAamyx1q5oQGNmAYABAI8zpPxcE0hUogEiceWq5wJBALKYx4PpDKvL6KV0NwZNayooWrHNcg4JmNKosZn92kcydKIOTXjUVY+6NHMzAzC2U46RqyomZhgAnC5imp9dsUVV+DQoUO4//778YlPfAJNTU0wFbgFv6+vr5jNEOlfLAYpmQSgXJwqFzVRI8uQIhH161KqVKKGrc+o1LgmEeWbGVcSNV5b+dplLiTTwIoaMjauKUSKs1XUuCvQVlO0PptbUSO2y4oaqlZcg4xDtD5rrjdWRY2IV8RP+iKqadxuNxwOh8bRLJ5I1LCiZvmKStR85zvfUf+8f//+BZ/3+OOPF7MZIt0zzWlFVo7kifradjtkkwlSJgNpdrZMiRrlA2D5K2qUiiBW1FCpcE0iyjczqcwPcNfFKr7tuRU1oRATNWQ8XFOIFKGEUrUiEiZALlHj9XrLvn219VmBihoRB1G14RpkHBMxYyZqWFGjb36/H4CxqmkAzqgphaISNV/96ldLFQeRoYn5NBmXC2Ud7CJJkF0uSKFQ2ebU5Cpqyjv4WVTUhMMSZLniXXmoCnFNIsoXCijHWbcjWfFtZ+YkaoJBHuDJeLimECkKJWpE67OKJGqyLddEHHO3y9ZnVK24BhnHVHQKgHFbn7GiRp9ERY3REjViRg0TNctXVKJm69atJQqDyNhERU05254JstMJhEIwhcNIl+H1K936LJOREI1KcDjKuz2qflyTiPKFAsr/3c5UxbetVNScAAAEAqyoIePhmkIEyLJ81tZnHo+n4M+VkqioCcQD6mOsqKFqxzXIOIxaUSPiHYuyRZUeGTVRIypqAoEA4vE46urqNI7IeEp25jw9PY0TJ04gFqt8ew0irakVNRVI1IhtlL+ipryJE4dDhiSJOTW825pKi2sSETAzo3zMczeUt0KykLkzakTCiMiouKZQrYqlY0hmlKrMuRU109NKxWRjY2PZYxDbnVtRw0QN1RKuQfo2GZ0EADTbjZWoYUWNvonWZx0dHRpHsjRerxdWqxUAMDHB99ZyFJ2oeeutt/Cnf/qn+MpXvoI///M/x9GjRwEoZch333033nzzzaKDJNK7ilfUAJDC5RkOXakZNSZTbhtM1FCpcE0iygmFzQAAt6fyFYtzZ9QEJ8pR/0lUflxTqNaJ5IhJMsFpdaqPa1FRM3dGjdguW59RNeMaZAyTMSVR01TfpHEkSyMqajijRp+MOqNGkiS1qmZsjNVay1FUoub3v/89vv/976OhoQGf/exn877ndrvh8/nw4osvFrMJIkOoZEWN7HIBAEwzM2V5/UrNqAHmzqlhWxwqHtckonyhiA0A0ODVIBlutcJjUW5iCE2ztSUZT7nWlOeeew533XUXbrvtNtxzzz3qhbdC3njjDXzrW9/Cv/23/xZf+MIX8M1vfhO/+93vlrxNouVS255ZG2CScp/XKzmjxlunbGNuRQ0TNVTteF5jHKIipclurERNi0O5mB5OhhFNRTWOhs5k1NZnAOfUFKuoq6O//vWvsX79evzX//pf8clPfnLe99euXYvjx48XswkiQ6hkRU0mm6gpd+uzSsyMEckgVtRQKXBNIsoXitkBAA1NZk2231ivtOgITmuyeaKilGNN2bt3Lx555BHcfPPN2LlzJ7q7u3H//fcv2L7J5XLhM5/5DL773e/igQcewHXXXYe/+Zu/wXvvvbecXSJaMpEcmTufBqhsoka0Poun4+rFRJGoicVibAdFVYnnNcYQS8Uwm1SuyxhtRk2DtQF2s3KuMB7hBXW9MXKiprk5W63FRM2yFJWoOXXqFK688soFv+/xeHiXC9WEilbUZFufmcrW+kxJmohql3IS22CihkqBaxJRvkCiHgDgbrZqsn2PU5lrEAyxapKMpxxrytNPP41t27bhuuuuQ1dXF+68807YbDbs2bOn4PM3bNiAyy67DF1dXWhvb8f111+P7u5ufPjhh0vaLtFyheKFEzWVbH3msrrUah7R/szlckGSlPMHfrajasTzGmMQbc+sJmveHC8jkCSJ7c90SpZlNVHT3t6ucTRLJypq2PpseSzF/HBdXd1Z72AZHR2FK3v3P1E1q+iMmrJX1FRmRs3cbbD1GZUC1ySifKGUkth3tdZpsn1PQwrwA8GZoj5uEmmi1GtKKpXCwMAAbrzxRvUxk8mEjRs34siRI+f8eVmWcfDgQQwPD+O2224r+JxkMolkMql+LUkS6uvr1T9XmtimFtteDqPFC5Q/5pmk0vrMU+fJ24aoqGlsbFzStpcTryRJ8Ng8mI5PYyY5gw6pA2azGW63G8FgEKFQqGx3HBvtPcF4qwfPa4xhMpqdT2NvMuT7uKW+BUOzQ2r7NtKH6elpJBIJALmkh5FwRk1xijpz3rBhA1566SXccMMN874XCATw/PPP45JLLilmE0SGIGXnxVSioqZSrc8qM6NG2cbMjPE+1JD+cE0iypFlIJhR1qSGjnpNYvC60wCAQNimyfaJilHqNSUUCiGTycxrFeX1ejE8PLzgz0UiEXz5y19GKpWCyWTCl770JVx44YUFn/vkk0/iiSeeUL/u7e3Fzp071RNmrRjtblCjxQuUL2bTsHIzVUtDCzo6OtTHxZ38a9asyXt8sZYar8/hw3R8GhaXRd2ez+dDMBiE1WpdVgxLYbT3BOM1Pp7XGIOoqGmqN9Z8GoEVNfrk9/sBKOuczWa88yjOqClOUYmaz3/+87j33nvxX/7Lf8EVV1wBAHjvvfdw8OBB/Mu//AsA4Oabby4+SiKdM2UTNRWtqClz67NKVNSI1mdim0TF4JpElBMJA+nsxzxXp1OTGBq8yv9nYzakUoCFhTVkIHpZU+x2Ox544AHEYjEcOHAAjzzyCNra2rBhw4Z5z73pppuwY8cO9Wtxd+/4+DhSqVTZYz2TJElob2+H3++HLJf/c2WxjBYvUP6YT42fAgDYMjaMjIwAANLptFpRk0wm1cfLGa/TrKxjAyMD6LP2KY9l20EPDAygp6dn0a+1FEZ7TzDe0rJYLJoluvWyBtHZiUqUJrsxEzUt9cr7m4kafRGJmnLfhFAuIvku9oOWpqhT5s7OTvzVX/0VfvGLX+Dxxx8HAOzevRsAsH79enzpS18yZJkW0VJpUVEjkkOlVslEjdjG7Cxbn1HxuCYR5YRG4wAAC5Kwt2vTM9vTmEvCh0ISfD79XYQhWkip1xS32w2TyaRe4BYCgcBZB7KbTCb1hLenpwenT5/GU089VTBRY7VaYbUWnkml5UVQWZZ1eRF2IUaLFyhfzGJGjdvmVl9/7nvY7XYva7tLjddTp8zCCcQC6s+53craFgwGy/7vZbT3BOM1Pp7XGIOoqBGVKUbDihp9EjdAGDVRI9qRijk7tDRF39u4cuVKfPvb38bs7Kx6J0RbW5v6wYmoFlS0oiZ791j5KmoqN6OmoUFpfTY7y4oaKg2uSUSK2dNKe0wPgoBDm9ZnZo8DLsxgFg0IBk3w+dKaxEG0XKVcUywWC/r6+nDw4EFcdtllAIBMJoODBw9i+/bti36dTCaTN4eGqJxmEso5ToMtd44TDAYBKBUtCyUGS00M6Q4lcsPTRYLzzOQnUbXgeY3+zZ1RY0SsqNGnaknUjI2NIZPJwGTijdlLsexETTKZxMsvv4x9+/ZhdHQU0WgU9fX1aG9vx+bNm3H11VfDwh4XVCPEvJhMBQb6idZnpjLPqHE4yj+jRiSD2PqMisU1iSjfjF8ZQOs1zQBSnSYxyG43GjGtJmoAJmrIGMq1puzYsQMPPfQQ+vr60N/fj2effRbxeBxbt24FADz44IPw+Xy49dZbASgzZ1avXo22tjYkk0m8++67ePnll3HHHXeUcneJFhRMKEkZkSgBcomRs1WClZq3TtlWIB5QHxMXq8W8HKJqwfMa45iIZVufGXxGzURkQuNIaC6jJ2paWlogSRJSqRSmpqbQ3GzMijOtLOvofurUKXzve99TBwM5HA7Y7XaEQiEcP34cr732Gv7hH/4Bd999N7q6ukoaMJEeSdkTBLkCd7dkKjSjRsyPKSexDbY+o2JwTSKab2Y8AQBwW8IAtEnUZFwueBHAIFYhFOJxnoyhnGvKli1bEAqFsGvXLgQCAfT09OCee+5RL3hPTEyoc2UAIB6P4+GHH8bk5CRsNhtWrFiBr33ta9iyZUvJ9pfobM5WUePxeCoWh8embCsYD6qPMVFD1YjnNcYiKmqa7ca8EN3iYEWNHhk9UWO1WtHc3Izx8XH4/X4mapZoyYmaWCyGnTt3IhQK4fOf/zyuvfZa+Hw+9ftTU1N46aWX8A//8A/YuXMnHnjgAdjt9pIGTaQ3Jg0qaqQyVNRkMkAkUrkZNS4XW59RcbgmERUmEjUeW1SzGERFDQAEAjzOk/5VYk3Zvn37gq3O7rvvvryvb7nlFtxyyy1L3g+iUhGJGq0ratx181ufiUSRSBwRGR3Pa4xHzKgxakWNaH02EWVFjZ4YPVEDKO3PxsfHMTo6igsuuEDrcAxlybc37tmzBxMTE/jWt76FG2+8MW/hAACfz4ebbroJf/7nf46xsTG8+OKLpYqVSJ8yGUhiRk0FKmrKmaiJRiXIcuUSNWx9RsXimkRU2MyU0mbMXR/TLIaMx6MmapTWZ0T6xjWFKJ9eWp8VqqhhooaqDdcg4xEJDqPPqJlJziCW0u6cgfJVS6IGAEZHRzWOxHiWfNb8zjvvYNOmTdiwYcNZn3fBBRfgwgsvxNtvv73s4IiMQIpEIMlKwkFuaDjHs4uXcToBlGdGjUiYSJKM+nq2PiP945pEVFhoSjm+uuu1Gzqe8XjgRQAAEzVkDFxTiPIVan2mSaKmLpuUSbD1GVUvrkHGIypqxKwXo3Hb3LCZbABYVaMXMzMzmMneCG7kRE17ezsAJmqWY8lnzadOncL69esX9dwLLrgAp06dWnJQREaizqexWCBXoPRYrahJJoF4vKSvLRI1TqcMqQJFLrlEDStqaHm4JhEVNhNSjqseV0qzGDJer1pREwrxOE/6xzWFKJ9I1IhECcCKGqJy4RpkLJFkBNGU0mLYqBU1kiSpSSbOqdEHv98PQFnjnNmbtI1IVNSI/aHFW3KiZnZ2dtEfyjweD2bLcNc/kZ6IyhbZ5UIlshvynIO1KRwu6WvPTdRUgtPJGTVUHK5JRIUFZ8wAgIaGjGYxyHNanwUCrKgh/eOaQpSTkTOYSc6vqBGJEZEoqYSzzahhRQ1VC65BxiKqaexmO5xW415QF+3PmKjRh2poewaw9VkxlnzWnEqlYLFYFvVcs9mMVEq7OzmJKkFU1GQq0PYMAGCxIFNfr2y7xB/OwmHlkOBwVCZRIypqxHaJloprElFhobDye+H2ahdD3oya6cqsK0TF4JpClBNOhpGRlWS/HmfUiNZnrKihasE1yFjU+TT1TZAq0Y6kTFhRoy9M1NDiVoEzjI2NYWBgYFHPI6p2JpGoqeBdZbLLBUSjZUjUKB8wXK7K3IEtthOLSUilgEV+LiXKwzWJaL5QVOk33dCo3Ymj7HLBI4UAGQhNalfZQ7QUXFOIFKJ6xWqywm7OtXcWiZFKJmq8dcq2ZpIzSGfSMJvMeRU1siwb+kIpkcA1yDjURI1B254JakVNhIkaPRgeHgZg/ESNmFHD1mdLt6zLoo8//jgef/zxUsdCZEgiUSO73ed4ZunITicwPm741meiogZQ2p95vbzjmpaOaxLRfKG4clHN3aRhBtxkgtcRB8JAKKBdGERLwTWFSCHm0zTYGvKSIKKiRovWZ4CSQGq0N6rbT6fTCIfDcGXneBIZGdcg45iKTQHIVaQYVbNDiV8knkhb1VZRMz4+vqRqQVpGouarX/1qOeIgMiwpe1dZJStqMtkTEWlmpqSvKxI1lWp9ZrMBNpuMREJCOGyC15uuyHapenBNIioslFBaZDa02DSNw+NKAmEgEGSLS9I/rilEOaKiZm7bMyCXqGlsbKxYLFaTFQ6LA5FUBMFEEI32RtjtdlitViSTSQSDQSZqyPC4BhlL1VXUsPWZLlRLoqapqQlmsxnpdBrj4+OG359KWnKiZuvWrWUII99zzz2H3bt3IxAIoLu7G7fffjv6+/sXfP5rr72Gxx9/HOPj42hvb8dtt92Giy++WP3+5z73uYI/98d//Mf49Kc/DQC46667MD6ef2C69dZbceONNxa/Q1TVNKmoEYmaMs2oqVRFjbKtDBIJM2Zn2a6Alq4SaxKREQVSytw0V2udpnF4PRlgFAjO8C4q0j+uKUQ5IlHTYMufwylan1WyogZQqmoiqQhCcSUuSZLg8XgwMTGBYDCIFStWVDQeolLjGmQsE7HcjBojE4kaVtToQ7UkasxmM1pbWzEyMoLR0VHD708l6e6see/evXjkkUdw5513Ys2aNXjmmWdw//3340c/+lHBD4OHDx/Gj3/8Y9x66624+OKL8corr+CBBx7Azp07sWrVKgDAT3/607yfeffdd/G///f/xuWXX573+Oc+9zl84hOfUL+22+0gOhdR1ZJpaDjHM0tHJGpK3fpMJEuczsrNEnC5ZExPg4kaIqJSkWUEZeXmgYaOek1DcXuV/wcjNsgywBECRETGoLY+s+bOcaLRKGKxGIDKzqgBAK/NC3/Yj0AioD7mdrsxMTGBUPbGOSKiShGJjWa7sVufsaJGX6olUQMoc2pEooYWT3d9KJ5++mls27YN1113Hbq6unDnnXfCZrNhz549BZ//7LPPYvPmzfj0pz+Nrq4u3HLLLejr68Nzzz2nPsfr9eb999Zbb2HDhg1qzzyhvr4+73lM1NBimLRsfVbiihqRLGloqFxFjZhTI6p5iIioOKlAGGEo64RrhbatYDxNyrE9I5uYkCciMpBgXDnH8dq9ucey5z1ms7nircZECzZRUQPkqnqYqCGiShOJjRZHi8aRFIcVNfoRiUTU9qLVkKgR19z9fr/GkRiLripqUqkUBgYG8tqNmUwmbNy4EUeOHCn4M0eOHMGOHTvyHtu0aRPeeuutgs8PBAJ49913cdddd8373lNPPYVf//rXaG5uxtVXX40bbrgBZrO54Oskk0kkk0n1a0mSUF9fr/5Zr0Rseo5xMfS0H2rrM49nyfEsdz/mVtSU8u9gdla5oNbQIC/pdYv59xBt1mZnTZr/e+rpfVWsatoXIlqa8HAuia/1jJo6Xz3qEEMcdgSDJjQ0cBYZEZERTMenASiVLIK4gORZxnlPsTx1SlImmAjmHssmakRcRESVMh5REjWt9a0aR1Kc5nqlIiiYCCKejqPOrG3b5FomqmmcTicaKtixp1xEooYVNUujq0RNKBRCJpOZV0bt9XoxPDxc8GcCgcC8lmgej2fBD2svvfQS7HY7LrvssrzHP/WpT6G3txculwuHDx/GY489hunpaXzxi18s+DpPPvkknnjiCfXr3t5e7Ny5Ey0txsimt7e3ax1CSehiP+JxAIBn1Sp4lpn1XvJ+ZA94DQAaSphpT6WU/3d1NaCjY+kLw3L+PZqyLV0tlkbo5aYBXbyvSqSa9oWIFmdmOAIAcCAMq03bZG3G64UXAYyiHYGAhK4uTcMhIqJFCsQDAABvnTf3WPYcu9Jtz4A5iZp4LlHjzs4IZUUNEVXaWHQMgPErarx1XlhNViQzSUxEJ7DCxXlfWpnb9qwabrhlomZ5dJWoqYQ9e/bgmmuugc2Wf4fp3Kqc7u5uWCwW/O3f/i1uvfVWWK3Wea9z00035f2M+CUaHx9HSlzt1iFJktDe3g6/3w9Zrlx7q1LT0340jY/DBmAqk0E8e2BdrOXuhwtKkibs9yO0xG2ezdhYIwA7MpkARkaii/65Yv49rFYvgHoMDQUxMhJZ0s+Wmp7eV8Uy2r5YLBbDJLqJ9C40oswP8Fm0v3AlezxoxDRG0Y5QiC0uiYiMQm19ViBRU2h2bLl5bAtX1DBRQ0SVlMwkMRWbAmD8ihpJktBU3wR/2I/x6DgTNRqqpvk0QO6mYSZqlkZXiRq32w2TyTSvGiYQCCx4147X61V75QrBYLDg8z/44AMMDw/jT//0T88Zy5o1a5BOpzE+Po7Ozs5537darQUTOAAMcVFUlmVDxHkuetgPScyocbuXHctS9yPjdCrbnp0t6f7PzCgJR5crs6zXXc6/h8uVAaDMx9H631LQw/uqVKppX4hocYL+BADAa50F4NQ0lkw2UQMAwSATNURERiEqakQlCwBMTyvHc5/PV/F4ClXUsPUZEWlBzHMxS2Y02hs1jqZ4LfUtSqIm286NtFFtiRrOqFkeXZ0xWywW9PX14eDBg+pjmUwGBw8exNq1awv+zNq1a3HgwIG8x/bv3481a9bMe+4LL7yAvr4+9PT0nDOWEydOQJIktZyaaCGmmRkASqKmUuRsv0rT7Ow5nrk0MzO5GTWVImbUhMPGL+0kItKDwJhS2dto17ZKETgzUcPjPBGRURRqfSYSNY2Nlb8w6bZl25wlctUzTNQQkRZEQqOlvgUmSVeXVZelpV7pbCESUKSNak3UsKJmaXR3RNmxYweef/55vPjiixgaGsLDDz+MeDyOrVu3AgAefPBBPProo+rzr7/+euzbtw+7d+/G6dOnsWvXLhw7dgzbt2/Pe91IJILXX38dH//4x+dt88iRI3jmmWdw4sQJjI6O4uWXX8bf/d3f4ZprroErO7SdaCGmbKm9XMFEzdyKmlKanc1V1FSKyyVnt627wxERkSEFJpXjaqMjrnEkSqLGiwAAVtQQERlJodZnU1NKqx8tEjWFKmpEHEzUEFElVct8GqG5vhkAMB5lRY2WqjVRMzU1hXhc+/NSo9BV6zMA2LJlC0KhEHbt2oVAIICenh7cc889aiuziYmJvKFK69atw9e//nX86le/wmOPPYaOjg5885vfxKpVq/Jed+/evZBlGVdfffW8bVosFuzduxd///d/j2QyidbWVtxwww15M2iICorFIMWUWQAVrajJJhClcLikrytan1WyoiaXqOGd1qRPzz33HHbv3o1AIIDu7m7cfvvt6O/vL/jc3/72t/jd736HwcFBAEBfXx8+//nPL/h8onIIKjc8w9uQ0DYQALLXi0YcBcBEDRGRkagVNXav+piWFTWFZtSIOERcRESVICpqjD6fRmBFjT5UW6KmsbERNpsNiUQC4+Pj6Orq0jokQ9BdogYAtm/fPq8iRrjvvvvmPXbllVfiyiuvPOtrfuITn8AnPvGJgt/r6+vD/fffv+Q4iUTbM1mS1HZklSASNaVsfSbLuaqWhobKVdQ4ncq22PqM9Gjv3r145JFHcOedd2LNmjV45plncP/99+NHP/pRwUG6hw4dwlVXXYV169bBarXiH//xH/Hd734XP/zhDzXp5061KRA0AwC8nrTGkXBGDRGREcmynEvU2Lzq45omagpU1IibOZmoIaJKEhU1rY7qStSwokZb1ZaokSQJbW1tGBwchN/vZ6JmkXjGTFQEKaicKMgNDYCpcr9O5Wh9FosByaSWFTU8HJH+PP3009i2bRuuu+46dHV14c4774TNZsOePXsKPv/rX/86PvnJT6KnpwcrVqzAV77yFciyPG+WGlE5Tc/aAABeHcw2zUvUTFdubSEiouWLpWNIZJSqzEIzarS4+eRsrc+YqCGiSpo7o6YaMFGjvVgshsnJSQDVk6gBOKdmOXRZUUNkFKKippJtz4DcPBwpu/1SmJsocTrZ+owolUphYGAAN954o/qYyWTCxo0bceTIkUW9RjweRyqVOuu8s2QyiWQyqX4tSRLq6+vVP2tJbF/rOM7FKHEClYk1EKkDAHibTUVtpySxejzwQLmoFprKlG2/+R4oPaPECRgrViIjmI4piQ+LZIHT6sw9rmFFjdumnP+EEiHIsgxJktQ4gsEgMpkMTBW8cY6Iale1VdSIGTVsfaYdkciw2+2arLHlwkTN0jFRQ1QEUygEIJc4qRSRGDJFo0AiAdhsRb+mmE/jcmUqWRyktj5joob0JhQKIZPJqG01BK/Xi+Hh4UW9xi9/+Uv4fD5s3Lhxwec8+eSTeOKJJ9Sve3t7sXPnTrS06OcOrfb2dq1DWBSjxAmUN9ZAXHl/dvU1luSOrGJj9TniQASIzFjKfocY3wOlZ5Q4AWPFSqRnou2Zp86TlwCdmpoCoE2iRlT2JDNJRFNROKwO9TOaLMsIBoNVdXGLqJSefPJJvPnmmzh9+jRsNhvWrl2LP/7jP0ZnZ6fWoRkSK2qo1ETbs/b29qq68Uh8NmeiZvGYqCEqgmh9likwq6KcZLcbsiRBkmWYQiFkmpuLfk1RUSMqXCqFrc+oWj311FN49dVXcd9998F2lmTqTTfdhB07dqhfiw9m4+PjSKVSZY/zbCRJQnt7O/x+P2RZv22rjBInUJlYpxLK3c8mV0L90L8cpYrV7UoCEWBiIl1UPGfD90DpGSVOID9Ws9msq0Q3kREFE8o5zty2Z7IsIxAIANAmUeOwOGCWzEjLaQQTQTisDthsNjidToTDYUxPTzNRQ7SAQ4cO4ZOf/CRWr16NdDqNxx57TJ2jabfbtQ7PcKqtoqbFoXxuCsQDSKQTsJmLvxGYlub06dMAUHXJU1FR4/f7NY7EOJioISqCqKjJNDRUeMMmyA0NkEIhJVlUgkSNqKhxuzNFv9ZSuFzK9sLh6rlrgKqD2+2GyWRSL0oIgUBgXpXNmf7pn/4JTz31FL797W+ju7v7rM+1Wq2wWq0Fv6eXi6OyLOsmlrMxSpxAGWOVZUyllZsH3J32kmyj2Fjd7gwwBgRnLGX/9+F7oPSMEiegn2MmkdEFYgEA+YmaUCiEdDoNQJtEjSRJ8NR5MBWbQjAeRIezQ41FJGqIqLB777037+u77roLd9xxBwYGBrB+/XqNojKusYiSqKmWihpvnVdNhE9EJ9Dpqq5kgREMDQ0BALq6ujSOpLREoqZcN+tVIyZqiIqgVeszQGl/ZgqFYAqFkC7B683MaF1RI0GWgSqq8iSDs1gs6Ovrw8GDB3HZZZcBADKZDA4ePIjt27cv+HP/+I//iH/4h3/Avffei9WrV1cqXCLFzCymoSQHPSud53hyZXi8ynE+GC6ckCQiIn2Z2/pMEIkQh8Oh2R34bpsbU7EphBIh9bHGxkYMDQ3Nu7GGiBYWiUQAwLBzNAup1Ly6cDKMSEr5+2tztpVle5WevWeWzGiub8ZoZBSTsUmsaFhR0tevplmC5doXUVHT1dVVsb+nSvy7rFihvJdGRkbKvl/V8j5jooaoCFq1PgNyySGRLCqWqKhpaKh0RY1yAS+TkRCLSaiv592wpB87duzAQw89hL6+PvT39+PZZ59FPB7H1q1bAQAPPvggfD4fbr31VgBKu7Ndu3bh61//OlpbW9WLBna7nW0FqCLi/iDiUN5r3nYbAO2PqR6fsr7EUxZEo0D2HJ+IiHSqUOszLefTCCIekUgCcvGwooZocTKZDH7xi19g3bp1WLVq1YLPM8IczULKPa/u6NRRAIDD6kD/qv6ybquSs/c63B0YjYwiXZ8u20zJapolWOp9mZiYAABs2LCh7DM9z1TOf5fNmzcDUBI1lZq/Y/T3GRM1REUwzcwA0KiiJpsckkp099jsrHLArHRFjcOR297sLBM1pC9btmxBKBTCrl27EAgE0NPTg3vuuUdtfTYxMZH3YeNf/uVfkEql8MMf/jDvdW6++WZ87nOfq2ToVKNCg2EAgAVJOJ36OJ46m+tgQhoZmBEMmlBfX9kbAoiIaGmm40rSo7Eul5QRiRAtEzUem3L+M7eiRnwmY6KGaHF+9rOfYXBwEH/1V3911ufpeY5mIZWarXdg5AAAoK2+rapmL3otXgDA4dOHcZHropK+tpHmHp5Lufbl2LFjAJQqt0q1CavEv4vJpHTuiUajOHToEHw+X1m2A+j/fWaxWBaV6GaihqgIkphRo1HrM6CUFTXKAbTSFTUmE+B0ZhAOmzA7K0HnN+hQDdq+ffuCrc7uu+++vK8feuihCkREtLDg6SgAwGcO6qeVpMcNLwKYQhNCIRPa25moISLSMzGjplDrMy0TNe465fwnGA+qj7Gihmjxfvazn+Gdd97BX/7lX6KpqemszzXCHM1Cyj1bzx9WhqK3OdqqavaimLczHhkv2zaNNPfwXEq5L7Isq63PVqxYUfG/o3L+u9TV1aGpqQmTk5MYHh6uyGcIo7/PTFoHQGRkJi1bn2W3WapEjVYVNXO3OTvLQxIRUTGC/gQAwGsLaxxJTsbjQSOUC2jBII/zRER6V6j1mR4SNaKiplCihjNqiBYmyzJ+9rOf4c0338R3vvMdtLa2ah2SYYlETbvT2O2VzqQmaqLjGkdSe6anpxGNKjfbVbrtWSV0dnYCAIaHhzWOxBh4tkxUBJEk0aT1WXabUokSNaGQcjhwuyufqBHteUSyiIiIlicwprSiaKyLaBxJTsbrVRM1gQCP80REeidmwBRK1JSzbcm5iAofkUgCWFFDtBg/+9nP8PLLL+Mb3/gG6uvrEQgEEAgEkEgktA7NcEYjowCUippq0lzfDACYiE5oHEntGRoaAgC0trZW5VxbkXxiomZx2PqMqAhq67OGhopvW1TxiKqeYuUqairfkkZsk4kaIqLiBCeV42mjMwag8tWehWQaG1lRQ0RkIIUSNVNTUwD0V1HDGTVE5/ab3/wGwPy2zX/yJ3+CrVu3Vj4gA6vWRE2LgxU1Wpnb9qwaiYqaSs3eMTomaoiKoGVFjdhmqRI1uRk12lXUhMO8gEdEVIzAtJLw9rqSGkeSk/H54EUAQK56k4iI9EvvM2pCiVxHAVbUEJ3brl27tA6haohETbW1PmNFjXZERU21J2pYUbM4PFsmKoKU7YWcyd7JVUmlbn2mZUVNQwMraoiISiEQNAMAvJ60xpHkZHy+ORU1PM4TEekdZ9QQERUmZtRUXUVNdkbNWGRM40hqj0jUdHV1aRxJebD12dIwUUO0XLEYTLEYgFwbskqSS9z6TMuKGpeLM2qIiEohMGsFAHgbK38sX8jcRI2o+CEiIn1KZVJqxUpjXS4po4tETYEZNWx9RkSVIsty9bY+yyZqpuPTSGb0U5lfC0QCo1oTNWx9tjRM1BAtk0iQyCYTZC1m1JSpokZUt1QSW58REZXGdEQZQOlt1s/xNOP15lqfTaS0DYaIiM5qblsx0WoMyCVCfD5fxWMS1ERNgYqacDjMwehEVFazyVlEUhEA1ZeoaaxrhElSzh8mo5MaR1NbaqX12cjICGRZPzcT6pV+zuKJDEZN1LjdgKnyv0qZElfUhEIiUcOKGiIio5qOOQAAnlarxpHMYbPBUxcFAIQm9dOSjYiI5gvEAwAAl9UFqym3luiiosY2v6LG4/HAlD0XY1UNEZWTqKZx29xwWB0aR1NaZpMZTfYmAJxTU2nVnqhpb1fmOcXjcUxNTWkcjf4xUUO0TCYN59MAc1qfhUJAkVlpWQZmZ5XDgRYzapxOZZvhMBM1RETFCCRcAABPu03jSPJ5G5RKmiCvoRER6ZpI1MydTxONRhHLtnzWQ+uzcDKMVEZZV0wmEzzZ8yLOqSGichoJK62bqq2aRmiubwYAjEfHNY6kdkSjUTV5Ua2tz2w2G1palNZ6nFNzbkzUEC2TpHGiRm19lkgA2ROn5YrHgWRS+4oaMSeHiIiWIZXCVEa5WOVZUa9xMPk8HiUhHwzyOE9EpGciUSOSIgDUi0gWiwUul0uLsAAod7ELc1u0cU4NEVVCtc6nEVrrWwEwUVNJp0+fBgC4XC643e5zPNu4RLWQ2F9aGM+WiZZJ84oapxNytszfVOScGlFNA+TmxVQSW58RERXPFAphCsrsAHeXvtoxuBuV43tw1qJxJEREdDZi/svcipq5bc8kSbvP6xaTBU6rE0DhOTVM1BBROY2GqztRIypq2PqsckTbs66uLk3X13ITiRqxv7QwJmqIlknMhhGzYiofgEmZj4PiEzUzM8qC4HRmYDYXHdmSsfUZEVHxUmPTmIGyLnib9HU89TQpHzmDkTqNIyEiorMp1PpMVNT4fD4NIspXaE4NEzVEVAmioqbd2a5xJOXR4lDaU7GipnJEhUlnZ6fGkZSXaOvGRM25MVFDtEyiokbWqKIGmNP+rMh+zKLlmBZtz+Zud25lDxERLU1ocFb9s8ejzfF8Ie5WZSD1bKIOyaTGwRAR0YIKJWrmVtRoTbRkC8VzN6qJuDijhojKyR/xAwBaHa0aR1IeLfVKooYVNZUzt6Kmmon9Y+uzc+NVUaJlkrSuqJmz7WIragIB5c5rMUOg0kTrM1bUEBEtX+h0FADgNYc0qY48m4b23MycUIgfP4mI9GoqplTPNNblkjJ6rKgRCSWAM2qIqDKGw8og9E5ndVY/iNZnY5ExjSOpHSJxUSuJGlbUnBvPlImWSesZNQBK1vpMDHfWKlEjWp+JFmxERLR0weEYAKDRNnuOZ1aeqcmDBihrVTDIYz0RkV5NxiYBAE31TepjExPK3dXNzc2axDSXqKhh6zMiqrSR8AgAoNNVnYkaVtRUnkjUiBku1YozahaPiRqiZVJn1GjZ+ixbUSOqe5Yrl6hh6zMiIqMKjKYAAI32qMaRzJfx+dAI5QKaWHOIiEh/JqPZRI09l6iZnMw+1tRU8GcqyW1TblSb2/pMxCXiJCIqtVQmpVaadDg7NI6mPNocbQBys3io/ETiotoTNaKiZmpqCpFIRONo9I1nykTLZMresaWHGTVGr6hpaFC2G49LiMc1CYGIyPAmx5Skd3MDEzVERLQ8akWNThM1hSpqRKWPqPwhIiq10cgoMnIGFsmiVp5UG5GomY5PI5aKaRxN9Uun0xgZUaq0qr31mcfjQUNDAwBW1ZwLz5SJlsmkgxk1auuzoitqtJ1RIypqAGBmhoclIqLlmJhSBtM0eRMaRzJfxueDFwEAbH1GRKRnYkbN3NZnukrUZGfUBOPzEzWsqCGichHzadqd7TBJ1XnNwlvnRZ25DgDn1FSC3+9HOp2GxWJBa2ur1uGUHefULE51Hl2IKkDSwYwaUVFTbOuzQEA5FHi92iRqzObcnJpQiBfwiIiWYzJoAwA0+bQ5lp9NprExV1HDEQJERLoky7LuW58VqqgRcbGihojKZXhWSdR0OqtzPg0ASJKEdkc7ALY/qwQxn6azsxNms1njaMqPc2oWx6J1AESGJMu6qKgRSaLiK2q0nVEDKFU14bCYU5PWLA4iIqOamHEAAHw6vCFLSdS8AwAIjemv4oeoUp577jns3r0bgUAA3d3duP3229Hf31/wub/97W/xu9/9DoODgwCAvr4+fP7zn1/w+UTFCiaCSMnKvLO5FTUiASIqV7RUaEaNiCscDiMajaK+vl6T2Iioeo2ElRZVna7qTdQASvuzkzMn4Y/4tQ6l6tXKfBph5cqVAHIJKiqMFTVEyyDNzkJKK8kELWfUyI2NAHLzcpZL6xk1AOB2s6KGiKgYE1EXAKC5Q4f34Vit8NrCAIDgaFLjYIi0sXfvXjzyyCO4+eabsXPnTnR3d+P+++9HcIEbbg4dOoSrrroKf/EXf4Hvfve7aGpqwne/+11MTU1VOHKqFaKaxmV1qe1vUqkUAtlOAnqtqGloaIDNplSVsv0ZEZWDaH3W4ezQOJLyanMqc2r8YSZqyu3kyZMAgO7ubo0jqQy2PlscJmqIlkFUsMh1dZDtds3iyJQsUaPtjBogN6eGM2qIiJZnIqHcZdzYVadxJIV5HEqCZmaSVZNUm55++mls27YN1113Hbq6unDnnXfCZrNhz549BZ//9a9/HZ/85CfR09ODFStW4Ctf+QpkWcaBAwcqHDnVCnU+zZy2Z9PZ8wxJktCYPffQkrfOCwAIxAPqY5Iksf0ZEZWVWlFTxa3PAKWiBmDrs0o4deoUAGDVqlUaR1IZbH22ODq85ZJI/9T5NB4PIGlXAZLx+QCUrqLG69Wu9RkraoiIlk+KRjEmtwAAmnocGkdTmMeVBAKcUUO1KZVKYWBgADfeeKP6mMlkwsaNG3HkyJFFvUY8HkcqlYLL5Sr4/WQyiWQyV7EmSZLaAkrS4POq2KYW214Oo8ULlD7myZhSjdJc36y+pqhQaWxshMVS3OWDUsQrKmpCiVDe6zQ3N2NkZASTk5Ml+/sw2nuC8RKVz8iskqip9ooasX9M1JSfSNTUSkWNSEiJlr5UGBM1RMtgEokaDdueAWdU1MjyspNGemh9xooaIqLlkyYmMY4LAQC+rjoA2h3PF+JxK5U0ooqTqJaEQiFkMhl4z/js6PV6MTw8vKjX+OUvfwmfz4eNGzcW/P6TTz6JJ554Qv26t7cXO3fuREtLy7LjLoX29nZNt79URosXKF3MqWFlPk2ntxMdHcrFug8++AAA0NbWpj5WrGLizTiV9S0YD6K9vV29yL9ixQocOHAAqVSqZHEKRntPMF6i0hOtz2phRg3A1meVIFqf1UpFjZhRMzo6ynlyZ8FEDdEymOZW1GhIJGqkRAJSJALZ6Vz6a2T00vpM2fbMDC/gEREtVWQoiDiUVpxNzdpVR56Np1E5vgdm+PGTaKmeeuopvPrqq7jvvvvUWRxnuummm7Bjxw71a3EBe3x8HKlUqiJxziVJEtrb2+H3+yHL+jwuzWW0eIHSxzzgHwAAOCUnRkaUu8cPHz4MQEkqiseWqxTxxpIxAEBaTuPY4DE4rcr5T0NDAwDg6NGjRcdZyngrifGWlsVi0TzRTfqQzCQxFhkDUDutz/wRJmrKKRaLwe9X/o5rpaKmsbERDQ0NmJmZwdDQENasWaN1SLrEM2WiZVBn1GhcUSM7HJBtNkiJBEzT00gvI1EzMyNBlrVP1LjdyofzUIgVNURESzV1IgwAcEgROBz6u9gBAO4m5fgejNgAJM/+ZKIq43a7YTKZ1KHsQiAQmFdlc6Z/+qd/wlNPPYVvf/vbZz2Zt1qtsFqtBb+n5UVQWZZ1eRF2IUaLFyhdzBMxZb5Lk71JfT3R+szn85Xs76WYeO1mO6wmK5KZJKZj03BYlHafc2fUlPrfz2jvCcZLVFqj4VHIkGE1WdFU33TuHzAwzqipjKGhIciyDKfTCV92pEG1kyQJq1atwvvvv4+TJ08yUbMAXhElWgaRqNG6ogaSlN/+bBlE2zO7PQO7vWSRLZnLxYoaIqLlmhyMAwCabUGNI1mYp0W5PygYY5k71R6LxYK+vj4cPHhQfSyTyeDgwYNYu3btgj/3j//4j/j1r3+Ne+65B6tXr65EqFTDpqJTAACfPXfRSCRqRCJEa5IkwW1zA1Dm1AjNzc0AlEQNEVEpnZ49DUCZ32KSqvsyartTaUUYToYxm5jVOJrqJebTrFq1qqbmdHFOzblV9xGGqEwkncyoAVCyRI3Xq+1dTKyoISJavqkRpa1Ri0O/J1TuDuVugEDCgYz+RugQld2OHTvw/PPP48UXX8TQ0BAefvhhxONxbN26FQDw4IMP4tFHH1Wf/9RTT+Hxxx/HV7/6VbS2tiIQCCAQCCAWi2m0B1TtREVNc31z7rFs4kMkQvTAU6fcLBeM525OEIkkkVgiIiqVodkhAECXq0vjSMrPaXWiwaq0kmT7s/IR82lqpe2ZIBI1Yv9pPrY+I1oGkw4TNdIyEzWBgPZtzwDOqCEiKsbkuPL/JmcUwNLbYFZCw0rlpE+GCTMzEjwetjmh2rJlyxaEQiHs2rULgUAAPT09uOeee9TWZxMTE3l3Vf7Lv/wLUqkUfvjDH+a9zs0334zPfe5zlQydasRkNFs9Y89Vz0xNKVU2eqmoAQonalhRQ0TlMjij3P2/smGlxpFURpuzDTOBGfjDfvR7+7UOpyqJRIVIXNQKsb+ioojmY6KGaBlE9YpIkmipVBU1WidqREXNzAwraoiIlmpy0gwAaPHGNY5kYdZOH+yIIoZ6hEImeDxprUMiqrjt27dj+/btBb9333335X390EMPVSAiopypWDYpMydRo7fWZwDgsWUTNYn5iRpW1BBRqYnWZ7VQUQMA7Y52HA0c5ZyaMhKJilqtqGGiZmG8Ikq0DNWUqAkERKJG2zubWVFDRLR8k0FlgLjPp9+eYpmWFjRCWauCAR7riYj0RJZlTMaySZk5w7JFhYquEjXZippAPKA+JuKbmJjgYHoiKqnBWaWipquhNhI1bY42AGCipozmzqipJXMTNVyrC2OihmgZTNkWANWQqNFPRY1I1PCwRES0VBMz9QCAplaNAzmLdHNzLlEzwhkbRER6MpOcQTKTBAD47D71cVGhoqcZNb46Jb7pWO78RyRqUqkUgsFgwZ8jIlqOoZnamVEDAO3OdgCAP8wZNeUgy3LNtj7r6uqCJEkIh8Nqa1XKp8vWZ8899xx2796NQCCA7u5u3H777ejvX7gv4muvvYbHH38c4+PjaG9vx2233YaLL75Y/f5DDz2El156Ke9nNm3ahHvvvVf9enZ2Fj//+c/x9ttvQ5IkXH755fh3/+7fwW63l34HyfDUihqf7xzPLL/iEzV6mVGjZNNDId5lTUS0VBMRFwCgqUOXH+0U9fVoNI0BGSA4GAbg0ToiIiLKmogqlTNOqxP1FiX5n0wmEcjO5tRTRY1IJIlWbQBgt9vR0NCAmZkZTExMqLOfiIiKkZEzauuzmplRk62o8UeYqCmHyclJRCIRSJKElStr4z0l2O12tLW1we/349SpU7r6bKEXurt1fe/evXjkkUdw8803Y+fOneju7sb999+/4F0xhw8fxo9//GN8/OMfx86dO3HppZfigQcemNfvbvPmzfjpT3+q/veNb3wj7/v/43/8DwwODuL//X//X3zrW9/CBx98gJ/85Cdl208yMFnOVdRUQaJGtD7zerVO1Cjbj0ZNSCY1DYWIyHDGE14AgG+FTdtAzqHJPgMACJ5mRQ0RkZ6obc/mzKeZzp5fSJKkq8SHmqiJ59+NKy74cE4NEZXKeHQciUwCJsmkVppUO7GfbH1WHqKapqOjA3V1dRpHU3liLo/4e6B8ukvUPP3009i2bRuuu+46dHV14c4774TNZsOePXsKPv/ZZ5/F5s2b8elPfxpdXV245ZZb0NfXh+eeey7veRaLBV6vV/3P5XKp3xsaGsJ7772Hr3zlK1izZg3OO+883H777di7dy9LsWgeaWYGUioFoNpan2k9oya3fc6pISJagkQC4xnlopWvp17jYM7O54wCAKZGmJEnItKTqahy3js3USMSHj6fD2azWZO4Cmm0K+c/c1ufAbn2bGKuDhFRsQZnlPk0Hc4OWE1WjaOpDHVGTZiJmnIQhQUiYVFrenp6AADHjx/XNhCd0lV/jFQqhYGBAdx4443qYyaTCRs3bsSRI0cK/syRI0ewY8eOvMc2bdqEt956K++xQ4cO4Y477oDT6cQFF1yAW265BQ0NDeprOJ1OrF69Wn3+xo0bIUkSjh49issuu2zedpPJJJJzbvuXJAn19fXqn/VKxKbnGBdDy/0wZ8v/M/X1kByOol6rFPshz0nULOd1RKLG65WXHUcp9sNmA+rrM4hGTZidNaOpKb3s11quavn9AKprX4jo7KSpaYxhAwDA1+0EoN/BjE0NCWAcmBrXOhIiIppLVNTMnU8jEh56a01SqPUZwEQNEZWeaHtWK/NpAKDdkauokeXlXyeiwmp1Po3Q29sLgImahegqURMKhZDJZOaVVXu9XgwPDxf8mUAgAI8nv8e5x+NRe+kCStuzyy+/HK2trfD7/Xjsscfw13/917j//vthMpkQCATgdrvzXsNsNsPlcuW9zlxPPvkknnjiCfXr3t5e7Ny5Ey0tLYvfYQ21t1dHyaYm+zGo3FFhamlBR0dHSV6yqP1Ytw4AYAkElhVPJKL8v7fXi44O7/LjQPH/Hl4vEI0CdXWtKNFf7bJUy+8HUF37QkSFhQcDSEJpedak848hvkYlCT81pbuibiKimiYSNc31zepjoruEURI1bH1GRKUmKmpqKVHT6mgFACQyCUzHp/MS+FS8Wk/UsKLm7HSVqCmXq666Sv3zqlWr0N3dja997Wt4//33sXHjxmW95k033ZRXySMyzOPj40hl22LpkSRJaG9vh9/vhyzr947bc9FyP+o++gg+AEm3GxMjI0W9Vin2w5RKoQ0AgkGMDA4ClqX9Wk9MtACwIJ2ewMgyW9GU6t/D6VRiGRiYRHt7Ytmvs1zV8vsBGG9fLBaLYRLdRHozNRAGADilMOrr9f377sv+mk+F9D1Lh4io1kxEs9Uzc1qfjY8r5Y+iUkUv5iZq5t7tzYoaIiq1odkhAMDKhtoZ+m4z29Bkb8JkbBL+sJ+JmhKr9dZnoqLmxIkT2gaiU7pK1LjdbrXCZa5AILDg8EKv14tgMJj3WDAYPOuww7a2NjQ0NMDv92Pjxo3wer0IhUJ5z0mn05idnV3wdaxWK6zWwv0pjXBRVJZlQ8R5Llrsh5S9Qyvt85Vs28XsR3pONZg0PY3MEk+kcjNqMkXvT7H/Hg0NGQBAKCRp+v6slt8PoLr2hYgKmzqlzH1ptgXP8UztNbYrHz2nZu0aR0JERHOJ6pSm+vmJmtbWVk1iWkhjndL6OS2nEUqE4KlTOmyIRI2Im4ioWEMzSqKmlipqAGVOzWRsEqORUaxvWq91OFWl1itqRKJmamoKwWBwXpesWqervhMWiwV9fX04ePCg+lgmk8HBgwexdu3agj+zdu1aHDhwIO+x/fv3Y82aNQtuZ3JyErOzs2jMzvZYu3YtwuEwBgYG1OccPHgQsiyjv7+/mF2iKmTKtgDIZN8/mrNYkMke2EzT0+d4cr5UCggElMOAz5cpeWhL5XbnEjVERLQ4U8NKNWSLY1bjSM6tcUUdAGAy7tI4EiIimms8mq2emdP6bHRUGSStt0SN3WKH0+oEkN/+TMTJRA0RlcqJ0AkAwCp3bV1Ub3cqLdT9Yb/GkVSXWCwGv1/5O63Vihqn06mu16yqmU9XiRoA2LFjB55//nm8+OKLGBoawsMPP4x4PI6tW7cCAB588EE8+uij6vOvv/567Nu3D7t378bp06exa9cuHDt2DNu3bweg/BL83//7f3HkyBGMjY3hwIED+N73vof29nZs2rQJANDV1YXNmzfjJz/5CY4ePYoPP/wQP//5z7Flyxb4fCzxo3wiGZLR0XtDJI2WmqiZnlYOAZIko7FR+0RNQ4NS+TEzo7tDExGRbk36leN3U0NM40jOzbvKAQCYSPLOKSIiPRmLjAHIzSYAcgkPPban9dXNn1PT1tYGIJdgIiIqRjqTVluf9bh7tA2mwtod2URNhImaUhoaGoIsy3A4HLqb/1ZJoqqGc2rm01XrMwDYsmULQqEQdu3ahUAggJ6eHtxzzz1qC7KJiQm1By0ArFu3Dl//+tfxq1/9Co899hg6OjrwzW9+Uy0hM5lMOHXqFF566SWEw2H4fD5ceOGF+KM/+qO81mVf//rX8bOf/Qx/9Vd/BUmScPnll+P222+v6L6TMagVNXpL1Jw4oca2WJOTSkLE683AbC5HZEvDihoioqUbH1cO4K2NlZ/ttVSNq5UETVh2IhoJoN7B4z0RkR6MRpTkRlt9m/rY2Fg2eaOzihpAmVMzODuYl6hpb1cuLI6OjubNriEiWo7h8DCSmSRsJpuauKgVbc5s4jvCxHcpzZ1PU8trVG9vL9544w0magrQXaIGALZv365WxJzpvvvum/fYlVdeiSuvvLLg8202G+69995zbtPlcuEb3/jGkuKk2qRW1Oil9RlySaPlJmqamrSvpgFyFTWzs6yoISJarNFAPQCgtS2tcSTn5uhuhBUJJGHD9FAM9WvrtQ6JiKjmxdNxBOIBAECLI1c9o+uKmuxw66l47vxHxBmPxxEIBNRW50REyyHanq1sWAmzSQd3tlZQm4OJmnKo9fk0Qk9PDwBW1BTCq6FES6TLiprs4EzTxMSSfk5/iRpW1BARLZV/Rpn30tap/491kqMezdIkACBwLKhxNEREBAATUeUcwmayobFOSW6kUilMZM8tREsxPWm0K3FOx3Ktn+12u9qJQ1QDEREt18mQclG92117s0REooYzakpLzEbv6+vTOBJtsfXZwvR/Rk+kM3qsqEln7x5baqJmako5BPh8+kjUuN1KRU0oxEMTEdFi+WNeAEDLKuvZn6gTTRYlQRM4FdE4EiIiAnJ3TLc4WtRWLJOTk5BlGSaTSZdzW9WKmlh+R4G57c+IiIpxakZpU1Vr82kAoMPZAYCJmlI7duwYACZqRKJmYGAAsixrHI2+8Goo0RKpiRodnbBkskPIll5Ro5Tv6iVR4/EocQSDrKghIlqUVAr+lJKsb+l3ahzM4jTZZwEA06fjGkdCREQAMBbJzqJx5GbRiLZnzc3NMOthmOUZFkrUiOofv58XF4moOKL1WS1W1HQ6OwEAY9ExxNP8zF4qoqJm9erVGkeirb6+PkiShEAgoFbvkoKJGqKlkOVc6zMdVdSI1mdmg7c+83pFooaHJiKixZAmJuGHcvewYRI1zigAYMqv/5k6RES1QE3U1OcSNaJ1mB7n0wALJ2paW5V9YEUNERVLbX3WUHuJGp/dB7vZDoBVNaUSjUYxNDQEgBU19fX16pyejz76SONo9IVXQ4mWQAqHISWTAABZTxU1YkbN5OSSfk60PtNLokZU1AQCPDQRES1GcCCABOoAAC3tGgezSD5PAgAwNc4ydyIiPRiLLlxRo8f5NMC5K2o4o4aIiiHLspqoqcXWZ5Ikqe3PhsPDGkdTHU6ePAlZluF2u9GcvYZXy/r7+wEwUXMmXg0lWgK1msZuh1xfr3E0OWmRqMmeUC2W/ipqlIt2rKghIlqciaNhAIDPHEBdncbBLJKvUVlzpqb110qHiKgWiYoaMTwayFWkGK2iRsyoYeszIirGdHwaM8kZAEBXQ5fG0Wij06W0PxueZaKmFObOpxHz4GrZmjVrAABHjx7VOBJ94dVQoiVQEzU6qqYB5lTUTE0B6cW3ktFbRU2u9ZmEjD5CIiLStbGTSnVKe920xpEsXlOrcmIyFbRqHAkREQHAaERJyhSqqNFtoqbu7BU1bH1GRMUQ82nane2ot+jnJt1KEnNqTs+e1jiS6iDm09R62zNBJGpYUZOPiRqiJTBNKxfCZB3NpwGUxJEsSZBkWY1xMURFjc+njzkBovWZLEsIhXiHARHRuUycVo7fba6QxpEsnrfTBgCYCtfmSS8Rkd6oiZoCM2rEzBe9ERU1gXgA6UzuXIaJGiIqhYFg9qK6u3Yvqq9wrQDA1melMreihtj6bCFM1BAtgZgBo7eKGlgsyGSTR6aJiUX9SCaTq6jx+fRRvmKzAQ4H59QQES3W6KhyrGz3xjSOZPEaVzkAABMxl8aREBERkBsU3eHqUB/Te0WN1+4FAMiQEUwE1cfnzqiRZc5CI6LlORbIXlT31O5FddH6jBU1pSESNatXr9Y4En0QFTV+vx8zMzMaR6MfvBJKtAQiCZLW4QlLZolzaoJBCem0UrWil9ZnAODxcE4NEdFijUwog2nam+MaR7J43tUeAMBEuhFIJjWOhoiotiXSCYxHlfOHDkcuUSMqUkTiQ2+sJis8NmU9mdv+TCSWEokEppfQaYCIaK5jwexFdW/tXlQXrc9GwiMaR1IdROszJmoUHo9HrdrlnJocXgklWgJzNlEjkiJ6kmlqAgCYs1U/5yLanrlcGV0NoBZzalhRQ0R0biNBpSqlY4Vx7hr29jYAACbQDNPomMbREBHVtrGIchy2mWxqOzFA/xU1ANBoVzoKzE3U1NXVwZftfsD2Z0S0XKL12WpP7V5UV1ufzbL1WbGmpqYQCAQAAL29vdoGoyNsfzYfr4QSLYFJz4kaUVGzyNZn09NmAPqqpgHmJmo4o4aI6FxOh5WLVO3dxvlIJ9ptpmBF+NjiqkCJiKg8RiLKndLtznZIkvL5OxwOIxwOA9DvjBogN6dmbqIG4JwaIipORs7gePA4AFbUAEAwEcRsYlbjaIxNtD3r7OyEw+HQOBr9EO3PWFGTY5yzeiIdUFuf6TBRI9qxLTZRIypq9DKfRmBFDRHR4p2OK8f+tj67xpEsXn094DRFAACBgeA5nk1EROU0MptN1Dja1cdENU19fT2cTqcmcS0GEzVEVA7Ds8OIpWOwmqzocnVpHY5mXDYX3DY3AGA4zKqaYoi2Z319tTvzqBCRqGFFTQ6vhBItga4rarKtz4yeqPF4lHg4o4aI6OxSkQT8snIxqv38Bo2jWZqmOmVg5PSJiMaREBHVNn/ED0CpqBHGxpR2aK2trWqVjR4xUUNE5SDm0/S4e2AxWTSORlui/dnp2dMaR2JsnE9TGBM18/FKKNESmLN3l+kyUZONybzERI3+Wp8pcxZYUUNEdHYTh4PIwAwLkvD1ubQOZ0manFEAwPTpuMaREBHVNjEkusPZoT42N1GjZyJRMxnLn9HJRA0RFYPzaXLE2sBETXFE6zNW1OQTiZqTJ08iHud5IcBEDdHiyTJMk8pJgB5bny11Ro1eEzW5ihr93r1HRKQHo0eUapRO0yhMFmN9pPN5kgCAqdG0xpEQEdU2f3jhipqWbGtlvWq2K+c/E9H88x8maoioGMcCykX1Wp5PI6xsWAkAGJod0jgSY2NFTWGtra1wu93IZDI4fvy41uHogrHO6ok0JAWDkJLKhSXRZkxPRPJIJJPOZWpKJGr0dZFMJGpYUUNEdHajR5WqlBX2xSXo9aQp23ZzcoLHeiIiLRWqqPH7leRNR0dHwZ/RixaHkkgaj47nPS7iHhkZqXhMRGR8ovVZn4fVDytd2UTNDBM1y5VOp3HixAkArKg5kyRJ6O/vB8D2ZwLPjokWSZ1P09AA2PU3tFmtqBkfP8czFWNjZgBAS4u+Kmq8Xs6oISJaDP9JJdHe6Q5qHMnStXQoVZPjgTqNIyEiqm0iUTO3okYkOPSeqGmtV1qzjUfyz386OzsBAMPDHH5NREt3JHAEANDv7dc4Eu11NXQBAE7NnNI4EuM6ffo04vE46urq0NXVpXU4uiPanx09elTjSPSBV0KJFsmcrVTR43waYE6iJhqFFA6f8/mjo8qvf2urvipqOKOGiGhxhoeV42SHL6ZxJEvXvNIKABgNuwBZ1jgaIqLalMqk1ERNlyt38cgoiRpRUTMWHct7fMUKZfj12NgYe94T0ZIE40G1JeTaxrUaR6O9VQ2rALD1WTHEfJqenh6YzWaNo9EfkahhRY3ConUAREYhKlX0OJ8GAGSnExmHA6ZIBKaxMaR7e8/6fFFR096uz4oaJmpIL5577jns3r0bgUAA3d3duP3229Xy3DMNDg7i8ccfx/HjxzE+Po4vfvGLuOGGGyocMdWKwTEnAGBlZ0LjSJauuc8BAPCnWyGFQpA9Ho0jIiKqPaORUaTlNKwmK9ocberjRknUiIqaqdgUkpkkrCblJoDGxkbY7XbEYjH4/X50d3drGSYRGYiopulwdsBtc2scjfbEjJrRyChiqRjsFv11l9E7MZ+Gbc8KY+uzfLwSSrRIauszvQ7VlCRkWpWTFfM5BmdGo7nWYm1t+qqoETNqgkFJ40iIgL179+KRRx7BzTffjJ07d6K7uxv3338/gsHCrabi8Tja2tpw6623wuv1VjZYqjmngl4AQFePpmEsS2uXcrOAH+0wZ2chEBFRZZ2ePQ1AuSBpkpRzXQEG0QAAfoxJREFUA1mWDZOoabQ3wiwp68lENDevTZIktf3Z6dOnNYmNiIzpyLSSqFnXuE7jSPShsa4RDotyg5VYM2hpjhxR3lOrV6/WOBJ9WrtWqVw7duwYUqmUxtFoj4kaokUyi0RNU5PGkSws3a70ljadI1Ejqmnsdhlut75azoiKmkjEhITxbhKnKvP0009j27ZtuO6669DV1YU777wTNpsNe/bsKfj8/v5+fOELX8BVV10Fq9Va4Wip1pyMKMn5FWttGkeydK2tyrGeiRoiIu2Ii24rXCvUx6anp9V2YW1tbQV/Ti9Mkgkt9cpNdJxTQ3R2hw4dwn/7b/8NX/7yl/G5z30Ob775ptYh6dLh6cMA2PZMkCRJraoZnBnUOBpjEomadeuY/Ctk5cqVcDqdiMfjavVRLWPrM6JFUitqdNr6DMCiK2pGR5VETVtbGpLOClfcbhmSJEOWJQSDJrS06Ks1G9WOVCqFgYEB3HjjjepjJpMJGzduVD9slUIymUQymVS/liQJ9fX16p+1JLavdRznYpQ4gdLFOjsrYTLjAwB0bWwoy76X8+9VJGqm4UNycLzobdTie6DcjBInYKxYifSkUKJGJDZaWlpQV1enSVxL0eJogT/iX3BODStqiBTxeBw9PT34+Mc/ju9///tah6NbrKiZb2XDShyePozBWSZqlkqWZfXagagcoXwmkwnnnXce3n77bRw6dKjm/56YqCFaJNPkJAD9zqgBgHT2rjfz2NhZnzc6qhTTtbbqq+0ZAJhMgMcjIxCQEAgwUUPaCYVCyGQy81qYeb3ekt6d+eSTT+KJJ55Qv+7t7cXOnTvRoqM2i+3Zaj29M0qcQPGxHnhtFgDgwyRWX30h4HKVIqyCyvH32t4O2ExJJDJWxMckdJeovU4tvQcqxShxAsaKlUgPxHDoQokavbc9E1hRQ7Q4F110ES666CKtw9A9kahhRU3OSpdSUTM0M6RxJMYzNjaGQCAAk8m04JxbAtavX68maubeKFuLmKghWiTTuPLhX88VNSJRc67WZ7mKGn0mQTyeDAIBEwIB3hlL1e+mm27Cjh071K/FHeHj4+Oa92iVJAnt7e3w+/2QZX21SZzLKHECpYt134uTAC5Aj2kQIzNtwMxM6YLMKvffa5uzDoMzPhw/NAVbdh7CctXie6DcjBInkB+r2WzWVaKbSM9ERU2Xq0t9zCjzaYTWeqWjwEIVNUzUEC2Pnqv+CylFdW0gHsBoRLmWsq5xnWb7qbdK4ZVuJVFzaubUsmLS2/4UY6n7Iqppenp61N8fvdDTv8uGDRsAKC0alxuPnvanGEzUEC2SOqNGxyf/i219NjamVNS0temvogZQ5tScPAkEAhyjRdpxu90wmUwIBAJ5jwcCgXlVNsWwWq0LzrPRy8VRWZZ1E8vZGCVOoPhYBw8r8wNWOUYhy62lCqugcv29tnpjGJwBxk+nsbZEr19L74FKMUqcgH6OmURGUaj1mdESNS0OVtQQlYMRqv4LKaa69tipYwCAVZ5VWNO9plQhLZteKoU3BTYBrwOj8dGi1ga97E8pLHZfRrPX5i688ELdrqt6+He59tprAQAffvhh0X9PetifYjBRQ7RIYkZNuqlJ40gWttiKGr9f/xU1ABM1pC2LxYK+vj4cPHgQl112GQAgk8ng4MGD2L59u8bRUa0bOqH8f5UnoGUYRWlpSQODwNiYWetQiIhqjizLBVufGS1Rc66KGs6oIVoePVf9F1KKSuCXj7wMAFjjXqMeC7Wgt6pmZ8oJADg2dWxZfy96259iLHVf3nrrLQBAd3e3pu+pQvT079LS0gJJkjAyMoKDBw+iaRnXXfW0P4VYLJZFJbqZqCFajFgMpmxbGT23PsssekaNSNTos6LG51MSNVNTTNSQtnbs2IGHHnoIfX196O/vx7PPPot4PI6tW7cCAB588EH4fD7ceuutAIBUKoWhoSH1z1NTUzhx4gTsdrvh7+wgfTk1rAx4XtUa0TiS5WtdYQbeAcambFqHQkRUc6ZiUwgnw5AgGbr1maioGYvkn/+IipqZmRmEQiG43e6Kx0ZkZEao+i+kmErg9yffBwCsb1qvi33US1XzKtcqAMBEdAKziVk4rc5lvY5e9qcUFrsvhw8fBgCsXbtWt/uuh38Xh8OB7u5unDhxAgcPHlQrbJZDD/tTDCZqiBZBtBKT7XbIHo/G0SxMragJhSBFo5AX6IGp99ZnTU1KomZykoka0taWLVsQCoWwa9cuBAIB9PT04J577lFbn01MTOT1QJ2amsLdd9+tfr17927s3r0b69evx3333Vfh6KmaDU66AAAru/R3R+NiNXcryabRRCOkUAgyL6IREVXMyZmTAIB2ZzvsFrv6uNESNaKiZjya3/rM4XDA6/UiEAhgeHiYiRoiOqdDk4cAAOt96zWORF88dR401jViOj6NE6ET2NC0QeuQDEGWZXVGzdq1azWORv/Wr1+PEydO4NChQ0UlaoyOiRqiRRCJmnRbG6DjwVRyQwMydjtMsRhMo6NI9/QUfF6uokafrc+YqCE92b59+4Ktzs5MvrS2tmLXrl0ViIpq3amQDwDQ1affNelcWlYoa5Ef7TCfPo0UL6IREVXM4MwgAGBVwyr1MVmWDZeoWaiiBlCqakSi5rzzzqt0aES6EovF4Pf71a/HxsZw4sQJuFwuNOu4a0ilpDNpfDD1AQAwEVFAj6cH02NM1CzFyMgIgsEgzGYzVq9erXU4urd+/Xo8++yzOHTokNahaIpXQYkWwZQ9YUnrvXWRJCGTjdG8wJyaaBQIBvVdUdPcrCRqJiY4t4CI6EyhkITplJLU6DyvcOWkEYibBUbQAXO2ZSAREVXGyZBSUTM3URMMBhGNRgEYZxivqKiJpCIIJ8N53+OcGqKcY8eO4e6771ar/x955BHcfffdePzxxzWOTB+Oh44jlo6h3lKPHneP1uHoTq+7FwBwInhC20AMRCQc+vv7UVdXp3E0+rdhg5IArPVEDStqiBZBJD3EDBg9S7e2wnLiBEwLJGrE0Ga7XYbbrc++jSJRw4oaIqL5hoaU43gTJuDoa4FRm5+1tCg3CygVNc9rHA0RUW05NXMKQH6iRlTTNDY2on6BFsp647Q6UW+pRzQVxVhkDL2eXvV7Yk7N8PCwVuER6caGDRtY+X8WYj7N+b7zYTbxhtEzieTVidAJTeMwkg8+UCq01q9nK73FEH9PR48eRSKRgM1Wm3NMeRWUaBHU1mcGuLMs06rcVWYem1/+D+QSNW1tad12cfP5lIt3TNQQEc03OKAk2XtwQq2iNKLWViUp70c7TEO825mIqJLURI17fqLGKG3PAECSpAXn1DBRQ0SLxfk0ZycSNcdDx7UNxEBEZcj555+vcSTGsGLFCng8HiSTSXz00Udah6MZXgUlWgRTtpdr2ggVNdkYF6qo8fv13fYMmNv6jIcoIqIznf4wBgDokU4h4/NpHM3yiYqaBOowcyKgbTBERDXmVEhJ1HQ3dKuPGTFRAwCtDiVRc+acGrY+I6LFOjSlXFTn/JXCWFGzdCJRw4qaxZEkSU1q1XL7M7Y+I1oEtaLGACctoj3bQjNqRkZERU2mYjEtlUjURCImRKMS6uv12aKNiEgLQx8lAQDdrnHAZNyEdl0d4HXEEIjYMXEygRatAyKqgOeeew67d+9GIBBAd3c3br/9dvT39xd87uDgIB5//HEcP34c4+Pj+OIXv4gbbrihwhFTNUqkExgOK1UmKxtWqo8PZeeFiUoUo2hxKCvImRU1XV1dAJTfJSKihciyjAMTBwAwUbMQ0VZyJDyCaCqKeosx2mNqJRqNYmBgAAATNUuxfv16vP766zWdqDHu2T1RBZmzd5cZYkaNSNRkq4DOJGYbdHXpt6LG5ZJhsynJGbY/IyLKd+qEclxc1RI+xzP1r7VJSTqNjTAhT9Vv7969eOSRR3DzzTdj586d6O7uxv33349gMFjw+fF4HG1tbbj11lvh9XorGyxVtZOhk0jLaTitTrQ5cuc3IqHR3d290I/qkmh9dmZFzapVSlu34eFhJJPJisdFRMYwEh7BeHQcZsmM9U28qF5IY10j3DY3gFxFJi3syJEjyGQy8Pl8aM2OJ6BzE0ktJmqIaGGyrLYRM8KMGhGjaYFEzenTIlGj3/HTkgQ0NbH9GRFRIUeHXQCAvlUxjSMpXmu2UHVsug5IJLQNhqjMnn76aWzbtg3XXXcdurq6cOedd8Jms2HPnj0Fn9/f348vfOELuOqqq2C1WiscLVWzgaByl2+fpw/SnKGVJ0+eBJBLcBhFS33hiprW1lbY7XZkMhm2PyOiBe0b3wcAWNe4jpUiC5Akie3PlmBu2zNJr8OhdWhuokaWa/NGPrY+IzoHKRSCKRoFYJAZNdlWBebhYUCWlazHHKKiZsUK/VbUAEBzcxojI2ZW1BARzZFMAsenlbk0fes0DqYEWjqVNcmPdphHRpA22F3cRIuVSqUwMDCAG2+8UX3MZDJh48aNOHLkSEm2kUwm86oGJElCfX29+udKE9s0ygUKo8ULLD/mY8FjAIDVntV5P3vqlHKX9KpVq8ry91Cuv+NWZ66iZu5rS5KElStX4qOPPsLg4CB6e3uX9LpGe08wXqLl2TehJGo2t2zWNhCd63H3YP/EfhwPHdc6FN0TiRoxc4UWZ+3atTCbzZiamsLw8LA6a66WMFFDdA5i1kvG6wXq9X93hZijY4pGIQUCkBsb874/NKT82uu59RnAihoiokJOnTIjJVtQjwja17sR1zqgIrW0Ksf6EXTAfPo0EzVUtUKhEDKZzLwWZl6vF8PDwyXZxpNPPoknnnhC/bq3txc7d+5ES4u2E6DaDVCRPpfR4gWWHvPIm0pb581dm9GRPXeYnZ3FxMQEAODyyy8va7u9Uv8dr59V7sCdSEyo+yOsWbMGH330EUKh0LzvLZbR3hOMl2hp9o/vBwBc2HKhxpHo22rvagDA0cBRjSPRv/37lffUxo0bNY7EWOrr63Heeefh/fffx759+5ioIaL5xKwXI1TTAADq65H2+WCemoJ5eBipOYma2VkJgYCS+DBKomZy0qxxJERE+nHsmPLRbS2OINO98hzP1r/2dmUtOo0VMGeHWBPR8tx0003YsWOH+rW4S318fBypVOVb3kqShPb2dvj9fkO0rzBavMDyYz7oPwgAaDG3YCQ7i/ODDz4AoCQPo9EootmOAnqI91zsCTsA4FTglLo/gpgNsH///nnfOxejvScYb2lZLBbNE91UfrIsqxU1m5o3aRyNvvV7+gEwUXMu6XQa77//PgDgwguZ/FuqzZs3q4ma66+/XutwKk6XiZrnnnsOu3fvRiAQQHd3N26//Xb09/cv+PzXXnsNjz/+OMbHx9He3o7bbrsNF198MQClzcCvfvUrvPvuuxgbG4PD4cDGjRtx6623wufzqa9x1113YXw8v6ftrbfemteegGqTyWiJGgCZjg4lUTMygtSGDerjou2Zx5NBQ4P+PgzPlUvUsKKGiEgY+Eg5Jq7DYaRXrdU4muJ1diqJmkGshPn0OxpHQ1Q+brcbJpMJgUAg7/FAIFCyygWr1brgLBstL4LKsqzLi7ALMVq8wNJjPhbItT4TPze37Vm597/Uf8ftDqUiYzo+jUgykjdjQszbOXXq1LK3abT3BOMlWrxTM6cQiAdgM9mwzlcFfYXLqL+RiZrFOHr0KKLRKJxOJ/r6+rQOx3A2bdqEX/7yl3jvvfe0DkUTursCunfvXjzyyCO4+eabsXPnTnR3d+P+++9HMBgs+PzDhw/jxz/+MT7+8Y9j586duPTSS/HAAw+oHzQTiQSOHz+OP/zDP8TOnTvxn/7Tf8Lw8DC+973vzXutz33uc/jpT3+q/rd9+/ay7isZg6ioyRioJDtvTs0cRplPAwDNzWx9RkR0poEDCQDAWvMxZLJ3CRtZR8fcRA0HPVP1slgs6Ovrw8GDB9XHMpkMDh48iLVrjZ90JeMIxAOYjE0CAHrduZktJ0+eBJBLbBiJx+aBw+IAAAzP5p//iP0ZHByseFxEpH/vjb8HADjfdz7qzHXaBqNzqz2rIUHCdHwak9FJrcPRrX37lAqtCy64AGYzO8Qs1aZNSmXb/v37kclkNI6m8nR3BfTpp5/Gtm3bcN1116Grqwt33nknbDYb9uzZU/D5zz77LDZv3oxPf/rT6Orqwi233IK+vj4899xzAACHw4Fvf/vb2LJlCzo7O7F27VrcfvvtGBgYUHvwCvX19fB6vep/dru97PtL+idm1BipouZciZqursq3v1iq5mbl4t3UlO4OU0REmjn2kdLKqL95EqiC4buiomYYnZBO8CIaVbcdO3bg+eefx4svvoihoSE8/PDDiMfj2Lp1KwDgwQcfxKOPPqo+P5VK4cSJEzhx4gRSqRSmpqZw4sQJ+LM3EREtx0BwAIBSheKyudTHxY2O3QacFSZJEjpdyvnPcDj//GflSqVNqEhEERHN9fbY2wCAi1sv1jgS/au31KPL1QWAVTVnc+DAAQCcT7Nc69atg91uRygUwvHjx7UOp+J01foslUphYGAgr92YyWTCxo0bceTIkYI/c+TIkbxezICSfXvrrbcW3E4kEoEkSXA4HHmPP/XUU/j1r3+N5uZmXH311bjhhhsWzH4mk0kkk0n1a0mSUJ8dNC/p+MKJiE3PMS5GJfdDrajp6Cj59sq1H2qiZmQk77VPn1Z+5bu6MiXdZjn2o6lJKX+fmDBV7P1aLb8fQHXtCxHlHBtyAgD6V0Y0jqQ02toyMJsySGWsmDgR1dcHU6IS27JlC0KhEHbt2oVAIICenh7cc889auuziYmJvHV7amoKd999t/r17t27sXv3bqxfvx733XdfhaOnaiHanvV58tuxiESGSGwYTaezE0cDRzESzp9DIypqpqamEA6H4XQ6tQiPiHTqnVGl9e4lbZdoHIkx9Hv7MTg7iI8CH+Hyjsu1DkeX9u/fD4DzaZbLarViw4YNePvtt7Fv3z6sXr1a65AqSlfnw6FQCJlMZl6fZq/Xi+EzKgOEQCAAj8eT95jH45nX/1lIJBL45S9/iauuuiovUfOpT30Kvb29cLlcOHz4MB577DFMT0/ji1/8YsHXefLJJ/HEE0+oX/f29mLnzp2GGTbXbqA2XmdTkf3Izi7yrF8PT0dHWTZR8v3IzqVxTEzAMSfmyWx16vr1TnR0lP4kpZT7cd55yv+np23oKNPf+0Kq5fcDqK59Iap1waCE8Vnl2N23RkY1dHM3m4G21hSG/TYM+61YlUgANpvWYRGVzfbt2xdsr3xm8qW1tRW7du2qQFRUS44FCydqjFxRAwAdTuV84czWZ263G16vF4FAAKdOncL555+vRXhEpEPRVBQHJpTqh0tamahZjH5vP/YM7WFFzQLS6TTef/99AEzUFGPz5s14++238d577+Ezn/mM1uFUlK4SNeWWSqXw3//7fwcA3HHHHXnfm1uV093dDYvFgr/927/FrbfeWnAo50033ZT3M+Lut/HxcaRS+m0rJUkS2tvb4ff7DT2wr5L70TYwABOAcZcLqZGRcz5/Kcq1H7b6ejQBSJ08ifE5MR892gTABrd7GiMjsZJtrzz7YQbQivFxGcPD/op0+KmW3w/AePtisVgMk+gm0sqxY8rHtg4Mw9HfirDG8ZRKZ5eMYT8wJK9A7+Ag0jV21xQRUSWJRM1qb+5YK8uyOsPFiDNqACzY+gxQ9omJGiI604GJA0jJKbTWt2JlgzGrCSut39sPgK3PFnLkyBFEo1E4nU709fWd+weoIDGn5r333tM2EA3oKlHjdrthMpnmVcMEAoF5VTaC1+tFMBjMeywYDM57vkjSTExM4Dvf+c68tmdnWrNmDdLpNMbHx9GZbSM1l9VqLZjAAWCIi6KyLBsiznMp935Is7MwTU8DAFJdXWXbVqn3I5WtQDGPjEDOZNQ5BmJGzYoVqbLsSyn3w+dT5hbEYhJmZwGXq3Lv12r5/QCqa1+Iap1I1KzDYaQN2pqmkM5OZUjkIFbCcuoUEzVERGV0PKj0e1/tyR1rx8bGEIvFYDKZsGLFCq1CK0qnUzlnP7P1GaAkavbv369WDRERAcDbo8p8mkvaLmHL8EVa410DgImahbz9tvKe2rx584KjNOjcRKLm/fffRzKZXPD6ezXS1ZRui8WCvr4+HDx4UH0sk8ng4MGDWLt2bcGfWbt2rTqoSdi/fz/WrFmjfi2SNH6/H9/+9rfR0NBwzlhOnDgBSZLgdruXuTdUDczZO8syXi/kRbxv9CKdbXclxWIwTU0BAOJxYHRUWSi6utKaxbZYDocMh0O5eDc2pqtDFRGRJvISNQa947mQzk5lTRrESpg57JmIqGwyckZN1MxtfSYSGCtWrDDsxRCRqDmz9RmQqxISVUNERADw9phyUf1jbR/TOBLjWNOoXGsdnB1EOFkt9f2lIxI1l1zCVnrF6OvrQ0NDA2KxGA4fPqx1OBWlu6ufO3bswPPPP48XX3wRQ0NDePjhhxGPx7F161YAwIMPPohHH31Uff7111+Pffv2Yffu3Th9+jR27dqFY8eOqb2fU6kUfvjDH2JgYABf+9rXkMlkEAgEEAgE1BZlR44cwTPPPIMTJ05gdHQUL7/8Mv7u7/4O11xzDVwuV8X/Dkg/RKImZbQLYnV1SGfbSJmz851On1aSNHZ7Bk1NGc1CW4q2NpGo4Z0IREQDR5Q7/dbhMFJVVFGzYoWSqDmFVbCcOKFtMEREVWxoZgixdAxWkzWvzc/JbJLcqG3PAKCroQsAcGrm1Lxq8pXZNfMkbwYgoixZlvHW6FsAOJ9mKXx2H9ocbQCAD6c+1Dga/RGJmosvvljjSIzNZDKpM3727duncTSVpavWZwCwZcsWhEIh7Nq1C4FAAD09PbjnnnvUVmYTExN5JYnr1q3D17/+dfzqV7/CY489ho6ODnzzm99UP2ROTU3h97//PQDg7rvvztvWX/zFX2DDhg2wWCzYu3cv/v7v/x7JZBKtra244YYb8mbQUG2yZBM16a4ujSNZunRnJ8zj4zAPDyO5cSOOH1d+3Xt70xWZ91IK7e1pHD9ugd/PRA0R0dHDysF7Tf0gZI9H42hKp6tLuXHmOHphZlsaIqKy+XBauajW7+2HxZS7FCAqagydqHEp52uRVATT8Wn47D71e93d3QCYqCGinGPBY5iITsButuPCFg59X4rzfedjNDKKQ1OHcEkbk1zC9PQ0jh1T5sCxoqZ4F110EV599VXs27cPt912m9bhVIzuEjUAsH37drUi5kz33XffvMeuvPJKXHnllQWf39rail27dp11e319fbj//vuXHCdVP3HByIgtZtIdHcC+fTBlK2pyiZqUlmEtSVubcpe136+74j8iooqKxYCjp+oBAOu7gzBMxn0RVq1SjvUD6IOFF9GIiMrm/cn3AQDrfevzHhcXlow8+NhusaPN0YbRyChOzZzKS9SI/Tp58iTS6TTnBhARXht5DQBwUetFqDPXaRyNsaz3rceLQy/ig6kPtA5FV959910AQG9vL3w+3zmeTeci5tS899572gZSYbz6SXQW5qEhADBki5l0dhCoJbsPAwNKoqavzziJmvZ2pfWZmK1DRFSrPvrIinTGBB8m0XaecWamLcbKlUqiJoBGzJwIAGe0rCEiotIQF9XWN+Unao4eVYZC9/f3VzymUhLt3E6F8qszOzs7UVdXh0QigaHsuRER1bY3Rt4AAFzZUfimb1rY+U3nAwA+mGSiZi62PSstkaj58MMPEY1GNY6mcpioIToLi6ioMWKiJlsFJKqCjh9Xkh3GrKhhooaIatuhQ0qyfRP2Id2/WuNoSsvplNHUpBzvT8baYRof1zgiIqLqJBI15/vOVx/LZDJVUVEDAKsalPOfwZnBvMfNZjN6e3sB5KqHiKh2ybKM1/xKRc3l7ZdrHI3xiKrMD6Y+mDcTrJa9+eabANj2rFQ6OzvR1taGdDpdU3NqmKghOgtRUWPERE1qXqImN6PGKESiZnSUhyoiqm2HDlkBABdiP1IGv5BWiGh/dhy9bH9GRFQGkWQEx4PHAeS3PhsZGUE0GoXFYlFnuRiVqKgZnB2c9z2RhBoYGKhoTESkPydnTsIf9sNqsnLGyjKs9q6G1WTFTHIGQ7OsUgSAeDyOd955B4Aye52KJ0mSmvQSs+drAa9+Ei1ACgRgCoUAGDNRIypqLIODiMeB06eNV1HT0cHWZ0REQC5Rswn7kFpdXRU1QK792QD6YGaihoio5A5PH4YMGc31zWhxtKiPiwqTnp4eWK1WrcIriYUqaoBcooYVNUT0+sjrAIBNLZtQb6nXOBrjsZqsWONdAwA4NHlI42j04b333kMsFkNzc7Ph24jqyaWXXgoAeOuttzSOpHKYqCFagFpN09wMud54i7dILpmCQQy+H0UmI8HpzKClJaNxZIs3t/UZK2qJqFbJMvDB+0rCehP2IV2VFTXKTQSsqCEiKg91Po2vOufTAHNm1Mycmvc9VtQQkfDy6ZcBAFd1XqVxJMYlZp29P/m+xpHow969ewEAV1xxBSRJ0jia6iESNb///e+RyRjnWmYxmKghWoCR59MAgOx0It3UBAA48bZSGdTbm4KR1oz2diVRE4tJmJri4YqIapPfb8J00AIzUljXPg3Z4dA6pJITrc8G0AfziRPaBkNEVIXEXc9z59MAwJEjRwBUR6Kmx90DQKmoSWXyuwiszlajsqKGqLZl5IyaqLl2xbUaR2NcFzZfCADYN1E7s0PO5vXXlSqtK6+8UuNIqssFF1wAu92OQCBQM+s3r3wSLcBs8EQNkGt/duJgAgDQ12ec+TQAUFeXq6oRrduIiGqNaHu2DodhPr9X42jKQ7TlPIK1sHz0kcbREBFVH7Wipim/oubDDz8EAJx33nkVj6nUOpwdsJvtSGaS89qfiUTNyMgIIpGIFuERkQ4cmjqEydgkHBYHLm69WOtwDGtzy2YAwHvj70Gu8fYniURCnaHCRE1pWa1WXHTRRQBqp/0ZEzVEC7Bky+KNPLQ5lU3UHB9QftWNNJ9G6OxUEjVDQ0zUEFFtyptPs26dxtGUx+rVyvp0Aj1If3QKqJHSdiKiSpBlWU3UzK2okWW5qhI1JsmEXo9yQ8NAML/FWWNjIxobG5Xvsf0ZUc165fQrAIArOq6AzWzTOBrj2tC0ARbJgonoBIbDw1qHo6l33nkHsVgMTU1NWLt2rdbhVJ1LLrkEAPDmm29qHEllMFFDtABLtqzOyEObRTXQwLATgDETNV1dTNQQUW2bm6hJVmmiprU1A6czgwzMOB7rhHm4tk/4iIhKaTg8jGAiCItkQb831+Ls9OnTmJmZgdVqVStOjK7Pk51FE5yfjBH7yEQNUe363dDvALDtWbHsFjvOb1IS/++OvatxNNras2cPAODaa6/lfJoyEFVKor1ctWOihmgBVZGoyVbUHJlqBQD09RkvUbNiBVufEVFtO3TIAiBbUXP++ed4tjFJUq6qhu3PiIhK6+DEQQDAmsY1qDPXqY9/8IFSZdPf3w+brTruLD9boqYv2ymhVvrcE1G+aCqKN/xvAACuWXGNxtEY39z2Z7XsxRdfBABs3bpV0ziq1aWXXgqz2YzBwUEMDg6e+wcMjokaogKkYBDm8XEAxm99Ngkf/IlmAMC6dcZL1HR1KTEzUUNEtWhmRsKxY7lETbIKhj0vRNxMcBjrmKghIiqhd8bfAZC7qCaIRE01tD0TRKLmWHB+MoYVNUS17ZXTryCWjmGFawXWNVZnlXolXdSizA6p5UTN2NgYDh5UboZgoqY8nE4nNm3aBAB47bXXNI6m/JioISpAVNOk29ogNzRoHM3ypVetwkFcAABYuTIFl8t4Q95ERQ1bnxFRLXrvPStkWUIPjqOlzwHU12sdUtnkVdQcPapxNERE1eOdUSVRc+bgbHFxaf369RWPqVzOlqgRFTVM1BDVpucHnwcAbFu5jS2qSkAk//eN70MqY7ybgkvhpZdeAgBceOGFaG5u1jia6rVlyxYATNQQ1SxxJ6+R254BQLqzE/ulCwEA5/fOahzN8qxcqSRqBgctGkdCRFR5b7+ttKK5Aq8jsXGjxtGUV1+fcrz/EOexooaIqETSmbR6t/OZiZoDBw4AUC4wVQsxg8cf9mMmMZP3vTVr1gAAPvroI2QymYrHRkTakWUZz59SEjWfWPUJjaOpDv3efrhtbkRSEbw/+b7W4WhCzKdhNU15iTk1TNQQ1Sjrhx8CAJJGnwVgtWK/8woAwPpmv8bBLE93t3LhLhAwYXqad70QUW0RiZor8RqSVXQhrZC1a5MAgPexAZbDRwDZeFWgRER6c3j6MCKpCFxWF9Z416iPT01N4dSpUwCAjVV0I4C3zot2ZzsA4MPpD/O+19PTA5vNhnA4jNOnT2sRHhFp5MPpDzEcHobdbMeWzi1ah1MVzCYzLmu/DADw2kj1X0A/UzwexwsvvAAA+PjHP65xNNWtlubUMFFDVIAlm6hJVUG/5gOmzQCADbYj2gayTA6HjPZ2JVlz/Diraoiodsgy8M47uYqa5AUXaBxRefX3p2CxyAjCi9PBBpgmJ7UOiYjI8N4Zy82nMZtyrYRFNU1PTw88Ho8msZXL+Y3KzXYfTuUnaqxWqzqnRsznIaLa8JuTvwEAXNV5Feot1dtKuNKu7MhWOtRgoubVV1/FzMwM2tracMkll2gdTlVzOp246CJlJpJoN1etmKghKkCtqDF4okaWgUNRpRfzhfHfaxzN8vX0KP1OT5xgooaIasfAgBmBgAl1iGEz3qv6RI3NpiRrAGA/LmT7MyKiEhCJmjPbnu3btw8A1AG91WSdTxkSfmaiBgDOz3ZMOHz4cEVjIiJtPXv8WQDAp3o+pXEk1UUkat70v4l0Jq1xNJX17LPKe2r79u0wmXh5vdxEezkmaohqjGlqCuaxMQBAau1ajaMpztCQGTPJeliRwPkTr2odzrLlEjXmczyTiKh6iGqaS/A2TD0rIHu92gZUAeedp7Q/O4CNTNQQEZXAQomad95RHq/GRM15jcrNdoUSNevWZZM4H87/HhFVp5Ohkzg4eRBmyYxP9nxS63CqyoamDXBZXQglQjg0dUjrcComlUrhn//5nwEA119/vcbR1IY/+IM/AAC88sorSKVSGkdTPkzUEJ3BcvAgACDV0wPZ5dI4muJ88IFSgXIePkT9MeOejPT0sPUZEdWeufNpEjVSTn/eecqH7gPYCMvRoxpHQ0RkbMF4EB8FlKT33ERNJpPBW2+9BUDp+15tzvdlW59Nfwj5jHlnTNQQ1R5RTXNFxxXw2X0aR1NdLCaLOqdm7/BejaOpnNdeew1TU1Pwer244oortA6nJmzatAlerxehUAjvvvuu1uGUDRM1RGew7d8PAEhWwVDNDz+0AgA24gAsw8OQwmGNI1qevj7lwt2xY0zUEFHtmDufJvGxj2kcTWWcf75SUbMPm2A9VDt35RERlcO+caW9WXdDN5rqm9THjx07hkAgALvdjguqsK1mv7cfFsmCQDyA07On8763fv16AMBHH32EWCymRXhEVGHPnHgGAHB9LysfyuGqzqsAAC8NVXdLqrmeeOIJAMANN9wAi4XXqSrBbDbj6quvBlDd7c+YqCE6gzWbqElUQRuAAweyiRqHcley5dgxLcNZtnXrlETNkSMWZDIaB0NEVAGzs5JaFXklXquZRM3GjUqi5gOcj9j7p5Rha0REtCxv+N8AAFzSll+VKappLrroIthstorHVW52ix3nNylVNe+O599129nZCZ/Ph3Q6zaoaohpwInQC7469CwkS59OUySdWfQIA8NrIawgnjXlz8FLMzs7imWeU5N9nP/tZjaOpLddddx0A4IUXXtA4kvJhooboDNYDBwBUR0WNOt+gZxQADNvvv6cnBZtNRjRqwtAQ59QQUfV74w0bMhkJvRhAhyuEVLZVS7Vra8ugszMFGSa8G+qHeXBQ65CIiAxLtKHZ0rEl7/HXX38dQHW2PRM2t2wGkKsqEiRJwsbsed6B7HkfEVWvf/joHwAA16y4Bm2ONo2jqU6rPavR4+5BIpPAy6df1jqcsvv1r3+NSCSC3t5efKxGbqbTi23btkGSJOzbtw/Dw8Nah1MWTNQQzWGanITl1CkAxk/UDA+b4PebYTLJ2HRhAgAM2+/fYgFWr1aqag4fZlkpEVW/V1+tAwBsw/NIXH45YK6dJPXmzUpVzZu4DNbs3DgiIlqaSDKCd8beAZBrSwMAsizjlVdeUR6/6qqCP1sNRKLmvfH35n2PiRqi2iDLMn599NcAgD9c84caR1O9JEnCtlXbAAC/PfVbjaMpv//zf/4PAODmm2+GJEkaR1NbWlpacEl2dutvfvMbjaMpDyZqiOawZdsAJNetg+zxaBxNcUQ1zfnnp1B33koAxk3UAMDatcqFuyNHrBpHQkRUfq++qhzDP44XEM/24q0VF13ERA0RUbHe9L+JlJzCStdKrHKvUh8/fPgwRkdHYbfba6aiJp1J531PzOVhooaour099jZOhE6g3lLPtmdl9omVSvuz5089j4xcvf3qP/jgA7z00kswm81se6aR7du3AwD++Z//WeNIyoOJGqI5bG++CQBIVMFJy7vvKhf5Lr44gdSaNQCM2/oMAM47T6moef99VtQQUXWbmjLh/feVpPR12FODiRqlCvQ1XAnLvv0aR0NEZEwvDyvtZ7Z05rc9+93vfgcAuOKKK1BXV1fxuCpljXcNnFYnIqkIPpj+IO97F154IQDlglssFtMiPCKqgMcPPw4A+FTPp+C0OjWOprpd3nE5GqwNGIuO4S3/W1qHUzaimuZTn/oUVqxYoXE0temTn/wkAGDv3r0IBoMaR1N6TNQQzVFNiZp33lEu8l18cQLJ884DAFiOHYMUjWoZ1rJdeKFyh/X+/dU38JSIaK4XX6yDLEu4EPvQ0pxGKnsMrxWbNydhtWQwjBU49XYQyFTvXXlEROXy/KnnAQBbu7bmPS4G8F5zzTWVDqmizCYzLm+/HEBuVo+watUqtLS0IJlMsqqGqEqFEiE8eexJAMBt592mcTTVr85ch+t7rwcAtd1ctZmensYTTzwBAPjSl76kcTS1q6+vD2vXrkUqlcJzzz2ndTglx0QNUZYUCsG6X7lzN3HFFRpHU5xkMpfQuPjiBDJtbUi3tEDKZGD54INz/LQ+iUTN8eMWBIPsA0pE1ev555U7nG/AM4hv2waYauvjWn29jEsuVqpqXpq5BJaBAY0jIiIyllOhU/go8BHMkhl/0PUH6uPBYBCvvfYaAOBf/at/pVV4FbOlQ6kmOjNRI0mSOgD697//fcXjIqLye+LIE4imoljXuE5N2lJ5fab/MwCApweeRjwd1zia0vvFL36BWCyGTZs24bLLLtM6nJr2b/7NvwEAPPnkkxpHUnq1deZPdBZ1r70GKZ1GqrcX6a4urcMpygcfWBGLSfB6M+jrSwOShGR2aKbVoHeN+XwZrFqltD87cIBzaoioOqVSwIt77ACURE2sBi6kFbLlaiU5/wI+Duvbb2scDRGRsbwwpFTNXNp2KTx1ubmbL7zwAlKpFNatW4e+vj6twqsY0fbtDf8b8+bUMFFDVL1kWcb//eD/AgC+cP4XOPC9Qq7suBLtznYEE0G8cOoFrcMpqZmZGTz88MMAgG9961t8T2nsM59RkoKvvPIK/H6/xtGUFhM1RFl12X7N8Wuv1TiS4r32Wq6aRtyIncwOzTTyYGZRVfPOO2x/RkTV6c03bQgETfBhEpfb3q2KNWk5rrpKuQvvBXwclt+/o3E0RETG8twJpRXItlXb8h5/9tlnAdRGNQ0AXNB0Adw2N0KJEN4bfy/ve5dccgkA4K233oIsyxpER0Tl8sLgCzgSOAKn1Yk/XPOHWodTM8wmM25afRMA4NHDj2ocTWn9/Oc/RyAQQH9/Pz772c9qHU7NW7VqFS677DLIsoynnnpK63BKiokaIgCQZdT99rcAgPgf/ME5nqx/r7yitM255ppcuWkyOzTT9u67msRUCpdfrrTCef11JmqIqDo9/XQ9AODf4B+R3LYVssOhcUTauPjiBBrqExhHK957Iax1OEREhjEVm1Jbfd3Qe4P6eCAQwG+z5zuiZUi1M5vMuG7ldQCA35z8Td73LrzwQtTX12NychIfGLQ1NBEV9tC+hwAAf3zeH8Ntc2scTW257bzbIEHCC4Mv4GjgqNbhlMTk5CR+8pOfAAD+7M/+DGazWeOICMhV1ezatauqbrhgooYIgOXQIViGhpCx2w1/93I8nquomZuoSWTvGrN8+CGkYFCT2Ip15ZXK/rz5pg3JpMbBEBGVWDoNPPus0vbsc9iF6I03ahuQhmw24OPXxQAAT/svh/n0aY0jIiIyhv/vxP+HtJzGxuaN6HZ3q48//fTTSCQSOP/883H++edrGGFlfbL7kwCA507mDxyuq6vDFdm5pC+//HLF4yKi8njL/xbe8L8Bq8mKOzfeqXU4NafX04v/p/v/AQD8/+3dd3wU1drA8d9udje9k5CEkhASQu+I0pEiIIqCryIoKiIqeFGxIagXK1Zs4BWVIkpHmsoFpIm0KwgIoYVAIEA66cluki3vH2sWQkIaSWYXni+f/YTMzmafM7tznpk5c86ZGz1X4WhqxkcffURWVhatWrXi7rvvVjoc8Y9hw4bh5ubGyZMn2b17d8UvcBDSUCME4LrBeuBe0KcPFldXhaO5Pn/+qUOvV1OvnonmzY225ebAQIyhoagsFnQHHHMYmagoI76+JvR6NYcOSa8aIcSNZfduHampTviSTl/3/2Ho16/iF93ABt1lzWGruRftHzsVjkYIIRzD6ljrxLpX9qYBWLp0KQD33XdfncekpL6N+qJVa4nNjC11d3fPnj0B6xj3QgjHZ7FY+Gj/RwCMiBhBsHuwwhHdnMa1HgfAilMruKS/pHA01+fo0aMsWrQIgLfeekt609gRLy8vRoywDm04f/58haOpOdJQI4TFguuqVQAYhgxROJjrt2mT9W7s/v0NXD2/WeE/k2bq9u2r67BqhFoNPXpYhz/bvNlZ4WiEEKJmLVtmHebsfpZjHHE3OPiNA9fr9tsLcHEq5BTNOLpWetQIIURFzmafZU/iHlSoGB4x3Lb80KFDHDx4EJ1Od9ONre+l86JXA+uICStOrSjxXHFDze7du9Hr9XUemxCiZm08vZGdCTvRqXU81/E5pcO5aXUL7ka7eu3QG/V8dvAzpcOptqKiIl544QXMZjNDhw619cIU9uOxxx4DYOPGjVy4cEHhaGqGNNSIm572wAE0Z89idnXFMGiQ0uFcF4vlckPNHXcYSj1feNttADg7cPf+gQOt5SoupxBCOaqMDHT79uG8aRMu69ejPXQIVWam0mE5pMxMFet/tdZr4/iOvIcfVjgi5Xl4WLizRwoAP+5pAYWFCkckhKhNubm5HDhwgC1btvDLL7+wb98+kpKSlA7LoSyPWQ5A74a9aeDRwLZ83rx5AAwdOhR/f39FYlPSA1EPALAyZiVG8+URB1q0aEGjRo0wGAxs375doeiEEDXBZDbxyuZXAHik5SM08mykcEQ3L5VKxau3vArAD8d/4Gz2WWUDqqbZs2dz5MgRfHx8eOutt5QOR5QhKiqKHj16YDabmTVrltLh1AiN0gGI2qOJjsZ1/Xp0e/eiOXcOVWYmFl9faNUKtwEDyL/7bixeMrGa2+LFABgGD8bi7q5wNNfnwAEtFy5ocHU107Nn6Qtaht69AawXUzMyrN8HB3P77QacnCzExGiJjXUiIsKkdEh17swZJw4c0JGdrSYw0ESbNkU0bmwq1YNKiBpnsaA5ehS3Vatw3rwZ7enTpVdRqSi87Tb0995L/ogR4Cy93ypj6VI3CgrVtOVvWt+iIb1lS6VDsgsPTHDmp99hSdH/8eqWDegG91A6JIei16uIj3ciL0+Ft7eZxo1NaLVKRyWElcVi4dixY6xdu5YtW7Zw8uTJMieDbd68OUOHDmX06NEEBgYqEKljMBgNLDphHZ5lZNRI2/L4+HjWrFkDwOOPP65EaIob0HgAfi5+JOUnsSV+C3eEWeetUalUDB48mG+++Yb169czePBghSO1T0XmIqLToonLjkNv1OOt8ybCJ4Im3k1wdpLjPGEf5kbP5XDyYbx13kzqMKlKr7106RLHjx/n3LlzxMfHk5SUhF6vR6/XYzKZ8Pb2xtfXl4CAAFq3bk379u0JCAiopZLcGHo26Emfhn3YfmE7b+x+g03NNikdUpXs27ePTz/9FIC3336b+vXrKxxR3TOajcRlxXE66zRp+jQKTYU4qZ0IcA0gxCOEEPcQAlwDUCl8Ier5559n586dLF68mOnTp+Pi4tg3dUtDzQ3Ieft2PD/+GN3Bg6WfTEyExES8N2/G8513yH7lFfLHjIGbdJxFVUYGbv+cuOSPGaNsMDXgp5+sw+YMHmzA1bX0ia45JISiqCi0J0/ivGMHhmHD6jrE6+bjY6F37wK2bnVhxQo3Xn01R+mQ6sy+fVo++MCLPXtKnxAFB5vo3dtA794F9OhRiL9/6c9fiGqzWHDesQPPTz5Bt39/iaeMDRti9vcHJyecEhJwSkrCefdunHfvxuPLL8meMgXD3XcjLYnXVlgI382x1t+T+IK8ZyYqHJH9uK1bEZFeCZzKDmHRLCOPyTW0ChUUwC+/uLJ4sRv79+swGi/vexqNhaZNjXToUEinTkV07FhIs2ZG1NLHXtQhi8XCtm3b+Oyzz/jrr79KPBcUFERAQADOzs4kJyeTkJDAiRMnOHHiBLNnz2bcuHFMnDgRT09PhaK3X6tiV5GmT6OBRwMGh12uLGfNmoXJZKJ37960b99euQAVpHPSMSpqFLP+nsWXf3/JwNCBtgtLQ4YM4ZtvvmHTpk3o9Xpcb/JhR690JusM3x/7nhUxK8gqzCr1vFatpXW91nQK7ETn+p3pGNiREPcQxS/aiZvP+ZzzfLD/AwBe6/oafi5+5a6fnJzM5s2b2bt3L3/99Rfnzp2r8ns2bNiQAQMGcNddd9GlSxfUcjBVyhtd32B3wm42x2/mh8M/MCBwgNIhVUpqaipPPfUURqORYcOGce+99yodUp25pL/ElvNb2By/md8v/E5uUW6563toPYjwiaCpd1MifSOJ8I4g0jeSBh4NcNXUTT699dZb6dWrFzt27GD69Om8//77dfK+tUUaam4g6kuX8Hn+eVy2bAHAotViGDiQgj59KGrVCrO3N06XLlEvJgbj11+jiY3F57XXcFu9moyvvsLUsKHCJah77gsWoDIYKGrZ0jZ/i6PS61WsXWutCEeMuPYYy4Z+/dCePInrr786ZEMNwMiR+baGmhdeyEGnUzqi2qXXq5g+3Ysff7T2+NJoLHTqVEhAgJn4eCdOnNCSmOjE0qXuLF1qXSc42ESHDtC0qSetWhVy++0FuLtL442ohpQUfB95BJfNmwGw6HQYBgxAP2wYhbfdhtmv5ImQ0/nzuK5bh/vcuWji4/GbMAHD8uVkffghpgYNynqHm97q1a4kpmgJIpH7Wx4k53bpWl9MrYZ/PZzApNkhfHGoPyNTs3ENcFM6LLtkMsHixW58/LEnaWmXb8Dx9jbj6Wnm0iU1er2akye1nDyp5Z95xfHwMNO0qZEmTYw0aWL656eRli2N13gnIarv4sWLTJ482TZ5u06no3///tx1113ceuutpXrMZGVlsXHjRhYuXMjBgwf58ssvWbFiBTNmzGDgwIFKFMEuFZmLmP33bAAeb/U4GrX1NP/kyZMsWbIEgOeee06p8OzCuNbj+C76Ow6mHGTHxR30bmgdaaBTp06EhoZy7tw51q1bxwMPPKBwpMpLzU/l/X3vsyxmGRas5w8+zj608GuBh9aDNEMasRmx5BTlcDDlIAdTDvJd9HcAuGvdaeLVhCbeTWw/OwV2oqlPUyWLJG5gRrORZ7c/i96op2fjnjzY/MEy18vMzGTp0qX88ssvHCzjpuawsDCaNGlCaGgoISEhuLu74+rqilqtJisri/T0dC5evMjhw4c5deoUFy5cYP78+cyfP5+goCBGjBjB6NGjCQ0Nre0iO4wovygmd5rM+/veZ9J/J7H+nvWEeYUpHVa58vLyePTRR0lKSiIyMpKPPvrohm98tlgs7E7YzcLjC/lv3H8xWi6fA7hp3Ij0iSTQLRBXjStF5iKS8pNIzEskJT+F3KJcDqUe4lDqoVJ/11vnTX23+tR3r0+QW5DtZ0OPhnQM7Ii/a80NxfrSSy+xY8cOFi5cyL333sstt9xSY3+7rqksZfUvF9WWmppKUVFRnb+vJjoav7Fj0Vy8iEWrJe/RR8mdOBHzVd0xVSoVwcHBJF64gOvChXi9/z7qnBzM3t5kzpzpMHO02MqRmFjmEAmV+hs5OdS/9VbUmZmkf/WVIo0WNVGOYosWufHyyz40bmxk586Ua3aS0kRHE3jHHVhcXEg6dAhLDdyRWJPlqIzCQujatT4pKU7MnJnBAw/UzOSfdV2Oyjh2TMPEib7ExFjHqnnwwTyefz6HBg3MtnX0evjzT2e2b7c+ite9kqenmfvvz2fy5Bx8fOyjbFfSarXSffwqSuWTK7ls347f5MmQnIxFpyNvzBhyJ0zAXImu36r8fNznzMHzyy9RFRRg9vAg+7XXyB89mpq+fd8e991ruTpWvR563eZPQqozH/Eijy3pTEGvXkqHCdjPdi0qtNA30kScsTEv9NvL5IWNS61jL7FWRm3EumuXjn//25vjx631f3CwiYceymP4cD2NGlmHxjSbITFRzdGjWv76S8eBAzoOHdKSn1/2/ujmZmboUDVDh6Zz++0Gu+4Ud+U21Wg0kk+uolQ+ufJzMZvNrFmzhqlTp5KdnY2LiwuPPPIITz31VKWGM7NYLGzcuJG3336bs2fPAtb5Vt5+++0aGw7NkeqRYsUxf7DlA6bsnIK/iz+7H9iNh84Di8XCyJEj2blzJ0OGDOHbb79VOlzFt/Ebe95gbvRcmvk0Y9OITWjV1jpz1qxZzJgxgw4dOvDLL7/YTbxVdb3xFpoKmXd0Hp8e+NR2F/XtjW7nsVaP0adhH9Sqy/nCYrEQnxPPXyl/8VfyX/yV8hfHLh3DZCl7WOoWfi0YHjGcR1o+grvWvUbirW1yflI2ezhHudJ7f77H7L9n46H14MCTB/Ao9CjxfYqNjWXu3LmsWLECvf7ydYMOHTrQt29fOnfuTPv27fH29q70e+bk5LB3715+/fVXNm7cSHZ2tu25Xr168dBDDzFw4EC01Rxv1t73jaowmo0M/2U4fyX/RYRPBOvuXoe3c+W3dV0yGAyMGzeObdu24evry5o1a4iIiCixzo302WQXZrMpeROz9s7iVOYp2/JW/q0Y0HgA/Rv3p11AuxJ1/5UKTYWczT5LbGYspzJPEZsZS2xmLKezTpNXlFfh+4d7h3Nb8G3cFX4X3YK74aS+vpGeXnzxRZYsWULTpk3ZtGmT3Q2BVtmcIg01NUyJpOW6Zg3eL7yA2mDAGBZG+ty5GJs3L3PdqysVp/h4fCdMsA2Tljt2LNmvvWb3cwrUROXo+d57eM6eTVHTpqRu26bI8G81VckbjXD77QGcPq3ljTeyePLJcipFi4WA3r3Rnj5N5vvvk18DE1Yrkay+/tqdt9/2JizMyNatKTXylbWnpGs2w7ffuvP++14UFqoIDDTx+ecZ9OpV8WTa2dkqTpzQkpBQj7178/jjD2fOnrXeWRkQYOK997IYMsRQ20WoEjkRKk3RkyCDAa8ZM/D4znp3ZFFUFBmzZ2Ns0aLKf0oTG4vP5Mno/hnepqBbNzI//hhTDd5tZk/7bkWujvXTme58/Ik3jYjncO/x5C+ep3SINva0Xbc9t52HVoxCRyHrN6XTopW5xPP2FGtFajLW2Fgn3nvPi40brT1qfXzMTJ6cw5gxeZWai8ZohNOnNcTFaYiLcyIuTsOZMxpiYzWkpl4+LmrXrpCXX86hT5+C64q3tkhDTfmUbqg5duwYr776KuvWrQOsF8e++OILwsPDq/w39Xo9n376KV9//bVt3oA33niDBx544LrveHWkeqSYSqVC560j6ssoLhku8U63d3is1WMALF68mJdeegkXFxe2bNlCWFiYssGi/DbOMGTQa0Uv0g3pvNTpJZ7r+Bxg3UduueUWCgsLWb58Od27d7eLeKuquvFaLBY2nN3AO3++Y5v0u229trzV7S261O9S6b9TaCokPieeM1lniMuKIy47jlMZp9ifvN92h7a/iz8T203ksVaP4axxtuvtK+cnZbOnhpqlJ5fywo4XAPim/zc80f0J280BO3bs4LvvvmPr1q229Vu0aMHDDz/MoEGDamzOkYKCArZu3cqPP/7I77//bvsuBwYG8sADDzB69GgaNWpUpb/paHVPRVL0Kdy17i4uZF+gc/3O/DDoB7x09jVftl6v5/HHH+f333/HxcWF5cuX06lTp1LrOfpnY7FY2J+8nx9P/MgvZ37BYLJeF3LTuDE8YjhjWo6hlX+r636PnKIckvOSScpPIikvieT8ZJLzk0nKSyI2M5aYzJgSrwlyD2J40+GMaj6KJt5NqvW+WVlZ9O3bl+TkZB5++GG7GwJNGmoUUqdJy2SyXkj7z38AMPTtS8asWVh8fK75kjIrlcJCvD74AI+vv7b+2qaNdSi0apw81ZXrrRw1J08SMGgQqsJCLs2fT4FCQyfUVCW/bJkrkyf74uNjZu/eZDw9y/9b7t9+i/f06RRFRFgbqa7z7nYlklVurooePQJJTXXilVeymTSp/LEzK8Neku7580688IIPu3ZZW5/69zcwc2Ym/v7mCl552ZVlMZks/P67M2++6cWpU9Yrdw89lMf06VnYyzDcciJUmmI9NGNi8J0wAe3x49YFzzxD4vPPY7meO1JMJtznzcPz/fdRGwyYXV3JeeUV8saMqZEbA+xl362MK2M9ftyJQQP8KDJrWKQdQ78/JmKq4olcbbKr7ZqVzfi2Z/nVOIjI+un8sqMAD4/LMdlVrBWoiVhTUtR8/rknP/zghsmkwsnJwsMP5/PCC9n4+V1/+S0WOHxYx2+/1WPOHLOt103//gamT8+iSZOy75hWijTUlE/Jhpro6GjGjBlDUlISTk5OPP/88/zrX/9Co7m+Ebijo6N58cUXOXLkCADdu3fn7bffJioq6rridZR65Eov7X2JxUcWE+UbxYZ7N6Bz0nHy5EnuvPNO9Ho9r7/+Ok899ZTSYQL2sY1XxKzgud+fw0nlxLI7l3Fb8G0ATJs2jQULFtC5c2fWrFmDSqWyi3irojrx7k/ez4w/Z7A3aS8AAa4BTOkyhfub3X/Nu6irKrMgk/Vx65n992xbQ1BT76a83f1tHuzyoN1uXzk/KZu9NNT8fOZnJmydgNli5pl2zzC161S8vb2ZPXs23333HTEx1gvBKpWKAQMGMG7cOLp161arw1jFx8ezaNEili1bRmpqqu39+/Tpw+jRo+nfv3+letk4Wt1TEZVKRYoqhd7ze5NVmEWbem2YP3A+we7BSocGQGJiIo8//jh///03rq6uLFiwgB49epS5rqN+NhdzL/Jr3K8sObGkRCNJ68DWjIocxfCI4Xjq6m7+vwxDBvuT97Pl/BZ+PvMzmQWZAKhQ0bdR3zJ7clZEpVJx8OBBhg4disViYcaMGYyxo7nIpaFGIXWVtFQZGfhOnIjL778DkPPMM+S8/HKFvULKq1ScN2/G57nncMrIwKLTkT9yJHmPPoqxWTO7mwT6uipHg4F699yD7sgRDP36kf7994qVryYq+fR0FX36BHLpkhOvv57FU09V3MVQlZND/S5dUOfkkPHll+iHD6/We9v+nkLJauVKV5591het1sKaNWm0b399+57SSTcrS8WXX3oyd647hYUqXF3NTJ+ezejR+VX+ipZVloICmDnTk9mzPbBYVLRoUcTXX2cQEaH8PARyIlRanZ8EWSy4ff893m+/jcpgwOTvT9ann+L38MM1tk84nT2Lz4sv4rxnDwCmevXIf+ghDAMHUtSmTbUbjZXed6uiONYTJ5K4s48bZ5K9uJu1zP/4NIYHRyodXgn2tl0N731Lz9njSKABPbrm8f3iLIrbD+0t1vJcT6zHj2v49lsPVq92pbDQmhgGDDAwbVo2kZE1W5cXx3nkSDKzZrkzf747RUUqdDoLTz6Zy6RJubi52ce2loaa8ilxUU2v1zNjxgzmzp0LQHh4OF9++WWNTmZvNBr57rvv+OijjzAYrHeE9uzZk//7v/+jZ8+eVR4SzZHqkWILjy/k1Z2volapWXv3WjoGdiQ1NZVhw4Zx7tw5evbsyaJFi3BSYOSAstjDNrZYLEzaPolVsavw1nmzYugKWvm3Iikpie7du2MwGPjwww8ZPXq0XcRbFZWN12Q2seHcBuYcnsNfKdYezy5OLoxvM56J7SbiofOolfiMZiMrYlbwwf4PSNVbL2IPbzGcKe2n0MDD/uYxlPOTsindUGOxWJh7dC7T90zHgoWRzUYyOWIyCxcuZPHixaSnpwPg7u7OyJEjGTt2bJ33KCwqKmLjxo38+OOP/PHHH7blHh4e3HbbbfTq1YsuXboQERGBaxl3Tjpa3VOR4vL8duQ3Rq4fSbohnXqu9fis92f0bdRX0dg2b97Miy++SGpqKr6+vsyfP58uXa7dk9CRPptTGaf479n/suHsBv5O+9u23FXjyrDwYYxuMZo7291JUlKSomUpMBWwNX4ri08uZuv5yz3gwrzCGNNiDA9EPYCPs0+Ff6f4s3n11Vd5//33UalUfPjhh4waNaoWo688aahRSF0kLe2hQ/hOmIDm3DnMrq7WuWXuvrtSr62oUlEnJODzwgu47NhhW2YMDaWoVSuMzZphbNoUY6NGmEJDrfPfOFoDh9mMz7PP4rZqFSZfX1J/+w1zsHKt+NdbyZvN8Nhjfmze7EJUVBEbNqSi01XutR5ffIHXBx9gql+f1M2bS00IXhVKJSuLBZ54wpf//teVwEATq1alXdddvkqV49IlNfPnWy+CZWZaL1R3717A++9nEh5evfKUV5bff3dm0iQf0tKccHU18+67Wdx/v17R9lg5ESqtLk+CnM6fx3vKFFy2bwesPTQzZ87EUr9+ze8TZjNuixbh+fnnOCUmXl7s5WXNMU2aYAoLw9igAaaQEEz//Cyv+5cjHTCrVCo8PIIZ0DmV/8UE0Ih4fr/3PZy/fP3GuimiNuj1xPd+gQEXfyAXT7p0KeDbbzMICDDbX6zlqGqs2dkqfv3VlZUrXdm793IPtI4dC3nllWx69Kh4SMyaiDM21ol//9ub7dutrWNBQSbeeCOLu+4y1PS0U9cVqzTUlFbXF9V27drFlClTOHPmDACPPvoor732WpkXo2rCuXPneOedd9iwYQNm8+Xexw0bNiQsLIywsDAaN25MSEiI7REUFFTqrmZHqkcA1p1exzPbnsFkMfFa19d4uu3TJCYmMnr0aE6ePEnjxo35+eefqVevntKh2tjLNtYb9YxcP5L9yfvx0nnxdb+v6d2wN3PmzOGtt97Czc2NVatW0bZtW7uIt7Iq2r6nM0/zU+xPrDy1kou5FwHQqXUMjxjO5E6T66yxJLswm0/++oT5R+djsphwcXLhmfbPML7NeNv8NfZAzk/KpmRDzSX9JabsnML6s+sB6O/dH91mHRs3bMRksp43N27cmLFjx/LAAw/g5aX88FpxcXEsXryY5cuXk5aWVuI5tVpNaGgoYWFh+Pv7ExAQQL169QgMDKRp06aYzWa8vb3x8fHB29vbbhrdq+rKuikuK45xv43jeLp19IZ7mt7Dy51fJtSr5obFroyEhARmzJjBqlWrAGjevDnz5s0jtILhue0lj5UlTZ/GroRd7ErYxc6LOzmXc872nAoVXep34Z6Ie7g34l68dF52WZa4rDgWHl/IspPLyCrMAqw3EoyIHMGDUQ+WO2dOcXkSEhJ45ZVX+PHHHwF4+umnefnll9FV9mJpLXHohpoNGzbw888/k5mZSWhoKGPHji01gdOV9uzZY+taGBQUxOjRo+nYsaPteYvFwvLly9myZQt5eXk0b96ccePGEXzFBfrc3FzmzZvHX3/9hUqlomvXrjz22GNVnnyoNpOWSq/H/euv8fzsM1RGI8ZGjazz0bSq/PiBld0RdXv24DFnDs6//46qsOwLAGYXF0xNmlDYrh1F7dpR1KEDRc2bU6lB0a9TdSoUlV6P90sv4bZ6NRaNhvQfflB8wubrqRiLimDKFG+WLnXH2dnao6Rt2yp89wwGAgYORHv6NAW33Ub6woVY3NyqWAIrJSv47GwVw4fX4/hxLf7+Jj79NJN+/ao3hn5dlyMmRsOCBe4sW+aGwWC9QBsZWcRrr2XTr1/BdV2zragsyclq/vUvX9vwam3aFPL007n071+Au3vdpwV7PhGq6ZxUWXVxEqTKzsZ97lw8vvoKdX4+FmdnsqdOJW/sWFCra3efKCrCZf16XNetw3nnTtS55Q9faAoMpKhlS4patsTYqhVFrVtjDA+v/Thr2KkTap4Z7UR0UgA+ZPDfW16l8fJX6yR3VpU9blft/v0cH/EZw4w/kYkv/v4mXnklhwce0NO4sX3Fei2V2a56PfzxhzOrV7uxaZOLLUc4OVkYMsTAE0/k0qlTLdcPZcRpscCmTS5Mn+5FfLx16KpGjYyMHJnPgAEGWrQwKtJo40gNNUrklLq6qHbq1Ck+//xzVq9eDUD9+vVZsGAB7dq1q5P98sKFCyxatIht27bZhkS7FpVKRYMGDWjRogUtW7akRYsWtG7dmttuu43k5GS7rkeKzEV8efBLZh6YiQULj7V/jHe6vMO2bduYPHkyKSkpBAUFsXLlSpo0qd4477XFnvJKVkEWj216jP8l/Q+Ah5o/xKT2k3jhiRf4448/8Pf3Z968edx99912EW9llLV9k/KS2HhuIytPreRAygHbur7OvoxpOYZHWz5KoFvVep/VlBMZJ3hr31v8fs46SoiH1oN7I+7lziZ30rl+Z1w1yo7RbM/nJ9VV1RxUFiUaajILMvnh+A/MPjSbnKIc1BY1nv/zJGtDlm2dbt268dJLL9G5c2fUSt9BUgaz2Ux0dDQ7duzgjz/+4OjRo2RkZFT69SqVytZo4+vrS3BwMCEhITRo0KDEjQiBgYF2V/6r6ya9Uc+MfTOYf3Q+ZosZjUrD3U3v5qHmD9ElqEuNDbtYllOnTjFv3jyWL19u6407btw4pkyZUqkbSuwpjyXlJXEw5SB7kvawO2G3rfGrmE6to0eDHgwKG8TAxgMJcCtZn9lTWa6WX5TP6tOrmX90foly+bv407thb3qE9KClf0sifSJx0Viv219ZHrPZzHvvvcdXX30FWBviXnnlFQYMGFCrwx+Wx2Ebanbv3s2sWbN44okniIyM5Ndff2Xv3r189tlneHt7l1r/5MmT/Pvf/2bUqFF07NiRnTt3snbtWj744AMaN24MwJo1a1izZg0TJ04kMDCQZcuWER8fz8yZM20tau+99x4ZGRmMHz8ek8nEV199RdOmTXn22WerFH9tJC11cjKuq1bhMXeu7e5j/dChZH7wQbnz0ZSlqjuiKjcX3f79aGJirI+zZ3GKj8cpMRGVufR8GWZXV4o6dKCwc2cKu3ShsFMnLGV8bterSuUoLMR17Vo8P/8cTVwcFo2GjC++wDBsWI3HVVXVqRjNZtizR8eMGV4cPKhDrbYwa1YGw4ZVfXJ4zfHj1Bs2DHVeHkXNm5P15psUdutW5eGHlK7gU1LUPPywH9HR1v35zjv1jBuXR5cuhVVq7KiLcsTHO7FlizM//eTGwYOXW/Tbty/kqadyGTLEUNEIhpVSmbKYTDB7tgdffulhm3/AxcVCu3aFtG5dRKtWRYSHm2jSxIi/v7lWb/a31xOh2shJlVVrJ0FGI7qDB3FZtw63n35CnWU9wSno2pXMDz/EdMXJWp3t20VFaGJj0cTFoTlzxppnEhJwungRpwsXUOfnl/kys4cHRW3aUNS2LR59+pASGoqxcWO765liNsORvUWs+CSdH/a2xoiWIBJZ2XcmTeZNpNJdIeuY0nX7tbiuWUPiM7MZaVnCEdoCENa4iKcmaOnePYXwcOWHcyxPWdvVZIJTpzT8+aeOLVtc2LlTh8FwORc3a1bEiBF6hg/PJySk8vOV1XScxfR6+PprD7791oOsrMtx+vqaaNHCSNOm1kdoqJGQEBMhISZ8fS21tms6SkONUjmlNi+qZWZmsmXLFtatW8eWLVuwWCyoVCrGjBnDq6++SlRUlCJ1SHp6OqdPnyYuLo6zZ89y4cIFEhISSExMJCEhgcJr3Ijm5eVFq1ataN26NW3btqVt27Y0adLELu5ivqS/xG/xv/H14a85lXkKgIeiHuJu7d3M+mIWO/4ZESEqKoqFCxfSsGFDJcMtk73lFYPRwPS90/nh+A+A9a7dYWHD+HPBn8Rti8NJ5cT48eO5//77iYyMVOziTmWpVCq8/L3YeGQjexL38Nu530oMd+OkcqJ3w97cF3kfA0MHKt4QolKpCAoK4j87/8NH+z+yzV8D1guMzf2aE+ETQVPvpjTxbkKIewghHiHUd6uPRn1981xVhr2en1RXVXPQtdRFQ43ZYuZs9ln2XdzH6mOr2ZuxlyL+ec9EYJ31p7e3N8OHD2fUqFG0atXKruqXilgsFlJTUzl58iQJCQmkpqaSmprKpUuXSE1NJS8vj9TUVDIyMsjLq3h4+2I6nY4GDRrQqFEjGjVqRMOGDW0/GzZsSP369eu8Iedadf/h1MN8sP8Dtl/Yblvm7+JPn4Z96NuoL639W9PEu8l17e+5ubns27ePPXv2sGPHjhI3cnTp0oU333yTdu3aXXdZapPJbOJC7gViM2M5mXGSg6kHOZhykMS8xFLrtvRrSfeQ7vRo0INbg24tdyhLe8vJZbFYLOxL3seCYwvYEr+F3KKSN3c6qZxo5NmIYPdgQtxDiKwfiSee+Lv44+/iz7H9x5j59kyyErPAAmFhYdxzzz307t2bVq1a4e5ed704HbahZurUqTRt2pTHH38csLY6P/300wwePJh77rmn1PqffvopBQUFTJkyxbZs2rRphIaGMn78eCwWC08++SRDhw7l7n+GB8vPz+eJJ55gwoQJdO/enQsXLjB58mRmzJhB06ZNATh06BAzZszgP//5D35VGBKqOknLZeNGVPn5qAwGVHq99WdWFk4XL6KNjkZ76pRtXWODBuRMnYp+2LBqXYiqsR2xsNAaX0wM2kOH0B46hO7vv20X/IpZVCpMDRpgDA/H1LgxZh8fLN7emD09seh01jl11GosTk7W8jg5WW/XvPIBqCwW65Wuf5apAB9vbzIzMqzlsFhKrKPOzESdkoImLg7dn3/a7tQ21a9PxhdfUHiNicHqWnmfx2+/OZOdrSY/X0VenoqcHDVnzlgv4iQlWU8WPT3NfP55JnfcUfVGmmLav/7Cb+xYnP7phmsKCKCwa1eMYWGYfX2xuLpaH87O4OREQb9+WK6608AeKni9XsVHH3ny7bfumM3WfSMgwETHjoU0bGiifn0z3t5mtFoLGg1oNBZbg8jlkFX4+vqSnp5RohwWi6rEelf+LGtZ8U+9XkVWlppLl9TExmqIidGSmHj5RF+jsdCvn4Fx4/K47baqNSpVpCqfSXq6mm+/dWftWlfOnSv7IMjT00xYmJHQUBP16pnx8THj62vGzc2CRmNBq7WWp0WLIiIiqj5cm72eCNV0TqqK6uQT7ZEjOMXFWfNIQYH1YTCgys3FKSkJp7Nn0UZHo9brba8pataMnOeew3DXXaUaae1h38ZiQZWVheb0abTHjlkfR4+iOXasRDmKmd3cMDVujKlRI0xBQZi9vLB4eFh/urpezjVqNRa12vp78c9r5Z/yHsC5NE8Ona+PvlCDvtDJ+jPPQnKahvg0T/5KbcIlk68txqGaDXz0ahxeT95td41KV7KLz/8anLduxfXZl/km/X7eYyqpXL4buL57Nq3qp9DIPwc/ryL8vIvwcDVCUACqRsFoNKBWl5UDStflV7o6F5S1fkV/q6hIRX6+GpXKi/Pn8zh/Xs358xrOnXMiL6/k/hcSYmTwYAP33aenTZuiOv+qVLbnz6+/urJmjSv/+5/O1uhfFhcXMyEhZkJCTNSvb8LLy4ynpwUvLzMeHha0WutnotFYew75+Jjp1atyw7o5SkONUjmlOvkkNTWV//3vfxQUFJR4GAwG0tPTSUhI4MSJE8TFxZV43eDBg3n22Wdp06aN3dYhZrOZS5cucfr0aY4dO8bx48c5duwYJ06csN1deyUXFxfbha7g4GC8vLzw8PDA09MTd3d3nJycUKvVtodKpbL932KxlHgUu3q5xWLhcOFhCswFFFoKKbQUUmQpQm/Rk25OJ8WcQoIlwfZ6Z6MzIUdCSNyYaIvZycmJRx99lFdffbXWhpm7Xvb6ndiTuIcP9n3AvuR9tmVqsxpzohnSgHxwV7kTWj8UP28/vDy9cNY646J1QafVodVoUalVNGnSBD8/v5KfNSXLWdZzV65j68FY/Nw11jcYDeQV5ZFblEuaPo34nHjO55znfM55TJbLx+IqVLQPbM9dTe7i3oh7Fes9U5Yrvw8ms4ndCbtZcWoFOxN2kpSXdM3XOamcqO9WnxCPEILdg/HWeeOl88JT54mXzgtnJ2ec1E5o1BqcVNafvRr0qvJE2fZ6flJdVc1B11KdnLJp0ybO5pzlbMFZCk2FFBgLKDQXUmgqpMhcRIGpgGxjNlmmLHLIIdslG7P2qhtTkoDd4H7Gnb59+jJo0CAGDRpkq+/stX6pjqvLUlhYSFZWFpmZmWRkZJCWlkZCQkKpR3JycokhQMui1Wrx9/fHz8/P9tPb2xsXF5cyHyqVqsSjOM+V9bjcA7t0/eXj40NGRkaJ54r/f7boLDsNO/m78G8MlMzDTjgRqA7ES+WFp8oTD5UHWrToVDo0//zDCAaDgcKCQgx6A3q9nvT0dC6lXSIr03qB3vqmoHZS07p1a/r370+zZs3KrIdt8VG6Pi7u2ZSRmVF6neJj/6vqbwuWMpdd+T5X1um5RblkF2aTkp9CUl4SSflJFJhKjxqjVqmJ8o2iY2BHeoT0oHtId/xd/cv9/K/kaPtMkbmIv5L/Ytv5bRxMPcixS8fIKKhkrzQLoAfygPx/HgZw07nh6+6Lp6snns6eeLl44aJ1wcnJCa2TFq2TFo2TBp1Gh5PKiXau7WgZ1ZKoqKgqx1/ZnFL7tyFUgdFo5MyZMyWShFqtpk2bNsTExJT5mpiYGIYOHVpiWbt27di3z3qQlZKSQmZmJm3btrU97+bmRkREBDExMXTv3p2YmBjc3d1tjTSA7eQiNjaWW265pdT7FhUVlUhOKpUKV1dXNJqqb1Kfb79FXcZJAQAeHtChA0UtWmC44w4Mt98Ozs5Ud4CU4ruAtFrt9e2IWi00a4apWTNMQ4daq1KLBU18PJqjR9EcP269kHbxIhpAk5MDR49W//2uwacyK0VGYvLzQ3/PPRiGDsXi7l7t7VfTyvs8Fi70ISOj9N17wcEQEWGmd+8CRo3KJyDADNdToltvJXPPHtx++AHnzZtx0utxvXgRLl4sc/VLPXpgvmqs1xr7Xl0HrRbeflvPY48VsW6dC9u3O6PXO5GS4kpKSlX/mm/Fq1RDUBA0aGChRQsj3bsXcPvtBfj4FB9I1ey3siqfSf368NprBl57zcD58xpiYjTExjoRF6chIUFNSooTFosa0FHOVwOAxx/PpUWL0hfPK1KdurO21UZOKktN5hOP33/HdcOG8ldq3hyzhwcFt95KYe/eFHbuDGp1md9Ae9i3AQgIgIAAim69FduWMpnQnD9v7e156hSucXFYTp5EXViIGtCmpcFV40DXlu3cwxeMK/2EFgiGxsHQgly6uv7NsP6X6Dm5N2lFne3+gNhuPv8ymO+4g/x93Xhi1Soe3/gEmy51YSu3s48uGPEiAy8yjED6Pw+AYwoGXCbrHVzOztCsGbi6mmnWzEiHDkV07Vp4Vc+guj9yqcznr9XCgw8aefDBHIxGOHNGw7lzGi5ccOLCBTXJyU6kpan/OZ5RA2ry8jT8M3VJucLDi+jXL7PKsdpDz4ey1EVOqcl8kpyczNdff13uOj4+PnTo0IHGjRvTs2dP+vbtS6NGjUq8P9hnHVI8REzPnj1ty0wmEzk5Oezbt4+YmBhiY2M5c+aMrSEkMzOTzMzM2gvqMaCMDpYqVNT/5x+XgFjgOFAAPi18qFevHv369WPw4MElhva2R/b6nejVuBe9GvfiYOpBdlzYwe6E3WQWZEJI6XXz/vlXlv2J+613+yvE180XXzdfAlwDaOHXgs71O9M1qCs+Lj7KBVWOK78PGouGvmF96RtmnVg8ITeBszlnuZBzgfM550nMSyRNn0aqPhWj2ZofTZi4kH+BC/kXKnyvTsGd8NNWbU5Wezw/qa7q5KCazCk//PADGaEZ0PXa62jRUu+ffwCYgHRwTnMmwimCDs060OqeVrRp06bUHGPF8YH91S/VcXVZtFot7u7uhISUUSldwWg0cunSJZKTk0lKSiIlJYXk5GTbIzU11TaXD1h7m+RWMPx0XWqhbgFBQGMgGPCjxFVrEyayyCr7xVfx/ufftWwzbmPbsW3XE26d8HP3w8/dD52TjgYeDWjk2YhIn0ia+zanmW8z27Bf1eFo+4wWLT0b96Rn48vHbmmGNBJzE0nVp3LJcIlcSy7n08+TVZhFliGLrMIssguzK/X3jRhJt504lm3//P2M/r/RtG7dusrxV7butKvMk52djdlsxueq4bx8fHxISEgo8zWZmZmluml6e3vbDqKLf1a0ztWTjDk5OeHh4XHNg/HVq1ezcuVK2+/du3fn2Wefxde3Ghd4d++ucBXtP4+q3QNybbU2qWRgIHTuXDt/+zo4AR7/POxRWZ/Hli3lvUINuP7zqAEBAfDmm9ZHBcprn7eHyUoDAqBrOQeAylNxeY+u/W9kVT+TgACoxnQqV7DnPa1qaiMnlaVG88l771kfFahqDWIP+3aZgoKgSxfbr0r1Tbn3n0f5PIDutt/sdIuWyW4//4AAePFFePFFRgAjlI7nulkbxK0P+5lMuSqff3AwdO9e8XqVowWqdiez3X5XqZucUpP5ZODAgQwcOLDKryuLPX8uVwsKCiIyMlLpMG549vqdGBgwkIEta+Z7LyqvrO9DQEAA7aj8cESifNXJQTWZU7aUf3GjRtlr/VId1SlLcHBwtS4ii5uXI+8zAQTQghZ194ZP1v5b2NcMUw7k3nvvZcGCBbbHE088UecTqlWHXq/nlVdeQV/GcDGORMphX6Qc9udGKsuNzp7ziaN8jxwlTpBYa4vEWvMcJU5wrFhrk73lE0f7XBwtXnC8mCXe2iXxippkbzmlIjfS9+lGKgvcWOWRstivG6U8dtWjxsvLC7VaXeousczMzFIt/8V8fHzIumpelKysLNv6xT+zsrJKtPxnZWURFhZmWyc7u2RXKJPJRG5u7jXfV6vVltnd0t5ZLBbi4uIcoltbeaQc9kXKYX9upLIopTZyUlnsOZ84yvfIUeIEibW2SKw1z1HiBMeItS5yir3lE0f4XK7kaPGC48Us8dYuiVdcS3VykL3llIrcSN+nG6kscGOVR8piv26U8thVjxqNRkN4eDjR0dG2ZWazmejoaJo1a1bma5o1a8aRI0dKLDt8+LCty3pgYCA+Pj4l1snPzyc2Ntb2N5s1a0ZeXh5nrhgwOzo6GovFQkRERI2VTwghhOOojZwkhBDi5iQ5RQghhFKqk4OEEELUPbtqqAEYOnQoW7ZsYfv27Vy4cIHvvvuOgoIC+vTpA8CsWbNYvHixbf0hQ4bw999/8/PPP3Px4kWWL1/O6dOnGTRoEGCdHGnIkCGsWrWK/fv3Ex8fz6xZs/D19aXLP+PaN2zYkPbt2zNnzhxiY2M5ceIE8+bNo1u3bvj5VW3COSGEEDeOms5JQgghbl6SU4QQQiilohwkhBBCeXY19BlAt27dyM7OZvny5WRmZhIWFsbUqVNt3THT0tJQqS5PFxwVFcWkSZNYunQpS5YsITg4mJdeeonGjRvb1hk2bBgFBQXMmTOH/Px8mjdvztSpU9HpdLZ1Jk2axNy5c3nrrbdQqVR07dqVsWPH1lm564pWq+W+++5zqC6sZZFy2Bcph/25kcqipNrISY7EUb5HjhInSKy1RWKteY4SJzhOrDdbTnGUz6WYo8ULjhezxFu7JF5RnopykKO7kb5PN1JZ4MYqj5TFft0o5VFZHH3wNiGEEEIIIYQQQgghhBBCCAdld0OfCSGEEEIIIYQQQgghhBBC3CykoUYIIYQQQgghhBBCCCGEEEIh0lAjhBBCCCGEEEIIIYQQQgihEGmoEUIIIYQQQgghhBBCCCGEUIhG6QBE3dmwYQM///wzmZmZhIaGMnbsWCIiIpQOq1zHjh1j3bp1xMXFkZGRwYsvvsgtt9xie95isbB8+XK2bNlCXl4ezZs3Z9y4cQQHBysYdUmrV6/mzz//5OLFi+h0Opo1a8ZDDz1ESEiIbZ3CwkIWLlzI7t27KSoqol27dowbNw4fHx/lAi/Dpk2b2LRpE6mpqQA0bNiQ++67jw4dOgCOU44rrVmzhsWLFzNkyBAeffRRwHHKsXz5clauXFliWUhICJ999hngOOUQ9uHo0aO8+eabZT733nvvXTNfTJ8+nWPHjpVY1r9/f8aPH1/jMV5p4sSJtrqo2KhRo7jnnnuu+Rol9omUlBR++uknoqOjyczMxM/Pj549ezJ8+HA0mmsfhtXVdq3qscGePXtYtmwZqampBAUFMXr0aDp27FijMV2tMnn0atu3b+err74qsUyr1bJo0aJajbWierksSmxTKHsfAhg4cCDjxo0rtbyutmltHfs54nHwjebAgQOsXLmSc+fOodPpaNGiBS+//LLSYVWoqKiIqVOncu7cOT788EPCwsKUDqmU6uaauuQo+2B1co49Kevcxh6lp6fz448/cujQIQoKCggKCmLChAk0bdpU6dCEHXOE49bKqkpZNm/ezI4dOzh//jwA4eHhPPjgg3ZVh1a3jt+1axeff/45nTt3tptjgqqWJS8vjyVLlvDnn3+Sm5tLQEAAjzzyiF1816pall9//ZVNmzaRlpaGl5cXXbt2ZdSoUeh0ujqMurSKzg/KcvToURYuXMj58+fx9/dnxIgR9OnTp24Cvg72cdQmat3u3btZuHAhTzzxBJGRkfz666+8++67fPbZZ3h7eysd3jUVFBQQFhbG7bffzscff1zq+bVr1/Lf//6XiRMnEhgYyLJly3j33XeZOXOm4hVJsWPHjnHHHXfQtGlTTCYTS5Ys4Z133mHmzJm4uLgA8P3333PgwAEmT56Mm5sbc+fO5ZNPPuHtt99WOPqS/Pz8GDVqFMHBwVgsFn7//Xc+/PBDPvzwQxo1auQw5SgWGxvLb7/9RmhoaInljlSORo0a8frrr9t+V6svd5R0pHII5UVFRfHNN9+UWLZ06VKio6MrPGnu168fDzzwgO33uqp/77//fvr372/7vbhOvRYl9omEhAQsFgvjx48nKCiI8+fPM2fOHAwGA2PGjCn3tbW9Xat6bHDy5Ek+//xzRo0aRceOHdm5cycfffQRH3zwAY0bN67R2K5UmTxaFldXVz7//PNai+tayquXr6bUNgWYMWMGZrPZ9nt8fDzvvPMOt9122zVfUxfbtDaO/Rz1OPhGsnfvXubMmcODDz5I69atMZvNxMfHKx1Wpfz444/4+flx7tw5pUO5puvJNXXBkfbB6uYce3Ctcxt7k5uby+uvv06rVq2YOnUqXl5eJCYm4u7urnRowo45ynFrZVS1LMeOHaN79+5ERUWh1WpZu3atrV7y8/NToAQlVbeOT0lJ4YcffqBFixZ1GG35qloWo9HIO++8g5eXF5MnT8bPz4+0tDTc3NwUiL6kqpZl586dLF68mKeffppmzZqRmJjIV199hUql4pFHHlGgBJdVdH5wtZSUFN5//30GDBjAv/71L6Kjo/n666/x8fGhffv2tR/wdZChz24Sv/zyC/369aNv3740bNiQJ554Ap1Ox7Zt25QOrVwdOnRg5MiRZbaUWiwW1q9fz/Dhw+nSpQuhoaE888wzZGRksG/fPgWiLdu0adPo06cPjRo1IiwsjIkTJ5KWlsaZM2cAyM/PZ+vWrTzyyCO0bt2a8PBwJkyYwMmTJ4mJiVE4+pI6d+5Mx44dCQ4OJiQkhAcffBAXFxdOnTrlUOUAMBgMfPnllzz55JMlTgocrRxqtRofHx/bw8vLC3C8cgjlaTSaEt8lDw8P9u/fT58+fVCpVOW+1tnZucRr6+rA1NXVtcT7lncBRal9on379kyYMIF27dpRv359OnfuzF133cWff/5Z4Wtre7tW9dhg/fr1tG/fnrvvvpuGDRsycuRIwsPD2bBhQ43GdbWK8ui1qFSqEtuvrnoTXqteLotS2xTAy8urRJwHDhygfv36tGzZ8pqvqYttWhvHfo56HHyjMJlMLFiwgIcffpiBAwcSEhJCw4YN6datm9KhVejgwYMcPnyYhx9+WOlQynU9uaYuONI+WN2co7RrndvYo7Vr1+Lv78+ECROIiIggMDCQdu3aERQUpHRowo45ynFrZVS1LJMmTeKOO+4gLCyMBg0a8NRTT2GxWDhy5EgdR1626tTxZrOZL7/8kvvvv5/AwMA6jLZ8VS3L1q1byc3N5aWXXqJ58+YEBgbSsmVLu+h9W9WynDx5kqioKHr06GGrl7t3705sbGwdR15aeecHZdm0aROBgYGMGTOGhg0bMmjQIG699VZ+/fXXWo70+klDzU3AaDRy5swZ2rRpY1umVqtp06aNQ1+wTUlJITMzk7Zt29qWubm5ERERYdflys/PB8DDwwOAM2fOYDKZSnw+DRo0oF69enZdDrPZzK5duygoKKBZs2YOV47vvvuODh06lPj+gON9HklJSTz55JM888wzfPHFF6SlpQGOVw5hf/bv309OTg59+/atcN0//viDxx9/nBdeeIHFixdTUFBQBxFah/cYO3YsL7/8MuvWrcNkMl1zXXvaJ/Lz8205oDy1uV2rc2wQExNTYn2Adu3acerUqRqLqzKuzqPXYjAYmDBhAk8//TQffvihbbiI2naterks9rJNjUYjf/zxB3379i23YVapbVqsOsd+N+pxsCOJi4sjPT0dlUrFyy+/zPjx43nvvffsvkdNZmYmc+bM4ZlnnrGbnvpVUdlcU9scfR+sbM5R2rXObezR/v37CQ8PZ+bMmYwbN46XX36ZzZs3Kx2WsGOOfNx6tZqoEwsKCjAajXZRL1W3PCtXrsTLy4vbb7+9LsKslOqU5a+//iIyMpK5c+fyxBNP8MILL7Bq1aoSvdaVUJ2yREVFcebMGVvDTHJyMgcPHrRNdeBITp06Veb+7wjHHTL02U0gOzsbs9lc6q5HHx8fEhISlAmqBmRmZgKU6rLn7e1te87emM1mFixYQFRUlK27bWZmJhqNptSdT/Zajvj4eKZNm0ZRUREuLi68+OKLNGzYkLNnzzpMOXbt2kVcXBwzZswo9ZwjfR6RkZFMmDCBkJAQMjIyWLlyJW+88QaffPKJQ5VD2Kdt27bRvn17/P39y12vR48e1KtXzzYszKJFi0hISODFF1+s1fgGDx5MkyZN8PDw4OTJkyxZsoSMjIxrdsu2l30iKSmJ//73vxXenV3b27U6xwaZmZmK59yy8mhZQkJCePrppwkNDSU/P59169bx2muvMXPmzAq/09ejvHrZ1dW11Pr2sE0B/vzzT/Ly8sodt1mpbXql6hz73ajHwY4kOTkZgBUrVjBmzBgCAwP5+eefefPNN/n888/t4kLT1SwWC1999RUDBgygadOmpKSkKB1SlVQ219QFR94HK5tzlFbeuY09SklJ4bfffuPOO+/k3nvv5fTp08yfPx+NRuMQ8weIuueox61lqYk6cdGiRfj5+ZW6EK2E6pTnxIkTbN26lQ8//LAOIqy86pQlOTmZ1NRUevTowauvvkpSUhLfffcdJpOJ//u//6uDqMtWnbL06NGD7Oxs2xDOJpOJAQMGMHz48NoOt8Zda//X6/UUFhba9Q040lAjRB2aO3cu58+f56233lI6lGoLCQnho48+Ij8/n7179zJ79uxrTkBuj9LS0liwYAGvvfaaXVfOlXHlnQ2hoaG2C4R79uxx+LKJmrNo0SLWrl1b7jqffvopDRo0sP1+6dIlDh06xPPPP1/h379yjpjGjRvj6+vLW2+9RVJSUpWHsKhKrEOHDrUtCw0NRaPR8O233zJq1Ci0Wm2V3rc6qrNd09PTeffdd7nttttKbLey1OR2vZFUNo82a9aMZs2alfj9+eef57fffmPkyJG1Fl959bI93TF4teKG2fLGOVdqmwr7Vdl60GKxADB8+HBuvfVWACZMmMBTTz3Fnj17GDBgQK3HWqyyMf/999/o9XruvffeOoqsbLWda0T5HOHczRHPbcxmM02bNmXUqFEANGnShPj4eH777TdpqBGiAmvWrGHXrl1Mnz7dYfb5K+n1etswjeUND+woLBYLXl5ePPnkk6jVasLDw0lPT2fdunWKNtRUx9GjR1m9ejXjxo0jMjKSpKQk5s+fz8qVK7nvvvuUDu+mIQ01NwEvLy/UanWpOwcyMzPrbLz22lAce1ZWFr6+vrblWVlZdjEe5NXmzp3LgQMHePPNN0vceerj44PRaCQvL6/End5ZWVl2+floNBrbRcLw8HBOnz7N+vXr6datm0OU48yZM2RlZfHKK6/YlpnNZo4fP86GDRuYNm2aQ5SjLO7u7oSEhJCUlETbtm0dthyiZt11110VnvTWr1+/xO/btm3D09OTzp07V/n9IiIiAKrVoFCdWItFRkZiMplITU0lJCSk1PM1XddWNdb09HTefPNNoqKiGD9+fJXf73q2a1mqc2zg4+NDVlZWiWV1WadcK49WhkajoUmTJiQlJdVSdGW7sl4ui9LbFCA1NZXDhw9XubeWEtu0Osd+N+pxsD2obD2YkZEBQMOGDW3LtVot9evXL3dowNpQ2Zijo6OJiYmxXUguNmXKFHr06MEzzzxTi1FeVte5pjY46j54PTmnLlV0brN48WLUavsa8d7X17dEfQDW+uF///ufQhEJe+eIx63Xcj114rp161izZg2vv/46oaGhtRdkFVS1PMU9UD744APbsuIbOkaOHMlnn32m2E1p1f2eaTSaEvVsgwYNyMzMxGg0otEoc9m9OmVZtmwZvXr1ol+/foD1ZkGDwcA333zD8OHD7S6XlOda+7+rq6vdN3BKQ81NQKPREB4eTnR0tG3iJbPZTHR0NIMGDVI4uuoLDAzEx8eHI0eO2E7O8/PziY2NZeDAgcoGdwWLxcK8efP4888/mT59eqmJ0sLDw3FycuLIkSO2uwwTEhJIS0srceeqvTKbzRQVFTlMOdq0acPHH39cYtl//vMfQkJCGDZsGPXq1XOIcpTFYDCQlJREz549HebzELXPy8urSncrWSwWtm/fTq9evap1YHn27FmAEhdRK6uqsV79viqV6pqvr+l9oiqxFl84a9KkCRMmTKjWQe71bNeyVOfYoFmzZhw5coQ777zTtuzw4cNERkbWSEzXUlEerQyz2Ux8fHydj7F8Zb1cFqW26ZW2bduGt7c3HTt2rNLrlNim1Tn2u1GPg+1BZevB8PBwtFotCQkJNG/eHLCOnZ6amkpAQEBth1lCZWMeO3ZsiZ5iGRkZvPvuuzz33HN1un/Wda6pDY62D9ZEzqlLFZ3b2Mv34EpRUVGlht5JSEio8/pAOA5HOm6tSHXrxLVr17Jq1SqmTZtG06ZN6yrcClW1PCEhIaXqrKVLl2IwGHj00UepV69encRdlup8NlFRUezatQuz2WyrbxMTE/H19VWskQaqV5aCgoJSc1XaYw6pjMjISA4ePFhi2eHDhx3iWpg01Nwkhg4dyuzZswkPDyciIoL169dTUFBg912Liy9wFEtJSeHs2bN4eHhQr149hgwZwqpVqwgODiYwMJClS5fi6+tLly5dFIy6pLlz57Jz505efvllXF1dbS3abm5u6HQ63NzcuP3221m4cCEeHh64ubkxb968UkOM2IPFixfTvn176tWrh8FgYOfOnRw7doxp06Y5TDlcXV1LjTHt7OyMp6enbbkjlANg4cKFdO7cmXr16pGRkcHy5ctRq9X06NHDYT4PYX+io6NJSUmx3UlzpfT0dN566y2eeeYZIiIiSEpKYufOnXTs2BEPDw/i4+P5/vvvadGiRa3e5RUTE8OpU6do1aoVrq6uxMTE8P3339OzZ0/bXAdXx6rUPpGens706dMJCAhgzJgxZGdn254rvptJqe1a0bHBrFmz8PPzs91RPmTIEKZPn87PP/9Mx44d2bVrF6dPn671u7YryqNlxbpy5UoiIyMJCgoiLy+PdevWkZqaWub3uiaVVy+XFadS27SY2Wxm+/bt9O7dGycnpxLPKbVNa+LY76233uKWW26xnYg66nHwjcLNzY0BAwawfPly/P39CQgIYN26dQC2hnN7c/WFIhcXFwCCgoLssndFZXKNkhxpH6xMzrEnlTm3sTd33nknr7/+OqtWraJbt27ExsayZcsWu+kFJuyToxy3VkZVy7JmzRqWL1/OpEmTCAwMtNVLLi4utvykpKqUR6fTlaqbikc7sIc6q6qfzcCBA9m4cSMLFixg0KBBJCUlsXr1agYPHqxgKayqWpZOnTrx66+/0qRJE9vQZ8uWLaNTp06KN9hUdH6wePFi0tPTbT2eiz+XH3/8kb59+xIdHc2ePXuYMmWKUkWoNGmouUl069aN7Oxsli9fTmZmJmFhYUydOtUuDtzLc/r06RLznyxcuBCA3r17M3HiRIYNG0ZBQQFz5swhPz+f5s2bM3XqVLs6iN60aRMA06dPL7F8woQJtgrykUceQaVS8cknn2A0GmnXrh3jxo2r40grlpWVxezZs8nIyMDNzY3Q0FCmTZtG27ZtAccpR0UcpRzp6el8/vnn5OTk4OXlRfPmzXn33Xdtd146SjmEfdm6dStRUVElxrsvZjQaSUhIoKCgALDeqXPkyBHbQZ+/vz9du3at9QkHNRoNu3fvZsWKFRQVFREYGMidd95ZYt6aq2MFZfaJw4cPk5SURFJSEk899VSJ55YvX15mrHW1XSs6NkhLSytxV1VUVBSTJk1i6dKlLFmyhODgYF566aVaP6mqTB69Otbc3FzmzJlDZmYm7u7uhIeH884775QaaqWmVVQv28s2LXbkyBHS0tLo27dvqeeU2qY1ceyXnJxc4kK1ox4H30geeugh1Go1s2bNorCwkIiICN544w1b47q4PpXJNUpypH2wMjlHXJ+IiAhefPFFFi9ezE8//URgYCCPPPLINXufCgGOc9xaGVUty2+//YbRaGTmzJkl/s59993H/fffX5ehl6mq5bFnVS1LvXr1mDZtGt9//z0vvfQSfn5+DB48mHvuuUeZAlyhqmUZMWIEKpWKpUuXkp6ejpeXF506deLBBx9UqASXVXR+kJGRUWI43cDAQKZMmcL333/P+vXr8ff356mnnqJ9+/Z1HXqVqSzFgwEKIYQQQgghhBBCCCGEEEKIOuWYg80JIYQQQgghhBBCCCGEEELcAKShRgghhBBCCCGEEEIIIYQQQiHSUCOEEEIIIYQQQgghhBBCCKEQaagRQgghhBBCCCGEEEIIIYRQiDTUCCGEEEIIIYQQQgghhBBCKEQaaoQQQgghhBBCCCGEEEIIIRQiDTVCCCGEEEIIIYQQQgghhBAKkYYaIYQQQgghhBBCCCGEEEIIhUhDjRBCCCGEEEIIIYQQQgghhEI0SgcghKgbGRkZrF+/ntjYWE6fPo3BYODf//43rVq1Ujo0IYQQDkZyihBCiJog+UQIIURNkZwiHJ30qBHiJpGQkMDatWtJT0+ncePGSocjhBDCgUlOEUIIURMknwghhKgpklOEo5MeNULcJMLDw5k3bx4eHh7s3buXmTNnKh2SEEIIByU5RQghRE2QfCKEEKKmSE4Rjk561Ajh4AoLC3nuued47rnnKCwstC3Pzc1l/PjxvPbaa5jNZlxdXfHw8FAwUiGEEPZOcooQQoiaIPlECCFETZGcIm4W0lAjhIPT6XRMnDiRpKQklixZYlv+3XffkZ+fz4QJE1CrZVcXQghRMckpQgghaoLkEyGEEDVFcoq4WcjQZ0LcACIjI7n77rtZu3Ytt9xyC1lZWezevZtHH32UkJAQpcMTQgjhQCSnCCGEqAmST4QQQtQUySniZiANNULcIO6//34OHDjA7NmzMRgMtGzZksGDBysdlhBCCAckOUUIIURNkHwihBCipkhOETc66RcmxA1Co9Hw9NNPk5KSgl6vZ8KECahUKqXDEkII4YAkpwghhKgJkk+EEELUFMkp4kYnDTVC3ED+/vtvAIqKikhMTFQ4GiGEEI5McooQQoiaIPlECCFETZGcIm5k0lAjxA3i3LlzrFy5kj59+tCkSRO+/vpr8vPzlQ5LCCGEA5KcIoQQoiZIPhFCCFFTJKeIG5001AhxAzAajXz11Vf4+vry2GOPMWHCBLKysliwYIHSoQkhhHAwklOEEELUBMknQgghaorkFHEz0CgdgBDi+q1atYqzZ8/y+uuv4+rqSmhoKPfddx9Lly7l1ltvpWPHjgD89NNPAJw/fx6AHTt2cOLECQBGjBihTPBCCCHsiuQUIYQQNUHyiRBCiJoiOUXcDFQWi8WidBBCiOo7c+YM06ZNY8CAAYwdO9a23Gw2M23aNNLT05k5cybu7u7cf//91/w7y5cvr4twhRBC2DHJKUIIIWqC5BMhhBA1RXKKuFlIQ40QQgghhBBCCCGEEEIIIYRCZI4aIYQQQgghhBBCCCGEEEIIhUhDjRBCCCGEEEIIIYQQQgghhEKkoUYIIYQQQgghhBBCCCGEEEIh0lAjhBBCCCGEEEIIIYQQQgihEGmoEUIIIYQQQgghhBBCCCGEUIg01AghhBBCCCGEEEIIIYQQQihEGmqEEEIIIYQQQgghhBBCCCEUIg01QgghhBBCCCGEEEIIIYQQCpGGGiGEEEIIIYQQQgghhBBCCIVIQ40QQgghhBBCCCGEEEIIIYRCpKFGCCGEEEIIIYQQQgghhBBCIdJQI4QQQgghhBBCCCGEEEIIoZD/B8SJ+D65v1G0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# data\n",
        "x = pd.DataFrame({\n",
        "    # Distribution with lower outliers\n",
        "    'x1': np.concatenate([np.random.normal(20, 2, 1000), np.random.normal(1, 2, 25)]),\n",
        "    # Distribution with higher outliers\n",
        "    'x2': np.concatenate([np.random.normal(30, 2, 1000), np.random.normal(50, 2, 25)]),\n",
        "})\n",
        "np.random.normal\n",
        "\n",
        "scaler = preprocessing.RobustScaler()\n",
        "robust_df = scaler.fit_transform(x)\n",
        "robust_df = pd.DataFrame(robust_df, columns =['x1', 'x2'])\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "standard_df = scaler.fit_transform(x)\n",
        "standard_df = pd.DataFrame(standard_df, columns =['x1', 'x2'])\n",
        "\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "minmax_df = scaler.fit_transform(x)\n",
        "minmax_df = pd.DataFrame(minmax_df, columns =['x1', 'x2'])\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols = 4, figsize =(20, 5))\n",
        "ax1.set_title('Before Scaling')\n",
        "\n",
        "sns.kdeplot(x['x1'], ax = ax1, color ='r')\n",
        "sns.kdeplot(x['x2'], ax = ax1, color ='b')\n",
        "ax2.set_title('After Robust Scaling')\n",
        "\n",
        "sns.kdeplot(robust_df['x1'], ax = ax2, color ='red')\n",
        "sns.kdeplot(robust_df['x2'], ax = ax2, color ='blue')\n",
        "ax3.set_title('After Standard Scaling')\n",
        "\n",
        "sns.kdeplot(standard_df['x1'], ax = ax3, color ='black')\n",
        "sns.kdeplot(standard_df['x2'], ax = ax3, color ='g')\n",
        "ax4.set_title('After Min-Max Scaling')\n",
        "\n",
        "sns.kdeplot(minmax_df['x1'], ax = ax4, color ='black')\n",
        "sns.kdeplot(minmax_df['x2'], ax = ax4, color ='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzvHvAlmP8i4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y_-hvc6QElc",
        "outputId": "a3f50f9a-b654-4c24-8a43-64122c6b10f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The distribution of categorical valeus in the Sex is : \n",
            "M    725\n",
            "F    193\n",
            "Name: Sex, dtype: Int64\n",
            "The distribution of categorical valeus in the ChestPainType is : \n",
            "ASY    496\n",
            "NAP    203\n",
            "ATA    173\n",
            "TA      46\n",
            "Name: ChestPainType, dtype: Int64\n",
            "The distribution of categorical valeus in the RestingECG is : \n",
            "Normal    552\n",
            "LVH       188\n",
            "ST        178\n",
            "Name: RestingECG, dtype: Int64\n",
            "The distribution of categorical valeus in the ExerciseAngina is : \n",
            "N    547\n",
            "Y    371\n",
            "Name: ExerciseAngina, dtype: Int64\n",
            "The distribution of categorical valeus in the ST_Slope is : \n",
            "Flat    460\n",
            "Up      395\n",
            "Down     63\n",
            "Name: ST_Slope, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "df[string_col].head()\n",
        "for col in string_col:\n",
        "    print(f\"The distribution of categorical valeus in the {col} is : \")\n",
        "    print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a-j4sUIdQLaM",
        "outputId": "30f73f8c-3690-4950-d724-4d9be9e28c21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
              "0   12    1              1         41          147          0           1   \n",
              "1   21    0              2         55           40          0           1   \n",
              "2    9    1              1         31          141          0           2   \n",
              "3   20    0              0         39           72          0           1   \n",
              "4   26    1              2         49           53          0           1   \n",
              "\n",
              "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
              "0     98               0       10         2             0  \n",
              "1     82               0       20         1             1  \n",
              "2     25               0       10         2             0  \n",
              "3     34               1       25         1             1  \n",
              "4     48               0       10         2             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6b255ba-b6a8-47d9-8d9f-d7c0f2f06898\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>ChestPainType</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>RestingECG</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>ExerciseAngina</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>ST_Slope</th>\n",
              "      <th>HeartDisease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>147</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6b255ba-b6a8-47d9-8d9f-d7c0f2f06898')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6b255ba-b6a8-47d9-8d9f-d7c0f2f06898 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6b255ba-b6a8-47d9-8d9f-d7c0f2f06898');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-099fda9e-85af-4a40-9177-ac1e5a4619ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-099fda9e-85af-4a40-9177-ac1e5a4619ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-099fda9e-85af-4a40-9177-ac1e5a4619ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# As we will be using both types of approches for demonstration lets do First Label Ecoding\n",
        "# which will be used with Tree Based Algorthms\n",
        "df_tree = df.apply(LabelEncoder().fit_transform)\n",
        "df_tree.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "klOLiuxMQSHr",
        "outputId": "77acdc11-f008-4d3d-e12e-35e9f860f42d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  \\\n",
              "0   40        140          289          0    172      0.0             0   \n",
              "1   49        160          180          0    156      1.0             1   \n",
              "2   37        130          283          0     98      0.0             0   \n",
              "3   48        138          214          0    108      1.5             1   \n",
              "4   54        150          195          0    122      0.0             0   \n",
              "\n",
              "   Sex_F  Sex_M  ChestPainType_ASY  ...  ChestPainType_NAP  ChestPainType_TA  \\\n",
              "0      0      1                  0  ...                  0                 0   \n",
              "1      1      0                  0  ...                  1                 0   \n",
              "2      0      1                  0  ...                  0                 0   \n",
              "3      1      0                  1  ...                  0                 0   \n",
              "4      0      1                  0  ...                  1                 0   \n",
              "\n",
              "   RestingECG_LVH  RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  \\\n",
              "0               0                  1              0                 1   \n",
              "1               0                  1              0                 1   \n",
              "2               0                  0              1                 1   \n",
              "3               0                  1              0                 0   \n",
              "4               0                  1              0                 1   \n",
              "\n",
              "   ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
              "0                 0              0              0            1  \n",
              "1                 0              0              1            0  \n",
              "2                 0              0              0            1  \n",
              "3                 1              0              1            0  \n",
              "4                 0              0              0            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c5dcd94-5a1e-4e34-94be-6f3f4ea2b3ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>ChestPainType_ASY</th>\n",
              "      <th>...</th>\n",
              "      <th>ChestPainType_NAP</th>\n",
              "      <th>ChestPainType_TA</th>\n",
              "      <th>RestingECG_LVH</th>\n",
              "      <th>RestingECG_Normal</th>\n",
              "      <th>RestingECG_ST</th>\n",
              "      <th>ExerciseAngina_N</th>\n",
              "      <th>ExerciseAngina_Y</th>\n",
              "      <th>ST_Slope_Down</th>\n",
              "      <th>ST_Slope_Flat</th>\n",
              "      <th>ST_Slope_Up</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>140</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>160</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>138</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54</td>\n",
              "      <td>150</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c5dcd94-5a1e-4e34-94be-6f3f4ea2b3ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c5dcd94-5a1e-4e34-94be-6f3f4ea2b3ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c5dcd94-5a1e-4e34-94be-6f3f4ea2b3ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ba06f3eb-b5ff-4d37-baad-902d1ed82eef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba06f3eb-b5ff-4d37-baad-902d1ed82eef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ba06f3eb-b5ff-4d37-baad-902d1ed82eef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "## Creaeting one hot encoded features for working with non tree based algorithms\n",
        "df_nontree=pd.get_dummies(df,columns=string_col,drop_first=False)\n",
        "df_nontree.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "HL0ljyNiQc8Y",
        "outputId": "a9b7de88-da88-4cb0-8769-f04a81980290"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  Sex_F  Sex_M  \\\n",
              "0   40        140          289          0    172      0.0      0      1   \n",
              "1   49        160          180          0    156      1.0      1      0   \n",
              "2   37        130          283          0     98      0.0      0      1   \n",
              "3   48        138          214          0    108      1.5      1      0   \n",
              "4   54        150          195          0    122      0.0      0      1   \n",
              "\n",
              "   ChestPainType_ASY  ChestPainType_ATA  ...  ChestPainType_TA  \\\n",
              "0                  0                  1  ...                 0   \n",
              "1                  0                  0  ...                 0   \n",
              "2                  0                  1  ...                 0   \n",
              "3                  1                  0  ...                 0   \n",
              "4                  0                  0  ...                 0   \n",
              "\n",
              "   RestingECG_LVH  RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  \\\n",
              "0               0                  1              0                 1   \n",
              "1               0                  1              0                 1   \n",
              "2               0                  0              1                 1   \n",
              "3               0                  1              0                 0   \n",
              "4               0                  1              0                 1   \n",
              "\n",
              "   ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  HeartDisease  \n",
              "0                 0              0              0            1             0  \n",
              "1                 0              0              1            0             1  \n",
              "2                 0              0              0            1             0  \n",
              "3                 1              0              1            0             1  \n",
              "4                 0              0              0            1             0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e93b0e2-1d12-45f3-9a69-225a2132c723\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>ChestPainType_ASY</th>\n",
              "      <th>ChestPainType_ATA</th>\n",
              "      <th>...</th>\n",
              "      <th>ChestPainType_TA</th>\n",
              "      <th>RestingECG_LVH</th>\n",
              "      <th>RestingECG_Normal</th>\n",
              "      <th>RestingECG_ST</th>\n",
              "      <th>ExerciseAngina_N</th>\n",
              "      <th>ExerciseAngina_Y</th>\n",
              "      <th>ST_Slope_Down</th>\n",
              "      <th>ST_Slope_Flat</th>\n",
              "      <th>ST_Slope_Up</th>\n",
              "      <th>HeartDisease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>140</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>160</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>138</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54</td>\n",
              "      <td>150</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e93b0e2-1d12-45f3-9a69-225a2132c723')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e93b0e2-1d12-45f3-9a69-225a2132c723 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e93b0e2-1d12-45f3-9a69-225a2132c723');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46251c7c-e047-415f-b20d-d443c58bd06e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46251c7c-e047-415f-b20d-d443c58bd06e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46251c7c-e047-415f-b20d-d443c58bd06e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Getting the target column at the end\n",
        "target=\"HeartDisease\"\n",
        "y=df_nontree[target].values\n",
        "df_nontree.drop(\"HeartDisease\",axis=1,inplace=True)\n",
        "df_nontree=pd.concat([df_nontree,df[target]],axis=1)\n",
        "df_nontree.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "4cZkLde0WOGE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNptdJ4GQlv5"
      },
      "outputs": [],
      "source": [
        "feature_col_nontree=df_nontree.columns.to_list()\n",
        "feature_col_nontree.remove(target)\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuqGBseSQmu1",
        "outputId": "9618f239-7841-453c-dd72-1a765ffc2c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.93      0.87        82\n",
            "           1       0.93      0.83      0.88       102\n",
            "\n",
            "    accuracy                           0.88       184\n",
            "   macro avg       0.88      0.88      0.87       184\n",
            "weighted avg       0.88      0.88      0.88       184\n",
            "\n",
            "The accuracy for Fold 1 : 0.8800813008130083\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84        82\n",
            "           1       0.91      0.80      0.85       102\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.85      0.85      0.85       184\n",
            "weighted avg       0.86      0.85      0.85       184\n",
            "\n",
            "The accuracy for Fold 2 : 0.8531802965088474\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.65      0.77        82\n",
            "           1       0.78      0.98      0.87       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.87      0.81      0.82       184\n",
            "weighted avg       0.86      0.83      0.82       184\n",
            "\n",
            "The accuracy for Fold 3 : 0.8133668101386896\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.80      0.84        82\n",
            "           1       0.85      0.91      0.88       101\n",
            "\n",
            "    accuracy                           0.86       183\n",
            "   macro avg       0.87      0.86      0.86       183\n",
            "weighted avg       0.86      0.86      0.86       183\n",
            "\n",
            "The accuracy for Fold 4 : 0.8578845689446993\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.76      0.72        82\n",
            "           1       0.78      0.72      0.75       101\n",
            "\n",
            "    accuracy                           0.74       183\n",
            "   macro avg       0.74      0.74      0.74       183\n",
            "weighted avg       0.74      0.74      0.74       183\n",
            "\n",
            "The accuracy for Fold 5 : 0.7394349191016663\n"
          ]
        }
      ],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score\n",
        "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
        "acc_log=[]\n",
        "\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    #print(pd.DataFrame(X_valid).head())\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=LogisticRegression()\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_log.append(acc)\n",
        "    print(f\"The accuracy for Fold {fold+1} : {acc}\")\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwDyYVhh1vBH",
        "outputId": "45a11b18-b1b2-4d48-b1e4-4962b2e9cf99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8287895791013822\n"
          ]
        }
      ],
      "source": [
        "print(Average(acc_log))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jko1OjH_UsD4"
      },
      "source": [
        "# K-fold Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tHI5SZ-00a8",
        "outputId": "5e8fd5f0-bd64-4be5-e894-2b8aca93b36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8213222584981755, 0.8317137045722275, 0.8367572298394169, 0.8287895791013822, 0.8467350708399302, 0.8409774953617976, 0.8451886463720104, 0.8445160304141999, 0.8455404112864657, 0.844462288020884, 0.8545846633226936, 0.8515618040974741, 0.8456532271187444, 0.8479543332484508, 0.8504283304900745, 0.8490551048005409, 0.8516856290469483, 0.8507267586214955, 0.8509322344322345, 0.8527192982456142, 0.8532319765157297, 0.8526797497941719, 0.8546467829556067, 0.8507198879551819, 0.8541118421052629, 0.8527371669915526, 0.8532566535386087, 0.8522006503750924, 0.8533054567981038, 0.8519122599411973, 0.8539162660256411, 0.8525932400932401, 0.854400991165697, 0.8557081014223871, 0.8515572390572391, 0.8522254772254773, 0.8544823597455176, 0.8524821332513641, 0.8527199883449883, 0.8544871794871792, 0.854563492063492, 0.8540873854827342, 0.8510904499540863, 0.8524017957351289, 0.8552508783487044, 0.855289598108747, 0.8546533038720537, 0.8499896928468356, 0.8521565656565657]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score\n",
        "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "acc_aver_log=[]\n",
        "for i in range(2,51):\n",
        "  acc_log = []\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      #print(pd.DataFrame(X_valid).head())\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=LogisticRegression()\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_log.append(acc)\n",
        "      #print(f\"The accuracy for Fold {fold+1} : {acc}\")\n",
        "      pass\n",
        "  acc_aver_log.append(Average(acc_log))\n",
        "print(acc_aver_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxr4s94dMWlt",
        "outputId": "22a1485c-9313-4ac2-de0f-d9e2f2bafe0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8557081014223871\n",
            "34\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_log)))\n",
        "print(acc_aver_log.index((max(acc_aver_log)))+1)\n",
        "print(acc_aver_log.index(0.8545846633226936)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysPuwOQs4EwY",
        "outputId": "4836f0b3-5c06-4cf1-9255-bfd523256265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n"
          ]
        }
      ],
      "source": [
        "k_value = []\n",
        "for i in range(2,51):\n",
        "  k_value.append(i)\n",
        "print(k_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "liyFdqR66am8",
        "outputId": "96ec91f1-cd12-40ab-bdf4-5bb2a0344817"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_log,'ro-')\n",
        "plt.title(\"Logistic Regression\")\n",
        "plt.xlabel(\"Average Accuracy\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8eMBGZfRsMi"
      },
      "source": [
        "# Naive Bayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwZCDcMeR5GV",
        "outputId": "8b837dd7-a265-4e93-8f42-fcdc88631f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85        82\n",
            "           1       0.93      0.79      0.86       102\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.86      0.86      0.85       184\n",
            "weighted avg       0.87      0.85      0.85       184\n",
            "\n",
            "The accuracy for 1 : 0.8604734576757532\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87        82\n",
            "           1       0.93      0.85      0.89       102\n",
            "\n",
            "    accuracy                           0.88       184\n",
            "   macro avg       0.88      0.88      0.88       184\n",
            "weighted avg       0.88      0.88      0.88       184\n",
            "\n",
            "The accuracy for 2 : 0.8837876614060258\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.63      0.76        82\n",
            "           1       0.77      0.98      0.86       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.87      0.81      0.81       184\n",
            "weighted avg       0.86      0.83      0.82       184\n",
            "\n",
            "The accuracy for 3 : 0.8072692491630798\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79        82\n",
            "           1       0.81      0.87      0.84       101\n",
            "\n",
            "    accuracy                           0.82       183\n",
            "   macro avg       0.82      0.81      0.82       183\n",
            "weighted avg       0.82      0.82      0.82       183\n",
            "\n",
            "The accuracy for 4 : 0.8136923448442405\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.88      0.80        82\n",
            "           1       0.88      0.75      0.81       101\n",
            "\n",
            "    accuracy                           0.81       183\n",
            "   macro avg       0.81      0.82      0.81       183\n",
            "weighted avg       0.82      0.81      0.81       183\n",
            "\n",
            "The accuracy for 5 : 0.8152620140062787\n",
            "0.8360969454190755\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "acc_Gauss=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=GaussianNB()\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_Gauss.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_Gauss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QcG5aklV-jX"
      },
      "source": [
        "# K-fold Naive Bayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPO8mr5pHagl",
        "outputId": "ec2f70a6-998d-45e8-9f47-3e2c4d8bdbd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8327923948530824, 0.828466274645305, 0.8436588915820131, 0.8360969454190755, 0.8427668168716762, 0.8424477632738243, 0.8483709088603391, 0.8459869984946262, 0.8502142515542804, 0.8516293028197212, 0.8550623737867239, 0.8521026197747662, 0.8505987514608206, 0.8541931924284866, 0.8525362515508685, 0.8532555780933064, 0.8529678613074414, 0.8547914074229865, 0.8539935897435897, 0.85187134502924, 0.8586826503016436, 0.856910032157447, 0.8585885111620405, 0.8540392156862745, 0.8565325573549253, 0.8550763482781027, 0.8558897243107768, 0.8552834927074277, 0.8569092059900882, 0.8561406572554581, 0.8551532451923077, 0.8559683372183373, 0.8565018315018315, 0.8581663574520718, 0.8529611592111591, 0.8567479817479816, 0.8572151532677849, 0.8550283050283051, 0.8542744755244757, 0.8553783614759222, 0.8559930809930814, 0.8547509983556495, 0.8559974747474747, 0.8566947250280583, 0.8563899868247696, 0.856979368149581, 0.8563578493265993, 0.8527004741290455, 0.8544065656565657]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "acc_aver_Gauss=[]\n",
        "for i in range(2,51):\n",
        "  acc_Gauss=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=GaussianNB()\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_Gauss.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "      pass\n",
        "  acc_aver_Gauss.append(Average(acc_Gauss))\n",
        "print(acc_aver_Gauss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFhP3s_7LgR1",
        "outputId": "ee72dbae-5b3c-4bb2-a6bf-139b1d2e963a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8586826503016436\n",
            "21\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_Gauss)))\n",
        "print(acc_aver_Gauss.index((max(acc_aver_Gauss)))+1)\n",
        "print(acc_aver_Gauss.index(0.8550623737867239)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "vgwiDrNwITxR",
        "outputId": "259007e2-f50b-4d84-e077-bbd301f97558"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_Gauss,'ro-')\n",
        "plt.title(\"Naive Bayers\")\n",
        "plt.xlabel(\"Average Accuracy\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCH5B47RR-qK"
      },
      "source": [
        "# Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgjO9Nw6SC_p",
        "outputId": "a1885135-bdb5-4f44-d01e-323f09835256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86        82\n",
            "           1       0.92      0.82      0.87       102\n",
            "\n",
            "    accuracy                           0.86       184\n",
            "   macro avg       0.86      0.87      0.86       184\n",
            "weighted avg       0.87      0.86      0.86       184\n",
            "\n",
            "The accuracy for 1 : 0.8690817790530847\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.84        82\n",
            "           1       0.92      0.78      0.85       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.85      0.85      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "The accuracy for 2 : 0.8494739359158296\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.65      0.77        82\n",
            "           1       0.78      0.98      0.87       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.87      0.81      0.82       184\n",
            "weighted avg       0.86      0.83      0.82       184\n",
            "\n",
            "The accuracy for 3 : 0.8133668101386896\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.83        82\n",
            "           1       0.84      0.90      0.87       101\n",
            "\n",
            "    accuracy                           0.85       183\n",
            "   macro avg       0.85      0.85      0.85       183\n",
            "weighted avg       0.85      0.85      0.85       183\n",
            "\n",
            "The accuracy for 4 : 0.8468365129195846\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.74      0.71        82\n",
            "           1       0.78      0.72      0.75       101\n",
            "\n",
            "    accuracy                           0.73       183\n",
            "   macro avg       0.73      0.73      0.73       183\n",
            "weighted avg       0.74      0.73      0.73       183\n",
            "\n",
            "The accuracy for 5 : 0.7333373581260565\n",
            "0.822419279230649\n"
          ]
        }
      ],
      "source": [
        "# Using Linear Kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"linear\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLkSoECTWMsQ"
      },
      "source": [
        "# K-fold SVM Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLu2hjiqKH-3",
        "outputId": "7797f558-9be4-42dd-bb33-519c6b06f4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8090215095064336, 0.8180061047439752, 0.8379827200354952, 0.822419279230649, 0.8415824300734785, 0.8480718577298523, 0.8403803228021978, 0.8381134498888123, 0.8393797226207556, 0.8431154764837029, 0.8548881180379128, 0.8513637701215243, 0.8472063196201126, 0.849531260315574, 0.8489905784739454, 0.8508198106828938, 0.8521376487081136, 0.8545431177010122, 0.8562206959706959, 0.8535421888053468, 0.8544946027783555, 0.8565654880844472, 0.8547148657442776, 0.8558410364145657, 0.8599907219973008, 0.8544401126272473, 0.8579051796157061, 0.8558421069577257, 0.8554150506356388, 0.8558708843338824, 0.8552183493589743, 0.856667637917638, 0.8604476405946996, 0.8614687693259122, 0.8562770562770565, 0.8602118602118601, 0.8587544034912454, 0.8561489792259024, 0.8599023892773895, 0.8610850531582236, 0.8636243386243387, 0.8608703312191686, 0.8586317722681358, 0.858080808080808, 0.8596426218708829, 0.8642999140339568, 0.8630366161616161, 0.8550505050505051, 0.8577525252525252]\n"
          ]
        }
      ],
      "source": [
        "# Using Linear Kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_aver_svm=[]\n",
        "for i in range(2,51):\n",
        "  acc_svm=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=SVC(kernel=\"linear\")\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_svm.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "      pass\n",
        "  acc_aver_svm.append(Average(acc_svm))\n",
        "print(acc_aver_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOeS3TERRQ7p",
        "outputId": "e1c0120b-d819-4cdd-da09-1fad1e13864d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8642999140339568\n",
            "46\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_svm)))\n",
        "print(acc_aver_svm.index((max(acc_aver_svm)))+1)\n",
        "print(acc_aver_svm.index(0.8548881180379128)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "MNhT0RlqK7xn",
        "outputId": "f6d55e46-f876-46cf-f64d-96b1793c61c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_svm,'ro-')\n",
        "plt.title(\"Linear SVM\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDaSWB-xW7jz"
      },
      "source": [
        "# K-fold SVM Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f4E8l0ISWCS",
        "outputId": "9f588ef7-9a9e-498c-c86f-b2042316ecdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84        82\n",
            "           1       0.87      0.86      0.87       102\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.85      0.85      0.85       184\n",
            "weighted avg       0.85      0.85      0.85       184\n",
            "\n",
            "The accuracy for 1 : 0.852104256336681\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.77      0.74        82\n",
            "           1       0.80      0.75      0.77       102\n",
            "\n",
            "    accuracy                           0.76       184\n",
            "   macro avg       0.75      0.76      0.75       184\n",
            "weighted avg       0.76      0.76      0.76       184\n",
            "\n",
            "The accuracy for 2 : 0.7566953610712578\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.78        82\n",
            "           1       0.81      0.89      0.85       102\n",
            "\n",
            "    accuracy                           0.82       184\n",
            "   macro avg       0.83      0.81      0.82       184\n",
            "weighted avg       0.82      0.82      0.82       184\n",
            "\n",
            "The accuracy for 3 : 0.8119320899091345\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79        82\n",
            "           1       0.84      0.79      0.82       101\n",
            "\n",
            "    accuracy                           0.80       183\n",
            "   macro avg       0.80      0.80      0.80       183\n",
            "weighted avg       0.81      0.80      0.80       183\n",
            "\n",
            "The accuracy for 4 : 0.8045761893262497\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.72      0.69        82\n",
            "           1       0.76      0.70      0.73       101\n",
            "\n",
            "    accuracy                           0.71       183\n",
            "   macro avg       0.71      0.71      0.71       183\n",
            "weighted avg       0.71      0.71      0.71       183\n",
            "\n",
            "The accuracy for 5 : 0.7112412460758271\n"
          ]
        }
      ],
      "source": [
        "## Using Sigmoid Kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm_sig=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"sigmoid\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm_sig.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRxJeESaXAuy",
        "outputId": "2306daa4-f346-4597-d128-ec9c0396463b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8140483963894757, 0.7934694546846509, 0.775585585889428, 0.78730982854383, 0.792582612755247, 0.7893779541177921, 0.7698445664323422, 0.7774645450179394, 0.7831343854615016, 0.778777517165462, 0.8043810935226804, 0.7811052522746073, 0.7703359147324665, 0.7650392817059484, 0.7925082389888337, 0.7863133874239352, 0.7809478648121826, 0.7734448787080366, 0.7906904761904763, 0.7939807852965747, 0.7864695293900099, 0.7905143955961258, 0.7794374062756417, 0.7807647058823529, 0.770883940620783, 0.800549599306909, 0.7912922186418426, 0.788990308767185, 0.7862543094160742, 0.7978736159476194, 0.7962590144230769, 0.7783459595959595, 0.7892049127343244, 0.7875881261595546, 0.7853715728715729, 0.7875052875052877, 0.7874125874125872, 0.7888816311893233, 0.7898892773892773, 0.7949186991869915, 0.7959198209198209, 0.791425886774724, 0.790220385674931, 0.7975645342312011, 0.7979660737812911, 0.7967494089834516, 0.7957517887205388, 0.7982323232323234, 0.8002979797979797]\n"
          ]
        }
      ],
      "source": [
        "## Using Sigmoid Kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_aver_svm_sig = []\n",
        "for i in range(2,51):\n",
        "  acc_svm_sig=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=SVC(kernel=\"sigmoid\")\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_svm_sig.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "      pass\n",
        "  acc_aver_svm_sig.append(Average(acc_svm_sig))\n",
        "print(acc_aver_svm_sig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mc6pkZLRr9x",
        "outputId": "8cd32e0f-6ef6-44f2-86ac-dbec2d9c03ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8140483963894757\n",
            "1\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_svm_sig)))\n",
        "print(acc_aver_svm_sig.index((max(acc_aver_svm_sig)))+1)\n",
        "print(acc_aver_svm_sig.index(0.8043810935226804)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "aFQJ2pWoYG03",
        "outputId": "9e37aaf6-a27b-437c-f1a2-7bebaf758da6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHMCAYAAAA067dyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTvUlEQVR4nO3dd3xUZfY/8M+9UzJJIA1ISKSESJMiIEI0FCkiGFkVBRR0FRVwV9zV9Wf5KlJXVHR13VVcN+iqrKKALqgQwQIoEECkSi8htCSEkF4mM3Pv/f0xcy/TM+XO3DuZ83698tJMy5NJyJw55zznYQRBEEAIIYQQEsVYpRdACCGEEKI0CogIIYQQEvUoICKEEEJI1KOAiBBCCCFRjwIiQgghhEQ9CogIIYQQEvUoICKEEEJI1KOAiBBCCCFRjwIiQgghhEQ9CogIIQH56KOPwDAMPvroI6WXEpTNmzeDYRjMnz/f5/vMnz8fDMNg8+bNIVsXISS8KCAihAAAOI7D0qVLcdNNNyElJQU6nQ6pqam49tprMX36dHz99ddKLzGiHTt2DDNmzEDXrl1hMBgQHx+PLl264JZbbsHChQtx8eJFAMDSpUvBMAwmT57c7GO+/PLLYBgGTzzxBACgqKgIDMOAYRi0atUKtbW1bu8nCAKuvvpq6bYU2BECaJVeACFEeRzHYfz48Vi/fj2SkpJw2223oUOHDjCZTDh06BCWL1+Oo0eP4vbbb5fuM2HCBNxwww1IT09XcOXBGzx4MI4cOYK2bduG7Gts3LgRt912G4xGI2688UaMGzcOCQkJKC4uRkFBAb7//nvk5OQgLS0NU6ZMwVNPPYWvvvoK5eXlHtclCAI++OADAMDMmTMdrtNqtaivr8dnn33mch0A/PjjjygsLIRWq4XFYpH/GyYkAlFARAjBZ599hvXr16Nfv3746aefkJiY6HB9Q0MDdu7c6XBZYmKiy+0iUVxcHHr27BnSr/Hoo4/CaDTio48+woMPPuhy/YEDB5CcnAwAaNWqFaZMmYKlS5di2bJleOqpp9w+5saNG1FYWIicnBz07t3b4bqBAwfizJkzWLp0qduAaOnSpYiJicGoUaPw7bffyvAdEhL5qGRGCEFBQQEAYNq0aW6DnLi4OIwcOdLhMm89RBs2bMCQIUMQHx+PlJQU3HnnnTh69CimTZsGhmFQVFQk3VYs80ybNg2nTp3CxIkT0aZNG7Ru3Rq33HILDh48CAC4dOkSZs6cifT0dBgMBgwaNAibNm1y+/1UV1fj+eefR48ePWAwGJCcnIyxY8fihx9+cLmttx6i3bt3Y9y4cWjdujUSEhJw8803Y/v27Z6eRrfKyspw8uRJJCYmug2GAODaa69Fx44dpc/FIOb999/3+LhLly51uK09rVaLhx56CL/++iv279/vcF15eTnWrFmDu+++GykpKX59L4S0ZBQQEULQpk0bAMDx48eDfqzPP/8ct956K/bu3YtJkybh0UcfRWVlJW688UaHQMhZUVERsrOzcfHiRUybNg233HILfvjhB4wYMQInTpzADTfcgF27duGee+7B5MmTsX//ftx66604e/asw+NUVVUhJycHr776KhITE/Hkk0/i7rvvxvbt23HLLbfg3//+t0/fR0FBAYYNG4YffvgBt956Kx5//HHo9XqMGDHCJVvmTWJiIrRaLerq6lBSUuLTfa6//nr0798fR44cwbZt21yuv3z5MtasWYPExESPvUbTp08HwzBS4CT6+OOPYTKZMGPGDJ+/B0KigkAIiXp79uwRdDqdwDCMcP/99wtffvmlUFRU5PU+H374oQBA+PDDD6XLampqhKSkJEGv1wv79u1zuP1zzz0nABAACKdPn5YuP336tHT5Sy+95HCfhQsXCgCE5ORk4dFHHxU4jpOuW7ZsmQBAePLJJx3uM3PmTAGAMHPmTIHneeny48ePCwkJCYJer3f4+ps2bRIACPPmzZMu43le6NGjhwBAWLNmjcPjv/XWW9J6N23a5PU5Et19990CACErK0t4/fXXhR07dgj19fVe7/Puu+8KAIQHH3zQ5bo333xTACDMmjXL4XLxuRwyZIggCIIwevRoISkpSWhoaJBu07NnT6Fbt26CIAjCfffd59f3QUhLRgERIUQQBEFYsWKF0L59e+nFHoCQkpIi3HnnncLXX3/tcnt3AdF///tfAYDw0EMPudy+trZWSEpK8hgQZWZmChaLxeE+Z86cEQAIcXFxQk1NjcN1FotF0Gq1wogRI6TLmpqahLi4OKFVq1bC5cuXXdbw4osvCgCEBQsWSJe5C4i2bt0qABCGDx/u8hgWi0W4+uqr/QokKioqhLvuuktgGEZ6blmWFa699lph9uzZQmlpqct9qqurhfj4eCEuLk6orq52uK5Xr14CAGH//v0OlzsHRJ9//rkAQPj4448FQRCEn3/+WQAgLF68WBAECogIsUclM0IIAGDy5Mk4e/YsNmzYgDlz5mD8+PHgeR5r1qzB7bffjgcffBCCIHh9jL179wIAhg4d6nJdq1at0L9/f4/37d+/PzQajcNlGRkZAIDu3bujdevWDtdpNBqkpaXh/Pnz0mXHjh1DQ0MD+vXr57Y/ZtSoUQ7r9GTPnj0AgJtuusnlOo1G4/b78yY5ORlffvklCgsL8d5772H69Ono27cvfvvtNyxatAi9evXCrl27HO6TkJCAe+65Bw0NDfj000+lywsKCnD48GEMHjwY1157rdevO2HCBLRt21Yqm+Xl5UGn02HatGl+rZ+QaEABESFEotPppLk433zzDcrLy7FixQrEx8dj2bJl+Oqrr7zev7q6GgCQlpbm9npPlwNw28yt1Wo9XidebzabXb6+p1EA4uVVVVUe12H/OJ7W2759e6/39yQzMxOPPvooli5din379uHs2bP43e9+h4qKCrc9PeJl9s3V4v+7a6Z2ptfr8cADD2Dr1q3Yvn07vvjiC9x+++1ITU0NaP2EtGQUEBFCPNJoNJg8eTL+8pe/ALBu9fYmISEBAKQhg848XS4XMXAqLS11e73Y1NzcuADxek/r9fT4/urQoQM+//xz6PV67N+/HxUVFQ7X33DDDbj22muxZ88e7NmzB7W1tVi5ciUSEhJw7733+vQ1xKBq8uTJMBqNPgVShEQjCogIIc0Sy1XNlcwGDBgAANi6davLdXV1ddi3b5/sa7PXo0cPxMXFYf/+/W6zQOI2/euuu87r44jX//TTTy7XcRzn9vsLVExMDPR6PQD3z699lmj58uWor6/H1KlTER8f79Pj9+zZE8OGDcP58+eRmZmJMWPGyLZ2QloSCogIIfjss8/w/fffg+d5l+tKS0ulHpThw4d7fZw77rgDiYmJ+PTTT13m37z00kvNlqqCpdfrcd9996G2thZz5sxxuO7UqVP45z//CZ1Oh9///vdeHycnJwc9evTAzz//7FImfOedd3Dq1Cmf11RfX4+//vWvHrNNb731Furq6tCrVy9p/IG9+++/H7GxsVi+fDneffddAPB7y3xeXh5Wr16N//3vf2AYxq/7EhItaFI1IQQ7d+7EP/7xD7Rv3x5Dhw5Fly5dAACnT5/GunXr0NjYiDvuuAMTJ070+jgJCQlYsmQJfv/73yMnJweTJ09Geno6CgoKsH//ftx000346aefwLKhey/26quvYsuWLXjnnXewa9cujBw5EuXl5Vi5ciVqa2vxzjvvSN+fJwzD4IMPPsCYMWNw991346677kLXrl2xb98+/Pjjjxg3bhzWr1/v03rMZjPmzp2LBQsWYPDgwejfvz+Sk5NRUVGBbdu24bfffkN8fDzee+89t/dPSkrCpEmTsGzZMhw4cAADBw5sNsPlrGfPniGfxk1IpKOAiBCC//f//h+6deuGH374AQcOHMCGDRtgNBrRpk0bjBgxAlOnTsXUqVN9yi7cd999SElJwV//+lesWLECMTExGD58OLZv346nn34awJVeo1BISUnB9u3b8corr+B///sf3nzzTcTGxmLw4MF45plncMstt/j0OEOGDMGWLVswe/Zs6XiL7OxsbN68GRs2bPA5IEpISMC3336L77//Hlu3bsWaNWtw6dIlGAwGdOnSBU888QSefPJJZGZmenyMmTNnYtmyZdL/E0LkxwjNNQUQQogMOI5DVlYWTCaTzxObCSEkXKiHiBAiq6qqKjQ0NDhcJggCXnrpJZw9exYTJkxQaGWEEOIZZYgIIbJav3497rnnHtxyyy3IzMxEXV0dduzYgX379qFjx4749ddfaQ4OIUR1KCAihMjq9OnTePHFF7Ft2zZcunQJFosFHTp0wPjx4/HCCy94Hc5ICCFKoYCIEEIIIVGPeogIIYQQEvUoICKEEEJI1KOAiBBCCCFRjwIiQgghhEQ9mlTth8rKSlgsFqWXQQghhBAfaLVaJCcn+3bbEK+lRbFYLDCbzUovgxBCCCEyo5IZIYQQQqIeBUSEEEIIiXoUEBFCCCEk6lFARAghhJCoRwERIYQQQqIeBUSEEEIIiXoUEBFCCCEk6lFARAghhJCoRwERIYQQQqIeTapWEsdBv3MnNGVl4FJTYcrOBjQapVdFCCGERB0KiBRiyM9H4ty50JSUSJdx6emoXrgQxtxcBVdGCCGERB8qmSnAkJ+P5JkzwdoFQwDAlpYieeZMGPLzFVoZIYQQEp0YQRAEpRcRKS5duhT84a4ch7TsbLAlJWDcXC0wDLj0dJTt2EHlM0IIISQIOp0O7dq18+m2lCEKM/3OndB4CIYAgBEEaIuLod+5M6zrIoQQQqIZBURhpikrk/V2hBBCCAkeBURhxqWmyno7QgghhASPAqIwM2Vng0tPh8C4L5oJDANLRoZ1Cz4hhBBCwoIConDTaFC9cCEAwLmbXQySahYsoIZqQgghJIwoIFKAMTcXlXl54Nu3d7icS09HZV4ezSEihBBCwoy23ftBlm339iwWpGdlgeE4VPzrXzDedhtlhgghhBCZ0Lb7SKHVgk9OBgBYunalYIgQQghRCAVECuMTEwEAbHW1wishhBBCohcFRAoTKCAihBBCFEcBkcL4pCQAAEMBESGEEKIYCogUJpXMqqqUXQghhBASxSggUhiVzAghhBDlUUCkMGqqJoQQQpRHAZHCxICIeogIIYQQ5VBApDCxqZoyRIQQQohyKCBSmEBN1YQQQojiKCBSGO0yI4QQQpRHAZHCqIeIEEIIUR4FRApz2GVG5+wSQgghiqCASGGCOKnaYgHT0KDsYgghhJAoRQGRwoS4OAhaLQCAoT4iQgghRBEUECmNYWg4IyGEEKIwCohUgI7vIIQQQpSlVXoBztavX49vvvkGVVVV6Ny5Mx5++GF07drV4+3XrVuH7777DuXl5UhISEB2djamTp0KvV4PADh8+DC+/vprnD59GpWVlXj66acxePDgcH07PqEMESGEEKIsVWWICgoKsGzZMkycOBGLFy9G586dsWjRIlR7CBS2bt2K5cuXY9KkSfj73/+OP/zhD9i+fTs+++wz6TZNTU3IzMzEI488Eq5vw298cjIA2npPCCGEKEVVGaK1a9di9OjRGDlyJABgxowZ2LNnDzZt2oQ777zT5fbHjh1Djx49MHToUABAamoqhgwZghMnTki3GTBgAAYMGBCW9QeKhjMSQgghylJNhshisaCwsBB9+/aVLmNZFn379sXx48fd3qdHjx4oLCzEyZMnAQAXL17E3r17VR8AOaMeIkIIIURZqskQ1dTUgOd5JNnm8oiSkpJQXFzs9j5Dhw5FTU0N5syZAwDgOA5jxozBXXfdFdRazGYzzGaz9DnDMIiNjQ3qMb2hHiJCCCFEWaoJiAJx6NAhrF69GtOnT0e3bt1QWlqKDz/8EF988QUmTpwY8OOuXr0aX3zxhfR5ly5dsHjxYjmW7BYd30EIIYQoSzUBUUJCAliWRZVTH01VVZVL1ki0YsUKDB8+HKNHjwYAdOrUCUajEXl5ebjrrrvAsoFVBCdMmIDx48dLnzMME9Dj+Iq3fX+UISKEEEKUoZoeIq1Wi6ysLBw8eFC6jOd5HDx4EN27d3d7n6amJpdgJdAgyJ5Op0NcXJz0EcpyGWDXQ0RN1YQQQogiVJMhAoDx48djyZIlyMrKQteuXZGfn4+mpiaMGDECAPDOO+8gJSUFU6dOBQAMHDgQ69atQ5cuXaSS2YoVKzBw4EApMDIajSgtLZW+RllZGYqKitCqVSu0bds27N+jO1QyI4QQQpSlqoAoJycHNTU1WLlyJaqqqpCZmYkXXnhBKpmVl5c7ZITuvvtuMAyDzz//HBUVFUhISMDAgQMxZcoU6TanTp3CggULpM+XLVsGALjpppswa9as8HxjzaCmakIIIURZjCAIgtKLiBSXLl1y2H0mF/bCBbQfPBiCToeS06eBEPcsEUIIIdFAp9OhXbt2Pt1WNT1E0UywZcAYsxlMY6OyiyGEEEKiEAVEKiDExUHQWquXDDVWE0IIIWFHAZEaMAwd30EIIYQoiAIilaDjOwghhBDlUECkErTTjBBCCFEOBUQqIU6rpllEhBBCSPhRQKQS1ENECCGEKIcCIpWgHiJCCCFEORQQqQT1EBFCCCHKoYBIJeg8M0IIIUQ5FBCpBJ+cDIAyRIQQQogSKCBSCYGaqgkhhBDFUECkElQyI4QQQpRDAZFKUFM1IYQQohwKiFTCISASBIVXQwghhEQXCohUQhAnVZvNYBoblV0MIYQQEmUoIFIJIS4OglYLAGCosZoQQggJKwqI1IJhqI+IEEIIUQgFRCpCx3cQQgghyqCASEUoQ0QIIYQogwIiFeHFxmrqISKEEELCigIiFaEMESGEEKIMCohUhHqICCGEEGVQQKQiPJ1nRgghhCiCAiIVofPMCCGEEGVQQKQiYlM1lcwIIYSQ8KKASEUEKpkRQgghitAqvQByBZXMwoTjoN+5E5qyMnCpqTBlZwMajdKrIoQQoiAKiFSEtt2HniE/H4lz50JTUiJdxqWno3rhQhhzcxVcGSGEECVRyUxFBPseIkFQdjEtkCE/H8kzZ4K1C4YAgC0tRfLMmTDk5yu0MkIIIUqjgEhFpJKZ2QymsVHh1bQwHIfEuXMBQQDjdBVjCz4T5s0DOC78ayOEEKI4CohURIiPh6C1VjHp+A556XfuhKakxCUYEjGCAG1xMfQ7d4Z1XYQQQtSBAiI1YRjqIwoRTVmZrLcjhBDSslBApDJ0fEdocKmpst6OEEJIy0IBkcpQhig0TNnZ4NLTITDui2YCw8CSkWHdgk8IISTqUECkMuK0auohkplGg+qFCwEAzvv3xCCpZsECmkdECCFRigIilaEMUegYc3NRmZcHITbW4XIuPR2VeXk0h4gQQqIYBUQqQz1EoWXMzUXT0KEArJmh8pUrUbZjBwVDhBAS5SggUhk6viP02Lo6ANat9uZ+/ahMRgghhAIitaGSWegx9fVX/r+mRsGVEEIIUQsKiFRGbKqmE+9Dh62tdfv/hBBCohcFRCpDPUShx9hKZgBliAghhFhRQKQy1EMUegxliAghhDihgEhlpB4iKpmFhsUC1miUPmUoICKEEAIKiFRHEHuIqqsBwXmEIAmWfbkMAFgqmRFCCAEFRKojlczMZjCNjQqvpuVhnQMiyhARQggBBUSqI8THQ7DNxaHjO+TnnCGipmpCCCEABUTqwzA0iyiEnHuGqGRGCCEEoIBIlWjrfeg4l8yoqZoQQghAAZEq8faN1URW1FRNCCHEHQqIVEhqrKYeItlRhogQQog7FBCpEPUQhY4YAHEpKQAoQ0QIIcSKAiIVEqhkFjJiyYxPT7d+ThkiQgghoIBIlej4jtARS2ZcRob1cwqIiC84DvqCAsSuWQN9QQHAcUqviBAiM63SCyCuqGQWOoxTQMTU1longjOMkssiKmbIz0fi3LnQlJRIl3Hp6aheuBDG3FwFV0YIkRNliFRI2mVGTdWyEzNCUkDE82Dq65VcElExQ34+kmfOBGsXDAEAW1qK5JkzYcjPV2hlhLQgKsnAUoZIhWgOUehIGaK2bSFotWAsFjA1NRBatVJ4ZUR1OA6Jc+cCggDn/CEjCBAYBgnz5sE4dixgmy5PCPGPmjKwlCFSIeohCh0xIBJatwbfujUA6iMi7ul37oSmpMQlGBIxggBtcTH0O3eGdV2EtBRqy8CqMkO0fv16fPPNN6iqqkLnzp3x8MMPo2vXrh5vv27dOnz33XcoLy9HQkICsrOzMXXqVOj1+oAfU0nUQxQ6YvAjtGplzcRVVtJ5ZsQtTVmZrLcjhNhRYQZWdRmigoICLFu2DBMnTsTixYvRuXNnLFq0CNUegoOtW7di+fLlmDRpEv7+97/jD3/4A7Zv347PPvss4MdUmsO2e0FQdjEtjNgvxLdqRRki4hWXmirr7QghV6gxA6u6gGjt2rUYPXo0Ro4ciQ4dOmDGjBnQ6/XYtGmT29sfO3YMPXr0wNChQ5Gamop+/fphyJAhOHnyZMCPqTSpZGYygTEaFV5NyyLOHRJat4ZgC4hoFhFxx5SdDS49HYKHHYgCw8CSkQFTdnaYV0ZI5FNjBlZVAZHFYkFhYSH69u0rXcayLPr27Yvjx4+7vU+PHj1QWFgoBUAXL17E3r17MWDAgIAf02w2o6GhQfpobGyU61v0iRAfD8GWIqTjO2QkCNIcIj4+HnxCAgAqTRIPNBpUL1wIAHDO04pBUs2CBdRQTUgA1JiBVVUPUU1NDXieR5KtZCRKSkpCcXGx2/sMHToUNTU1mDNnDgCA4ziMGTMGd911V8CPuXr1anzxxRfS5126dMHixYsD/K4CwDDgExOhqagAW10tTVUmQWpqAmM2A3DMEFHJjHhizM1FZV4ekh5/HExTk3Q5l56OmgULaA4RIQEyZWeDa9sWbHm527KZwDDg0tPDmoFVVUAUiEOHDmH16tWYPn06unXrhtLSUnz44Yf44osvMHHixIAec8KECRg/frz0OaPA0D4hMRGwBUREHqzdvCHBLkNETdXEG2NuLsyDBiFm61YAQM2TT6LuqacoM0RIMDgOQkwMGFgzsPavskplYFUVECUkJIBlWVQ5lYmqqqpcMjyiFStWYPjw4Rg9ejQAoFOnTjAajcjLy8Ndd90V0GPqdDrodLogv5vg0HBG+Ym9QnxcHKDRUIaI+IyxL5trtRQMERKk1m+/De2FC+BatQLi46G5eFG6TqkMrKoCIq1Wi6ysLBw8eBCDBw8GAPA8j4MHD2LcuHFu79PU1OSSwWHZK61RgTymGkiN1RQQycZ+BhEAaZcZNVWT5jANDdL/awsLFVwJIZFPe/AgWv3znwCA6tdfh/G226y7zsrKwKWmWstkCrzpUFVABADjx4/HkiVLkJWVha5duyI/Px9NTU0YMWIEAOCdd95BSkoKpk6dCgAYOHAg1q1bhy5dukglsxUrVmDgwIFSYNTcY6oRzSKSn9RQbZtKLYhN1VQyI82wP96FAiJCgmA2I/kvfwFjsaAxNxfG3/0OYBiYcnKUXpn6AqKcnBzU1NRg5cqVqKqqQmZmJl544QWpvFVeXu6QEbr77rvBMAw+//xzVFRUICEhAQMHDsSUKVN8fkw1ouM75Ge/5R6gDBHxnUtARAcCExKQVu+8A93hw+CSk1H98suq+nekuoAIAMaNG+exnDV//nyHzzUaDSZNmoRJkyYF/JhqRMd3yE/MEAnx8db/UoaI+Mg+IGJrasBWVIBv00bBFRESebSHD6P1W28BAGpeegl8u3bKLsiJKgMiYtdUTQGRbMQeIp4yRMQfHAfWNiCVj48HW18PbWEhTBQQEeIdx13pDUpJQcKiRdZS2bhxaLzjDqVX54ICIpWSSmbUVC0bqanauYeIAiLihf0OM3Pv3oj55RdoCguBQYMUXBUh6ubuFHvAusu3+pVXVFUqE6lqUjW5gpqq5Wd/sCvglCGiM+OIB2K5TNBoYOnZEwA1VpMIxXHQFxQgds0a6AsKAI4LyZfxdIo9YN2xqf/115B83WBRhkilqIdIfoyHXWYMz4Opr5cCJULsSQFRfDwsV18NQCUBkX05QsGtyiQyuMvYcOnpqF64UN55P15OsQcAKHCKva8oQ6RS1EMkP9ZpDpFgMECwDeCkadXEE3EGkRAXB0tWFgDlAyJDfj7SsrPRdtIkJM+ahbaTJiEtOxuG/HxF10XUyVPGhi0tRfLMmbL+3qjxFHtfUUCkUoJ9QETlHFlIk6rFTBDDSGUz2mlGPBGPfHEIiE6fBnhekfWE88WNRBBP5TAvGRvG9tqSMG+ebOUzNZ5i7ysqmamUVDIzmcAYjRBiYxVeUeRzbqoGbGWzigpqrCYeiSUzPj4eXIcOEHQ6ME1N0BQXg+vQIbyLaebFTVBxOYKEjrdyGJ+U5NLYbM8+YyPHcEQ1nmLvK8oQqZQQHw/B9geNju+Qh3PJDLBrrKYMEfFAKpnFxwNaLSydOwNQpmwWyeUIEhpeM4YzZiBh7lyfHkeujI0pOxtcejo81TUEhoElIyOsp9j7igIitWIY2mkmM+emagB0wCtpFmNXMgMglc00CgREkVyOICHQTMaQAaA/csS3h5IrY6PRoHrhQrdXKXWKva8oIFIxOr5DXs7b7gGAF3eaUYaIeOCQIQLAKdhYHcnlCCK/5jKGIr51aykYcSYA4Nq0kTVjI8THg7E9tj0uPR2VeXlhP8XeV9RDpGLiTjPaei8PqReEMkTED6xzhqhLFwC2xuowE8sRbGmp1BBrT4D1RUeN5QgiP18zgQ333ov499+HwDAOvzcCAAYAW1mJ2NWr0ThxYvCL4jgk/PWvAID6hx+G8dZbI2Y0BGWIVIynadXyEQSXw10ByhCR5tk3VQNQduu9XTnCORwSX9y4rCyApT/t0cDXTKDxlltQmZcHvn17x/unp6Np0CAwPI/kJ55Aq3feASyWoIY3xn7xBXRHjoBPSEDtX/4CU04OGu+809qwreJgCKAMkapRD5F8mIYG6Z2RQBki4gePPURnzwImE6DXh3U9xtxcVOblIemppxzO4eNTUsBWViJm2za0evdd1M2aFdZ1kfBrNmPIMFcyhhoNjGPHug7zZBgkLFqEVu+9h4RXXkGrf/wDrK1MDPg3vJFpbETCa68BAGr//GcIKSnyfbNhQG8jVIx6iOQjbblnWYcRBnTAK2mOeJaZ2EPEp6WBj4sDw/PQnj2ryJqMubloHD8eANCQm4vyVatwcd8+VNtKFQkvv0zziKKBvw3MGo1rxoZlUTNnDurvuQcC4BAMAf7Nt4rPy4OmtBSWDh1Q/9BDQX1rSqCASMXo+A75OJTL7JoLpQNeqWRGPLA/usN6AaPoTjORprQUANB0883Si1vDQw+hzvZClPSnP0G3f3/Yzq8iyjDm5qLuiSdcLvergZnjYPj5Z7dX+Tq8kb10Ca2WLAEA1P7f/wEGgw+rVxcqmamYdHwH9RAFTZxBJPaBiChDRJrDOvUQAbY+nYMHoS0sRJNC69JcuGBdS0aGw+U18+dDe+YMDBs3IuXeewGDwaH5NiTnVxFFieXcppwcNNx3n98NzOJuNU98Gd7Y+s03wdbXw9SvHxrvuMP/b0IFKEOkYgI1VcvGXUM1QBki0jwpQ2RXalX8TDNBgOb8eQAAd9VVjtdptah8911YrroKmpoasE47keiIjzAIc1ZOe/gwAKDpppsCamAOdr6V9uRJxH36KQCgZs6ciG3qDzhDVF5ejv/97384dOgQampq8Mwzz6BXr16oqanBF198gZEjR6KLbXsqCQw1VctH2jrtdKI9ZYhIc5znEAHKB0RMVZXU6+GcIQKsGQPGbJZ2njncl474CKmwnSpvR3foEADA3KtXQPf3dbeaQ9s2x0kN2nEffgiG49B4yy0w3XhjQGtQg4ACovPnz2Pu3LkQBAFdu3ZFaWkpeNtBhwkJCTh27Biamprwxz/+UdbFRhvqIZKPdLCrU4ZI3HZPu8yIJ14DIgVmEQF25bJ27dz2aogvVJ7IfX4VsRKP0XA+kFvMyoViKCHT2AjtqVMAAHPv3gE9hi/zrRgASc89hyqGAXQ6l6BPAGAaNiygr68WAeW1PvnkE8THx+Mf//gH/vSnP7lcP2DAABw9ejToxUU7yhDJR9pl5tRDJNjPIVLo9HKibi5N1bgynFFTWipdH06a4mIAbspl4vV0xEf4hflUeZH26FEwPA+ubVvwgU4ot59v5TTRWvzcfPXVYOvqkPLYY0ieMcPl7DQASJg7N6JLsQEFREeOHMGYMWOQkJAAxs048LZt26KioiLoxUU7QWyqrq52ecdB/CM1VTtniMSSmSAo8sJG1E8sTfG2xlXA+m+Ts81Y0SiQJfLUUC2iIz7CT6mDd3W2/iFz794OO2j9Jc63cje8sXLpUlzauBG1TzwhZYtcgj7bf0MR9IVLQAERz/OIiYnxeH1NTQ20WtrAFiypZGYygTEaFV5NZJMyRE49RDAYIOh01ttQYzVxw12GCLA708xWrggnraeGahvpxHFP51ep+MTxSKVUVk7sH7IE2D9kz5ibi4s7d6J81SpULlmC8lWrULZjh7XMp9WiaehQr+emhSroC5eAAqKsrCzs2bPH7XUcx6GgoADdu3cPamHE+uIt2BoeGdppFhR3B7sCABhGyhJRHxFxYTKBMZsBXNnaLFKysVrKEHkIiLwe8aHyE8cjlVJZOamhOsD+IRfuhjeKV7XwUmxAAdGdd96Jffv2YenSpTh37hwAoKqqCgcOHMBLL72ECxcu4I4InUOgKgxzpemX+oiCwngomQF2W+8pICJO7MuoERUQwa4E0ratw+VqP3Fc9dxtqed56Hfvdgk+7YUkK8fz0pZ72QIiL1p6KTagutaAAQMwa9YsfPjhh/jhhx8AAG+//TYAIDY2FrNmzUIvGdJ3xDaLqLKSAqIgeSyZwa6PiEpmxIm0wywmBrCVVkVK7jSTmqo7dPB6O2NuLkz9+qH94MEQGAaXV6yA6YYbKDMUILdb6tPSwLVpA70tMBEAwM2p8oD8WTlNURHYhgYIBoP0+xhKfp2dFoECbvQZPnw4Bg8ejAMHDkjb7tu3b49+/foh1m6AGQkOn5wMFBXR1vsgeSyZgQ54JZ65a6gWOWSIBCGohla/mExgL14E4D1DJBIzRIwgWLMIFAwFxOOW+osXobl4EbxOh5pXXgGfkIDEefMcJz9rNKj8179kz8pJDdU9egDh6Nu1lWKTZ86E4Bz0tYBSbFDPoMFgwODBg+VaC3GDp2nVspBKZu4yRPZb7wmx46mhGgAsmZkArOVstrISfJhO9taUlFiHKxoMvn3NmBjw8fFg6+vBVlaCs+1eJX7wtqUe1gyQkJSEhsmTrafKjxtn3XV29iySnnsOjMUCS48esi9L9v4hH4ilWHfDJ2sWLIjoUmxAAVF5eblPt2vrVLsm/qNZRPIQt907H91hfxlliIgzbwERYmNhueoqaC9cgObUqfAFRPZb7n3MSvEpKdaAqKICHJ0g4Ldmz/oCoLl06cqgS1tjMnJyEPvNNzBs3gzDd9+hrmtXWdelREAEWIMi49ix0gBQf89OU6uAAqJZs2b5dLsVK1YE8vDEjkABkSwoQ0QCIQVEbkpmgHXrvfbCBWgLC2EeNCgsa/KlodoZn5wMnDsHlubDBSSY3VXGMWNg2LwZMd99h7rHHpN1XdKW+zAHRACuBH0tSEABkbsjOXiex6VLl/Dzzz8jISEBY8eODXpxhI7vkAtDPUQkAGIPkaeAyNKlC2K2bAnrTjMxILI001BtT8xesZWVIVlTSxfM7irjmDHA7NnQ//or2MuXwbdpI8ua2IoKaEpLAQDma66R5TGjXUAB0YgRIzxed8cdd2D27NlosP0hIcHhxWnV1EMUOI4D29gIwH3JjA54DZLdIY8tJXUuEneZ8e5KZlBm631zx3a4IwVElCEKSDC7q/irroKpTx/oDx5EzA8/oPGee2RZk1bMDmVmun2jR/wX0BwibwwGA0aMGIF169bJ/dBRiUpmwRPLZYD7FzZpDhGVzPxmyM9HWnY22k6ahORZs9B20iSkZWdH9HlG9rz2EEGZrffNHdvhDp+cDIAyRAELctBl0y23AAAM338v25KCPeGeuJI9IAIAQRBQRRkNWVBTdfCkhmq9HnBz5AzNIQqMuA3Z+ZBH8WTvlhAUNddD5BAQhelwYE0zx3a4QwFR8Iy5uah57jmXXWa+DLpstLWQxGzeDNiy1cFSqqG6JZM1IGpoaMDu3bvx9ddfowvtZJCFdKzE+fNXpqISv3hrqAbssnBUMvOdQid7hxvTTA8R17EjBK0WjNHodReSbAQh8KZqUEAULPEYl6YbbnA968sLS+/e1pJbYyNitm2TZS26I0cAUIZITgH1EN3TTA20bdu2mD59ekALIlcY8vOR+PzzAABtaSnaTpoELj0d1QsXRvSsh3CTGqrd9A8BlCEKRLPbkO0OeYzknShsMyUzaLWwdO4M3alT0Jw65VeQEgimslLqh/OrZEY9RLIw/PQTAKDx7rvReOedvt+RYWC85RbEf/wxDN99h6abbw5uIUYjtCdOAKAMkZwCCojuvvtuME7zLxiGQXx8PNLS0tCvXz9oWkhTpVI8TkW1lSPoLCLfSSUzDy9qdLir/1r6IY+i5nqIAOvWe92pU9CePg3T8OEhXY/UUJ2a6rb864mUIaKAKGBMdTV0e/cCAJoC+DlLAdEPP6Ca5wE28AKN7sQJMBYL+KQk8H4ExsS7gAKiyZMny70OYq+ZcoTAMEiYNw/GsWNbzG6eUBIzRO4OdgWuNFUztbXWPpAg/lBFi5Z+yKOI8XJ0hyicO820AZTLANp2L4eYggIwHAfz1Vc3e4acO0033gg+Ph6aixehO3AA5v79A16L1r5/KFxHxkQB+suvQmI5wtOvuX05gjRPepfvoYdIKpkJgsPp5sQzcRuyp9O9Q3KytwKkHiIvGaJwBkRSQ7WfWQGHgMjNtnHSvJiffwYQWHbI+gAxaLKNrDF8911Qa5HOMKP+IVn5lCF69913/X5ghmHcDnAkzYuWckS4sM1kiGAwQNDpwJjNYGpqPPYaETviIY8zZrhc1RIOeRT5UjILa0AUaIbIVjJjLBYwtbVSVpT4LuiACNayWey6dTB89x1qn3024MehHWah4VNAdMj25PvDuceI+E7RckQLHLLHNNNDBIYB37o1NBUVYGtrEZ7N05GvKScH0OkA284bEd+uHaoXLWoRPW5sM9vuAeu0agDQnDsHmEyAXh+y9QQaEMFgAB8XB7ahwXqeGQVEftEUFUFbVARBqw1qk4Bx1CgILAvdkSPQnDsHrmNH/x9EECggChGfAqIlS5aEeh3ETjBTUYNhyM93e4JxpO9q83awq0hISABsAZEiIjAQjVuxAozZDPM116B6wQIkPfMMtGfOoHrevIj+fbHnS4aIb98efGws2MZGaM6eBSfzAZ72pIAogB4WPjn5SkCUmSnzylo2MTtkuv76oKZCCykpMA0ejJgdO2D4/nvUP/yw34+hOXcObG0tBL0elhD+rkUj6iFSI/upqE6ZtlCVI1rykD2pqdrLHzIlt95H5LRnnkf8smUAgPqHHoJpyBA0DRkCANAdO6bkymTlS1M1GAZcmMpmgRzbIaLG6sDFbNkCAGgaNizoxzKOGQMg8D4i6UDXbt1Cmo2MRhQQqZQxNxeVeXng27d3uNyXqah+a+FD9qSSmZeASKkDXiM1EI35+Wdoi4rAJySgccIEAFcaPMWGz5bAl6ZqIEx9RE1N0Fy8CCDIgIi23vvHYkHM1q0AgKabbgr64Yy2Yzz027cH9AZMaqimcpnsAtp2DwB79+7F2rVrcfr0aTQ0NEBwU9pZsWJFUIuLdsbcXBjHjkXSn/+MuDVr0Jibi8r33pO9lNLSh+yJJTOPTdUAeHHrfTgzRBE8XiH+o48AAA2TJkn9NRZbQKRtKQGR3a5DNQRE4r9R3mCQmqT9QdOqA6Pbtw9sTQ34pCSYr7026MfjsrJg7toVupMnEbNpE4x33OHX/bXUPxQyAWWIduzYgVdffRXV1dXIycmBIAgYMmQIhgwZAr1ej86dO2PixIlyrzU6aTQw9+kDABBiY0PywtjSd7WpNUMUqeMVNOfOIeaHHwAA9Q88IF1u7tkTAKAtLgbTAs4yZIxGKUPqc0AUwkNeHRqqA9i0QhmiwEi7y4YOle3vrzGIw16poTp0AgqI1qxZg65du+K1116ThjSOGjUKf/7zn/HGG2+gsrISqRE+kE1NQl37b+lD9sQgx1tApESGKFID0bhPPgEjCGgaNsyhgVhITITF1uwrnrMUyexnUgkGg9fbhiVDFERDNUAZokDJsd3eWZMYEG3c6LJL0xumqgpa2ywq8zXXyLYeYhVQQHT+/HkMGTIELMtKR3RYLBYAQGpqKsaOHYuvvvpKvlVGuVCP3ZeG7Hl41xnpQ/aaO9wVsMsQhTEgishA1GhE3PLlAID6adNcrm5JfURiQMTHxTU7vVzael9aGrLhngFvubehDJH/mJoa6PfsASBvQGS67jpwKSlgq6uh/+UXn+8nvtGwdOgAISlJtvUQq4ACopiYGGi11vaj+Ph4aLVaVNmlyBMTE1Gmsne1kSzk7+zsd7U5XSV+HslD9hgftt1Lu8zCWDKLxEA0dt06aCoqYMnIgNHNAZUW27vWltBH5GtDNQAIycngbAGHJkRlMykgCvDsKsoQ+U88rsOSlRXYzCBPNBrpgNf4jz5C7Jo10BcUNLtxhcploRVQQJSRkYHztrQdAGRmZuLnn38Gx3EwmUzYunUr2rZtK9sio1043tkZc3NR+a9/ufQmMADqHn88oufKsL5kiBITrbcNZ1O1t/EKtv+qLRCVmqnvvx/Quu7JkDJELahk5ktABACcLUsUt2KFTy9u/go6Q0QBkd9ibKfbG2XYXeaMa9MGABCbn+/zuA1pyz0FRCERUEA0aNAg7Nq1C2Zb7fOuu+7CoUOHMG3aNEyfPh1Hjx7FnXfeKec6o5r0h6y21joJN0S4Dh3ACAL4+HhUvv02Gn/3OwCA7rffQvY1Q66pCYztOfPaQ6RAhgiwG6/gVBYTkpLkH68QJN1vv0G/Zw8EnQ4NU6e6vY0UEB07BtjK6JGKFTNE3mYQ2Rjy86WsWKv//Ccks6SoZBZ+oegfAqy/L63ee88lI9/cuA0pQ0RnmIVEQAHR7bffjn/961/Q6XQAgIEDB2L+/PkYPXo0br75ZsyZMwcjbIfYkeAJiYkQbD0MbAh370izNoYNQ+Ndd6Hm+echMAwMmzdDc/JkyL5uKLH2jbHeMkS2pmolJlUbc3NR/uWXDpc1jh+vqmAIAOI+/hgA0HjbbeDbtXN7Gy4zE3xsLBijMaQ7rsKB8eHYDuDKLCmmsdHhcllnSQmCvE3VdMBrszRnzshyXIeLQOe+mUzQnjgBgEpmoSLbYMZrrrkG06ZNwwMPPIA+tm3iRCYaDXixpBPCd3cx27YBsG0vBcB17ixNVRVLJZFGmlIdF+e19KTkpGoALi+mun37FFmHJ0xVFWJXrwYANLhpppawLCzi9vsI7yOSmqq9lczCNNSUrawEazRaj+1xGtbqK8GWIWLMZqmvjngmHdcxcGBQx3U4C3TchvbkSTAmE/jWreXtZyKSgAKiN998E7/88otUMiOhF/Kx+0Yj9Lt2AQBMtiMYAOuxDAAQt3Jl2MtJcmB82HIPXAmIlDrLzGFHE6w9OGJTr6I4DvqCAiTOmQPWaIT5mmtguv56r3dpKTvNfOkhCtcsKY2tZ5NPTQViYgJ6DCE2FrxtfACVzZoXqnJZoOM2HBqq6fD0kAgoIDp27BjeeOMNTJ8+HW+//TZ2794tbbsnoRHq+r9+zx4wRiO41FTrGTk2pmHDYO7WDWx9PeJWrgzJ1w4l6bTyZgIisWTG1NYCfPjPuxfXyWVmgmvfHgzHKZ4lsj9jLe5//wNgPUvL8O23Xu8XVEBkC8B83XUTSmLWzlvJLFyzpILdYSai88x8JPNxHfYCHbdB/UOhF1BA9N5772HevHkYNmwYDhw4gNdeew0zZszAv/71L+zfvx+8Ai8oLV2oZxFJ//iHDHF898EwUpYo/sMPFQkWgiGVzLxsube/nrE7riGc7GclmQYOBABp/okSPJ2xxtTUNNsXYwlwp5naDrllfcgQhWuWVLAN1SIhxH9HWgrd/v2yHtdhr9lxGwC4lBSXcRt0hlnoBRQQMQyDXr16Yfr06fj3v/+NF198ETfeeCN2796Nl19+GTNmzEBeXp7ca41qoX5n59w/ZK9x4kTwCQnQnj6NmM2bQ/L1Q0Xcct/s1mmDAYJtk4ASfUSMXSZLDIh0u3eHfR0Agu6LESfoakpKwPj4+6rGQ2596SEK1ywpuQIiyhD5RiqXDRki/9iLZsZtMLD+fOI++8x6IcdBv20bdHv3AoDUo0fkF3RTNcuy6Nu3L2bOnIm8vDzMmDEDFosFP/74oxzrIzahLJkxdXVSeca+f0gkxMej4Z57ANiyRBHE1wwRGEbRPiL7wM103XUAbBkiBXYDBdsXI7RuDUunTgB8LJuFqTHZXz7tMvPy4ma9UJBlllSwO8xEHG2994k4f0jucplIGrfh1CDPpaejKScHjCAg6bnnkDxjhjVrOnmyNAYi5ZFHFMuatnSy7DKrrKxEfn4+5s2bh6VLl8JoNKJHjx5yPDSxEUI4VE2/cycYiwWWzp097l6onzbNugV/40ZoTp2SfQ2hwvjYQwQou/XePhth7tsXgk4HTXk5NGfPhn0tcvTFiFkiX8pmaj3klvFxDpGnFzcA4NPSYBw9Oui1yF4yowyRR6E6rsOZMTcXF3fuRPmqVahcsgTlq1ahbOdOXF65ErVPPQXAOrTRJWt68aJiWdOWznXUrI+qq6uxY8cOFBQU4NixYxAEAV27dsXvf/975OTkIMX2TiQQ69evxzfffIOqqip07twZDz/8MLraHSJpb/78+Tjs5l3ogAED8PzzzwMAqqqq8Omnn+LAgQOor6/HNddcg4cffhjp6ekBrzHcQvnOzqF/yNPXz8xE0+jRMPzwA+I//hg1tnfFaicd7NpchgjKbr132NFkMMDcpw/0e/dCv3s3Gjt3Duta5OiLsfTqBWzY4FOGSK2H3PozqdqYmwvj2LHW4K6sDHyrVkj6f/8PmosX0er991E3a1ZQaxEDIotcJTPKELnHcYj/8EMwHAeuffugm9ibpdG4nXFU++STiP/gAzDV1W6zpgLDIGHePBjHjlXVJPtIF1BAtHDhQhw5cgQ8zyMzMxP33nsvcnJyZDnhvqCgAMuWLcOMGTPQrVs3rFu3DosWLcJbb72FRNssHntPP/20ww632tpaPPPMM7jxxhsBAIIg4PXXX4dWq8UzzzyDuLg4rF27Fn/961/x5ptvwtDMKdZqEcp3dt76h+zVP/wwDD/8gLgVK1D77LOyzuYIFalk5kuGSIEDXkVSycy2TtN110G/dy90e/ag8a67wroWsS+GLS2VSlb2BIYBl57utS9G3AnjyywitR5yy/pxlhkAlxe3mhdfRPKTT6LVW2+hYcIE8IG+uBqN0Fy6BECGXWbUVO2RIT8fiXPnQmPLyGhKS5GWnY3qhQvDPiRVv3Mn2Opqj9fbZ01lHRoZ5QIqmVVXV2PixIl46623sHjxYtx5552yBEMAsHbtWowePRojR45Ehw4dMGPGDOj1emzatMnt7Vu1aoWkpCTp48CBA4iJicENN9wAACgpKcGJEycwffp0dO3aFRkZGZg+fTpMJhO22QKBSBCqZki2okLaztncP6ym4cNh7toVbF0dYletknUdoeJPyYwXt94rkSFyDojEnWZKNFZ7O+zX1ifTXF+MtPX++PFmj/BQ6yG3Pg1m9KJx4kQ0DRoEtqEBiX/9a8DrEF+g+dhY6Y1RoKip2j21NfWrNWva0gUUEL3xxhu4++67ZS85WSwWFBYWom/fvtJlYtP28ePHfXqMjRs3IicnR8r8iNkj8ZgR8TF1Oh2OHj3q9jHMZjMaGhqkj0anKcJK4EL0zk5fUAAAMPfs6fE4BondFvxWH3wA/bZtqpgX4w3ra1M17DJESvQQ2bIR4ouvWdxpdviwyxTrcBD7YoTYWIfLufR0n85Y4zp1Ah8fD6apCdrCQu9fTAzAPGSjAGUOufW1h8jzAzCofuklCCyL2K+/hj7AN2AODdVBDuSjgMgNFTb1qzVr2tLJdnSHHGpqasDzPJKSkhwuT0pKQpUPZ3idPHkS586dw2i7JsaMjAy0bdsWy5cvR11dHSwWC9asWYPLly97fMzVq1dj2rRp0sf8+fMD/6ZkIo7dZ2tqABknhPvSP2SvceJE8AYDtKdPo+3kyaqYF+MN4+u2e9hliJQIiJzWyV11Fbi0NDAWC3QHDoR9PYA1KBLLqPVTplibPnfs8K18YHeEhy99RMbcXLfNx74GYKHg61lm3lj69EHDAw8AABLnzAno365cDdVAkCfeq2hoppzU2NSv1qxpS6eqgChYGzduRKdOnRwasLVaLZ5++mmUlJTg4Ycfxv33349Dhw5hwIABYDz8sk2YMAEfffSR9KGGgIhPTJT+cch5wKsUEDXTPyTd/uefwRiNLpcrOS/GG6k3x5cMkbjLTAU9RGAYZctmNhrbC2fTqFHWkqofWRp/+ojAcdAfPAgAMNkyxE033OB7ABYC/jRVe1Pz9NPgUlKgO3YsoLEVsgZE9k3Vfox0UNvQTDlpLl707XbhLE95m1WkYNa0pVNVQJSQkACWZV0yN1VVVS5ZI2dGoxHbtm3DqFGjXK7LysrC66+/jo8++gh5eXmYPXs2amtrPfY96XQ6xMXFSR+xTmUDRWg0EGQ+4JW9cAHa06chsKxv7zTE1LIbSs6L8cZ+AnRzpF1mCm+7F4nziHQKTqxmL18GAPBt2vh9X7+23u/aBc3Fi+ATElD32GMAYA28FfyD73dTtQdCcjJqbTteW//tbzDk5/uVZZHr2A7gSoaIMZl8PitPbf01AfGQ3WKqqhD33//69hBhLk95m1WkVNa0pQt4230oaLVaZGVl4eDBgxg8eDAAgOd5HDx4EOPGjfN63x07dsBisWDYsGEebxNnS32XlJTg1KlTuMc2bDBS8CkpYKuqZKv/i7vLzP36ScGWN2Jq2RM17nzw9XBXQNkMkbvmb7N9hkgQFDnQUfxd4wMYo+HPmWaxX38NADCOGwdLVhYAQHPunN9fUzYcJ2VC+SBKZqKGe+9F/JIl0BUVIWXGjCtfJj292V1MWhkzREJsLASDAYzRCLaiAlxzwV4z/TWRsP3befcYYH3e6x54APGffALthQvS5gF3/8J82VUZKs7jHLjUVOs6VPpcRzpVZYgAYPz48fjxxx+xefNmnD9/Hu+//z6ampowYsQIAMA777yD5cuXu9xv48aNGDRoEFq7KY1s374dhw4dwsWLF7Fr1y689NJLGDRoEPr16xfqb0dWcs8Qkbbb+9g/FIk7H9gIyRC5O2LE1LcvBK0WmrIy6bTzsLJYpPJsIAGRRTzCo7TU+++sxQLDunUAgMbbb5eGg2ouX1akoRyAQ/Yk2AwRABjWr4e2qMhl154vWRa5plQDsE5kt2Xbffk7osb+Gn94zG6VlCBh8WJoL1yAJTMTNbNnAwyjzvKUbZxD4513+l22Jv5RVYYIAHJyclBTU4OVK1eiqqoKmZmZeOGFF6SSWXl5uUvvT3FxMY4ePYoXX3zR7WNWVlZi2bJlqKqqQnJyMoYPH46JEyeG+luRnawzRATB74bqiNv5IAhXmpX96SFSSckMsbEw9+4N/f790O3Z43GKeKiI2SHB7kXUH0KrVrB07gztmTPQHj4Mk4c+Nf327dCUl4NPSrL2sul04Fu3BltbC83587B06xbMtxEQKWOn1QJ6fXAPZldq9jvLIgjQFBdbH0aGDBFgDW41paU+ZZoj8U2QxFt2y/ZfPjYWl9atg5CUBC4z020mqWbBAipPRQmfAqIFCxb4/cAMw2Cuh36T5owbN85jicxdg3NGRgZWrlzp8fFyc3OR2wJ+oeXcMqspLISmtBSCXg/ToEE+3UeOgX3hxDQ2guF5AD7OIVJqUnVTExjb7iPndZoGDoR+/37od++G8Y47wrosMfDmk5ICfldq7tUL2jNnoPMSEMV+8w0AoDE3F7CNx+A6dAB75Ag0584pGxDFxQVdqgym1MxevgzGaLT+23JzNEgg/Mk0R9ybIDvNPe8AwDY2Wn83c3KoPEV8K5kJbl78ysvLcfjwYRQVFUnzeoqKinD48GFcvnzZ7X1IcOQsmYnZIdPAgYCvTeMyDOwLJ6l/iGF82jqt1OGurO3FF3Atz5jFg14V2GkmBURBHMPTbB+R2SyVixp/9zvpYotYNlOiVAi7hmoZ+oeCybKI5TI+LS34TJWNP1vvm93+Dah2+3dAzzuVp6KaTxki56zM0aNHsXjxYjz66KO46aaboLH90nAch02bNuHTTz/FY7adIkQ+Qc0QceLrcR3OxJ0PiS++6LBdVY2pZYdymQ/v8gX7OUQ8D7DhabGTshEGA6B1/Ccpbr3XHTwINDb6HrzKIJgdZiJLMwFRzLZt0FRWgmvTxiE7IvbLKBUQBTul2l4wWRY5d5iJ/HpjZXsTlDxzJgQ4lvzEz5uGD1dl4BDJ2S2ijID+4v/3v//FyJEjMWrUKCkYAgCNRoObb74ZI0eOxLJly2RbJLGSLUPE89KEal/7h+yJpzSLWaKKpUsVnRfjiT8N1YBdyUwQpBfEcJBGA7h58eU6dgTXrh0Yi0Wa0xMusmSIbI3V2hMn3A4llHaX3XabQzAoBkRahXaaMTJtuQeCG7In5wwikb+9iNL2b6ffA/ENRNzKlYj58UfZ1icXU3Y2uHbtXLLZIhpuSJwFFBCdOXPG69llqampOHv2bMCLIu7J1VStPXwYmspK8PHxMPfvH9iD6HQQbI22lm7dVPkO0Z8t9wAAgwGCrYclnFvvnc8xc7ySuTKPKMxlMzkCIq5jR/CtWoExmaA9dcrxSpMJhvXrATiWy8T7AcpniOQIiLwN2bNeKHgsNcu6w8wmkF5EY24uav/yFwDW3Y/lq1ah9LffUH/vvWB4HsmPPQatD/OmwoktLbWOT0BklPiJ8gIKiJKTk7F9+3ZwboaKcRyHgoICJAd5CCFxJVdTtdQ/lJ0tNbEGtB5x+66Mk7PlxPpxsCsA65ZkBRqr2WZefM0KTayWIyACy14Z0OhUNov5+Wew1dVXmlftKF4yEzNEMpUoPQ3ZA6wlSePNN7u9nxgQWeTMEAWYadbadruZBg+2lje1WlS/8gqacnLA1tUh5cEHwZaVqeKID/byZbSZMgWaigpwaWnWHiw7NNyQuBPQtvs77rgDS5cuxezZszFmzBi0t/0jLykpwffff4+ioiJMnz5d1oUSGQOiAPuHXNaTnAwUFYFR6UGRjB8Hu4qEhASgoiKsjdVSv4qHwE06wmPPnrAOaJQlIIJ1HlHMrl0uGQSxXNY4frzLu3SLGBCVlQFGI2A7rDlcmgtSA+GyiykxEcl/+Qs0ly4hbtUqNNx3n8t9Qloy8/PfrTgo02H8g16Pirw8tLv9dmgLC9HmrrvANjZCU1oq3cSX4ZNucVxAO76Y2lqk3HcfdKdOwZKRgctr1oBr3552j5FmBRQQ3XzzzWBZFp999hny8vIcrktISMCMGTNws4d3PCRw0h+y6mrAYnFpwG0Wx0G/bZt06nbTDTcEtx6VZ4j8OdhVpESGqLl1mq+9FoJGY50dU1wMXsYXR2/kCojc7jQzGmHYsMH6v7ff7nIfITkZfHw82Pp6aC5cAHf11UGtwV9yNlU7sO1iEtU9/jgS581Dq3/+Ew2TJrnsJFO8qdp+LbZsnfM8LCE5GZc//hjtxo6F7vRpj8Mn/cnIeJou7Tawsg+cEhPR+u23of/tN3Bt2uDyZ59JwaRapucT9Qp4MOOoUaNw00034dSpUygvLwcAtG3bFldffbVDozWRj3jAKyMIYKuqwLdt6/N93f2BafPII4G9cxPXo/KASMzy+DKUUSQosPW+uWyEEBcHc69e0P/2m3UeUbgCIhl2mQHuAyLDTz+BrasD1769lAFzwDDWWUTHjkF7/nz4AyIZm6q9qb/vPrRasgTa8+dds0SNjdDY/raGJENUVeVXxlFj6wu1uOln4jp3th4L0tAQ9BEf4nRp58Nn3QVW7v6uAQBvMODy8uXg7A76JqQ5Qe0r1mg06N69O3JycpCTk4Pu3btTMBRKWm1AB7yG6nBGaS0qDYj8OdhVxItb7xXIEHlbpxJ9RLKVzHr2hMAw0JSVgbW9wBvEctnvfudxvIHUR6TATjOHwYyhFBuLulmzAACt/vlPwGSSrhJf5Pn4eGkDgxzEnydjNPp8NApTXw+N7ffB3cR0/c6d1qNWPN3f1yM+mjk7DbhygLSnv2sCrN+bljb2ED/5lCE67MPhjO70sr0zJPLhk5P9O+A1hIczqj5D5G33lgdKHN/hy44m03XXIf6jj6x9RGEiV0AkxMeD69wZ2qIiaA8fhnnQIBi++w6A9ewyT5TcaRauDBHglCVauRIN998PwK5EddVVsvaNCXFxEPR6MCaT9YBXH4I+cS18YqLbg6DlOuLD16neqcOGWW/n4ViOSDh0lqhPyI7uAIAVK1YEdD/iGZ+SApw+7XOGKJQn1IsBEaPSgCiQpmolDnj1KSCyH9DY1ATExIR2TQ0NYMXT3oMsmQG2IzyKiqA7fBhsTQ3YhgZYOnSAecAAj/dRclo1G64MESBliaReosmTAb1e9jPMJAzjcJ6ZL1v6xXKZp9vKNQTR18BKe+aM1+uD+btGopdPAdG8efNCvQ7iI39nEYXycEa1Z4gYf7fdwy5DFM5t9z5ksrjOncGlpEBTUQHdwYNSCS1ka7L9fgkxMbIEBeZevRCbnw/d4cPQ790LADD+7ndeMx9iIKDEcMaQNVV7UH/ffWj17rvQXrggZYm0IWioFvHJydaAyNe/I7ag1OLhgGG5zjn0NbBquOMOxH31VbO3U+Whs0S1fAqIqPSlHv5uvQ/l+Hq1B0SBNFUrmSHy+uLLMDAPHAjN999Dv3t32AIiPjlZlnKNeIRHzLZtYGzN2o233eb1PqoomYUjQwRcyRLNnStliUKx5V7k79Z7rbst9/bsj/iwbfwQif/nyxBEKbAqKXHbjyQGVg1Tp/oUENGxHMQfQR/WZDQacf78eZw/fx5GW4qdhI6/W2aDOTag2bWoPCDydiSGJ0pkiLxOqrYjls0MGzaEfOidXDvMpMeznXunKS0FazvCI2XGDK8N/eKLL3vxorVMGEbh7CES1U+dCi4tzZol+vxzaA8dsq6lsVH2n7O/f0fcziBy4mn4JAPAOH68b7tZNRrUPvmk26vsp0ubbrwxZH/XSPQKeNv9yZMn8emnn+Lo0aPgeR4AwLIsevbsifvvvx9Xh3mbbLTwe6iat8MZgxxfL9hv31Uhh8NdfaREhsjnIYC2QCJmxw7E7NgBIIihd82tSaaGasC2NfqFF1x+/5qbT8OnpIA3GMAajdAUF4Pr0iXotfhK1qM7fGWXJUqcPRuM7e9q67ffRtwXX8j6c/a79G4LiDyVzETOwyc1J08i4e9/h2HDBmhOnWp+fIIgwLBhg7UxWqcDY3f+nfMB0h4zUnQsBwlQQBmiEydOYN68eSgsLMSoUaPw4IMP4sEHH8SoUaNw+vRpzJs3DydPnpR7rQSBDVUT37kJTtN+gx1fL2WIqqsVGc/fHH8PdwWU3WXmLZNlyM9H6zff9Dj0LtDRCZ6Iv19csAGRH9uoXTCMYmWzUEyq9gXXpo01cLQFQ9J6ZP45+1t6b7ZkZs82fLLxzjtR9//+H4wjR4IxmZD0wgsus4Wcxa5ZA8PGjRD0elzasAHlq1ahcskSlK9a5XKAtKeMFB3LQQIVUIbo888/R0pKCv76178iyWk+xqRJkzBnzhx89tlnmDNnjhxrJHYCPeDVmJsLyzvvQL9/P+pmzoRxzJigx9fzdttvmepqCDJkE+Tk9+GuUHhStad1hnB0gidylcyC3eXIdewI3YkT0J4/D5Ob+4eKWDLjZTrLzCcch8SXXnK/Hpl/zv78HWFqa6UssN+HzDIMql96CTGjRyNm61bErl6NxrvucntTtqICCXPnAgBqn3gClh49mn14l+NQ6FgOEoSAM0RjxoxxCYYAICkpCTfffDNOnDgR7NqIG8GcZya+MDXedZf1xSfYPxo6nZR9UV3ZjOPAin0gAZTM1LTLTAwqgh5658+aZCqZBbvLUWwoDutwRkFQpGQWzp+zP39HxOeeT0ry69+SiMvMRO2f/wwASFiwwOOYjoR586CpqIC5Z0/UPfaY71/ALiMly981ErUCCogYhnF70r2I53kwYTqAMtoEHBA1NUkvOrIeA6DSxmrxBQ0IrGTG1NUBTmWLUJGyER5efEM5OsET8fdLzCQEKthdjoqUzEwmMBYLgPAGROH8OftTem9uy70v6v74R5i7dYOmvBwJr77qcn3Mpk2I+9//IDAMqv72N5cz3QgJh4ACoh49emDDhg24dOmSy3Xl5eX47rvv0LNnz6AXR1yJL1CMeMCrj6RjAAyGoF/kHNaj1oBILJfpdH4NMZRKZoIglbJCymQCYzuuwdOLbyhHJ3giV8ks2F2O0qn3YQyIxAAVCOO2e4T35yz9HfHhjZVf/UOe6PWofuUVAEDcJ59AZ3cEDVNfj8T/+z8AQP0jj3gd1klIKAXUQzRlyhTMmzcPTz75JAYPHoz09HQAQHFxMX799VdoNBpMmTJF1oUSK2k6tCCAra72+QXLYaaJnMcAqDQgCqShGgBgMEi7W9jaWnC2jFGo2Addnkpmcg2984dsu8y8zafxYTeQEueZSaVWgwHQBrwR12/h/Dn7lSESp1QHExABMN14IxomTULcqlVIeu45VM+bB83lyzCsWwft+fOwdOyI2ueeC+prEBKMgDJEXbp0wcsvv4z+/fvj119/xZdffokvv/wSu3fvRv/+/bFo0SJkZmbKvFQCANBqpWZmfxqrQzXkTbUZogC23FvvyIS1sVrazeTtxdcWVABwybSEaouxnNvug9kNJJXMSkulsQOhJu36C2N2CEBYf85SU7UPB7zKUTIT1cyZAz4uDrojR9D23nuRPGsWYm075xrvvjusGTlCnAX89qdDhw545plnwPM8amwvHAkJCWA9nFxN5MMnJ4OtrvarjyjUAZHazjML5GBXkZCQAFRUhGXrva/DI8WgInHuXIddW86zWWTB81d6iGQazBjobiC+XTsIBgMYoxGakhJwnTrJsh5vwnbSvRvh+jkLrVpJmVCmogKCl78LspTMbPQ7dzqUJKX1AGj1j3/A3Ls3bZcnivE5IPrHP/6BcePGoYdtK6QgCLh8+TKSkpLc7jYjocOnpABFRf5liEJ0UKRqM0Tiwa4BBEThzBD5s5tJDCoMGzYgZcYMAEB5fj74du3kXVNVlTQHR85+M3E3kH+LYcBlZEBbWAjNuXPhDYjCPINIFJat5OIBrxcvgq2sBO/l74IvU6p9Io6PcLccWIMiOqGeKMnndE5BQYFDE3VdXR1mzZqFo0ePhmRhxLNAZhFpQnRQpN+Ts8MkkINdReEczuj3AECNBsbcXJhtb0z0v/wi/5rEcllCAqDTyf74/gr3qfdhP8fMnTBsJffl7whTXS2NoPB7BpETJcZHEOIPqm9FoEC23ocsIFJphkgMZvgA5qbw4tb7cGSIAmz+brJlWmIKCmRfk0bG/iE5iC/E2jAFRKwC55gpwZc3M1J2qE2boJ8PJcZHEOIPCogikN8ZIkEIWQ+RYH98h4oEMqVaJDZih7OHyN91moYMAQDot22TfU1yNlTLIdw7zXw5SqUl8OXviBiEytE/pMT4CEL8QQFRBPI3Q8RUVoK17SThbCMSZFtLC2yqDucBr4GWZ5puuAECw0B34gRYmd9Rqy4gCnfJTMGm6nDy5e+ItOU+yHIZEPxMKkJCza9dZqdOnYLO1lPQaHuBPXr0KOrtpgLby6Zf7JDw94BXqaG6bVtA5rOZ1Foyk0pRAZTMpB6icGy7DzBwE5KTYenVC7pDh6Dfvh3GO+6Qb00yDWWUS7iHM0ZNQORDhkjaci9HM3uQM6kICTW/AqL8/HzkO522vGrVKo+3X7FiRWCrIl75WzIL1Q4zwCkgEgRZhz4GQypFBVD2CGuGKNABkgCahgyB7tAhxGzbJm9ApLYMkRgQFRdbp7OHeFgiEy09RL5kiMQeIhkyRECYx0cQ4ief/7LMmzcvlOsgfvC3ZBaq/iHgyon3DMeBqasL6PDHUBD7fwJZj5QhCkNfVDBbvJtyctAqLw8xMvcRqS0g4tPSpJk5mosXQ/J7bC9qmqp9yDTLOYNIRCfUE7XyOSDq1atXKNdB/OBvyUwboh1mAIDYWPAGA1ijEWxVFTiVBERSY6zKe4jYIMYDmLKzIbAstEVFYC9c8DpLxq812X6vOJWUzMCy4K66CtqiIussohAHRFHXVO3pjZUgyDeDyFkgM6kICTFqqo5ADge8clyztw9lhghQ53lmsmSIVDSp2h0hIQHmfv0AyLv9XsoQyTmUMUjh3GkWNT1EzbyxYqqqpB43i0wlM0LUjAKiCOR8wGtzQh0QSetR0XDGYAINtU6qdicU84jUVjIDwjucURWDGcOguV5EqVzWrp3smzEIUSMKiCKRTicND/TptOowBURqyhAFfLgrrgREYZlUHcR4AMBpHpGbE9IDWpPKdpkBdhmicARECh/dES5ShqixEXBzwKvcDdWEqB0FRBHK58ZqsxnsxYsAIjwg4jjoCwoQu2YN9AUFzZYK2SACIrFkxtTVAbYzvUIl2H4V06BBEHQ6aC9ckGbGBMVolPqa1JQhkqZVh6Fk5vdxKhFKaN0agm3Hnru/I2JAJMuWe0IiQMgCIj7ELyTRztet95rSUjCCACEmJmTv+EMdEBny85GWnY22kyYhedYstJ00CWnZ2TA4jYCQNDWBaWqyri2YkpkgSJmmUAk2GyHExcHUvz8Aecpm4gujoNVKgaEaSMMZbdnOUBJLZnwLL5mBYbw2VmtknFJNSCTwOSDav3+/zw9qNpvxt7/9LaAFEd/4HBCJ5bL0dIANTfwbyqZqQ34+kmfOBGs3swQA2NJSJM+c6TYoYu0GhQZUijIYINgGkIa6bBbo0R325DzGQyqXpaSoZqYUYDec8cIFnzYSBCNa5hAB3hurtTJOqSYkEvj8Cvn666/7FBQZjUa8/PLL2L17d1ALI975WjIL1aGuDmsJVUDEcUicOxcQBJcTssUptwnz5rm8QEoN1bGxgQ3xY5iwNVYHs+1e5NBYHWQfkRobqgGAb98eglYLxq4EHCrR0kMEeH9jJWWIqGRGooTPAVHHjh3x+uuvY9++fR5vU1tbiwULFuDw4cP4/e9/L8f6iAc+Z4hCOKVaWkuIzjPT79wJTUmJSzAkYgQB2uJi6HfudLw8iINdRWHZem8ygTGZAAQ388Y0cCCEmBhoLl6E9tSpoJYkBthq2nIPANBopKBeG8qyGc9HzS4zwMsbK7sZRLTlnkQLnwOiOXPmoFOnTnj99dexd+9el+srKiowd+5cFBUV4Y9//CPGjx8v60KJI/EPWXNb3UO9wwwIXYZI4+Ohpc63C3bnFgBpF18oM0SMfWkvmGyEwQDTwIEAgi+baVS4w0wUjllEjNEoZR+jKkPk9HeEraiQJnaHehAmIWrhc0AUFxeHOXPmIDMzE3/729+wZ88e6bqSkhLMmTMHZWVl+Mtf/oIRI0aEYq3Ejq/TqiM5IOJSUwO6XTAHu4qEMGy9l8plMTGArWcpUHLNI1JryQwIU0Ak/kwYBoLBELKvoxaeAiJpy31aGhAFzwMhgJ+7zGJjYzFnzhxkZWXhjTfewO7du1FUVIS5c+eirq4Ozz//PAYPHhyqtRI74h8yjRpKZuIfVZkDIlN2Nrj0dOkkbGcCw8CSkWE9B8mOHI3KYckQBTE80plp6FAAsI4kCGKHp5oDIksYdpo5lMtCtAlBTTy9sQrZkR2EqJjf/+INBgNmz56Nq6++Gm+++Sbmz58Pnucxd+5c9OnTJxRrJG6oqWQmOJ94LxeNBtULF7p9TDFIqlmwwOVQSDGrE8g5ZtLjixmiMAREwQRuIlO/fuBjY6GpqID22LGAH0eNQxlFYc0QRUG5DPCSIbI1VFsoICJRxOeAqLCwUPooLi7Gvffei6SkJHAchwcffBAMwzjcprCwMJTrjnq+lMyYmhopOAjHLjOmqQmM0SjrYxtzc1E3Y4bL5UJCAirz8mDMzXW5TpYMURgOeJX1VHW9XsqUBVM2U3OGKBzDGaPlHDORp78jtOWeRCOf9yQ///zzHq9bsmSJ28tXrFjh/4qIT6R3duIBr05ZEsAuO5ScHNI/8EJ8vHVLtMUCprISgsznHrG2IYuNubkQtFrEff01TAMGuA2GgOCmVIukXWbhyBDJlI0w5eTAsHkz9Nu2of6RRwJ6DFUHRGLJrLjYWhYMQUmLjaIdZoDn3aq05Z5EI58Doj/+8Y+hXAfxk3TiPc+Dqa6G4OYFLBzlMusiGPBJSdCUl4OtqgIvczZK3FbfeNddsHTtirivv0bMtm1gamvdBj2MDCWzcGSIpB4iGUpmgF1j9Y4dHoPk5ogvjJwaA6L0dAgaDZimJrCXLoFPS5P9awR7lEqk8bTtnrbck2jkc0BEO8dURqcD37o12NpasBUVbl/AwhYQAQ4BkZzYigrobD0xpsGDwbdpA/PVV0N36hRiNm6E8Y47XO4jR8ksLBkimftVzH37Wn8nqquhO3QI5muv9e8BBEHVGSJoteDat7ee23buXEgDoqjrIaqvB5qagJgYhxlE1FRNoknL30bRgjU3rTocO8xEoTq+Q//LLwAAc/fuUqOvcdw4AEDs+vVu78PKsO0+LD1EMjZVAwC0WqmPSB9AHxFTUwPGYgGg0oAIoT/TLJqGMgLWwF+wZRLFvyNseTlYoxECw9AMIhJVKCCKYM0GRGHOEAG2niYZ6XfsAACHrfViQBSzcaP1Xa0TOXpzxCBFc+GCNbgIwflZoSjPSGWzAAY0Stmh+HjVzp4JdWN1NJ1jBgBgWZc+IjE7xLdvD+j1ii2NkHCjgCiCeTupGrDLEIVwh5m0llAd32HLEJluuEG6zNy/P7i0NLB1dW5f+MWddYE2VRvy85H0xBMAAG1xMdpOmoS07Gy3B8kGIxTlmSbxoNeCAsR+8YVfwZyqy2U2od56z0bZLjPA9e+I1D9E5TISZSggimDNnWcWjoNdpbWEoGTG1NVB99tvAIAm+4GfLAvj2LEAAIObspmUeQmgFGXIz0fyzJlgy8sdLmdLS5E8c6asQZHsJTMA2jNnIDAMWKMRyU884Vcw53DSvUr5NZyR46yB4Zo1PgeG0dZUDbhuvddS/xCJUhQQRTCvARHHQVNSYv3fcJbMmhkU6Q/9r7+C4XlYOnVy2bkmls0MGza4nnYfaIaI45A4dy4gCC4HyornWyXMmydb+UzuXWaG/HwkP/qoyyBLX4M56WBXFQ5lFPmaITLk5yMtOxttJ01C8qxZPgeG0TaHCHD9O0IN1SRaUUAUwbz1ELEXL4LhOAhaLXgfzwQLai0hOL7DXf+QqOnGG8EnJEBTXg693bl6QOCZF/3OndCUlLgEQyJGEKAtLpbGAARL1gZeGYI5qWSmtpPu7UgB0fnzHqeiS1k+2xsCkS+BYdT1EMH17whNqSbRigKiCOZtWrVULktPD2gejb9CsctMDDya7PqHrlyph3H0aABOZTNBCDjzoikrk/V2zZGzZCZHMKeJgJIZl5EhlQTFEp/jDYILDKMyIHLKENGUahKtKCCKYN5KZuHccg+EoIfIaIR+3z4A7jNEgF3ZbP16KVvAGI1gbC92/pbMOB8zab7erjlSeUaGgEiOYE7KEKm4ZAa93rr7Ce7LZsEGhmyUzSECnDJEPH/lzRRNqSZRhgKiCOatZKYNY0M1IP8uM/2+fWBMJnBpaeAyM93epmnkSAgxMdAWFUkHmkr9QwzjdynKlJ1tnYbMuH85FRgGlowMjwGav+Q87V6OYC4SdpkBV6YnuwuIgg0MpabqaOwhqqwEe+kSmKYmCCxrzS4TEkV8nlQdTuvXr8c333yDqqoqdO7cGQ8//DC6du3q9rbz58/H4cOHXS4fMGCAdP6a0WjEp59+il27dqG2thapqam49dZbccstt4T0+wg1n0pmEZohcugf8hSgxMejadgwGH74AYZvv0Vdz55XAqJWrTzezyONBtULFyJ55kwIDCOVWABIQVLNggWylSDlzBCJwRxbWuqwbpHAMODS070Gc5GwywywNfvu2uV2p1mwgWG0DWYEHDPNGrFclp4O6HRKLouQsFNdhqigoADLli3DxIkTsXjxYnTu3BmLFi1CtYeBf08//TTy8vKkjzfeeAMsy+LGG2+UbvPxxx9j3759+NOf/oS///3vuO222/Cf//wHv/76a7i+rZBwaGTmeYfrwh4QJSZa11JfD5hMQT+e1D/UTDam8dZbAdh2m8Gu5BFgkGHMzUVlXp5UlhFx6emozMvzeKBsIGQtz9iCOQAuGS5fg7mIKJmhmeGMFgvct1pbNZfli7ajOwDHTLOWDnUlUUx1AdHatWsxevRojBw5Eh06dMCMGTOg1+uxadMmt7dv1aoVkpKSpI8DBw4gJiYGN9g14h4/fhw33XQTevfujdTUVNx8883o3LkzTp48Ga5vKyScD3i1F+6ASEhIkF54g55WbTZDbwtWmytPNY0ZA4Flof/tN2jOn5flYFdjbi4u7tyJ6v/7PwCAJTMTZTt2yBoMwWwGY5uyLdfMm2CDOWnbvdozRB5KZjGbN6PNQw+BASAgsMAw2puqpS331FBNopCqAiKLxYLCwkL07dtXuoxlWfTt2xfHjx/36TE2btyInJwcGOyOHujevTt2796NiooKCIKAgwcPoqSkBNd6OPzSbDajoaFB+mhsbAzuGwsVvV564Xcum4W7qRoaDQQxSxRk2Ux38CDYhgbwSUmw9Ojh9bZ8mzYw2YY2GjZskG/nlkaDJltJla2okH2nntg/BMg7mFEM5i5/8omUKSn/5pvmgzmzWQpkVR8Q2X6ntUeOSAMXY777DikPPQTGaIRxzBhUvvtuQIEhG40BkZghqquD9tQpADSDiEQnVfUQ1dTUgOd5JNn6UURJSUkotr3Ae3Py5EmcO3cOf/zjHx0uf/jhh/Hvf/8bf/jDH6DRaMAwDB599FH06tXL7eOsXr0aX3zxhfR5ly5dsHjxYv+/oTDgU1LA1tWBrayEuJGYqa+XgpJwNVUD1j4itqoq6IBIKpcNHgywzcfsxrFjEbNjBwzffouGKVOsawniYFeR+KLA1tSAqa6WAj45SOWymBj5ezU0GjSNHAkuKwvawkLojh1Dk1Nw4LIeW3ZIYFmp/KlGhvx8JL7wAgBAW1KCtpMmgUtOBltdDYbn0Zibi8olS6xjGcaPR/JjjyF27Vo03nYbKv/1L++BrcUCxmgEEF1N1UJiIgSWBcPz0mR4mkFEopGqAqJgbdy4EZ06dXJpwP72229x4sQJPPvss2jXrh2OHDmCDz74AMnJyW6zRBMmTMD48eOlzxl/m3PDiE9JAc6edcgQidkhPjEx4PO8AlqLuNMsyGnVMV4GMrpjHDcOiQsWQL9zp3SWlxxZFyEuDlybNtBcvgzNuXOwyBgohGM3k7lXL2gLC6E9fBhNN93k9bZS/1BSUljmVgVCHLjoMom7shIMrAF05b/+BWhtf9Y0GjTl5CB27VowJlOz35dYLgOiq6kaLAs+KQmaigpoT5wAQBkiEp1UVTJLSEgAy7KocsowVFVVuWSNnBmNRmzbtg2jRo1yuNxkMuGzzz7Dgw8+iOuvvx6dO3fGuHHjkJOTg2+++cbtY+l0OsTFxUkfsbGxwXxbIeXugNdwnmHmsBY5dprxPPS7dgFwPNDVG65TJ5h79QLD84hdswaAfGUosblUHFYnFyYE55g5M9syoDo3uzCdqX6HmbeBi7D2DGnOnXPZWSiObNCcOdPsl5AaqrXaqDvlXfy5M7bNGRQQkWikqoBIq9UiKysLBw8elC7jeR4HDx5E9+7dvd53x44dsFgsGDZsmMPlFosFHMe5ZHlYloXgYfR/JGlpAZH22DGwVVXg4+Jg7tPH5/uJu810tkZ5OUpmQOhOVw92N5wvpIDoyJHm16PyHWbNDlyEtYTmPHDRYguItGfOuOzEdHkM+x1mKs4Kh4L9cS2CRgOumRIrIS2RqgIiABg/fjx+/PFHbN68GefPn8f777+PpqYmjBgxAgDwzjvvYPny5S7327hxIwYNGoTWTi+EcXFx6NWrFz755BMcOnQIZWVl2Lx5M3766ScMtj9BPUK5m1Yd7h1mIjmO7xBf0EyDBl0pffjAOHasw+dsVZUsh7BabBkiuQMiKUMUwuZdiy0g0p44Adh2tHmi9qGMgQ5c5K66CoJWC6apCWxpqdf7srbNE1FVLrOx/7lzV13l1789QloK1f3W5+TkoKamBitXrkRVVRUyMzPxwgsvSCWz8vJyl2xPcXExjh49ihdffNHtYz755JNYvnw5/vnPf6Kurg7t2rXDlClTMGbMmFB/OyHnblq1UgGRHBkiqX/Iz2BVW1QEQaORju2I+/JLxBQUoHrhwqC2y4ulA7czb4Ig9RCFMCDiMjLAJyaCra6G9sQJWLxk3NQeEAU8cFGrBdehg3WaeVERTF6ypuH4maiVfYaIttyTaKW6gAgAxo0bh3G2c6qczZ8/3+WyjIwMrFy50uPjJSUl4bHHHpNreariblq10gFRwMd3CMKVDJGP/UOArdn20Uddm21tp5sHM1BRDIhkzxCFYwAgw8Dcqxditm+H7siRiA6IgpnEbcnMtAZEZ87AlJPj8WtIP5NozxBR/xCJUqormRH/uC2ZhXsGkbiWIDNEmtOnoSkrg6DXw9S/v293CvJ08+ZY7AMiGXvO5Dzp3htfG6vVHhAFM4lbaqwuKvL6JaJxSrWIt9u0IgiCLOVmQiINBUQRzqVkxvMRGxDFiNmhAQMAu8Ga3gR7unlzxOeQbWhwe2ZcoKSDXUMcEFmuuQZA8wGRRu27zBD4JG5L584ArGVVb6LxHDPAmmFtvWSJ9Hn8ypVIy86GIT9fwVUREn6qLJkR3zmXzNhLl8CYzdbTqtPSwruWIAMiqVzmx2nywZ5u3iyDAVz79tCUlkJz7pxsu7DClY0QM0Taw4etGS4Pu6fUvstMZMzNhXHsWGsgXFYGLjXV+vviZcaQxccMkaxny0UIj7OdZCg3ExJpKEMU4ZwPeJWyQ+3bh32niGC/lgAE0j8U7OnmPt1X3Hov4yyicL34mrt3h8Cy0FRUgPUSFKq+ZGZPo4EpJweNd95p7QlqZuAiZ7/13kvZU8wQRU1TdYjLzYREGgqIIpx0wCvHgampUayhGrBrqq6p8fuPKHvhArRnz0LQaGAaONDn+4nNts59JaLmTjf3hbj1Xs6dZuEqmSE2FparrwbgpWwmCJEVEPnJ0qkTBIYBW1vrtewZbU3VoS43ExJpKCCKdDEx0jtatqJC2YDIdrQFIwjWoMgPMb/8AgAw9+njX6NxEM22vgrFTrNwNvA210fENDSAsc0pUnvJLCAGg9R35K1sFm09RCEvNxMSYSggagHsG6uVDIig00kZD5/LZhwHfUEBYj/7DIBtIKOfAm229VUoAqJw7TIDnPqI3K3FljURDAYIKj6mJhjSxGpvAVGU9RCFo9xMSCShpuoWgE9JAc6ds2aIxB6iMB/bIa0lKQlsXR3Yqio0VzQz5Ocjce5caEpKpMtiv/wSpuxsv4OYQJptfWWJ8AxRc0d4SOeYJSe32CMrLJmZiNm+3euZZtHWVB3MbCdCWiLKELUA9ueZKXWOmbQWH3eaibtbWLtgSLxf8syZgW359bPZ1lfStOrz55s9D8tX4ZyKLGWITp4EjEaX68UMEdcSy2U2UmP16dMebxN1k6rDUG4mJJJQQNQC2G+9V7RkBh/PM4uw3S1cRgYElrWeh3XpkiyPGY7T7kV8+/bgk5LAcBx0J064XN+SG6pF0iwiLxkiJgrPMgt1uZmQSEIlsxZAzBBpioulAXtKBUS+HN8h7m7xxH53i7ejFsJGpwOXng7thQvQnD0LXob5TuE47V4iHuFRUADt4cMw9+3ruJYIGMoYLEuXLgCaaaqOspKZKJTlZkIiCWWIWgAxIBJ3EfHx8RBsO77CvhYfMkSRuLuFk3Prvdl8ZVdXmLIRUh/RoUMu10XKUMZgcLYMkebyZTC1tW5vE23b7h2EqNxMSCShgKgFEN/Z6w4eBGDLDinUHCsFROJRIm5E4u4WOXeaiS+8QJgyRPDeWC3+rOxPPG9phNatpR4pT43V0dZUTQhxRAFRCyA1Vdve+SpVLnNYi5cMUTiGKcpNzp1m0guvXg/o9UE/ni8s9oe8Oh/TEAUlM+BKlsjT1ntpUnU0ZogIIRQQtQTOL2RK7TADfNxlZr+7xekqte5ukXaayZEhEqdUhzETYe7WDYJGA7aqynVnXxSUzIBmZhEJwpXBjJQhIiQqUUDUAjiXOpTMEIm9S81tuxd3twitWztcrtbdLbKWzMK4w0xiMMDStSsA14nV0bDLDLiy9d5tycxkAmOxAKCAiJBoRQFRC+CSIVKyZObDLjORMTcXxptvBgA0/O53KF+1CmU7dqguGALsSmYXLgQ9DkCp3Uye+oiipWRm8TKLyKGvi0pmhEQlCohaADVliHwdzCjSHT0KAGi8+25V727h27eHoNOBsVigKS0N6rGUat51e6YZx0k/qxZfMhN3mrnJELFiucxgUO3vICEktCggagkMBodGUNUERG6OA3BgMkFrGxQoNv2qlkYjPa+as2eDeqiwnXTvxN2ZZmx1tTQMU/zZtVScOIuopMRlYrc0pZqyQ4RELQqIWgKOk9L8AgCuXTvFliKVzDhOeuH3RHvyJBiLBXxCgqKN4L6Sq49I6ZKZtrAQsE1llspliYmAThfW9YQbn5ICvlUr6+BPp59htA5lJIRcQQFRhDPk5yMtOxua8nIAAAMgbdiwwM4Ck0NsrLXsgObLZmIvi/maayLiUFGLTDvNlCqZ8amp4Nq0AcPz0B0/bl1LlDRUAwAYRuoj0jj1EdEOM0IIBUQRzOMBqaWlgR+QKgNf+4jEgEjsbVE72TJECpXMwDAufURRFRDBbhaRUx+RFBBRyYyQqEUBUaRS8QGpUtnMy7RqANDaZ4giQKSXzADXPqJo2WEmEs80c55FxEbzsR2EEAAUEEUs8YBUT4Um+wNSw83fDFGkBERyTatmlZhDZGO2n1iNKxkiroXvMBNxHnaaSU3VVDIjJGpRQBSh1HxAqi8BEXv5MjQXLwIALD17hmFVwZMyRCUlgNkc8OOoIUOkO3IEEISoK5l5mkVETdWEEAqIIpSaD0j1JSASy2WWzMyIeRHiU1MhGAxgeB6a4uKAH0fJbISla1cIWi3Y6mpoioujr2QmZojOnwdsk6kB6iEihFBAFLHUfECq4ENAFGnlMgDWpuQOHQAEN4tIkaM7RDExsHTrBgDQHjp05aT7KAmI+PR0CDEx1gGbFy5Il9MuM0IIBUSRyv6AVKegSOkDUqWm6upqj7eJtB1mIjkOeVWyhwi4EoTqDh+OupIZWBaWTp0AOO40U2oUAiFEPSggimDiAal8+/YOlyt9QKo/JTOz2idUO5Fjp5nSDbzm3r0BWIPSaCuZAXaHvNr1EdGkakKIVukFkOAYc3NhHDvWuuusrAxcaqq1TKbgeUzNBkQWizQYMKJKZpA3IFIqG2FxlyGKkl1mwJU+IvsMEfUQEUIoIGoJNBrrwagq0VxApC0qAmM0go+LA2crX0QKOaZVS+UZpUpmtqyc5vTpK+eYRVGGSJxFpLGbRaR0kEoIUR6VzIjs+ORkAF4CItsMHEvPngAbWb+CQWeILBYwtoNFlSqZ8e3agWvXTgqGBJ0OQuvWiqxFCe6mVVMPESEksl6NSERobpdZRO4wsxEzWpqLF11OTPeF/YG3SmWIAMfeLT4lJSLOkpOLdJ5ZURFgCwpplxkhhAIiIjtpl5nRKJ2qbk+ckhxpDdWANfslZnY058/7fX+pNKPTAXq9rGvzh6VHD+n/hZgYRY54UQrXoQMEjQas0QjWNhxUDIioqZqQ6EUBEZGdEB8PQWttT3OXJdJG6JZ7AADDBLX1Xg2lGUN+PuJWrpQ+1549i7TsbMUOAw47nQ6cbZ6UeKYZQ2eZERL1KCAi8mMYj43VTHU1tLaBeOYIObLDWTB9RIqddG9jyM9H8syZYJx+LmxpKZJnzoyaoEgqm9n6iKipmhBCAREJCU8Bke7oUQCA5aqrICQmhnlV8gjmkFdFp1RzHBLnzgUEweVQYLHBOmHevKgon0mN1adPAzwPlnqICIl6FBCRkPDUWB3R5TKboEpmCs670e/cCU1JiUswJGIEAdriYuh37gzrupQgHfJ65gwYuz43CogIiV4UEJGQ8JghEhuqW0BAFGklM01Zmay3i2Sc3U4zaYcZw0AwGBRcFSFESRQQkZCQdpo5B0QRvOVeFKklMy41VdbbRTIpQ1RUdOVnEhcXVeMHCCGOKCAiIcHb+oMcMkQ8D63YQxSBW+5FUobo8mWpGddXSu4yM2Vng0tPdzkMWCQwDCwZGdajX1o48YBXtqZGOvWeymWERDcKiEhISNOqKyulyzRnz4JtaIAQEyMdnxCJhMREKeDzdxaRorvMNBpUL1wIAC5Bkfh5zYIFip6DFzaxseBshyKLZVzack9IdKOAiISEux4iqVzWvTugjexj9KSy2dmzft1P6e3dxtxcVOblgbcFAyIuPR2VeXkw5uYqsi4liGUzKSCiDBEhUS2yX5WIarnbZdYSdpiJuI4dgYMHoT13Dk1+3E/pgAiwBkXGsWOtu87KysClplrLZNGQGbJjycxEzI4dUkCk1NlyhBB1oICIhITXDFFLCYjgf2M1q+QcInsaDUw5OcquQWHSLKLjxwFQhoiQaEclMxIS7naZtYQt96JAAyIxQ0TZCOWJJTPGbAYACLGxCq6GEKI0CohISDhniJj6eumYhEjeYSYKdOu9GkpmxEqcRSSinwkh0Y0CIhISUkBUXw+YTNAeOwZGEMClpoJv00bZxckg0GnVqimZEVhsJTMRBUSERDcKiEhICAkJ0lZutrq6RfUPAVcCIra6Gkx1tc/3o5KZegiJieBs4yEA+pkQEu0oICKhodFIh7eyVVUtaocZYM0mcLZMlz9lM0UPdyUu7MtmNIeIkOhGAREJGfs+opaWIQICK5spOamauLLYB0T0MyEkqlFAREJG2mlWWdmiAyKfM0QWCxijEQBliNSCsx3hAQCakhKA4xRcDSFESRQQkZARAyLdkSNgq6shaLWwdOum7KJk5O9OM/tzz6hfRXmG/HzEf/yx9Hmrf/8badnZMOTnK7gqQohSKCAiISMGRDHbtwOANRjS6xVckbz8LZlJ/UM6HRATE7J1keYZ8vORPHOmw5wsAGBLS5E8cyYFRYREIQqISMiIx3fodu0C0LLKZYD/JTPqH1IJjkPi3LmAIIBxuooRBABAwrx5VD4jJMpQQERCRmqqtvXNtJQdZiJLRgYAQHP6NPTbtjX7Akpb7tVBv3MnNCUlLsGQiBEEaIuLod+5M6zrIoQoiwIiEjJiQCRqSRkiQ34+2k6dCgBgm5rQdvLkZvtPaMu9OmjKymS9HSGkZaCAiIRMSw2IxP4TtrTU4fLm+k+oZKYOXGqqrLcjhLQMqjztfv369fjmm29QVVWFzp074+GHH0bXrl3d3nb+/Pk4bDs01N6AAQPw/PPPAwAmT57s9r73338/br/9dvkWThzwCQnS/3OtWoFv21bB1cikmf4TgWGQMG8ejGPHAhqN4/W2DBFPGSJFmbKzwaWngy0tlXqG7AkMAy49HabsbAVWRwhRiuoCooKCAixbtgwzZsxAt27dsG7dOixatAhvvfUWEm2Tj+09/fTTsFgs0ue1tbV45plncOONN0qX5eXlOdxn7969eO+995BNf/BCxpCfj8T/+z/pc01dHdJuuAHVCxfCmJur4MqCI/afeGLff2LKyXG8jjJE6qDRoHrhQiTPnAmBYRyCIvG4mZoFC1wCWkJIy6a6ktnatWsxevRojBw5Eh06dMCMGTOg1+uxadMmt7dv1aoVkpKSpI8DBw4gJiYGN9xwg3Qb++uTkpKwa9cu9O7dG2lpaeH6tqKKVFK6fNnh8pawpTmY/hMqmamHMTcXlXl54Nu3d7icS09HZV5eRAfthJDAqCpDZLFYUFhYiDvvvFO6jGVZ9O3bF8ePH/fpMTZu3IicnBwYDAa311dVVWHv3r2YNWuWx8cwm80wm83S5wzDIDY21rdvItoFUVKKBMH0n1BTtboYc3NhHDvWmvUrKwOXmmotk0Xg7yUhJHiqCohqamrA8zySnJpxk5KSUFxc3Oz9T548iXPnzuGPf/yjx9v89NNPMBgMGDx4sMfbrF69Gl988YX0eZcuXbB48eLmvwESVEkpEgTTf0I9RCqk0UTk7yEhRH6qCoiCtXHjRnTq1MljAzYAbNq0CcOGDYPey8TkCRMmYPz48dLnDONpYglx1uK3NHvrP7H911P/idRDRKeqE0KI6qiqhyghIQEsy6LKaZx+VVWVS9bImdFoxLZt2zBq1CiPtzly5AiKi4u93gYAdDod4uLipA8ql/kuGrY0e+o/gV7vtf9E6iGiDBEhhKiOqgIirVaLrKwsHDx4ULqM53kcPHgQ3bt393rfHTt2wGKxYNiwYR5vs3HjRmRlZSEzM1OuJRMnYklJ8JBVExgGloyMiN/SbMzNxcWdO1G+ahWqFyywXshxaLrpJo/3kSZVU0BECCGqo6qACADGjx+PH3/8EZs3b8b58+fx/vvvo6mpCSNGjAAAvPPOO1i+fLnL/TZu3IhBgwahdevWbh+3oaEBO3bsaDY7RIJkKykBcAmKWtyWZlv/Sf306bB07AiG46D/5RePN5eaqmmXGSGEqI7qAqKcnBz8/ve/x8qVK/Hss8+iqKgIL7zwglQyKy8vR2VlpcN9iouLcfToUa/BTkFBAQRBwNChQ0O5fILo3NLcZPu9itm2zeNtWNplRgghqsUIgputMsStS5cuOWzHJ83guKjZ0hy7ejWSH38cpmuvRfm337q9TeqQIdAWFaF8zRqYBg0K8woJIST66HQ6tGvXzqfbtqhdZkRlomhLc5Pt+9T99huYykoIyckut5G23VPJjBBCVEd1JTNCIhGflgZzt25gBAExO3a4vQ0NZiSEEPWigIgQmYh9RHp3fUQWC1ijEQAFRIQQokYUEBEiE9OQIQDcN1YzDQ3S//M0mJEQQlSHAiJCZNJ0ww0QGAa648fBOk3ilsplWi0QE6PE8gghhHhBAREhMhGSk2Hu0weAa5bIYUo1HQVDCCGqQwERITISy2bOfUS0w4wQQtSNAiJCZORpQCNNqSaEEHWjgIgQGZkGD4ag1UJ79iw0Z89Kl7O2pmoKiAghRJ0oICJERkJ8PEwDBgBwzBLRDCJCCFE3CogIkZm7PiKph4gCIkIIUSUKiAiRmUMfke2oQGmXGZXMCCFElSggIkRmpuuug2AwQFNWBu3JkwAAhgIiQghRNQqICJFbTIx0mr1+61YAVDIjhBC1o4CIkBBocjrGgzJEhBCibhQQERICUh/R9u0Ax4GlXWaEEKJqFBAREgLmvn3Bt24NtqoKusOHpQwRTaomhBB1ooCIkFDQamG64QYA1u33VDIjhBB1o4CIkBCR+oi2bqWSGSGEqBwFRISEiBgQ6XfuBFNVBYACIkIIUSut0gsgpKWy9OwJrk0baC5fls4y4+PiFF4VIYQQdyhDREiosCxMOTkOF1GGiBBC1IkCIkJCSCybiXRHjgAcp9BqCCGEeEIBESGhZLE4fJryyCNIy86GIT9foQURQghxhwIiQkLEkJ+PxDlzIDhdzpaWInnmTAqKCCFERRhBEJz/XhMPLl26BLPZrPQySCTgOKRlZ4MtKQHj5mqBYcClp6Nsxw5Aown78gghJBrodDq0a9fOp9tShoiQENDv3AmNh2AIABhBgLa4GPqdO8O6LkIIIe5RQERICGjKymS9HSGEkNCigIiQEOBSU2W9HSGEkNCigIiQEDBlZ4NLT4fAuC+aCQwDS0YGTNnZYV4ZIYQQdyggIiQUNBpUL1wIAC5Bkfh5zYIF1FBNCCEqQQERISFizM1FZV4e+PbtHS7n0tNRmZcHY26uQisjhBDijLbd+4G23ZOAcJx111lZGbjUVGuZjDJDhBAScv5su6fDXQkJNY3G5UwzQggh6kIlM0IIIYREPQqICCGEEBL1KCAihBBCSNSjgIgQQgghUY8CIkIIIYREPQqICCGEEBL1KCAihBBCSNSjgIgQQgghUY8CIkIIIYREPZpU7Qetlp4uQgghJFL487pNZ5kRQgghJOpRySwAjY2NeO6559DY2Kj0UqIKPe/KoOddGfS8K4Oed2Wo4XmngCgAgiDg9OnToORaeNHzrgx63pVBz7sy6HlXhhqedwqICCGEEBL1KCAihBBCSNSjgCgAOp0OEydOhE6nU3opUYWed2XQ864Met6VQc+7MtTwvNMuM0IIIYREPcoQEUIIISTqUUBECCGEkKhHAREhhBBCoh4FRIQQQgiJenQ4l5/Wr1+Pb775BlVVVejcuTMefvhhdO3aVelltSiHDx/G119/jdOnT6OyshJPP/00Bg8eLF0vCAJWrlyJH3/8EfX19ejZsyemT5+O9PR0BVcd2VavXo1ffvkFFy5cgF6vR/fu3XH//fcjIyNDuo3JZMKyZctQUFAAs9mMfv36Yfr06UhKSlJu4RHuu+++w3fffYdLly4BADp06ICJEydiwIABAOg5D5c1a9Zg+fLlyM3NxbRp0wDQcx8KK1euxBdffOFwWUZGBt566y0Ayj/nlCHyQ0FBAZYtW4aJEydi8eLF6Ny5MxYtWoTq6mqll9aiNDU1ITMzE4888ojb67/66it8++23mDFjBl5++WXExMRg0aJFMJlMYV5py3H48GGMHTsWixYtwosvvgiO4/DSSy/BaDRKt/n444+xe/duPPXUU1iwYAEqKyvxxhtvKLjqyJeSkoKpU6fi1VdfxSuvvII+ffrgtddew7lz5wDQcx4OJ0+exPfff4/OnTs7XE7PfWh07NgReXl50sfChQul65R+zikg8sPatWsxevRojBw5Eh06dMCMGTOg1+uxadMmpZfWogwYMAD33nuvQ1ZIJAgC8vPzcdddd2HQoEHo3LkzHn/8cVRWVmLXrl0KrLZlmD17NkaMGIGOHTsiMzMTs2bNQnl5OQoLCwEADQ0N2LhxIx588EH06dMHWVlZeOyxx3Ds2DEcP35c4dVHruuvvx7XXXcd0tPTkZGRgSlTpsBgMODEiRP0nIeB0WjE22+/jUcffRTx8fHS5fTchw7LskhKSpI+EhISAKjjOaeAyEcWiwWFhYXo27evdBnLsujbty/9AwmjsrIyVFVV4dprr5Uui4uLQ9euXennIKOGhgYAQKtWrQAAhYWF4DjO4ff/qquuQtu2bel5lwnP89i2bRuamprQvXt3es7D4P3338eAAQMc/p4A9PseSqWlpXj00Ufx+OOP45///CfKy8sBqOM5px4iH9XU1IDneZdaZlJSEoqLi5VZVBSqqqoCACQmJjpcnpiYKF1HgsPzPD766CP06NEDnTp1AmB93rVarcO7aICedzmcPXsWs2fPhtlshsFgwNNPP40OHTqgqKiInvMQ2rZtG06fPo1XXnnF5Tr6fQ+Nbt264bHHHkNGRgYqKyvxxRdfYO7cuXjjjTdU8ZxTQEQIcfDBBx/g3LlzDrV9EjoZGRl4/fXX0dDQgB07dmDJkiVYsGCB0stq0crLy/HRRx/hxRdfhF6vV3o5UUPcLAAAnTt3lgKk7du3q+LnQAGRjxISEsCyrEukWlVVRbsOwkh8rqurq5GcnCxdXl1djczMTGUW1YJ88MEH2LNnDxYsWIA2bdpIlyclJcFisaC+vt7hHVx1dTX9/gdJq9Wiffv2AICsrCycOnUK+fn5yMnJoec8RAoLC1FdXY3nnntOuozneRw5cgTr16/H7Nmz6bkPg/j4eGRkZKC0tBTXXnut4s859RD5SKvVIisrCwcPHpQu43keBw8eRPfu3RVcWXRJTU1FUlISfvvtN+myhoYGnDx5kn4OQRAEAR988AF++eUXzJ07F6mpqQ7XZ2VlQaPRODzvxcXFKC8vp+ddZjzPw2w203MeQn379sXf/vY3vPbaa9LH1VdfjaFDh0r/T8996BmNRpSWliIpKUkVv++UIfLD+PHjsWTJEmRlZaFr167Iz89HU1MTRowYofTSWhTxH4morKwMRUVFaNWqFdq2bYvc3Fz873//Q3p6OlJTU/H5558jOTkZgwYNUnDVke2DDz7A1q1b8eyzzyI2NlbKhMbFxUGv1yMuLg6jRo3CsmXL0KpVK8TFxeE///kPunfvTi8QQVi+fDn69++Ptm3bwmg0YuvWrTh8+DBmz55Nz3kIxcbGSv1xopiYGLRu3Vq6nJ57+S1btgzXX3892rZti8rKSqxcuRIsy2Lo0KGq+H2n0+79tH79enz99deoqqpCZmYmHnroIXTr1k3pZbUohw4dcttDcdNNN2HWrFnSYMYffvgBDQ0N6NmzJx555BGHIYLEP5MnT3Z7+WOPPSYF/OLQtG3btsFisdCgOhn861//wsGDB1FZWYm4uDh07twZd9xxh7TriZ7z8Jk/fz4yMzNdBjPScy+ft956C0eOHEFtbS0SEhLQs2dP3HvvvVLJWOnnnAIiQgghhEQ96iEihBBCSNSjgIgQQgghUY8CIkIIIYREPQqICCGEEBL1KCAihBBCSNSjgIgQQgghUY8CIkIIIYREPQqICCGE+GX+/PmYP3++0ssgRFYUEBGiAhs2bMDkyZPxwgsvKL0U1eJ5Ho8++igmT56MvXv3Kr0cQkgLQwERISqwdetWtGvXDidPnnQ4x41cIR5x0a5dO2zZskXp5RBCWhgKiAhRWFlZGY4dO4YHH3wQCQkJirzY8zwPk8kU9q/rj59//hldunTBbbfdhl27dsFoNCq9JLc4joPFYlF6GYQQP9Fp94QobMuWLYiPj8d1112HG264AVu3bsWkSZMAABaLBTNmzMCgQYPw2GOPOdyvoaEBM2bMwNixY/HAAw8AAMxmM1avXo0tW7bg8uXLSExMxJAhQ3DPPfdAp9NJ9508eTLGjh2L7t27Y/Xq1SgpKcFf/vIXDB48GF9//TV++eUXFBcXo6mpCR06dMCECRNwww03OHx9k8mETz75BNu2bYPZbEbv3r0xY8YM/OEPf8DEiRMdDoytqKjA559/jr1796K+vh7t27fH+PHjMWrUKJ+eI5PJhF27duHuu+9GTk4OPv74Y/z6668YOnSoy2337t2LNWvW4PTp02AYBhkZGbjtttscbnvixAl88cUXOH78OCwWC9LS0jBq1Cjk5uYCgNQf49wns2TJEhw+fBhLliwBYA1mH3/8cdx///3QaDRYv349ysrKsHjxYnTo0AFffvkl9uzZg9LSUvA8jy5dumDy5Mno06ePw+PyPI/169fjxx9/RGlpKQwGA7KysnDvvffi6quvxrx589DQ0IDXX3/d5ft94oknkJqaitmzZ7t97l599VWcP38e77zzjst1s2fPBsdxePXVVwEAmzZtws8//4xz586hoaEBaWlpuPXWW3HLLbd4+MlYbd68Ge+++y7eeecdpKamSpeLBzXPmzcPvXv3dnj+V65ciePHj4PjOFx99dWYMmUKevbs6fXrEBJKlCEiRGFbt25FdnY2tFothgwZgpKSEpw8eRIAoNVqMXjwYOzatcsl67Br1y6YzWYMGTIEgPVF9bXXXsM333yDgQMH4uGHH8agQYOwbt06/P3vf3f5ugcPHsTHH3+MnJwcTJs2TXoh+/bbb5GZmYnJkydjypQp0Gg0ePPNN7Fnzx6H+y9ZsgTr16/HgAEDcN9990Gv1+OVV15x+TpVVVWYPXs2fvvtN4wdOxbTpk1D+/bt8d5772HdunU+PUe//vorjEYjcnJykJSUhN69e7vNpG3evBmvvvoq6urqcOedd2Lq1Kno3Lkz9u3bJ93mwIEDmDdvHs6fP49bb70Vv//979G7d2/s3r3bp7W4s3nzZqxfvx6jR4/GAw88gFatWqGhoQEbN25E7969cd9992HSpEmoqanBokWLUFRU5HD/9957Dx999BHatm2L++67D3feeSd0Oh1OnDgBABg+fDjOnDmDs2fPOtzv5MmTKCkpwbBhwzyuLScnB2VlZdLvlOjSpUs4ceIEcnJypMu+++47tGvXDhMmTMADDzyAtm3b4v3338f69esDfm6cHTx4EPPmzUNjYyMmTZqEKVOmoKGhAQsXLnRZIyHhRBkiQhRUWFiICxcu4KGHHgIA9OzZE23atMHWrVvRtWtXANYXtE2bNmH//v0YOHCgdN+CggKkpaXh6quvBmANrA4cOIAFCxY4vNPu2LEjli5dimPHjqFHjx7S5cXFxXjjjTfQoUMHhzX94x//gF6vlz4fN24cnnvuOaxduxbXXXedtO7t27cjNzcX06ZNAwCMHTsW7777Ls6cOePweJ9//jl4nsff/vY3tG7dGgBwyy234K233sKqVaswZswYh6/nzs8//4zu3bujbdu20nPywQcfoKamBgkJCQCsGbMPP/wQXbt2xbx58xweUxAEANagMS8vD8nJyXjttdcQHx/vcptAXL58GW+//ba0FvFrLVmyBFrtlT+zo0ePxpNPPolvv/0Wf/zjHwFYA4TNmzfj1ltvlX4PAOB3v/udtKYbb7wR//nPf7Blyxbcd9990m22bNmCmJgYDB482OParr/+euh0OhQUFEi/UwCwfft2MAzjEBAtWLDA5We/aNEirFu3DuPGjQvkqXEgCAKWLl2K3r1744UXXgDDMACAMWPG4KmnnsLnn3+OF198MeivQ0ggKENEiIK2bNmCxMREqYTCMAxuvPFGbNu2DTzPAwD69OmD1q1bo6CgQLpfXV0dDhw4gBtvvFG6bMeOHejQoQMyMjJQU1MjfYiPfejQIYev3atXL5dgCIDDC2JdXR0aGhpwzTXX4PTp09LlYsZl7NixDvd1ftEUBAE7d+7EwIEDIQiCw7r69++PhoYGFBYWen2OamtrsX//fikTBkAq39k/JwcOHEBjYyPuuOMOlwBLfOE9ffo0ysrKkJub6xAM2d8mENnZ2Q7BEACwLCsFQzzPo66uTioP2T+XO3fuBMMwUpnU3Zri4uIwaNAgbNu2zSG4KygowKBBg2AwGDyuLS4uDv3798f27dsdgr6CggJ069ZNCjIBx599Q0MDampq0KtXL1y8eBENDQ3+PCVuFRUVoaSkBEOHDkVtba30u2A0GtGnTx8cOXJE+r0nJNwoQ0SIQsQXtN69e6OsrEy6vFu3bli7di1+++039OvXDxqNBtnZ2VKvjk6nwy+//AKO4xze3ZeUlODChQuYPn26269XXV3t8Ll9r4e93bt343//+x+KiopgNpuly+0DhvLycjAM4/IY7du3d/i8pqYG9fX1+OGHH/DDDz+4/Xo1NTVuLxcVFBSA4zh06dLFYQdet27dsHXrVikIE6/r1KmTx8e6ePEiAGvWTE6ensvNmzdj7dq1uHDhAjiOc3v7ixcvIjk5Ga1atfL6NYYPH46CggIcOXIEvXr1woEDB1BdXY3hw4c3u76cnBzs2rULx48fR48ePVBaWorCwkIpuyc6evQoVq1ahePHj6OpqcnhuoaGBsTFxTX7tbwpKSkBAKkHy52GhoZmnwtCQoECIkIUIm4jLygocMh0iLZs2YJ+/foBAIYMGYIffvgBe/fuxeDBg7F9+3ZcddVVyMzMlG4vCAI6deokNVg7s88EAHBbpjpy5Ahee+01XHPNNXjkkUeQnJwMjUaDzZs3Y+vWrX5/j2JGYtiwYbjpppvc3qZz585eH0P8unPmzHF7/cWLF5GWlub32rxhGMZtCc1T9sLdc/nzzz/j3XffxaBBg3D77bcjISEBLMtizZo1UmDmj/79+yMxMRFbtmxBr169sGXLFiQlJeHaa69t9r4DBw5ETEwMtm/fjh49ekjlMvtG+dLSUvz1r39FRkYGHnjgAbRp0wZarRZ79+7FunXrAsrcON9HfE7vv/9+h99de96yXYSEEgVEhChELJc98sgjLtft3LkTu3btgslkgl6vxzXXXIPk5GQUFBSgZ8+eOHjwICZMmOBwn7S0NJw5cwZ9+/YNuPyzc+dO6HQ6zJ4922FX2ubNmx1u17ZtWwiCgLKyMqSnp0uXO89QSkhIQGxsLHie9+mF25k4kmDcuHHo1auXw3U8z+Odd97B1q1bcffdd0vZqbNnz7pkqkRi4HTu3Dmv64mPj3cbtJSXl/u89h07diAtLQ1PP/20w89j1apVLmvav38/6urqvGZGWJbF0KFDsXnzZtx3333YtWsXRo8eDZZtvvPBYDDguuuuw/bt2/HAAw+goKAA11xzDVJSUqTb7N69G2azGc8995xD8OxcanVHXLdzWe3SpUsu3ytgLeMF8vtASChRDxEhCjCZTPjll1+krfbOH+PGjUNjYyN+/fVXANYXw+zsbOzevRs///yzS7kMsDbeVlRU4Mcff3T79XyZ28OyLBiGcXhnX1ZWhl27djncrn///gCsE7btOe9GEte9c+dOlx1SQPPlMnEn2e233+7yHOXk5KBXr15SBunaa69FbGws1qxZ4zJTScxMdOnSBampqcjPz0d9fb3b2wDWF+7i4mKH9RUVFeHo0aNe1+v8vTs/7okTJ3D8+HGH22VnZ0MQBJdAyfm+gLVsVl9fj7y8PBiNRq+7y5zl5OSgsrISGzduxJkzZ1x+f9ytt6GhwSUYdkcMdA4fPixdxvO8y+9iVlYW0tLS8M0337j9fWzu94GQUKIMESEK+PXXX9HY2Ijrr7/e7fXdunWThjSKL1w5OTlYv349Vq1ahU6dOrk0RA8fPhzbt2/H0qVLcfDgQfTs2RM8z+PChQvYvn07Zs+eLe1I8+S6667D2rVr8fLLL2PIkCGoqanBhg0b0L59e4fdY1lZWcjOzkZ+fj7q6urQrVs3HD58WOoRsc+ITJ06FYcOHcLs2bMxevRodOjQAXV1dSgsLMRvv/2GDz/80ON6tm7diszMTJdyn+j666/Hf/7zHxQWFiIrKwsPPvgg3nvvPTz//PMYOnQo4uPjcebMGTQ1NeHxxx8Hy7KYPn06Fi9ejGeffRYjRoxAcnIyLly4gPPnz0uzfEaOHIm1a9di0aJFGDlyJGpqavD999+jY8eOaGxs9PocigYOHIhffvkFf/vb33DdddehrKwM33//PTp06OAQDPTp0wfDhw/Ht99+i9LSUvTr1w+CIODIkSPo06ePQ6N6ly5d0LFjR+zYsQNXXXUVsrKyfFoLAAwYMACxsbH473//KwWq9vr16wetVovFixfj5ptvhtFoxI8//oiEhARUVlZ6feyOHTuiW7du+Oyzz6RMl9j7ZY9lWfzhD3/Ayy+/jKeeegojRoxASkoKKioqcOjQIcTGxuL//u//fP6eCJETZYgIUcCWLVug0+k8lg1YlsV1112Hffv2oba2FgDQo0cPtGnTBo2NjS7v7sX7PPPMM5g6dSrOnTuH//73v1i1ahVOnTqF3Nxch9KWJ3369MEf/vAHVFVV4eOPP8a2bdtw3333YdCgQS63ffzxxzF27Fjs2bMHn376KSwWC5588kkAcCi3JSUl4eWXX8aIESOwc+dOfPDBB1KGxn4LuTNxJIH9qAFn4nViJmnUqFF49tlnERcXhy+//BKffvopTp8+jQEDBkj36d+/P+bNm4f09HSsXbsWH3/8MQ4ePOjwdTp06IDHH38cDQ0NWLZsGX799Vc8/vjj6NKlS7PPoWjEiBGYMmUKzpw5gw8//BD79+/Hn/70J7dBzGOPPYb7778fZWVl+OSTT7B69WqYzWZ0797d5bZiL5YvzdT29Ho9Bg4ciMbGRvTu3RuJiYkO12dkZOCpp54CwzD473//i++//x4333yzNKyyOX/+85/RvXt3fPXVV1i9ejV69+6NqVOnutyud+/eWLRoEbKysrBhwwZ8+OGH+Omnn5CUlITx48f79T0RIidGCGb4BiGE2CkqKsKzzz6LP/3pT36Vc4jv8vPz8fHHH2PJkiUeM2eEEP9RhogQEhB3Z5+tW7cODMPgmmuuUWBFLZ8gCNi4cSN69epFwRAhMqMeIkJIQL766isUFhaid+/e0Gg02LdvH/bu3Yubb76ZXqxlZjQa8euvv+LQoUM4e/Ysnn32WaWXREiLQwERISQgPXr0wIEDB/Dll1/CaDSibdu2mDRpEu666y6ll9bi1NTU4J///Cfi4+MxYcIEj834hJDAUQ8RIYQQQqIe9RARQgghJOpRQEQIIYSQqEcBESGEEEKiHgVEhBBCCIl6FBARQgghJOpRQEQIIYSQqEcBESGEEEKiHgVEhBBCCIl6FBARQgghJOr9f/CGFsLa8TpgAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_svm_sig,'ro-')\n",
        "plt.title(\"Sigmoid SVM\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKtCC-bsYYOW"
      },
      "source": [
        "# K-fold RBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk7DmrFTSax6",
        "outputId": "b0ac254e-d2dd-47f4-db0d-d3ab90900293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        82\n",
            "           1       0.91      0.93      0.92       102\n",
            "\n",
            "    accuracy                           0.91       184\n",
            "   macro avg       0.91      0.91      0.91       184\n",
            "weighted avg       0.91      0.91      0.91       184\n",
            "\n",
            "The accuracy for 1 : 0.9108082257293162\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.90      0.83        82\n",
            "           1       0.91      0.78      0.84       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.84      0.84      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "The accuracy for 2 : 0.8433763749402199\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.70      0.78        82\n",
            "           1       0.79      0.93      0.86       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.84      0.81      0.82       184\n",
            "weighted avg       0.84      0.83      0.82       184\n",
            "\n",
            "The accuracy for 3 : 0.81324725011956\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.73      0.79        82\n",
            "           1       0.81      0.90      0.85       101\n",
            "\n",
            "    accuracy                           0.83       183\n",
            "   macro avg       0.83      0.82      0.82       183\n",
            "weighted avg       0.83      0.83      0.82       183\n",
            "\n",
            "The accuracy for 4 : 0.8163487080415358\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.72      0.71        82\n",
            "           1       0.77      0.75      0.76       101\n",
            "\n",
            "    accuracy                           0.74       183\n",
            "   macro avg       0.74      0.74      0.74       183\n",
            "weighted avg       0.74      0.74      0.74       183\n",
            "\n",
            "The accuracy for 5 : 0.7359937213233518\n",
            "0.8239548560307967\n"
          ]
        }
      ],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm_rbf=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"rbf\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm_rbf.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_svm_rbf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQToNmkfeX1A",
        "outputId": "c51c9dee-72a0-4a85-cdc8-754acb81b3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.812382369886691, 0.8163916843029702, 0.8407878287772566, 0.8239548560307967, 0.8225119758048147, 0.8371470149725077, 0.8410494606496444, 0.8306966086714369, 0.8324041128646581, 0.8424954838120037, 0.8430984409267582, 0.8488646847362727, 0.848833007884732, 0.8468916522838091, 0.8557905552109181, 0.8406000676132522, 0.8428522481183651, 0.8521400626663783, 0.8573012820512822, 0.855169172932331, 0.8588112243718652, 0.8538683847257184, 0.8565097756274228, 0.8588809523809523, 0.8615806342780026, 0.8586974767164824, 0.8594551855830053, 0.8581538362471426, 0.8600187190260716, 0.8567577465229269, 0.8618990384615385, 0.8581876456876458, 0.8604126265890972, 0.8541496598639456, 0.8586790524290525, 0.8573239823239824, 0.8631947000368053, 0.8593227285534979, 0.8597916666666668, 0.8582238899312069, 0.8606583231583236, 0.8586445853887715, 0.8601067493112947, 0.859242424242424, 0.8630050505050507, 0.8605496453900711, 0.8602982954545455, 0.8620336013193157, 0.8616414141414142]\n"
          ]
        }
      ],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_aver_svm_rbf = []\n",
        "for i in range(2,51):\n",
        "  acc_svm_rbf=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=SVC(kernel=\"rbf\")\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_svm_rbf.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "      pass\n",
        "  acc_aver_svm_rbf.append(Average(acc_svm_rbf))\n",
        "\n",
        "print(acc_aver_svm_rbf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhPlGES2SO8k",
        "outputId": "b8738f1a-65fb-4321-cc18-eb293ca8ac63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8631947000368053\n",
            "37\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_svm_rbf)))\n",
        "print(acc_aver_svm_rbf.index((max(acc_aver_svm_rbf)))+1)\n",
        "print(acc_aver_svm_rbf.index(0.8557905552109181)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "6WYVYYGGe3u-",
        "outputId": "60392203-5f97-424a-e935-d1162cf9af25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_svm_rbf,'ro-')\n",
        "plt.title(\"RBF SVM\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v8mQ-3deSTp"
      },
      "source": [
        "# K-fold Poly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5JrbYwQSen9",
        "outputId": "136fbb39-7269-499e-848d-2b966536eacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89        82\n",
            "           1       0.92      0.89      0.91       102\n",
            "\n",
            "    accuracy                           0.90       184\n",
            "   macro avg       0.89      0.90      0.90       184\n",
            "weighted avg       0.90      0.90      0.90       184\n",
            "\n",
            "The accuracy for 1 : 0.897297943567671\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.90      0.83        82\n",
            "           1       0.91      0.78      0.84       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.84      0.84      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "The accuracy for 2 : 0.8433763749402199\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.63      0.75        82\n",
            "           1       0.77      0.96      0.85       102\n",
            "\n",
            "    accuracy                           0.82       184\n",
            "   macro avg       0.85      0.80      0.80       184\n",
            "weighted avg       0.84      0.82      0.81       184\n",
            "\n",
            "The accuracy for 3 : 0.7974653275944525\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79        82\n",
            "           1       0.81      0.89      0.85       101\n",
            "\n",
            "    accuracy                           0.83       183\n",
            "   macro avg       0.83      0.82      0.82       183\n",
            "weighted avg       0.83      0.83      0.82       183\n",
            "\n",
            "The accuracy for 4 : 0.8174957739676406\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.77      0.72        82\n",
            "           1       0.79      0.70      0.74       101\n",
            "\n",
            "    accuracy                           0.73       183\n",
            "   macro avg       0.73      0.74      0.73       183\n",
            "weighted avg       0.74      0.73      0.73       183\n",
            "\n",
            "The accuracy for 5 : 0.7356314899782661\n",
            "0.81825338200965\n"
          ]
        }
      ],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm_poly=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"poly\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm_poly.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_svm_poly))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO3SUqSqfTjJ",
        "outputId": "f88e78f8-aee2-4034-8a78-6b54d1c4a543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8185855579028231, 0.8107749768589682, 0.8400329170732587, 0.81825338200965, 0.8278863719400804, 0.8376523992141712, 0.8537985707103353, 0.8333814104504418, 0.8402625538020085, 0.8533173181768536, 0.853358358847415, 0.854004421963479, 0.8451042175180105, 0.8478324326363542, 0.8543196533808933, 0.8464824205544286, 0.8474984639714775, 0.8526595237121551, 0.8608397435897437, 0.854596908939014, 0.8575254836696484, 0.8546841145807009, 0.8554593554593555, 0.8499285714285714, 0.861880060728745, 0.8582426359107644, 0.8581707244301231, 0.8592404778003154, 0.8576505602240896, 0.8523605782263276, 0.8585386618589744, 0.8509906759906762, 0.8564910579616463, 0.8559863945578232, 0.8549813612313613, 0.8560347310347308, 0.8589581471160422, 0.8555572632495713, 0.8546955128205129, 0.8559412132582866, 0.8548382173382175, 0.8539053323937046, 0.85393709825528, 0.8576150392817059, 0.8604797979797979, 0.8620164410058029, 0.8613347011784515, 0.8543805400948258, 0.8568232323232323]\n"
          ]
        }
      ],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_aver_svm_poly = []\n",
        "for i in range(2,51):\n",
        "  acc_svm_poly=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=SVC(kernel=\"poly\")\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_svm_poly.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "      pass\n",
        "  acc_aver_svm_poly.append(Average(acc_svm_poly))\n",
        "print(acc_aver_svm_poly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV48XkmdTBqS",
        "outputId": "06ed3a2c-7078-4d40-a862-f07c5d84e710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8620164410058029\n",
            "46\n",
            "13\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_svm_poly)))\n",
        "print(acc_aver_svm_poly.index((max(acc_aver_svm_poly)))+1)\n",
        "print(acc_aver_svm_poly.index(0.8451042175180105)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "4fNafExof6ym",
        "outputId": "823c76f2-21aa-4a8a-9dd4-33376927f393"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHMCAYAAAA067dyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDUklEQVR4nO3deXhU5dk/8O85s2SDScISSFiyEBJ2hACpAZFFik2pCoIVtGItoKJ92/pa/RUEhLdocbcV26IURYuAVLRCpKBCWcIOiuxLCFsIIZCFkEwyM+f8/sicQyaZSWYmZzIzyfdzXVw6M2fOeXJImDv3cz/3I8iyLIOIiIioBRP9PQAiIiIif2NARERERC0eAyIiIiJq8RgQERERUYvHgIiIiIhaPAZERERE1OIxICIiIqIWjwERERERtXgMiIiIiKjFY0BEREHn0UcfhSAIyM3N9fdQiKiZYEBERD4hCILDH51Oh3bt2mHUqFFYsWKFv4fXoE2bNmH8+PGIi4uD0WhEdHQ0UlJSMGnSJPz5z3+GsuvRQw89BEEQ8O677zZ4zh//+McQBAFr164FAHzwwQfq/Rk+fLjL9+Xm5kIURfVYItKe3t8DIKLmbd68eQAAi8WC48eP44svvsDmzZuxb98+vPHGG34enXMvvfQSZs+eDb1ej7vvvhupqanQ6XQ4c+YM/vvf/2LNmjWYOXMm9Ho9pk+fjhUrVuD999/HzJkzXZ4zNzcXX3/9NWJjY/Gzn/3M4TW9Xo9t27bhxIkTSE1NrfPe999/H7IsQ6/Xw2q1av71EhEAmYjIBwDIzv6J+frrr2VBEGRBEOSzZ896de6pU6fKALx+f31yc3NlnU4nm0wm+dChQ3Vet9ls8oYNG2RJktTnUlJSZADy/v37XZ73hRdekAHIs2bNUp9btmyZDEC+7777ZADys88+W+d9VqtVjouLkwcPHix36tTJ6T0losbjlBkRNanRo0ejR48ekGUZe/fuVZ/fv38/7r//fsTExCAkJATx8fGYOXMmLl++3OA5jx8/DkEQMHLkSJfH9O3bFwaDocHz7d69GzabDSNHjkTfvn3rvC6KIsaOHeswdTV9+nQAwHvvvef0nDabDcuWLYMgCJg2bVqd13v37o3bb78dH374ISwWi8Nr69evR15ennoNIvINBkRE1ORke/2NElSsW7cOGRkZ+PLLL3HXXXfhmWeeQWpqKv76179i0KBBOHv2bL3n69GjB0aOHIktW7bg5MmTdV7Pzs7G4cOHce+99yI2Nrbec7Vt2xYAkJOTA5vN5tbXM3XqVBiNRnzyyScoLy+v8/pXX32FS5cu4a677kJiYqLTc0yfPh1Xr17FF1984fD8e++9h1atWmHy5MlujYWIvMOAiIia1Ndff40TJ05AEAQMHjwYZWVlmDp1KqxWK7755husWLECL7/8MjZu3Ig//elPyMvLw+OPP97geZX6nSVLltR5TXnOnfP86Ec/Qnx8PH744QeMHDkS//jHP3DkyJF6g6P27dvjvvvuQ0lJCVavXl3ndSVzNGPGDJfneOCBB2AymRyyTJcuXcJXX32FBx98EK1atWpw7ETUCP6esyOi5gn2GqJ58+bJ8+bNk2fNmiXff//9sk6nkwHIv/vd72RZluWPP/5YBiBPnjy5zjksFouckJAgA5DPnTunPu+shshiscixsbFy27ZtZbPZrD5fVFQkh4WFyd26dXOo+6nP999/L992223q1wBADgsLk4cPHy4vXrzY4fyKr7/+WgYgDx061OH5vLw8Wa/XyzExMXJVVZXDa0oN0ezZs2VZluUnnnjCobZqwYIFMgB59+7dsizLrCEi8iFmiIjIp+bPn4/58+fj5Zdfxrfffos77rgDH330kbrC7MCBAwCAUaNG1XmvXq9Xl6MfPHiw3usoK76uXbuGf/3rX+rzH330ESoqKjBjxgy3l6z369cPBw8exN69e/HKK6/gwQcfRExMDLZu3YqnnnoK6enpKCoqcnjPqFGj0K1bN+zYsQPHjh1Tn1+2bBmsViseffRRGAyGeq87ffp0yLKMpUuXQpIkLF26FP369cOQIUPcGjcReY8BERH5lCzLkGUZkiTh+vXr2Lx5Mx5++GH19ZKSEgBwWdujPF9cXNzgtWbMmAGdToe///3v6nNLliyB0WjEL3/5S4/HPmjQIPz+97/HJ598gtzcXOzevRs9evTA999/j/nz5zscW7Ng+v333wcANbgRBMGtouiBAwdi4MCBWLZsGb766iucO3eOxdRETYQBERH5VWRkJAAgPz/f6evKqjDluPp06tQJ99xzD7Zu3Yrjx4+rxdTjx49H+/btGz3WIUOG4J133gEAfPvtt3Ve/+UvfwmDwYDly5ejqqoK3377LXJycjBy5EgkJye7dY0ZM2bg0qVLeOKJJxAWFuYQPBKR7zAgIiK/GjBgAABgy5YtdV6zWq3Ytm0bgOrsiTuU4uq///3vHhVTu6t169YAbq2Uq6lDhw645557UFhYiM8//1zNFNVXTF3blClTEBERgYsXL2LSpEmIiorSZNxEVD92qiYiv7rvvvvQpk0bfPLJJ3jqqafwox/9SH3trbfewtmzZ3HXXXeha9eubp1v9OjRSElJwYcffgiz2YzU1NR6+xPVtmfPHhw9ehQ///nPERYW5vCaxWLBokWLAMDlVhvTp0/Hv/71L7z++uv4/vvv0a5dO4wfP97t67du3RobNmxAYWEh0tLS3H4fETUOAyIi8qtWrVrhH//4ByZNmoQ777wTkyZNQteuXbF//35s3LgRHTt2dKgJaoggCHjiiSfwzDPPAPAsOwMAeXl5+OUvf4mnn34aw4YNQ69evRAaGorLly9jw4YNyM/PR3JyMubOnev0/T/+8Y+RkJCAPXv2AACefvppGI1Gj8YwbNgwj44nosbjlBkR+d29996LHTt2IDMzE//5z3/w2muv4dixY3jiiSewf/9+JCUleXS+Rx99FKIoIjQ0FFOnTvXovaNHj8aKFSswadIk5OXlYfny5XjllVfwxRdfIDExES+//DIOHjyIDh06OH1/7W7ULIomCg6C7GwinIgoiG3ZsgUjR47Eww8/jI8++sjfwyGiIMAMERE1O6+88gqA6ukqIiJ3sIaIiJqFH374AevWrcP+/fvx1VdfYdy4cUhPT/f3sIgoSDAgIqJmYf/+/Zg1axZMJhMmTZqEd999199DIqIgwhoiIiIiavFYQ0REREQtHgMiIiIiavEYEBEREVGLx4CIiIiIWjyuMvNAUVERrFarv4dBREREbtDr9YiOjnbvWB+PpVmxWq2wWCz+HgYRERFpjFNmRERE1OIxICIiIqIWjwERERERtXgMiIiIiKjFY0BERERELR4DIiIiImrxGBARERFRi8eAiIiIiFo8BkRERETU4rFTNREREVWz2WDcvRu6ggLYYmJQlZ4O6HT+HlWTYEBERC1XC/7Hn6i20KwsRM6dC93ly+pztthYlCxYAHNmph9H1jQEWZZlfw8iWFy9epV7mRE1Ey39H3+imkKzshA9YwYgyxBqPC8L1Y+KliwJyp8Lg8GA9u3bu3UsAyIPMCAiah6a6z/+RF6x2dAhPR3i5csOPw8KWRBgi41Fwa5dQZdB9SQgYlE1EbUsNhsi586tEwwBgGD//dA0bx5gszX92Ij8wLh7N3QugiGg+udCn5cH4+7dt5602WDMzkbY55/DmJ3dLH5eWENERC2K8o+/KzX/8a/KyGjCkRH5h66gwL3jrlwB0HynmxkQEVGL4vY//m4eRxTsbDExbh3X+pVXoP/+e7R6/32gVrWNmJ+P6Bkzgnq6mVNmRNSiuPuPv7vHEQW7qvR0SCaTy9dlVNcR6c+fR+v33mu2080MiIjItWZYJ1CVng5bbKxaQF2bLAiwxsVVL8EnagHCvvwSQmkpgOrgpyZZEABBQPGbb+LmAw8AgGe1RkGEARERORWalYUO6eloN2kSop96Cu0mTUKH9HSEZmX5e2iNo9OhZMECAE7+8bf/t3T+/KBbTUPkjZCvv0bUb34DAYB55EhIsbEOr9tiY1G0ZAkqJk1C1Z13unXOYJ1uZg0REdVRc1l6Tc2hTgAAzJmZKFqyBFHPPAPhxg2H10peeimovzYil2o1IoUso83jj0OwWlE+YQKK334bkGWXzUqb+3QzAyIictTAsnRZEGCaNw/msWODOotizsxExdatiPjoI1SMHQvdpUswHj4MXX6+v4dGpDlnK8NkQYAgyzDfdReK33gDEKsnjVytrlSmm8X8fLVmqCalX1GwTjdzyoyIHHjVkyRI6fLyAACVo0ahbOZMAED4qlWA1erPYRFpSsn4irXaTQiyDBlA+fjxgMHQ8IlqTjfXqsFTHgfzdDMDIiJy0JKWpSsBka1TJ5jvvhu26Gjo8vMRsnmzn0dGpJF6Mr4AAEGAaeFCtxdMKNPNUseOjpex1xoF83RzwE2ZbdiwAV9++SWKi4sRHx+Pxx57DMnJyS6PX79+PTZu3IjCwkKYTCakp6djypQpMBqN6jHXr1/Hxx9/jO+++w6VlZXo2LEjZs6ciW7dujXFl0QUVJp7nUBNuosXAQC2zp2BkBBUTJqEVkuWIHzFClSOGePn0RE1ni8akZozM2EeOxbhn3yCqOefhxQRgYKdOwF9wIUUHgmoDFF2djaWL1+OiRMnYtGiRYiPj8fChQtRUlLi9Pjt27djxYoVmDRpEt5880088cQT2LlzJz755BP1mLKyMsyZMwd6vR6zZs3Cm2++iUceeQQRERFN9WURBZWWsixdKCmBaC+otnXqBAAonzIFABD6zTcQWUtEzYDPMr46HcofeACy0Qjx5k3oLlzwYnSBJaAConXr1mH06NEYOXIkOnfujOnTp8NoNGKzi/T1iRMnkJqaimHDhiEmJgb9+/fH0KFDcfr0afWYL774Am3btsXMmTORnJysHtexVrqPiOzqW5beDOoEFLpLlwAAtuhoyOHhAABr9+6oHDIEgs1WXUtEFOR8mvE1GmHp3bv6f7//3vP3B5iACYisVitycnLQt29f9TlRFNG3b1+cPHnS6XtSU1ORk5OjBkBXrlzBwYMHMWDAAPWYffv2ISkpCW+88QamTZuG5557Dl9//XW9Y7FYLCgvL1f/VFRUaPAVEgUPc2YmSl56qU7Nga1jx6CvE1A4TJfVUD55MgAgfOVKQJKafFxEWlIzvi5eb2zG19K/PwDA8N133g0wgATMhF9paSkkSUJUVJTD81FRUcizFz7WNmzYMJSWlmLOnDkAAJvNhjFjxmDChAnqMQUFBdi0aRN++tOfYvz48Thz5gyWLVsGvV6PESNGOD3v2rVrsWbNGvVxYmIiFi1a1LgvkCjI2OxZVGuXLhALCyFWVKBoyRJYBg7088i0oWaIagVE5p/9DNK8edCfPw/j9u2oGj5cu4vW6gNTs8cLkU/odCiZNw/RTzxR5yUtMr5V/fsjAoDh0KHGjDIgBExA5I0jR45g7dq1mDZtGrp37478/HwsW7YMa9aswcSJEwEAkiShW7dumGKvDUhMTMT58+exadMmlwHR+PHjMW7cOPWx4KKWgqg5Mxw/DgCoGjQIYkkJQr/9FsYDB5pNQKRXAqK4OIfn5bAwVIwfj4gPP0TEihWaBUTNdYdwCnxiWRkEALIoQqiR9bTFxqJ0/vxGff+pGaIffqheqRbEAX7ABEQmkwmiKKK4uNjh+eLi4jpZI8WqVaswfPhwjB49GgDQtWtXmM1mLFmyBBMmTIAoioiOjkbnWr8Bdu7cGbvr6aFiMBhgcKcnA1Ezpj9xAgBg7dEDsNmqA6J9+3Bz2jQ/j0wbrqbMAODmlCmI+PBDhG7YAPHaNUht2zbqWs2987dfMetWP4sFrd5+GwBQOns2LP36aXqvrMnJkMLDIZaXQ3/qVPW/F0EqYGqI9Ho9kpKScPjwYfU5SZJw+PBhpKSkOH1PZWVlneyNKDp+SampqXWm3PLy8tC+fXuNRk7UPCkZIkuPHqgaPBgAYNy7t86HerCqLyCy9umDqv79IVgsCPv008ZdqIHO30Bw7xDuT812vz0Nha9ZA/2FC7C1b4/yqVNRlZGBivvuq15ir0XgqNPB0q8fAMAQ5IXVARMQAcC4cePwzTffYMuWLbh48SLef/99VFZWqlNb77zzDlasWKEen5aWhk2bNmHHjh0oKCjAoUOHsGrVKqSlpamB0U9/+lOcOnUKn332GfLz87F9+3Z88803GDt2rD++RKLgUFUFvX2xgrVnT1gGDICs00GXn6/W3gQ7VzVECmUJfviKFY0KAltS5++m5Kr7spJ1Y1AEh+xQ2cyZkMPCfHMZ+7RZsK80C5gpMwDIyMhAaWkpVq9ejeLiYiQkJGDWrFnqlFlhYaFDRuj++++HIAhYuXIlrl+/DpPJhLS0NEy2rxIBgOTkZDz77LNYsWIF/vWvfyEmJgZTp07FHXfc0dRfHlHQ0J85A8FqhdS6dXWNjSDA0qcPjN9/D+PevahwEUQEjcpKte+K0oOotop774XpxRdhOHMGxj17vF6F4/fO381xSqmF7LfXWA7ZoV/8wmfXqVLqiBgQaevuu+/G3Xff7fS1F1980eGxTqfDpEmTMGnSpHrPmZaWhrS0NK2GSNTsKdNl1tRUwP5LSNWgQdUB0b59qBg/3p/DazRlyw4pNBRSmzZOj5Fbt0bFvfciYuVKhK9Y4XVA5M/O3821kNsX3ZebnSbKDgE1CquPHgWqqoAaO0UEk4CaMiOiwKCvUT+kcKgjCnIO9UP1rCJVO1d/+SVCNm1C2Oefw5id7bzex2aDMTvb8ZjKSoSuX1/vWGRUtzjQuvN3c55S8nvWLQg0VXYIAGzx8ZCioiBUVcFw7JhPr+VLAZchIiL/Uwuqe/ZUn1MCIv2xYxDKyiC3auWXsWmh5qau9bEMHAhrp07QX7qEto8+qj5fO8viNBPTvj2k8HAYzp0DYO/6LQhqIbXynABAMpkAi0W76Z1mPqXUkvbb80oTZocAAIKAqn79ELp1Kwzff69mjIINM0REVIeSIaq5hFbq2BHWLl0gSBIMBw74a2ia0Nezwqym0K++clpEXjPL4jITc/UqDOfOwRYRgWsffoii996rs0O41L49pNBQGE6eRPSvf63ZSrPmXsjt6+7Lwa4ps0MKSzOoI2KGiIgcCDduqAGDJTXV4bWqQYOgv3ABxn37tO3g3MTUKbP6MkRKlsUJQZYhA4icNQsQReeZGNizQq1aoXLkSECng3ns2DoFzsZdu9D24YcRlpUFac4clCxcWO80nltfX3OfUtLpUPr884j67W/rvKQESc1hvz2vNHV2SLnsbbcBCO6VZgyIiMiBkh2ydewIOTra4bWqQYMQvnatd3VEAbTaSV1yX09A1GDhLgDd1av1XkcAoLty5VZxr05Xp8i3auhQFL39NqJnzkTEhx/CFhODsl//ulH3qiVMKenPn68OOvV6CFbrrRdEEUXvvhvUReNesf98hX3+eXV2qF27JssOAbdWmulPnIBQUdFkgZiWGBARkQODk4JqhVpYfeCAR236A221U0M9iABtsycNnct8zz0oLSxE5Jw5ML36KlotWQKxpER93dN7pUwpiS6mzWRBgC02NminlITSUkQsXQoAKPrznyG1bw9dXh5Mc+dCV1LSbJqHusvZz5dQVYWQzZub7OdL6tgRtpgY6AoKYDh8WP23IpiwhoiIHDhs2VGLtUcPSK1aQSwrUzNJDQm41U6SdKuoup6ASMvsiTvnuvnYY6j4yU8AAEKNYAjw4l7pdChZsMDpS1ps6OlvEcuWQSwpgaV7d5h/9rPq7ssTJ6L8sceqX//gA/8OsAm5+vkSbtxo2p8vQbhVRxSkO98zICIiB/VliKDTocq+uatb02YBuG2FePUqhKoqyKIIW4cOLo9TC3dd1PPIggBrbGzDx7hb3Guzwfjdd+rKs5q8uVfmzExUOem/ZouNDeq904SyMrRasgQAUPab31TXcNndfPhhyHo9Qnbvhv7oUX8NsekE2M9XsDdoZEBERLfIstpHpOaS+5rUabN9+xo8XSCudlILqjt2BOrbxLlGlqV2wKNmWRYsaPgYNzMxmt8rWYbePjWoBEaV6eko2LUraIMhAIhYvhxicTGsiYmouOceh9ekjh1htmfZWkKWKNB+voK9sJoBERGpxCtXIBYXQxZFWLt1c3pM1aBBANzLEAXiaqf6NnWtzZyZiaIlS+osl6+ZZXHnGLfGpfG90l24AF1+PmS9Hjd+/evq565cCdppMgAQKioQ8fe/AwBu/M//OP1abtr7RYV99hmE4uImHF3TC7SfL2XKTJ+TU2fat17Ompr6AYuqiUilbtmRmAi4WCViGTgQsihCf/EixMuXIcXGujxfIK52crcpo8Kcmel0uXzND2N3jmmI1vdKCVgtffuqGSJ9bi6E0lLIJpPb4wok4R9/DF1hIaxdu7rcPqYqPR2Wnj1hOHYM4atX4+aMGU08yqYTaD9fUps2sHbpAv2FCzAcOoQqN/YMDaQFF8wQEZHKWUPG2uRWrWC1T6c1NG0WiA309O70IKrNvly+4r771OXzXh1TD7dqljy4V8Y9e6rPO3gw5DZtYI2LA2Dfb8ob/v4t3mxGq7/+FQBQ9utfu57uFAQ1SxTx4YeAJDXRAJteIP58KVkid6bNAm3BBQMiIlI527LDGbf3NdPp1Oma2vzVQM+TKbMm5U7Nkgf3SglWq4YMAQBY+vQBABiOHPF4aKFZWeiQno52kyYh+qmn0G7SJHRIT2/SD6zwlSuhu3IF1k6dUD5xYr3HVkyYAMlkgj43FyFbtjTNAP1Bp0OJi+ah/lpNWGWvI2qwsDrACsIBBkREVIM7GSLAs8Jqw+HD1Q30QkJqXUyPor//vcnT4u40ZfQXV/VIUvv2HtUjCcXFavsEpebL2rs3gOq/D08ExG/xlZVo/c47AKq7Lze0m7ocHo7yn/8cQPUS/WZNr6/++RIdP879tZrQ0q8fgIYDokArCAdYQ0RECpsNhlOnALhYcl+DEhAZDh+GUF4OOTzc6XG6ixcRvno1AKBwxQoIkgTd2bOInDcPYkWFXxroudOU0Z9q1iNFzpoFw6lTuPHrX3v0wWbcvx+CLMOakACpfXsAXmaIvNkkVquO5DXOY/j+e+guX4atY0eUP/igW2+/+cgjaPXeewjZvBm63FzYEhI8H0MQCP/kEwBA2RNPoHLkSL93grf06wdZEKC/dAliYSGkdu2cHhdoBeEAM0REZKc7exaC2QwpNBS2rl3rPdYWFwdbx44QbLZ6m7C1WrwYgtWKymHDYPnRj6prbB56CDefeAIA0PqNN5q0xkMoLYVYWgogcAMiALfqke6/HwAQsn27R29XpjKV6TIAsNgzRPqTJ4GqKvfO4+Fv8VpNrdU+j9J3yHznnUBoqFvnsCUlwTxyJARZRsTy5R5dv/4TB8aKKAAQL11SpwTLJ09uVA2bVuTWrdUVqvX92xBoBeEAAyIislNXmKWmNvyPqSA0WEckXr6M8JUrAQA3am3CWTZ9OiSTCYYTJxD65ZeNG7gH1OxQdLTLrFYgqbzzTgBAyI4dgMXi9vvU+qEa2yfYOneGFBUFwWKpDorc4O5v54ZjxzSbWnN1HhlA+OrVHgVXSnF1+MqVECoq3H5ffWPzdy1VTeGrV0OQJFTefjtsSUl+GYMzasfqQ4dcHlOVng5bTExAFYQzICIiAIChni07nGmojqjVX/8KoaoKlenpqLr9dofX5MhIlE2fDgBo/eabTfZbtlu73AcQS58+sEVHQywrg9Hd7RCqqmA8eLD6f2vuJyUIsPTqBcD9aTN3fzuPnDsX0TNnNr5Atr4pOvt/PSm0rRw5Etb4eIglJWj92muNyuoERC1VTZKE8FWrAFRnhwKJutKsvu9ZnQ7Wzp2r659qveSvgnAGREQE4FZBdUP1Qwo1INq/v860l1hQgIh//hMAUFYrO6S4OW0apMhIGE6dQpgnWaJGTFkEev1QHaKIqmHDAAAhW7e69RbD4cMQzGbYoqNhTU52eM3iYWF1g60AAMhGY/V2IxZLowtkNS+01elQaf8+bfW3v3mf1QnAFVHG7duhv3ABksmEigDrPO6whYeLOkHjtm0IOXAAsiDUqTPyV0E4AyIiAoBbW3a4GRBZevaEFBYGsaQEensxtqLV3/8OwWxG1cCBqHTRnE02mdQsUSs3s0SNnbII5BVmrqjTZv/9r1vHqw0ZBw0CagUyHhdW12wFUOslWRAAQUDR4sUoWbjQvdM1MAWndaFtaFYWwv/1rzpj9zSrE4groiLsxdQVEya4bKLqL5bevSHrdNAVFqqNUB0PsCBy3jwA1dOaVw4cQOGnn6Jo8WIUfvqp37aXYUBERBAqKqDLzQUAteligwwGWAYMAOBYRyRev45wexHrjd/+ts6Hck03p02DFBUFw+nTCPvii3ovp8WUhVdNGf2scvhwANUFqoK9ILw+akF1zekyOzVDdOSI28Xs5sxMFP397w6bqAKOv8VbU1LcOldDU3CaFtpqmNUJtBVRwvXrCN2wAQBwM8CmywAAYWHVtYhwvvw+YvlyGE6cgC06Gjf+938b3dRUKwyIiAj6kychyDJsbdq4XCbrjLPC6oglSyCWl6OqXz9UjhpV7/vl1q1R9vjjAOy1RFar8wM1+nAL2KaM9bB16gRrUhIEmw0h2dn1HyzLTleYKazJyZBDQiCWlUF37pzbY7AmJ0OQJEgGA4reeqvOb/HuTK1JJtOtIM3ZtKfNBuOuXS6LbAHPCm21zOrY7K0LGjyuiVZEhX/2GYSqKlT17QurPesXaFw1aBSvXUPr114DANz4f/8PcnR0Uw/NJQZEROTYkLGejE5ttQurhaIitRFe2W9+49a5bj72GGzR0dDn5CDs88+dHqPVh1vQ1RDZmd2cNtPl5kJXWAjZaERV3751DzAY1ClRT/oRKcv+q26/HRWTJtX9Lb6+LtuoLogWS0vR9qGHEPbxx3WnPQcNQvsxY2B6/XW1yLax3bo1y+qYzQj/+OMGzyMD0J0/X/3Al0vzZVntPRRoxdQ1uSqsbr1oEcTSUlT16RNw42dARERub9lRW9XAgdVN2HJzIV69ilb/+AfEsjJYevaE+cc/dusccqtWDn2JjNu21fkg0eTDrbKyerd3BNeUGXBr2qyhwmp1/7L+/V326/G0sBoAjDt2VJ936FCXx7jqsm2Li8PNhx+GFBqKkB07EPX883WnPQsKYDhxApLRiKK33kLRe+/VPY+HhbZuT7/VzP7UCmSEq1fRdvJkhP/735BF0WWgpgR90f/7v2jz4IPoMGSIz5bmGw4ehOH4ccihoai47z5NzukLaobo0CF1etZw6BDCV6wAAJT+8Y9+mxpzhZ2qicjtLTtqkyMjYU1JgeHECbR6/XWEf/YZAODGb35Tp+akPjd/+UtE/OUv0J87h3Y1OhHbYmNx43/+x+0Pk/o+BJXdtKXQUEht27o9tkBQdfvtkHU66HNzoTt/3mXjTGf9h2pzqCNyh9WKkJ07AQCV9hVvrtTssl27Y3LZY48hZuxYCE76KalZoaio6iJhnc7ledylTOOJ+fnqtKozpoULUfLSS9Dl5dXZdV3W6SDYbJBMJlx/7z2IpaVOd2YvffFF6E+eROvXXkPotm0ui7i1WDml9Paq+OlPIUdGNupcvmRNTa2eni0tre4UnpiIyBdegCDLKJ8wod7vUX9hQEQUCLTa7sBLBg+X3CtCs7Kgu3ABANDqo48AALJe71EwBFRPBYllZXWeFy9fRuQf/qBOlSm/idcmCwJssbH11pY49CDyYFowEMitW6MqLQ0he/YgZOtWlD/8sNPjau5w74qnAZHhhx8glpZCioyExdk0XG32Atk6T1+75jQYUgiozvAZd+9Wp+Scncdt9mm86BkzIAuCQ1AkCwIgy5BDQ2H8/nu0++lPnY/JZoMM4MYzz6jtD1wGanffjYh//APi9evub3PiIeHmTXVauXzKFK/O0WQMBlh69oTxu+8QsXQp5FatYNy/H1J4OEpnzfL36JzilBmRn/m7+614/bo61aSsDHGHsupLKC93fMFqRfTjj7s/fqVg2gnB/kc2GlEyaxYgCE5rVICGa0uCccl9TQ1NmwnXr8Nw+jQA+5J7F6y9ekEWBOiuXIF49WqD1w2xT5dV3n57o4J0f6zUcjmNFxuLovfeQ8HOnSifMEH9PnMaJgsCIpYsuVUH5GJFlHH3buicBEPqaTRYmh/65ZcQb96ENTGxSTs4eyM0K0vtiN7qgw/UzXnNd98NKTbWn0NziQERkTNNtF9RIHS/1dv7D1m7doUcEeHemzTsKNxQwTQACFVVsAwY4PTDTQ4Lc2sqIlgLqhVKP6eQHTuc3ldlusySnAypTRuX55EjImC1b/PgTpZILaiup37IHf7au8qcmYkru3c77XMjxcQ0WNjrdsF+EwR8ETWLqQM4y+nqlyUZQNjatX7b6qQhDIiIammyjE2AdL/1ZrpMyyXNnnyQ1PxwK336aQDVdUzmn/ykwfcHYw+imiy33QbJZIJYXOx0j6j6+g/VZnW3sNpsVs/bUP1QQxpcmu/Lvavq6XOjVSDjbiAn1dxDz51fvOzHRPz1rzDu2wdZFFE+aZJb1/ILjbdfaUoMiMh3AmhXaHc1ZcYmULrf6j3cwwzQ9rdhjzMH9g+3m7/9LWSjEbr8fOjOnm14LEE+ZQa9HpX2LI2zaTNPAiJ3O1YbDxyo3gYkJgbW7t09HbGj+pbm+2nvKkC7zJU7vZgAIOq55xCaleXWL141j4n84x+rz2MwuNw/MBAEyr9r3mBARD7h77oYrzRxxiZQut96umUHoO30h7eZAzksDFVpaQBuTevUJxibMtamTptt2+b4gtkMo70BnlsBkZsZIuW+Vg4dqskUTb01PX7YuwrQMHPlRsBn7dgRuqtX0Wb6dERPn17vL16ufjkTKiv9s5msmwLl3zVvMCAizQVCXYw3mvo3G3/VVDiQpFsZIg96EGk6/dGIzIGaMbEX/rokSeqeSkEdENkbNBr37YNw86b6vPGHHyBUVcHWti1siYkNnkfJEOnOnnU4T21qQNTI6bKa6qvp8QsNM1cNFnHv2IEbTz2lrpZ09YtX5Jw5iHzhhaCcdgqIf9e8xICItOXPuhh3p+hcHNfUv9n4tabCTnfxIsSbNyEbjbC68UF6643aTn94mzlQlkIbs7Pr3ZtLLCyEUFUFWRRhq3WNYGJLSIC1a1cIFguM9t5AABy363AjkyO1awdbx47VQf7Ro06PEcrKYLB3Ga7SMCACEDB7Vym0zFzVG/CFhqJyxIj6FxDIcvU08JUrQTntFAj/rnmLfYhIU0qWxZWaP8iN6jFSS2hWltOGaSULFjj8Y+bquLJf/QohW7a4dS3NfrOp2ScFjr8tNlVNhdqQsVs3wGDw6L3Kh4jTRnXz53v8G399Tf1cqerfH1J4OHTXr0N/7JhaLFybMl0mdejg8dcZaCrvuAP6f/4TIVu3ovKuuwAABiUgqme5fW2WXr2gy8+H4cgRWJxMsxl37YJgs8EaHx/UWTV3efP951I9PZS0nCoKxGmnBvs/wT+1Yu5gQESa8sf8sTJFh1rdaGt3h3V53OXLasEi0Ljmf55SgoromTOBGk3rbB07orRWMOcL3m7ZodD0QwTwvBmf0Yiq9HSEbt6MkB07GgyIrM3gg71y+HBE/POft+qIGtjQ1RVLnz4I/fZbl4XVvpguC3iNbQbpBi2nigJx2gnQ/pelpsKAiDTV5PPHDUzRyQAi//AHSJGRiHz+eZdz8jKqi3Rv/O53ML38cnVQ1ES/2Zjvukvt7KxsFVD097/DYi8Y9iVvt+xw0AQfIvWpHDZMDYhuzpjh9JjmUD+kqBw6FLIownDyJMS8PIjl5dAVFUEODVVrg9zRUGG12pCxkf2HyFFDW4rIglA9nQnUf4zGv5xpTfNflpoAa4hIU009f9xgITQAXWEh2j3wQP1dZAGIFRUum//5chWM4ehRCJWVkKKiUHX77dXP2QudfcZeR6Vs9WBJSfHt9XxIaRho3LULsFqdHqML8h5ENcnR0epO4iHbtt3aruO22wCj0e3zqEvvT5xwyE4CgHjtGgz22qLGNmSkWtypv1uwICBbFHgswGrFGsKAiLRV84e91ku++EF2d+pNat3a7fMpRZHFL70EALBFR/t0FYzxwAEA1TvHW3r1AnCre7Qv1GyJoLens5XeKMHI0qsXpKgoiGVlMNiXntcW7E0Za6u5/N6T/kM12bp2hdSqFYTKSujtW34olN3tLT17QmrXToMRU03uFHEHYouC5o4BEWlO+UGuvROzL36Q3Z16u/G//+vZ+XQ6VIwfX/2/RUX1Lk1uLMP+/QAcAyKDi5U/jeWyJcLVqwHdEqFeOh0q7VN2rpbfB/u2HbUpy+9DvvkGId9+CwBqTya3iaLLaTNOl/meO+0HAq5FQTPHgIh8wpyZibJf/Up9XD5xok9+kN2dors5darHU3myyaQu0dafOqXpuGtSM0RpaY4BkZPagUYJkK1CfKGhfkRB36W6FrGgoHqD1tJS6AoLAQBRzz/vcUDrqmO1Q0NG8h13ppSCbNopmDEgIp/RXbum/r/UurVvfpDdnaIzGr2ak7cmJwNAnSkFrYhXr0J//jxkQYBlwABYu3eHbDBALC1VP8S1Eswt9Rui1hHt2weYzQ6vCTduQCwpAdA8MkShWVnVqxJrr5YsKPA4y+csQ6S7dAn63FzIOp1a00bUEjAgIp8Rr1699f/FxT67jjrXHh3t8HztKTpv5uSVYmODjzJESnbImpoKuXVrwGi8FYRpPG0WzC31G2JNToatQwcIZjOM9ilIhRJYSlFRkCMi/DE87Wic5VMDohoZSaM9O2Tp37/6e5KohWBARD4j1sgQ+TIgAqqDnRvPPAMAqOrXz+Vcu6dz8mpwcvKkT8Zds35IofQE0rqOKJhb6jdIEFxOmzWnFWZaZ/msKSnVGcmSEvU+cbqMWioGROQzuibKEKnXu3IFQHUtTr1z7R7MySs7fPtqyqxm/ZDC4bd2DQVzS313qAFRrY1em1NTRs2zfEYjrEoW9PBhQJZvFVS3pIaMRGBARD4k2os9AUAsKvL59ZSOqFJcnGbnVAIi3fnzQEWFZuetPrlV3SvKUiNDZPXVSrMmbonQ1JQ6IsN330EoK1Ofb05NGX2R5atZWK0/cwa6K1cgh4R4tA0IUXPAgIh8w2yGWFqqPmySDJE9ILLFxmp2TqldO0hRUdVTETk5mp0XqO4SLVZUQDKZ1Kk5AOpKM11uLoTyck2vqdRR1Q56mkNvE1uXLrDGx0Ow2RymjNQpMw0DZX/xRZavZmG1Uj9UNWgQEBra+AETBREGROQTNeuHAEAoKal3N3ItqJkADQMiCAIsPpo2M+7bBwCoGjBA3boDsO9E3r59dRDmgwaNlp49IdhskEURRa+/3qx6mzibNlObMjaDDJFbXY49zPIpGSL9kSMtc/8yIjsGROQTSm8UW5s2AKqLPYUaGSPNyTJ0+fnV19QyIMKtaTODxoXVymooZ3uWqf2IfBAQhfz3vwCqsw0VDz7YrHqbVDkprG5uTRm17mCsdkfPy0PIN98AACq53J5aIG7uSj6hLLm3xcVBMJshlpdDLC6GLSrKJ9cTioog2PvP2Dp00PTc6kozjZfe19yyo841e/UC/vtfn3SsDt2yBQBQOWKE5uf2NyVDZDhyBML165BbtYJoL7ZvDqvMFFpunBmybZu6qbBYVQUAaPPkkyhZsKBZZA2J3MUMEfmEMmUmtW8PyR4E+bKOSK0fattW89oHX6w0E69dgz43F4B9yqwW9bd2rQOiqioYs7MBAOZmGBBJ7dvDkpoKAAjJzq5eoi7LkENDm9+eXBp0MFa2cqndt0jMzw/erVyIvMSAiHxCWXIvtWsHuSkDIo2ny4AaAVFOjsvd1D1lsGeHLMnJ6v2pyWHKTMPaK+O+fRBv3oStXTt1NVtzU7MfkUNBtYtC5BarGW/lQuQNBkTkE2KNgKgpM0SSDwIiW6dOkMLCIFgs0J07p8k566sfAgBrt26QjUaIZWXQXbigyTWBW/VDlcOHOxRyNydV9oJg444dav1Qc+hBpLXmvJULkTea57+I5HdKDyJbjYBICNIMEURRrSPSagsPZw0ZHRgMt4q5NSysDmnG9UOKyh/9CLIownDmjBp4Nqf6Ia00561ciLzBgIh8QlllJrVvr+4x5svmjD4NiFBj2kyLgMhmUxsyOiuoVmhdRyRevQqjfRPPyjvv1OScgUiOjISlb18AQNi//w2AAZEzzXorFyIvBOQqsw0bNuDLL79EcXEx4uPj8dhjjyG5RuO62tavX4+NGzeisLAQJpMJ6enpmDJlCoxGIwBg9erVWLNmjcN74uLi8NZbb/nyy2jRlAxRU0+Z+Swg0nClmf7ECYg3b0Jq1UrdNsEZi8Ydq0O2bgUAVPXp0/wKjGupHDoUxu+/V5uDChUV1bUwzaS9gBaUJo9ifr5aM1STLAiwxcYG7VYuRJ4KuIAoOzsby5cvx/Tp09G9e3esX78eCxcuxFtvvYXIyMg6x2/fvh0rVqzAk08+iZSUFFy+fBnvvvsuBEHA1KlT1eO6dOmCOXPmqI/FZlo/ESjUZfc1i6pLSnx3PSUg8lE3YiVw0WKlmVo/dNtt9X5Aax4QtYDpMpX9lyFF68WLEf7ZZ1xKXpO9yWP0jBmQBcEhKGoOW7kQeSrgooJ169Zh9OjRGDlyJDp37ozp06fDaDRi8+bNTo8/ceIEUlNTMWzYMMTExKB///4YOnQoTtf64BJFEVFRUeofk8nUFF9Oy2SzQbx+HUATLbuXZd90qa7BYcqskau+GqwfUq6pTJmdOwfhxo1GXROSpGaImvN0GVC9lLzV22/X2a+NS8nr0rrJI1EwC6gMkdVqRU5ODu677z71OVEU0bdvX5x00SU4NTUV27Ztw+nTp5GcnIwrV67g4MGDuOOOOxyOy8/Px+OPPw6DwYCUlBRMmTIF7Zr5tIG/iNevV/d+EQRIbdr4vKhaKC2FaN/zyxerzADAGh8PWa+HWF4O3eXLjapJMdgzRPXVDwGA1KYNbB07QpefD/3x47AMHuz1NfVHj0JXWAgpIqJ5b9rZwFJyWRBgmjcP5rFjmfmw07LJI1EwC6iAqLS0FJIkIapWX5aoqCjk2TMAtQ0bNgylpaXqdJjNZsOYMWMwYcIE9Zju3btj5syZiIuLQ1FREdasWYO5c+fi9ddfR1hYWJ1zWiwWWCwW9bEgCE6PI+fUJffR0YBe7/MMkbrkPioKsq/+ngwGWBMTYTh1CvpTp7wOiISiIhjOnAHQcEAEVE+b6fLzYTh6tFEBkdKduiojo850UnOiLCV3peZS8qqMjCYcWYCzN3kkaskCKiDyxpEjR7B27VpMmzYN3bt3R35+PpYtW4Y1a9Zg4sSJAIABNToBx8fHqwHSzp07MWrUqDrnXLt2rUMRdmJiIhYtWuT7L6aZqLnCDECTBUS+mi5TWLt3VwMib+twjAcPVp8rMRGyfZ+3+lh69ULot982uo5IqR9qjt2pa+JSciLyVkAFRCaTCaIoorjWB2dxcXGdrJFi1apVGD58OEaPHg0A6Nq1K8xmM5YsWYIJEyY4LZ6OiIhAXFwc8u2bgdY2fvx4jBs3Tn0ssMOtR2quMANqBUSyrHnH4KYMiIDGrTRzt35IoUVhtXDzJoz79gFo/vVDXEpORN4KqKJqvV6PpKQkHLb3SgEASZJw+PBhpLhYnlxZWVknYGloBZnZbEZ+fr7LIMtgMCA8PFz9w+kyz9RcYQYAsr0PkWCxQLDX+mgpmAIid+uH1Gv27Fl9zePHvS7mNu7YAcFigTU+HrbERK/OESyUpeSyi6BbFgRY4+K4lJyI6giogAgAxo0bh2+++QZbtmzBxYsX8f7776OyshIj7Kn+d955BytWrFCPT0tLw6ZNm7Bjxw4UFBTg0KFDWLVqFdLS0tTAaPny5Th69CgKCgpw4sQJvPrqqxBFEcPsLf5JW7UzRHJoKOSQkOrXfDBtJjZRQGRpbEAkSeqUmbsZImtSEuSQkOpibi+3DQlVtuto5tkhAOpScgB1giIuJSei+gTUlBkAZGRkoLS0FKtXr0ZxcTESEhIwa9YsNZtTWFjokBG6//77IQgCVq5cievXr8NkMiEtLQ2TJ09Wj7l+/Trefvtt3LhxAyaTCT169MDChQu59N5HatcQQRAgRUVBd+UKhKIiQOOuwTof9yBS2Lp1gywI0BUVQbx2DVLbth69X3/qFMQbNyCFh8Pao4ebb9LDkpoK46FDMBw96lWGR60fGjnS4/cGI2UpeeTcuQ4F1rbYWJTOn8+l5ETkVMAFRABw99134+6773b62osvvujwWKfTYdKkSZg0aZLL8/32t7/VcHTUEHUfMyUgAtSAyBcZIl9u7FqTHBYGW5cu0J8/D/2pU6jyMCBSGzL27w/o3f/Rs/TqpQZE5p/+1KNr6nJzoc/NhazXt6hVRFxKTkSeCsiAiIKbuuy+RsDgy5VmTVVDBFRv4aEGRD/6kUfvNXhYUK1esxF7minZoarBgyG3auXx+4Mal5ITkQcCroaIgl+dKTMAkn3bFa0DIqGsTN2vqkkCokbUESkZIk8DIou9sNqblWYhLal+iIioERgQkbZkGeK1awAcAyLZRxkinb11gmQyNUkGxNuASCgpgcHebd3i5gozhbrr/cWLEOzBn1uqqhCyYweAFrJ/GRFRIzAgIk0JJSUQqqoAALYmmDLz9R5mtVnsu94bPAmIbDaE21dG2jp0qO7g7QE5KgpWe8G44dgxt99n3L8f4s2bsLVtC0vv3h5dk4iopWFARJpSp8tatwZCQ9XnfbWfWVMtuVcoGSLd5ctubbgampWFDunpiPzjH6vfd+UKOqSne7zBqDd1ROru9nfeCTTQm4uIqKXjv5Kkqdo9iBTNJUMkR0WpXY71p0/Xe2xoVhaiZ8xQgzaFN7uue1RHZLPBmJ2NsC++AABU1tromIiI6mJARJpSu1TXqB8CfBgQNdGS+5qs9mmzeuuIGth1HQBM8+YBNptb13R3Cw8lI9Vu0iToL1yovs6f/uRxRoqIqKVhQESacpUhUrbv8FVA1FQZIqBGYXU9GSJl13VXu7bV3HXdHWph9fHjLoMolxmpggKPM1JERC0NAyLSlK6hKbOiIm2v54eAyJ0tPLTedd2WmAgpNBSi2Qzd2bNODtA2I0VE1NIwICJNNTRlpnVRtT8zRPWtNNN813WdTt3o1dm0mdYZKSKiloYBEWlKnTKrta2FmiEym4GKCk2uJVRUqFNw/giIdOfOAWaz02PUXdddnMObXdfrK6zWOiNFRNTSMCAiTemUbTtqZYjk1q0h2/eREktKNLmWUisjhYdDbsKNeqWYGEgmEwRJgt7Z9BUA6HS4+YtfQADqBEXe7rpeX2G1FBbm1jnczkgREbUwDIhIU866VAOo3vFe4+07HKbLBFeTRT4gCA2vNJNltQ+QHB7u8JItNhZFS5Z4vOu60ovI8N13CPv8cxizs6uX2G/diqg//KH6Wi7e601GioioJeHmrqQptYaoVlE1YN++4/p1zQMiyd7FuSlZUlJgPHDA5UqzkM2bEbJnD+SQEBRs3gz9+fON3nVdZ19Gr7t2DdFPPQUAkCIiIN68CQCwdugA3ZUrkAVBLaQGvM9IERG1JAyISDNCeTnE8nIAdVeZAdr3IvJHQbWi3sJqSULrRYsAADcffRRS586o6ty5UdcLzcpC1G9/CxlwKJxWgiHznXeiaOlShGzejMi5c9V7A1Tfn9L58z3OSBERtSQMiEgzSkG1HBrqdKNVrVeaNXWX6prqmzILXbcOxsOHIbVqhbKnn278xepZUg9UT5PpT52CbDTCnJkJ89ix1avOGpmRIiJqSRgQkWYcpsuc1PQ0xwyRPienurePEnBYrTC9+ioAoOzxxyG1adPoaylL6l0RAHVJfVVGBqDTVf+XiIjcxqJq0oyrpowKSeNu1U29sWtNts6dIYeGQqishO78efX58E8/hT4nB7Y2bXBzxgxNrsUl9UREvseAiDSjZIhcBkTNKEMEnQ7Wbt0A1Jg2M5vR6o03AABlTz/tdNrQG5o3eSQiojoYEJFmlBqi2l2qFbKWAZHZDJ19ib9fAiLc2sJDKayO+Phj6PPyYIuNxc2pUzW7jtrk0UVrAS6pJyJqPAZEpBlXG7sqtMwQ6a5cAWAv4LZPxTW1moXVQlkZWv35zwCAG7/7HRAaqt2FdDqULFgAAHWCIi6pJyLSBgMi0ozOzSkzLVaZqdNlHTs2bVPGGpQpM+OePTDNnQvdtWuwJiSg/IEHNL+WOTMTRUuWQOrY0eF5b5s8EhGRI64yI80oXapdTZlpmiHyZ/0QqvsCRc6dCwDQnzsH/blzAICKMWMAg8En1+SSeiIi32FARJppyqJqfwZEoVlZiJ4xA5AdN8qQAbR6/31YhgzxXcaGS+qJiHyCU2akmQaX3SsB0Y0bgMXSqGupS+6betuOepokKo9N8+ZV9yYiIqKgwYCItFFVpWZ+6mzsaifbN3cFALG0tFGX81eGSGmS6KpqSZBltUkiEREFDwZEpAmlfkjW6dRMUB06nbrjvVBU1Kjrqdt2NHGGiE0SiYiaJwZEpAmH6TLR9beVVnVE6k73TZwhYpNEIqLmiQERaUItqG7btt7jlAxRowKiqqpb+6Y1cUDEJolERM0TAyLSRENdqhVaZIh0BQUQZBmy0ajJ5qmeXZxNEomImiMGRKSJhlaYKbTYvsOhKWM903O+wiaJRETND/sQkSYa6kGk0CJDJCoF1X5qygiwSSIRUXPDgIg04emUWWO27/B3l+pbA2GTRCKi5oJTZqSJhjZ2VWhSQ+SnFWZERNR8MSAiTagbuzZFUXWgZIiIiKjZ8HrKrLCwEJ999hmOHDmC0tJS/P73v0evXr1QWlqKNWvWYOTIkUhMTNRyrBTA1CmzhjJE0dHVxzMgIiKiAOJVhujixYt47rnnsHPnTsTExKC8vBySJAEATCYTTpw4gQ0bNmg6UApgkqR2qnZ7lVkjOlXr/LWPGRERNVteBUQff/wxIiIi8Pbbb+PXv/51ndcHDBiA48ePN3pwFBzEoiII9oC4wcaMjZ0ys1ohXrkCgBkiIiLSjlcB0bFjxzBmzBiYTCYITjr2tmvXDtevX2/04Cg4qEvuo6IAg6HeY9VVZiUlgD2I8uhaBQUQJAmyXt9gNoqIiMhdXgVEkiQhJCTE5eulpaXQ67miv6VQt9FooKAauLV1hyDLELzY8V6dLuvQgT1/iIhIM14FRElJSThw4IDT12w2G7Kzs5GSktKogVHw0LlZPwQACAmBFB4OwLtpMy65JyIiX/AqILrvvvvw3Xff4b333sOFCxcAAMXFxTh06BD++Mc/4tKlS7j33ns1HSgFLtHNJfeKxtQRcYUZERH5glfzWgMGDMBTTz2FZcuW4euvvwYA/OUvfwEAhIWF4amnnkKvXr20GyUFNHeX3CvkqCggLw9iSYnH12JAREREvuB1oc/w4cMxZMgQHDp0CPn5+ZAkCR07dkT//v0RFham5RgpwLnbpVrRmO07GBAREZEvNKryOTQ0FEOGDNFqLBSk3O1SrZAa0YtIZEBEREQ+4FVAVGjPCDSkHZdFtwieTpk1pls1M0REROQLXgVETz31lFvHrVq1ypvTU5BRi6o9nDLzOCCSJOjy8wEwICIiIm15FRA9+eSTdZ6TJAlXr17F1q1bYTKZMHbs2EYPjoKALN9adu/mlJnsZUAkFhZCsFohiyKkDh08ei8REVF9vAqIRowY4fK1e++9F7Nnz0Z5ebm3Y6IgIty4AaGyEoDvM0RqD6KYGICNP4mISENe9SGqT2hoKEaMGIH169drfWoKQOp0WUQEZDdXF3q7ykyXlweA02VERKQ9zQMiAJBlGcXebt5JQcXT6TKg8RkiBkRERKQ1TecdysvLcezYMfz73/9GYmKilqemAOVpQTXgfUDEJfdEROQrXgVEP//5z+t9vV27dpg2bZpXA6Lgom7s6m1AJMuAILj1PjVDFBfn0RiJiIga4lVAdP/990Oo9SEmCAIiIiLQoUMH9O/fHzruRN4i6DzsUg0Asr0PkWCxQCgvhxwR0fCbbDbojx+vft+NG4DNxt3uiYhIM14FRA888IDW46DGsNlg3L0buoIC2GJiUJWe3mTBgrpthwc1RHJoKOSQEAiVlRCLi2FrICAKzcpC5Ny5aobI9NZbiFi1CiULFsCcmen94ImIiOwCcu3yhg0b8OWXX6K4uBjx8fF47LHHkJyc7PL49evXY+PGjSgsLITJZEJ6ejqmTJkCo9FY59jPP/8cK1asQGZmJh599FEffhVNo3awAFTX2DRVsOBpl2oAgCBAioyErqAAQlER0KmTy0NDs7IQPWNG9dRazevm5yN6xgwULVnCoIiIiBrNrYDo3Xff9fjEgiA4beDYkOzsbCxfvhzTp09H9+7dsX79eixcuBBvvfUWIiMj6xy/fft2rFixAk8++SRSUlJw+fJlvPvuuxAEAVOnTnU49vTp09i0aRPi4+M9HlcgCoRgQedFUTVQXUekKyiov7DaZkPk3LmALKN2lZEgy5AFAaZ582AeO5bTZ0RE1ChuBURHjhzx+MS1a4zctW7dOowePRojR44EAEyfPh0HDhzA5s2bcd9999U5/sSJE0hNTcWwYcMAADExMRg6dChOnTrlcJzZbMZf/vIXPP744/jss8+8GltACZBgwZspM8C9lWbG3bsdMl+1CbIMfV4ejLt3oyojw6PrExER1eRWQLR48WJfjwMAYLVakZOT4xD4iKKIvn374uTJk07fk5qaim3btuH06dNITk7GlStXcPDgQdxxxx0Ox73//vsYMGAA+vXr12BAZLFYYLFY1MeCICDMzaaDTSVQggWvpszgXkCkKyhw61zuHkdERORKQNUQlZaWQpIkRNk/LBVRUVHIs3cprm3YsGEoLS3FnDlzAAA2mw1jxozBhAkT1GN27NiBs2fP4uWXX3ZrHGvXrsWaNWvUx4mJiVi0aJGHX41vBUSwUFEBsawMgOdTZu7sZ2aLiXHrXO4eR0RE5EpABUTeOHLkCNauXYtp06ahe/fuyM/Px7Jly7BmzRpMnDgRhYWF+OCDD/DCCy84LbJ2Zvz48Rg3bpz62NvpP18KhGBBWXIvG42QTSaP3utOhqgqPR222FiI+fkQatVJAYAsCLDFxlavqiMiImoErwOigwcPYt26dTh79izKy8shO/nAWrVqlUfnNJlMEEWxzrYfxcXFdbJGNa8xfPhwjB49GgDQtWtXmM1mLFmyBBMmTEBOTg5KSkrw/PPPq++RJAnHjh3Dhg0bsGLFCoii4w4mBoMBBoPBo7E3tUAIFhymyzwMGt3az0ynQ8mCBYieMQMy4FArJduvVzp/PguqiYio0bwKiHbt2oU333wTXbp0QUZGBjZt2oShQ4cCAPbu3YvY2FgMHjzY88Ho9UhKSsLhw4cxZMgQANXBy+HDh3H33Xc7fU9lZWWdDE7NAKdv37547bXXHF7/61//iri4ONx77711gqGgUTNYEASHoKipggV12w4PC6oB97fvMGdm4sb//i9Mtf4ObbGxKJ0/n0vuiYhIE14FRJ9//jmSk5Pxf//3fygrK8OmTZswatQo9OnTBwUFBZg9ezZivJyqGTduHBYvXoykpCQkJycjKysLlZWVGDFiBADgnXfeQZs2bTBlyhQAQFpaGtavX4/ExER1ymzVqlVIS0uDKIoICwtD165dHa4REhKC1q1b13k+2JgzM1G0ZInTPkRNESyoXarbtvX4vZ7sZybbC9orhwxB+dSpTd58koiImj+vAqKLFy9iypQpEEVR3aLDarUCqF72PnbsWHzxxRe48847PT53RkYGSktLsXr1ahQXFyMhIQGzZs1Sp8wKCwsdMkLKNiIrV67E9evXYTKZkJaWhsmTJ3vzpQUdc2YmzGPHImboUOgvXICtTRsU7NrVJMGCt0vugVvbd7gTEBm/+w4AUDlqFCqctF4gIiJqLK8CopCQEOj11W+NiIiAXq93qPuJjIxEQSNWN919990up8hefPFFh8c6nQ6TJk3CpEmT3D5/7XMEPZ1Obc4omM1Nvm2HrTFTZkVFDR5r+P57AEDVbbd5fB0iIiJ3eFVAExcXh4sXL6qPExISsHXrVthsNlRVVWH79u1o5+EybGocZfm7WF4O1Oih5Etql+pGTJnVW1QNQLx2Dfrz5wEAln79PL4OERGRO7wKiAYPHoy9e/eqzQsnTJiAI0eO4NFHH8W0adNw/Phxp12lyXeE8nL1/8WSkia5piZF1WYzYDa7PE7JDlmTkiA72bqFiIhIC15Nmd1zzz2455571MdpaWl48cUXsXv3boiiiIEDB6JPnz6aDZIaUFUFoapKfSgUFwNNkKETr10D4HmXagCQW7eGrNNBsNkglpRACg11ehyny4iIqClo1pixZ8+e6Nmzp1anIw8IN286PBZLSmBrgus2JkOk7nh//TrE4mJIHTo4Pcx48CAAwMKAiIiIfMirKbM33ngDe/bscdjvi/xHrB0QlZb6/qJmM3T2gmj92bOAzfMQrMHtO2T5Voaof39vRklEROQWrzJEJ06cwO7duxEaGopBgwYhIyMD/fv3V1eeUdNyliHypdCsLETOnq0+bjNtGmyxsShZsMCj3kcN9SLS5eVBV1gIWa+HpXfvxgyZiIioXl5FMH/7299w7NgxZGdnY/fu3di+fTvCw8MxZMgQZGRkoG/fvsHbAToICfYVZupjN3r7eCs0KwvRM2aoy/wVYn4+omfMQNGSJW4HRQ2tNDMo02U9egD25oxERES+4FVAJAgCevXqhV69euGxxx7DkSNHsHPnTuzZswdbtmxBq1atkJ6ejhkzZmg9XnKiyTJENhsi584FZBm1dy4TZBmyIMA0bx7MY8e61QupoV5EynSZhdNlRETkY41O44iiiL59+2LGjBlYsmQJpk+fDqvVim+++UaL8ZEb6tQQ+SggMu7eDd3ly3WCIYUgy9Dn5cG4e7db55Ma6FatdKhmQTUREfmaJkU/RUVF2LlzJ3bu3ImTJ08CAFJTU7U4NbmhdoZI8FFApHOz+7i7x9VbQyRJMBw6BIBL7omIyPe8DohKSkqwa9cuZGdn48SJE5BlGcnJyfjFL36BjIwMtGnTRstxUj1q1xD5apWZzc0Ne909rr5VZvozZyCWlUEKDYU1JcXdIRIREXnFq4BowYIFOHbsGCRJQkJCAh588EFkZGR4vcM9NY5o71Ith4RAqKx0a8NUb1Slp8MWGwsxPx9CraJqAJAFAbbY2Oqd6N1QX4bIoEyX9e0LcPUiERH5mFefNCUlJZg4cSIyMjIQGxur9ZjIQ0qGyBYbC31uru+KqnU6lCxYgOgZMyADDrVEslD9qHT+fLc3l61vlZlaUM3pMiIiagJeFVW//vrruP/++xkMBQilhsgWF1f92Id9iMyZmSh+9dU6hdW22FiPltwD9WeIWFBNRERNiXMRzUDtgMjXjRltiYnV/42JQem8ebDFxFRPk7mZGVK4DIiqqmA4cqT6f7nknoiImgADomZAVKbMlIDoxo3qrTQ8DFDcpT97FgBg6dULFffd5/V51IDoxg3AYgEMBgCA4fhxCFVVkKKiYEtIaORoiYiIGsZ20s1A7QwR4NtpM11ODgDAas8UeUuOjFT/v+bKOKVDdVX//oDgqusRERGRdhgQNQNKQCRFRUGyb3Hhyw1e9faAyJaU1LgT6XSQTCYAgFCjW7WRHaqJiKiJMSBqBpSASG7VSs26+LKOSJkya2yGCHBeR8QVZkRE1NQYEDUDSg2R3KrVrQDDVwGRJEGfmwsAsDY2Q4S6AZFw8yb09m7n7FBNRERNxa2i6vnz53t8YkEQMHfuXI/fR54T7I0ZpfBwSPYMka92vNfl5UGorIRsMMDWqVOjz1c7IDL88AMESYKtY0dIHTo0+vxERETucCsgkmUZQq3i1sLCQhQUFCA8PFztUF1QUIDy8nJ06NABbdu21X605JRQM0Pk4ykzpX7IGh+vSQfp2tt3KB2qmR0iIqKm5NYn2osvvujw+Pjx41i0aBEef/xx3HnnndDZl3fbbDZs3rwZ//znPzFz5kzNB0tOSNKtrTsiIiDbi5R9FRCpK8w0mC4D6maIjKwfIiIiP/Cqhuijjz7CyJEjMWrUKDUYAgCdToe77roLI0eOxPLlyzUbJLmmTJcBgBQRcWvKzEerzNQVZhoUVAN1t+9QM0RcYUZERE3Iq4Do3Llz9W7kGhMTg/Pnz3s9KHKfusJMFIHQ0Hq3w9CCusLMBxki8fp16O3fN1xyT0RETcmrgCg6Oho7d+6EzWar85rNZkN2djaio6MbPThqWM36IQiCz5fd6zVqyqioGRApy+2tSUkOTRuJiIh8zauq2HvvvRfvvfceZs+ejTFjxqBjx44AgMuXL2PTpk3Izc3FtGnTNB0oOafWD4WHA4Bvi6otFuguXACgYYbIHjiLxcUsqCYiIr/xKiC66667IIoiPvnkEyxZssThNZPJhOnTp+Ouu+7SZIBUPyVDJLVqVf1fpYbIBwGR7vx5CDYbpLAwSPYguLHUVWZFRbd2uOd0GRERNTGv102PGjUKd955J86cOYPCwkIAQLt27dCtWzeHQmvyLbWGKCKi+r8+zBA5FFRrtMeYsykzZoiIiKipNaqRjE6nQ0pKClJSUrQaD3modkDkyykzLbfsUNQuApf1elh699bs/ERERO5wKyA6evSoVyfv1auXV+8j96nbdtQKiITSUkCSAFG73Vn0GvcgAm6NV2FNTQXsG9QSERE1FZ9t3QEAq1at8up95D51p/vaNUSSBKGsTG3UqAWtl9wDAEJCIIWHq8XhnC4jIiJ/cCsgmjdvnq/HQV5Sp8zsq8wQFgY5JARCZSXEkhLYNAyIdBovuQcA2GyQw8IAe0Bk6ddPu3MTERG5ya2AiFNfgUtUAiJ7hgiozhLpCgqqV5p16aLNhSoqoM/LAwDYunXT5JShWVmInDsXumvX1Odav/oqpDZtYM7M1OQaRERE7mh0gYnZbMbFixdx8eJFmM1mLcZEHqi97B6oUVitYbdqfW6uem5Jg6aboVlZiJ4xA+Llyw7Pi9euIXrGDIRmZTX6GkRERO7yepXZ6dOn8c9//hPHjx+HJEkAAFEU0aNHDzz88MPoplEWgepXZ8oMuLXBq4b7mTkUVDd2yb3Nhsi5cwFZRu0zCbIMWRBgmjcP5rFjAbZwICKiJuBVQHTq1Cm8+OKL0Ov1GDVqFDp16gQAuHTpEnbs2IF58+bhxRdfRHJysqaDpboEF1NmgLZL77Vccm/cvRu6WpmhmgRZhj4vD8bdu1GVkdHo6xERETXEq4Bo5cqVaNOmDf7v//4PUfY+MopJkyZhzpw5+OSTTzBnzhwtxkj1EGv1IQJq7CCvZUCk4ZJ7XUGBpscRERE1llc1RKdOncKYMWPqBEMAEBUVhbvuugunTp1q7NjIDeqy+5oBkQ9qiHT2DJFNgwyRLSZG0+OIiIgay6uASBAEpzvdKyRJgqDR1g5Uv9qdqgHfbN+hZYaoKj0dtthYyC6+R2RBgDUuDlXp6Y2+FhERkTu8CohSU1Pxn//8B1evXq3zWmFhITZu3IgePXo0enDUMGWVmbMaIq2mzITSUujs+9Vp0oNIp0PJggUAUCcoUh6Xzp/PgmoiImoyXtUQTZ48GfPmzcNvf/tbDBkyBLGxsQCAvLw87Nu3DzqdDpMnT9Z0oOSc0uFZdjZlptEqM6Wg2ta+PeTWrTU5pzkzE0VLllT3IapRYG2LjUXp/PnsQ0RERE3Kq4AoMTERL730Ej755BPs27cPVVVVAACj0YjbbrsNDz74IDp37qzpQMkJWb7Vh8jZlJlGNUQ+2bID1UGReezY6lVnBQWwxcRUT5MxM0RERE3M6z5EnTt3xu9//3tIkoRSeybCZDJB1HAzUWpAZSUEqxWAiwyRRlNmPtmyQz25jkvriYjI79yOXt5++22cOHFCfSzLMgoLCyFJEqKiohAVFcVgqIkp02WA84BIqxoipaDapnGGiIiIKFC4HcFkZ2c7FFGXlZXhqaeewvHjx30yMGqYOl0WGuowzeSQIZLlRl9Hy6aMREREgYgpnSDmrEs1AMhKY0arFUKNLJJXZFnTJfdERESBiAFREFOX3NeYLgOq9zWT7Rmjxk6bidevq6vVrPHxjToXERFRoGJAFMScLbkHAAiCZoXVanaoUycgLKxR5yIiIgpUHq0yO3PmDAwGAwCgoqICAHD8+HHctE/d1JbOTsM+5WzJvUKOjASuX290QKRjQTUREbUAHgVEWVlZyMrKcnju008/dXn8qlWrvBsVucVVDRFwa4NXzTJELKgmIqJmzO2AaN68eb4cB3nB2T5mCnXpfSObM7KgmoiIWgK3A6JevXr5chzkBdGNgKjRGSIuuSciohaARdVBTK0hcjJlJptMABq5n5kkQeejbTuIiIgCCQOiIKb0GJLDw+u8pkW3ajE/H6LZDFmng61LF6/PQ0REFOi83svMlzZs2IAvv/wSxcXFiI+Px2OPPYbk5GSXx69fvx4bN25EYWEhTCYT0tPTMWXKFBiNRgDAxo0bsXHjRrXTdufOnTFx4kQMGDCgSb4eXxGVPkT1FVU3ooZI3bKja1fAvrqQiIioOQq4gCg7OxvLly/H9OnT0b17d6xfvx4LFy7EW2+9hUh71qOm7du3Y8WKFXjyySeRkpKCy5cv491334UgCJg6dSoAoE2bNpgyZQpiY2MhyzL++9//4pVXXsErr7yCLkGc+VCKql0uu0fjaohYP0RERC2Fz6bMJEny6n3r1q3D6NGjMXLkSHTu3BnTp0+H0WjE5s2bnR5/4sQJpKamYtiwYYiJiUH//v0xdOhQnD59Wj1m0KBBGDhwIGJjYxEXF4fJkycjNDQUp06d8mqMgcKdVWaNCoi4woyIiFoItwOi77//3u2TWiwWvPbaax4Pxmq1IicnB3379lWfE0URffv2xcmTJ52+JzU1FTk5OWoAdOXKFRw8eNDldJgkSdixYwcqKyuRkpLicvzl5eXqH6UJZaBxtXUHoE0NkZ4F1URE1EK4PWX26quv4ve//z369+9f73FmsxmLFi3C0aNHPR5MaWkpJElClL3+RREVFYW8vDyn7xk2bBhKS0sxZ84cAIDNZsOYMWMwYcIEh+POnz+P2bNnw2KxIDQ0FM8++yw6d+7s9Jxr167FmjVr1MeJiYlYtGiRx1+Pr4nuNGZsxCozHZsyEhFRC+F2QNSlSxe8+uqrePbZZ3Hbbbc5PebGjRt46aWXkJOTg1/84hdajbFeR44cwdq1azFt2jR0794d+fn5WLZsGdasWYOJEyeqx8XFxeHVV19FeXk5du3ahcWLF2P+/PlOg6Lx48dj3Lhx6mNBEJrka/GUWkPkZJWZuuze2wyR1Qr9uXMAAFu3bt6dg4iIKEi4PWU2Z84cdO3aFa+++ioOHjxY5/Xr169j7ty5yM3NxZNPPukQULjLZDJBFEUU11oZVVxcXCdrpFi1ahWGDx+O0aNHo2vXrhgyZAgmT56Mzz//3KGOSa/Xo2PHjkhKSsKUKVOQkJBQZxsShcFgQHh4uPonLEA3Na136w5lysxsBsxmj8+tu3gRgtUKOTQUttjYxg2UiIgowLkdEIWHh2POnDlISEjAa6+9hgMHDqivXb58GXPmzEFBQQF+97vfYcSIEV4NRq/XIykpCYcPH1afkyQJhw8fdlnvU1lZWSeDI4oNf1mSJMFisXg1zkBRXw2R3Lo1ZPt98SZLpBZUJyQAbtxPIiKiYObRJ11YWBjmzJmDpKQkvP7669i/fz9yc3Mxd+5clJWV4Q9/+AOGDBnSqAGNGzcO33zzDbZs2YKLFy/i/fffR2VlpRpkvfPOO1ixYoV6fFpaGjZt2oQdO3agoKAAhw4dwqpVq5CWlqYGRitWrMDRo0dRUFCA8+fPq4/vuOOORo3Vr2w2iPbMj7MMEUSxUUvvueSeiIhaEo/7EIWGhmL27Nl46aWX8MYbb8BgMECn02Hu3LnopkGtSUZGBkpLS7F69WoUFxcjISEBs2bNUqfMCgsLHTJC999/PwRBwMqVK3H9+nWYTCakpaVh8uTJ6jElJSVYvHgxioqKEB4ejvj4eMyePRv9+vVr9Hj9RZkuA5zXEAHV02ZicXHjMkRcYUZERC2AIMuy7M6BOfYPSIXZbMbixYtRWlqK6dOnOy1OTmpmH6ZXr14NmGk28fJldBw0CLJej8u5uYCTwu92P/kJjIcO4dqHH6Lyrrs8On+bKVMQ+t//ovi111BeI7gkIiIKFgaDAe3bt3frWLczRH/4wx9cvrZ48WKnz69atcrd05OHHJbcu1gF15iVZswQERFRS+J2QPTkk0/6chzkofqW3Cu87lZdWQndxYsAGBAREVHL4HZA5O3KMfINoZ6NXRVKc0aPulXbbAj74gsIsgwpNBRSdHRjhklERBQUuJ46SNW3j5lCzRC5ueN9aFYWOqSnI/p3v6t+n9mMDj/6EUJd9GsiIiJqLhgQBSnRjYDIk2X3oVlZiJ4xA+Lly47Xyc9H9IwZDIqIiKhZY0AUpNQaIjcyREJD+5nZbIicOxeQZdQuzxbsixBN8+YBNpvX4yUiIgpkDIiCVH1dqhWSm6vMjLt3Q3f5cp1gSL2WLEOflwfj7t1ejZWIiCjQMSAKUm5NmSk73jcQEOkKCty6prvHERERBRsGREGqvo1dFe4WVdtiYty6prvHERERBRsGREFKmTJzq4aogQxRVXo6bLGx6mawtcmCAGtcHKrS070cLRERUWBjQBSkhPJyAG4uuy8vB+rbckSnQ8mCBdXnq/WSEiSVzp8P6HTeD5iIiCiAMSAKUqIbRdXKsnug4Toic2YmipYsqTMFZ4uNRdGSJTBnZjZitERERIGNAVGQUpfd11NDBJ0OUuvW1ce70YvInJkJ85gxAIDye+9F4aefomDXLgZDRETU7DEgClJqUXU9e5kB7i+9V+jPngUAmH/2M1RlZHCajIiIWgQGREHKnVVmgGfdqiHL0J85A4CbuhIRUcvCgChIiW5s7gp4tuO9WFgI8caN6lVl8fGNHyQREVGQYEAUpJRVZlJDU2bKjvdubPCqz8kBANg6dwZCQxs1PiIiomDCgCgYyfKtrTs0zBApARGny4iIqKVhQBSMzGYIkgSg/mX3QI0aooY2eAWgY0BEREQtFAOiIKTsYwa4v8rMnWX36pQZAyIiImphGBAFIbUHUXg4INb/Vyi5ucErwCkzIiJquRgQBSF364eAGlNmDRVV22zQ5+YCYEBEREQtDwOiICS62ZQRcL+oWnfpEoSqKsghIbB16tT4QRIREQURBkRByK1tO+zc3fFenS5LSGB3aiIianEYEAUhwY2NXRWSm6vMWD9EREQtGQOiIKQ0ZXQnIHJYdm+zuTyOS+6JiKglY0AUhEQvMkQAINSTJWKGiIiIWjIGREHIkxoiGI2QwsIA1F9YzR5ERETUkjEgCkKCB6vMADd2vDebobt4EQAzRERE1DIxIApCakDkToYIDTdn1J87B0GWIZlMkNq21WSMREREwYQBURDypIYIaHjpvf7MGQD27JAgaDBCIiKi4MKAKAipNURuBkSyfT8zlxkiFlQTEVELx4AoCHk8ZdZADREDIiIiaukYEAUhdesOjabM2IOIiIhaOgZEQcjTKTO1qNrFBq9cck9ERC0dA6IgJHiYIapv2b1QXAzdtWsAAGtiokYjJCIiCi4MiIKQupeZhzVEzjpV68+eBQDYOnZ0+3xERETNDQOiIORtDZGzDJFaUM3sEBERtWAMiIKNxQKhshKAB8vu3QmIWD9EREQtGAOiIKPUDwFeZIicFFUzICIiImJAFHTUgmqjETAa3XqPQw2RJDm8xiX3REREDIiCjujhxq5AjYBIktSC7OqTyMwQERERgQFR0FF7EHmyIiwsDHJICABArLHSTLxyBWJ5OWSdDrauXTUdJxERUTBhQBRkBA83dlWoWaIadURqQ8YuXdyefiMiImqOGBAFGbG8HIAXAZGTDV45XUZERFSNAVGQ8TZD5GzpPQMiIiKiagyIgoxXNURw3pxRf+YMAAZEREREDIiCjKf7mCmUDV4FZoiIiIjqYEAUZDzdtkNRJ0NksUB3/jwABkREREQMiIKMUkPk6ZRZ7Roi3YULEKxWSKGhkGJjtR0kERFRkGFAFGQEZZWZB40ZgVurzJQpM3XJfVISIPLbgIiIWjZ+EgYZdZWZp0XV9hoisVZAxOkyIiIiBkRBR2zssnt7Y0YGRERERLcwIAoyypSZ1MiiagZEREREt+j9PQBnNmzYgC+//BLFxcWIj4/HY489huTkZJfHr1+/Hhs3bkRhYSFMJhPS09MxZcoUGO3bUaxduxZ79uzBpUuXYDQakZKSgocffhhxcXFN9SVpptFbd9j3MmNAREREdEvAZYiys7OxfPlyTJw4EYsWLUJ8fDwWLlyIkhr9c2ravn07VqxYgUmTJuHNN9/EE088gZ07d+KTTz5Rjzl69CjGjh2LhQsX4oUXXoDNZsMf//hHmM3mpvqyNKMuu29EY0ahvBy6y5cBMCAiIiICAjAgWrduHUaPHo2RI0eic+fOmD59OoxGIzZv3uz0+BMnTiA1NRXDhg1DTEwM+vfvj6FDh+L06dPqMbNnz8aIESPQpUsXJCQk4KmnnkJhYSFy7FmSYKJ2qva0hkhpzGixQH/kCADAFh0NOTpa0/EREREFo4AKiKxWK3JyctC3b1/1OVEU0bdvX5w8edLpe1JTU5GTk6MGQFeuXMHBgwcxYMAAl9cpt9fhtHKRZbFYLCgvL1f/VFRUePslac7bTtVyeDhknQ4AYDx4EIB9yT0REREFVg1RaWkpJElClD2boYiKikJeXp7T9wwbNgylpaWYM2cOAMBms2HMmDGYMGGC0+MlScIHH3yA1NRUdO3a1ekxa9euxZo1a9THiYmJWLRokRdfkcZk2euACIIAKTISuuvX1YCI02VERETVAiog8saRI0ewdu1aTJs2Dd27d0d+fj6WLVuGNWvWYOLEiXWOX7p0KS5cuIAFCxa4POf48eMxbtw49bEgCD4Zu6eEigoIsgzA8xoiwL70/vp1GBgQEREROQiogMhkMkEURRTbe+UoiouL62SNFKtWrcLw4cMxevRoAEDXrl1hNpuxZMkSTJgwAWKNLsxLly7FgQMHMH/+fLRt29blOAwGAwwGQ6O/Hq2pK8wEAXJYmMfvV5oz6i9cAMCAiIiISBFQNUR6vR5JSUk4fPiw+pwkSTh8+DBSUlKcvqeysrJOBkestRWFLMtYunQp9uzZg7lz5yImJkb7wTcBh+kyL7JWykozBQMiIiKiagGVIQKAcePGYfHixUhKSkJycjKysrJQWVmJESNGAADeeecdtGnTBlOmTAEApKWlYf369UhMTFSnzFatWoW0tDQ1MFq6dCm2b9+O5557DmFhYWoGKjw8XO1VFAwEL5fcK2oHRLbExEaPiYiIqDkIuIAoIyMDpaWlWL16NYqLi5GQkIBZs2apU2aFhYUOGaH7778fgiBg5cqVuH79OkwmE9LS0jB58mT1mI0bNwIAXnzxRYdrzZw5Uw20/MJmg3H3bugKCmCLiUFVejpgXwnmjNqDyMONXRWyfYNXALB26uTVtBsREVFzJMiyvUqXGnT16lVYLBZNzhWalYXIuXPVBokAYIuNRcmCBTBnZjp9T8g336DtI4+gql8/FH71lcfXbP3yy2j9zjsAgMo77sC1lSu9GzwREVEQMBgMaN++vVvHBlQNUUsRmpWF6BkzINYIhgBAzM9H9IwZCM3Kcvo+b7ftUEg1MkRSeDhgs3l1HiIiouaGAVFTs9kQOXdudU+hWi8pS+pN8+Y5DVZEe0NJbwKi0KwstF68WH0c9p//oEN6usvgi4iIqCVhQNTEjLt3Q3f5cp1gSCHIMvR5eTDu3l33NXuGyNNtO5SMlFBrP7iGMlJEREQtBQOiJqYrKPD6OK9WmTUiI0VERNRSMCBqYjY3eyA5O07wYpVZYzJSRERELQUDoiZWlZ4OW2wsZBeNFWVBgDUurnoJfi2iFxmixmSkiIiIWgoGRE1Np0OJfR+12kGR8rh0/nyn/Yi8qSFqTEaKiIiopWBA5AfmzEwULVkCqWNHh+dtsbEoWrLEZR8iwYtVZo3JSBEREbUUDIj8xJyZiSu7d6Pk+ecBANauXVGwa5fLYAgARG/6EDUiI0VERNRSMCDyJ50O5gkTqv83Lw+wWus93Nu9zLzNSBEREbUUAbeXWUtj69QJUmQkxJIS6E+dgrVPH5fHKgGR5MVeZubMTJjHjvVo7zQiIqKWggGRvwkCLD17ImTXLhiOHnUrIPJ2t3vodKjKyPDuvURERM0Yp8wCgKVXLwCA4ejReo/zqoaIiIiIGsSAKABY3QyIlFVmnm7dQURERPVjQBQAlAyR/uhRwL6dRh1VVRCqqgA0YsqMiIiInGJAFAAsKSmQRRG6oiKI+flOj1GaMgKcMiMiItIaA6JAEBYGa7duAADDsWNODxGVpoyhoYCetfBERERaYkAUIBoqrFa37fBiyT0RERHVjwFRgLDWrCNyotFL7omIiMglBkQBoqEMkbrTPeuHiIiINMeAKECoK83OnAEqKuq8LjAgIiIi8hkGRAFC6tABtjZtIEgSDCdP1nldrSFiQERERKQ5BkSBQhDqbdDIDBEREZHvMCAKIJZ6CqtZQ0REROQ7DIgCSH2F1epO91xlRkREpDkGRAHEISCqtYWHwI1diYiIfIYBUQCxdu8O2WCAWFoK3aVLDq8pG7syICIiItIeA6JAYjTCmpwMoG4dkcgMERERkc8wIAowlp49AQCGI0ccnmcNERERke8wIAowlt69AdQtrOayeyIiIt9hQBRgXPUi4pQZERGR7zAgCjDKSjPduXNqVgjg5q5ERES+xIAowEjt2sEWEwNBlqE/dkx9Xq0hCg/319CIiIiaLQZEAchZg0ZmiIiIiHyHAVEAqhMQSRJE9iEiIiLyGQZEAah2YbXSlBHgbvdERES+wIAoAKmbvB47BkjSrW07RBEIDfXn0IiIiJolvb8HQHVZu3WDHBICsbwcunPnAEkCYK8fEgQ/j46IiKj5YYYoEOn1sKSkAAAMx45BVAqqucKMiIjIJxgQBaiadUTctoOIiMi3GBAFKLWO6OjRWzVELKgmIiLyCQZEAarm0nuBS+6JiIh8igFRgFIzRBcuQHf5MgAGRERERL7CgChAyVFRsMbFAQCM+/YBYA0RERGRrzAgCmBKYbVx714AzBARERH5CgOiAKZMm+kKCwEwICIiIvIVBkQBTAmIFJwyIyIi8g0GRAGsdkDExoxERES+wYAogNkSEiCFhamPZWaIiIiIfIIBUSDT6WBNTb318NIlwGbz44CIiIiaJwZEASw0Kwv6kyfVx63//Gd0SE9HaFaWH0dFRETU/DAgClChWVmInjFD7VKtEPPzET1jBoMiIiIiDQmyLMv+HkSwuHr1KiwWi+8vZLOhQ3o6xMuXITh5WRYE2GJjUbBrF6DT+X48REREQchgMKB9+/ZuHcsMUQAy7t4NnYtgCAAEWYY+Lw/G3bubdFxERETNFQOiAKQrKND0OCIiIqqf3t8DqG3Dhg348ssvUVxcjPj4eDz22GNITk52efz69euxceNGFBYWwmQyIT09HVOmTIHRaAQAHD16FP/+979x9uxZFBUV4dlnn8WQIUOa6svxii0mRtPjiIiIqH4BlSHKzs7G8uXLMXHiRCxatAjx8fFYuHAhSkpKnB6/fft2rFixApMmTcKbb76JJ554Ajt37sQnn3yiHlNZWYmEhAT86le/aqovo9Gq0tNhi42FLDifNJMFAda4OFSlpzfxyIiIiJqngAqI1q1bh9GjR2PkyJHo3Lkzpk+fDqPRiM2bNzs9/sSJE0hNTcWwYcMQExOD/v37Y+jQoTh9+rR6zIABA/Dggw8GfFbIgU6HkgULAKBOUKQ8Lp0/nwXVREREGgmYgMhqtSInJwd9+/ZVnxNFEX379sXJGr14akpNTUVOTo4aAF25cgUHDx7EgAEDGjUWi8WC8vJy9U9FRUWjzucNc2YmipYsgdSxo8PztthYFC1ZAnNmZpOPiYiIqLkKmBqi0tJSSJKEqKgoh+ejoqKQl5fn9D3Dhg1DaWkp5syZAwCw2WwYM2YMJkyY0KixrF27FmvWrFEfJyYmYtGiRY06pzfMmZkwjx1bveqsoAC2mJjqaTJmhoiIiDQVMAGRN44cOYK1a9di2rRp6N69O/Lz87Fs2TKsWbMGEydO9Pq848ePx7hx49THgotaniah06EqI8N/1yciImoBAiYgMplMEEURxcXFDs8XFxfXyRopVq1aheHDh2P06NEAgK5du8JsNmPJkiWYMGECRNG7GUGDwQCDweDVe4mIiCj4BEwNkV6vR1JSEg4fPqw+J0kSDh8+jJSUFKfvqaysrJO98TYIIiIiopYrYDJEADBu3DgsXrwYSUlJSE5ORlZWFiorKzFixAgAwDvvvIM2bdpgypQpAIC0tDSsX78eiYmJ6pTZqlWrkJaWpgZGZrMZ+fn56jUKCgqQm5uLVq1aoV27dk3+NRIREVHgCaiAKCMjA6WlpVi9ejWKi4uRkJCAWbNmqVNmhYWFDhmh+++/H4IgYOXKlbh+/TpMJhPS0tIwefJk9ZgzZ85g/vz56uPly5cDAO6880489dRTTfOFERERUUDj5q4eaLLNXYmIiKjRuLkrERERkQcYEBEREVGLx4CIiIiIWjwGRERERNTiBdQqs0Cn1/N2ERERBQtPPre5yoyIiIhaPE6ZeaGiogLPP/88Kioq/D2UFoX33T943/2D990/eN/9IxDuOwMiL8iyjLNnz4LJtabF++4fvO/+wfvuH7zv/hEI950BEREREbV4DIiIiIioxWNA5AWDwYCJEyfCYDD4eygtCu+7f/C++wfvu3/wvvtHINx3rjIjIiKiFo8ZIiIiImrxGBARERFRi8eAiIiIiFo8BkRERETU4nFzLg9t2LABX375JYqLixEfH4/HHnsMycnJ/h5Ws3L06FH8+9//xtmzZ1FUVIRnn30WQ4YMUV+XZRmrV6/GN998g5s3b6JHjx6YNm0aYmNj/Tjq4LZ27Vrs2bMHly5dgtFoREpKCh5++GHExcWpx1RVVWH58uXIzs6GxWJB//79MW3aNERFRflv4EFu48aN2LhxI65evQoA6Ny5MyZOnIgBAwYA4D1vKp9//jlWrFiBzMxMPProowB4731h9erVWLNmjcNzcXFxeOuttwD4/54zQ+SB7OxsLF++HBMnTsSiRYsQHx+PhQsXoqSkxN9Da1YqKyuRkJCAX/3qV05f/+KLL/DVV19h+vTpeOmllxASEoKFCxeiqqqqiUfafBw9ehRjx47FwoUL8cILL8Bms+GPf/wjzGazesyHH36I/fv345lnnsH8+fNRVFSE119/3Y+jDn5t2rTBlClT8Kc//Qkvv/wy+vTpg1deeQUXLlwAwHveFE6fPo1NmzYhPj7e4Xnee9/o0qULlixZov5ZsGCB+pq/7zkDIg+sW7cOo0ePxsiRI9G5c2dMnz4dRqMRmzdv9vfQmpUBAwbgwQcfdMgKKWRZRlZWFiZMmIDBgwcjPj4eTz/9NIqKirB3714/jLZ5mD17NkaMGIEuXbogISEBTz31FAoLC5GTkwMAKC8vx7fffoupU6eiT58+SEpKwsyZM3HixAmcPHnSz6MPXoMGDcLAgQMRGxuLuLg4TJ48GaGhoTh16hTveRMwm834y1/+gscffxwRERHq87z3viOKIqKiotQ/JpMJQGDccwZEbrJarcjJyUHfvn3V50RRRN++ffkD0oQKCgpQXFyMfv36qc+Fh4cjOTmZfw8aKi8vBwC0atUKAJCTkwObzebw/d+pUye0a9eO910jkiRhx44dqKysREpKCu95E3j//fcxYMAAh39PAH6/+1J+fj4ef/xxPP300/jzn/+MwsJCAIFxz1lD5KbS0lJIklRnLjMqKgp5eXn+GVQLVFxcDACIjIx0eD4yMlJ9jRpHkiR88MEHSE1NRdeuXQFU33e9Xu/wWzTA+66F8+fPY/bs2bBYLAgNDcWzzz6Lzp07Izc3l/fch3bs2IGzZ8/i5ZdfrvMav999o3v37pg5cybi4uJQVFSENWvWYO7cuXj99dcD4p4zICIiB0uXLsWFCxcc5vbJd+Li4vDqq6+ivLwcu3btwuLFizF//nx/D6tZKywsxAcffIAXXngBRqPR38NpMZTFAgAQHx+vBkg7d+4MiL8HBkRuMplMEEWxTqRaXFzMVQdNSLnXJSUliI6OVp8vKSlBQkKCfwbVjCxduhQHDhzA/Pnz0bZtW/X5qKgoWK1W3Lx50+E3uJKSEn7/N5Jer0fHjh0BAElJSThz5gyysrKQkZHBe+4jOTk5KCkpwfPPP68+J0kSjh07hg0bNmD27Nm8900gIiICcXFxyM/PR79+/fx+z1lD5Ca9Xo+kpCQcPnxYfU6SJBw+fBgpKSl+HFnLEhMTg6ioKPzwww/qc+Xl5Th9+jT/HhpBlmUsXboUe/bswdy5cxETE+PwelJSEnQ6ncN9z8vLQ2FhIe+7xiRJgsVi4T33ob59++K1117DK6+8ov7p1q0bhg0bpv4/773vmc1m5OfnIyoqKiC+35kh8sC4ceOwePFiJCUlITk5GVlZWaisrMSIESP8PbRmRfkhURQUFCA3NxetWrVCu3btkJmZic8++wyxsbGIiYnBypUrER0djcGDB/tx1MFt6dKl2L59O5577jmEhYWpmdDw8HAYjUaEh4dj1KhRWL58OVq1aoXw8HD84x//QEpKCj8gGmHFihW47bbb0K5dO5jNZmzfvh1Hjx7F7Nmzec99KCwsTK2PU4SEhKB169bq87z32lu+fDkGDRqEdu3aoaioCKtXr4Yoihg2bFhAfL9zt3sPbdiwAf/+979RXFyMhIQE/PKXv0T37t39Paxm5ciRI05rKO6880489dRTamPGr7/+GuXl5ejRowd+9atfOTQRJM888MADTp+fOXOmGvArTdN27NgBq9XKRnUa+Otf/4rDhw+jqKgI4eHhiI+Px7333quueuI9bzovvvgiEhIS6jRm5L3XzltvvYVjx47hxo0bMJlM6NGjBx588EF1ytjf95wBEREREbV4rCEiIiKiFo8BEREREbV4DIiIiIioxWNARERERC0eAyIiIiJq8RgQERERUYvHgIiIiIhaPAZERETkkRdffBEvvviiv4dBpCkGREQB4D//+Q8eeOABzJo1y99DCViSJOHxxx/HAw88gIMHD/p7OETUzDAgIgoA27dvR/v27XH69GmHfdzoFmWLi/bt22Pbtm3+Hg4RNTMMiIj8rKCgACdOnMDUqVNhMpn88mEvSRKqqqqa/Lqe2Lp1KxITE/HTn/4Ue/fuhdls9veQnLLZbLBarf4eBhF5iLvdE/nZtm3bEBERgYEDB+JHP/oRtm/fjkmTJgEArFYrpk+fjsGDB2PmzJkO7ysvL8f06dMxduxYPPLIIwAAi8WCtWvXYtu2bbh27RoiIyMxdOhQ/PznP4fBYFDf+8ADD2Ds2LFISUnB2rVrcfnyZfzud7/DkCFD8O9//xt79uxBXl4eKisr0blzZ4wfPx4/+tGPHK5fVVWFjz/+GDt27IDFYkHv3r0xffp0PPHEE5g4caLDhrHXr1/HypUrcfDgQdy8eRMdO3bEuHHjMGrUKLfuUVVVFfbu3Yv7778fGRkZ+PDDD7Fv3z4MGzaszrEHDx7E559/jrNnz0IQBMTFxeGnP/2pw7GnTp3CmjVrcPLkSVitVnTo0AGjRo1CZmYmAKj1MbXrZBYvXoyjR49i8eLFAKqD2aeffhoPP/wwdDodNmzYgIKCAixatAidO3fGv/71Lxw4cAD5+fmQJAmJiYl44IEH0KdPH4fzSpKEDRs24JtvvkF+fj5CQ0ORlJSEBx98EN26dcO8efNQXl6OV199tc7X+5vf/AYxMTGYPXu203v3pz/9CRcvXsQ777xT57XZs2fDZrPhT3/6EwBg8+bN2Lp1Ky5cuIDy8nJ06NABP/nJT/DjH//Yxd9MtS1btuDdd9/FO++8g5iYGPV5ZaPmefPmoXfv3g73f/Xq1Th58iRsNhu6deuGyZMno0ePHvVeh8iXmCEi8rPt27cjPT0der0eQ4cOxeXLl3H69GkAgF6vx5AhQ7B37946WYe9e/fCYrFg6NChAKo/VF955RV8+eWXSEtLw2OPPYbBgwdj/fr1ePPNN+tc9/Dhw/jwww+RkZGBRx99VP0g++qrr5CQkIAHHngAkydPhk6nwxtvvIEDBw44vH/x4sXYsGEDBgwYgIceeghGoxEvv/xynesUFxdj9uzZ+OGHHzB27Fg8+uij6NixI/72t79h/fr1bt2jffv2wWw2IyMjA1FRUejdu7fTTNqWLVvwpz/9CWVlZbjvvvswZcoUxMfH47vvvlOPOXToEObNm4eLFy/iJz/5CX7xi1+gd+/e2L9/v1tjcWbLli3YsGEDRo8ejUceeQStWrVCeXk5vv32W/Tu3RsPPfQQJk2ahNLSUixcuBC5ubkO7//b3/6GDz74AO3atcNDDz2E++67DwaDAadOnQIADB8+HOfOncP58+cd3nf69GlcvnwZd9xxh8uxZWRkoKCgQP2eUly9ehWnTp1CRkaG+tzGjRvRvn17jB8/Ho888gjatWuH999/Hxs2bPD63tR2+PBhzJs3DxUVFZg0aRImT56M8vJyLFiwoM4YiZoSM0REfpSTk4NLly7hl7/8JQCgR48eaNu2LbZv347k5GQA1R9omzdvxvfff4+0tDT1vdnZ2ejQoQO6desGoDqwOnToEObPn+/wm3aXLl3w3nvv4cSJE0hNTVWfz8vLw+uvv47OnTs7jOntt9+G0WhUH9999914/vnnsW7dOgwcOFAd986dO5GZmYlHH30UADB27Fi8++67OHfunMP5Vq5cCUmS8Nprr6F169YAgB//+Md466238Omnn2LMmDEO13Nm69atSElJQbt27dR7snTpUpSWlsJkMgGozpgtW7YMycnJmDdvnsM5ZVkGUB00LlmyBNHR0XjllVcQERFR5xhvXLt2DX/5y1/UsSjXWrx4MfT6W//Mjh49Gr/97W/x1Vdf4cknnwRQHSBs2bIFP/nJT9TvAwD42c9+po7p9ttvxz/+8Q9s27YNDz30kHrMtm3bEBISgiFDhrgc26BBg2AwGJCdna1+TwHAzp07IQiCQ0A0f/78On/3CxcuxPr163H33Xd7c2scyLKM9957D71798asWbMgCAIAYMyYMXjmmWewcuVKvPDCC42+DpE3mCEi8qNt27YhMjJSnUIRBAG33347duzYAUmSAAB9+vRB69atkZ2drb6vrKwMhw4dwu23364+t2vXLnTu3BlxcXEoLS1V/yjnPnLkiMO1e/XqVScYAuDwgVhWVoby8nL07NkTZ8+eVZ9XMi5jx451eG/tD01ZlrF7926kpaVBlmWHcd12220oLy9HTk5Ovffoxo0b+P7779VMGAB1+q7mPTl06BAqKipw77331gmwlA/es2fPoqCgAJmZmQ7BUM1jvJGenu4QDAGAKIpqMCRJEsrKytTpoZr3cvfu3RAEQZ0mdTam8PBwDB48GDt27HAI7rKzszF48GCEhoa6HFt4eDhuu+027Ny50yHoy87ORvfu3dUgE3D8uy8vL0dpaSl69eqFK1euoLy83JNb4lRubi4uX76MYcOG4caNG+r3gtlsRp8+fXDs2DH1+56oqTFDROQnygda7969UVBQoD7fvXt3rFu3Dj/88AP69+8PnU6H9PR0tVbHYDBgz549sNlsDr/dX758GZcuXcK0adOcXq+kpMThcc1aj5r279+Pzz77DLm5ubBYLOrzNQOGwsJCCIJQ5xwdO3Z0eFxaWoqbN2/i66+/xtdff+30eqWlpU6fV2RnZ8NmsyExMdFhBV737t2xfft2NQhTXuvatavLc125cgVAddZMS67u5ZYtW7Bu3TpcunQJNpvN6fFXrlxBdHQ0WrVqVe81hg8fjuzsbBw7dgy9evXCoUOHUFJSguHDhzc4voyMDOzduxcnT55Eamoq8vPzkZOTo2b3FMePH8enn36KkydPorKy0uG18vJyhIeHN3it+ly+fBkA1BosZ8rLyxu8F0S+wICIyE+UZeTZ2dkOmQ7Ftm3b0L9/fwDA0KFD8fXXX+PgwYMYMmQIdu7ciU6dOiEhIUE9XpZldO3aVS2wrq1mJgCA02mqY8eO4ZVXXkHPnj3xq1/9CtHR0dDpdNiyZQu2b9/u8deoZCTuuOMO3HnnnU6PiY+Pr/ccynXnzJnj9PUrV66gQ4cOHo+tPoIgOJ1Cc5W9cHYvt27dinfffReDBw/GPffcA5PJBFEU8fnnn6uBmSduu+02REZGYtu2bejVqxe2bduGqKgo9OvXr8H3pqWlISQkBDt37kRqaqo6XVazUD4/Px//93//h7i4ODzyyCNo27Yt9Ho9Dh48iPXr13uVuan9HuWePvzwww7fuzXVl+0i8iUGRER+okyX/epXv6rz2u7du7F3715UVVXBaDSiZ8+eiI6ORnZ2Nnr06IHDhw9j/PjxDu/p0KEDzp07h759+3o9/bN7924YDAbMnj3bYVXali1bHI5r164dZFlGQUEBYmNj1edr91AymUwICwuDJElufXDXprQkuPvuu9GrVy+H1yRJwjvvvIPt27fj/vvvV7NT58+fr5OpUiiB04ULF+odT0REhNOgpbCw0O2x79q1Cx06dMCzzz7r8Pfx6aef1hnT999/j7KysnozI6IoYtiwYdiyZQseeugh7N27F6NHj4YoNlz5EBoaioEDB2Lnzp145JFHkJ2djZ49e6JNmzbqMfv374fFYsHzzz/vEDzXnmp1Rhl37Wm1q1ev1vlageppPG++H4h8iTVERH5QVVWFPXv2qEvta/+5++67UVFRgX379gGo/jBMT0/H/v37sXXr1jrTZUB14e3169fxzTffOL2eO317RFGEIAgOv9kXFBRg7969DsfddtttAKo7bNdUezWSMu7du3fXWSEFNDxdpqwku+eee+rco4yMDPTq1UvNIPXr1w9hYWH4/PPP6/RUUjITiYmJiImJQVZWFm7evOn0GKD6gzsvL89hfLm5uTh+/Hi94639tdc+76lTp3Dy5EmH49LT0yHLcp1AqfZ7gepps5s3b2LJkiUwm831ri6rLSMjA0VFRfj2229x7ty5Ot8/zsZbXl5eJxh2Rgl0jh49qj4nSVKd78WkpCR06NABX375pdPvx4a+H4h8iRkiIj/Yt28fKioqMGjQIKevd+/eXW3SqHxwZWRkYMOGDfj000/RtWvXOgXRw4cPx86dO/Hee+/h8OHD6NGjByRJwqVLl7Bz507Mnj1bXZHmysCBA7Fu3Tq89NJLGDp0KEpLS/Gf//wHHTt2dFg9lpSUhPT0dGRlZaGsrAzdu3fH0aNH1RqRmhmRKVOm4MiRI5g9ezZGjx6Nzp07o6ysDDk5Ofjhhx+wbNkyl+PZvn07EhIS6kz3KQYNGoR//OMfyMnJQVJSEqZOnYq//e1v+MMf/oBhw4YhIiIC586dQ2VlJZ5++mmIoohp06Zh0aJFeO655zBixAhER0fj0qVLuHjxotrLZ+TIkVi3bh0WLlyIkSNHorS0FJs2bUKXLl1QUVFR7z1UpKWlYc+ePXjttdcwcOBAFBQUYNOmTejcubNDMNCnTx8MHz4cX331FfLz89G/f3/Isoxjx46hT58+DoXqiYmJ6NKlC3bt2oVOnTohKSnJrbEAwIABAxAWFoaPPvpIDVRr6t+/P/R6PRYtWoS77roLZrMZ33zzDUwmE4qKiuo9d5cuXdC9e3d88sknaqZLqf2qSRRFPPHEE3jppZfwzDPPYMSIEWjTpg2uX7+OI0eOICwsDP/v//0/t78mIi0xQ0TkB9u2bYPBYHA5bSCKIgYOHIjvvvsON27cAACkpqaibdu2qKioqPPbvfKe3//+95gyZQouXLiAjz76CJ9++inOnDmDzMxMh6ktV/r06YMnnngCxcXF+PDDD7Fjxw489NBDGDx4cJ1jn376aYwdOxYHDhzAP//5T1itVvz2t78FAIfptqioKLz00ksYMWIEdu/ejaVLl6oZmppLyGtTWhLUbDVQm/KakkkaNWoUnnvuOYSHh+Nf//oX/vnPf+Ls2bMYMGCA+p7bbrsN8+bNQ2xsLNatW4cPP/wQhw8fdrhO586d8fTTT6O8vBzLly/Hvn378PTTTyMxMbHBe6gYMWIEJk+ejHPnzmHZsmX4/vvv8etf/9ppEDNz5kw8/PDDKCgowMcff4y1a9fCYrEgJSWlzrFKLZY7xdQ1GY1GpKWloaKiAr1790ZkZKTD63FxcXjmmWcgCAI++ugjbNq0CXfddZfarLIh//M//4OUlBR88cUXWLt2LXr37o0pU6bUOa53795YuHAhkpKS8J///AfLli3Df//7X0RFRWHcuHEefU1EWhLkxjTfICKqITc3F8899xx+/etfezSdQ+7LysrChx9+iMWLF7vMnBGR55ghIiKvONv7bP369RAEAT179vTDiJo/WZbx7bffolevXgyGiDTGGiIi8soXX3yBnJwc9O7dGzqdDt999x0OHjyIu+66ix/WGjObzdi3bx+OHDmC8+fP47nnnvP3kIiaHQZEROSV1NRUHDp0CP/6179gNpvRrl07TJo0CRMmTPD30Jqd0tJS/PnPf0ZERATGjx/vshifiLzHGiIiIiJq8VhDRERERC0eAyIiIiJq8RgQERERUYvHgIiIiIhaPAZERERE1OIxICIiIqIWjwERERERtXgMiIiIiKjFY0BERERELd7/B9Gc3fl5Je7LAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_svm_poly,'ro-')\n",
        "plt.title(\"Poly SVM\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-MY5VxlStzf"
      },
      "source": [
        "# K-nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqTAHJcXSwNZ",
        "outputId": "56e90c61-eaaa-4407-aa02-3e0509fd82d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        82\n",
            "           1       0.93      0.93      0.93       102\n",
            "\n",
            "    accuracy                           0.92       184\n",
            "   macro avg       0.92      0.92      0.92       184\n",
            "weighted avg       0.92      0.92      0.92       184\n",
            "\n",
            "The accuracy for 1 : 0.9230033476805357\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84        82\n",
            "           1       0.91      0.79      0.85       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "The accuracy for 2 : 0.8482783357245336\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.72      0.81        82\n",
            "           1       0.81      0.95      0.87       102\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.87      0.84      0.84       184\n",
            "weighted avg       0.86      0.85      0.84       184\n",
            "\n",
            "The accuracy for 3 : 0.835246293639407\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81        82\n",
            "           1       0.83      0.89      0.86       101\n",
            "\n",
            "    accuracy                           0.84       183\n",
            "   macro avg       0.84      0.83      0.83       183\n",
            "weighted avg       0.84      0.84      0.83       183\n",
            "\n",
            "The accuracy for 4 : 0.8296908959188601\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.78      0.76        82\n",
            "           1       0.81      0.77      0.79       101\n",
            "\n",
            "    accuracy                           0.78       183\n",
            "   macro avg       0.77      0.78      0.77       183\n",
            "weighted avg       0.78      0.78      0.78       183\n",
            "\n",
            "The accuracy for 5 : 0.7763825163004106\n",
            "0.8425202778527494\n"
          ]
        }
      ],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "acc_KNN=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=KNeighborsClassifier(n_neighbors=32)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_KNN.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_KNN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npdv7xGuY8J6"
      },
      "source": [
        "# K-fold KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAfHXgPmL0iQ",
        "outputId": "8297032c-584c-415e-e0e5-45bafa1065ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8362156712118303, 0.8482445103035815, 0.8468602868102367, 0.8425202778527494, 0.8477682377298746, 0.8459028015263653, 0.8497868297960209, 0.8493201098559603, 0.84851649928264, 0.8494927191309685, 0.8521076259961348, 0.8534884599478273, 0.8483056332194263, 0.8470642465740507, 0.8523245580024814, 0.846154496281271, 0.8497367928589817, 0.8531083925820767, 0.8543516483516485, 0.8507644110275688, 0.851299031504981, 0.8539759318976489, 0.8471019721019721, 0.846733893557423, 0.8517037786774626, 0.8558357699805067, 0.8537206110514383, 0.8519044399368942, 0.8500444408532642, 0.8504747742769565, 0.8527794471153849, 0.8479555167055167, 0.8494640163757811, 0.8521490414347557, 0.8499669312169315, 0.8539748539748542, 0.8533979178716024, 0.8547145162529776, 0.8537004662004662, 0.8557066916823014, 0.8564356939356941, 0.856512802443035, 0.8507001836547292, 0.8540123456790122, 0.8583937198067632, 0.8591553836234687, 0.8578256523569024, 0.8499226963512678, 0.8523207070707071]\n"
          ]
        }
      ],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "acc_aver_KNN=[]\n",
        "for i in range(2,51):\n",
        "  acc_KNN=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "      X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "      y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "      y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "      ro_scaler=MinMaxScaler()\n",
        "      X_train=ro_scaler.fit_transform(X_train)\n",
        "      X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "      clf=KNeighborsClassifier(n_neighbors=32)\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_KNN.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "      pass\n",
        "  acc_aver_KNN.append(Average(acc_KNN))\n",
        "print(acc_aver_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk-zg5EHTmQq",
        "outputId": "b58d00be-88bc-4248-d125-00592f9d471b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8591553836234687\n",
            "46\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_KNN)))\n",
        "print(acc_aver_KNN.index((max(acc_aver_KNN)))+1)\n",
        "print(acc_aver_KNN.index(0.8534884599478273)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "Jl9cmm5WMVPO",
        "outputId": "37136b91-d6a6-4527-e7cc-0ee47e390af8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_KNN,'ro-')\n",
        "plt.title(\"K-nearest Neighbors\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7v4YAhuS-Qw"
      },
      "source": [
        "# Tree Base Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMjli_7oTGzY"
      },
      "outputs": [],
      "source": [
        "feature_col_tree=df_tree.columns.to_list()\n",
        "feature_col_tree.remove(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoXYfmkfTJ42",
        "outputId": "5cfeb525-a3f7-4861-bcaa-bf3093de66de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.87      0.76        82\n",
            "           1       0.86      0.66      0.74       102\n",
            "\n",
            "    accuracy                           0.75       184\n",
            "   macro avg       0.76      0.76      0.75       184\n",
            "weighted avg       0.77      0.75      0.75       184\n",
            "\n",
            "The accuracy for 1 : 0.7613582018173123\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.88      0.77        82\n",
            "           1       0.87      0.68      0.76       102\n",
            "\n",
            "    accuracy                           0.77       184\n",
            "   macro avg       0.78      0.78      0.77       184\n",
            "weighted avg       0.79      0.77      0.77       184\n",
            "\n",
            "The accuracy for 2 : 0.7772596843615496\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.62      0.72        82\n",
            "           1       0.75      0.91      0.82       102\n",
            "\n",
            "    accuracy                           0.78       184\n",
            "   macro avg       0.80      0.77      0.77       184\n",
            "weighted avg       0.79      0.78      0.78       184\n",
            "\n",
            "The accuracy for 3 : 0.766857962697274\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.72      0.72        82\n",
            "           1       0.77      0.78      0.78       101\n",
            "\n",
            "    accuracy                           0.75       183\n",
            "   macro avg       0.75      0.75      0.75       183\n",
            "weighted avg       0.75      0.75      0.75       183\n",
            "\n",
            "The accuracy for 4 : 0.7508452064718667\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.74      0.69        82\n",
            "           1       0.76      0.66      0.71       101\n",
            "\n",
            "    accuracy                           0.70       183\n",
            "   macro avg       0.70      0.70      0.70       183\n",
            "weighted avg       0.71      0.70      0.70       183\n",
            "\n",
            "The accuracy for 5 : 0.7036343878290268\n",
            "0.7519910886354059\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "acc_Dtree=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "    X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "    y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "    y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "    clf=DecisionTreeClassifier(criterion=\"entropy\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_Dtree.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "print(Average(acc_Dtree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pQ_YJcQcTPm2",
        "outputId": "d2803b9e-8ebb-4286-cee7-0f0adc825f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"3519pt\" height=\"1980pt\"\n viewBox=\"0.00 0.00 3519.00 1980.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1976)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1976 3515,-1976 3515,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#d9ecfa\" stroke=\"black\" points=\"1509.5,-1972 1384.5,-1972 1384.5,-1889 1509.5,-1889 1509.5,-1972\"/>\n<text text-anchor=\"middle\" x=\"1447\" y=\"-1956.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ST_Slope &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"1447\" y=\"-1941.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.992</text>\n<text text-anchor=\"middle\" x=\"1447\" y=\"-1926.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 735</text>\n<text text-anchor=\"middle\" x=\"1447\" y=\"-1911.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [328, 407]</text>\n<text text-anchor=\"middle\" x=\"1447\" y=\"-1896.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#5caeea\" stroke=\"black\" points=\"1152.5,-1853 1035.5,-1853 1035.5,-1770 1152.5,-1770 1152.5,-1853\"/>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1837.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1822.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.607</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1807.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 416</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1792.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 354]</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1777.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1384.3,-1908.72C1321.92,-1888.04 1226.49,-1856.41 1162.24,-1835.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1163.19,-1831.75 1152.6,-1831.92 1160.99,-1838.39 1163.19,-1831.75\"/>\n<text text-anchor=\"middle\" x=\"1163.82\" y=\"-1850.56\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 124 -->\n<g id=\"node125\" class=\"node\">\n<title>124</title>\n<polygon fill=\"#ea9a60\" stroke=\"black\" points=\"2173,-1853 2045,-1853 2045,-1770 2173,-1770 2173,-1853\"/>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1837.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1822.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.649</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1807.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 319</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1792.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [266, 53]</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1777.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 0&#45;&gt;124 -->\n<g id=\"edge124\" class=\"edge\">\n<title>0&#45;&gt;124</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1509.58,-1918.44C1632.09,-1896.79 1903.06,-1848.9 2034.54,-1825.66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2035.29,-1829.08 2044.53,-1823.89 2034.07,-1822.19 2035.29,-1829.08\"/>\n<text text-anchor=\"middle\" x=\"2030.2\" y=\"-1840.68\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#f0f7fd\" stroke=\"black\" points=\"852,-1734 730,-1734 730,-1651 852,-1651 852,-1734\"/>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1718.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FastingBS &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1703.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1688.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1673.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [24, 26]</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1658.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1035.22,-1787.8C985.64,-1768.66 914.54,-1741.2 861.83,-1720.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"862.8,-1717.47 852.22,-1717.14 860.28,-1724 862.8,-1717.47\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<polygon fill=\"#50a8e8\" stroke=\"black\" points=\"1152.5,-1734 1035.5,-1734 1035.5,-1651 1152.5,-1651 1152.5,-1734\"/>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1718.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 66.5</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1703.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.481</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1688.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 366</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1673.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [38, 328]</text>\n<text text-anchor=\"middle\" x=\"1094\" y=\"-1658.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 1&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>1&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1094,-1769.91C1094,-1761.65 1094,-1752.86 1094,-1744.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1097.5,-1744.02 1094,-1734.02 1090.5,-1744.02 1097.5,-1744.02\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#f8e0ce\" stroke=\"black\" points=\"643.5,-1615 530.5,-1615 530.5,-1532 643.5,-1532 643.5,-1615\"/>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 83.0</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.985</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [24, 18]</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M729.79,-1656.4C705.44,-1642.43 677.37,-1626.33 652.6,-1612.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"654.05,-1608.92 643.63,-1606.98 650.57,-1614.99 654.05,-1608.92\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"839,-1607.5 743,-1607.5 743,-1539.5 839,-1539.5 839,-1607.5\"/>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1592.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1577.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1562.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n<text text-anchor=\"middle\" x=\"791\" y=\"-1547.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 2&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>2&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M791,-1650.91C791,-1640.2 791,-1628.62 791,-1617.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"794.5,-1617.67 791,-1607.67 787.5,-1617.67 794.5,-1617.67\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#e9f4fc\" stroke=\"black\" points=\"497.5,-1496 386.5,-1496 386.5,-1413 497.5,-1413 497.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 37.5</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.998</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 18]</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M536.69,-1531.91C524.88,-1522.38 512.21,-1512.15 500.09,-1502.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"502.2,-1499.58 492.22,-1496.02 497.8,-1505.02 502.2,-1499.58\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"635,-1488.5 539,-1488.5 539,-1420.5 635,-1420.5 635,-1488.5\"/>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1473.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1458.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1443.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n<text text-anchor=\"middle\" x=\"587\" y=\"-1428.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 3&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>3&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M587,-1531.91C587,-1521.2 587,-1509.62 587,-1498.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"590.5,-1498.67 587,-1488.67 583.5,-1498.67 590.5,-1498.67\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#c8e4f8\" stroke=\"black\" points=\"366.5,-1377 255.5,-1377 255.5,-1294 366.5,-1294 366.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 34.0</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.981</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 18]</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M396.55,-1412.91C386.08,-1403.56 374.86,-1393.54 364.1,-1383.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"366.16,-1381.07 356.37,-1377.02 361.5,-1386.29 366.16,-1381.07\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"490,-1369.5 394,-1369.5 394,-1301.5 490,-1301.5 490,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"442\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 4&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>4&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M442,-1412.91C442,-1402.2 442,-1390.62 442,-1379.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"445.5,-1379.67 442,-1369.67 438.5,-1379.67 445.5,-1379.67\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#f1f8fd\" stroke=\"black\" points=\"228.5,-1258 117.5,-1258 117.5,-1175 228.5,-1175 228.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 14.0</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 14]</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M263.12,-1293.91C251.99,-1284.47 240.05,-1274.34 228.61,-1264.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"230.68,-1261.82 220.79,-1258.02 226.16,-1267.16 230.68,-1261.82\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"359,-1250.5 263,-1250.5 263,-1182.5 359,-1182.5 359,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n<text text-anchor=\"middle\" x=\"311\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 5&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>5&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M311,-1293.91C311,-1283.2 311,-1271.62 311,-1260.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"314.5,-1260.67 311,-1250.67 307.5,-1260.67 314.5,-1260.67\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"99,-1131.5 3,-1131.5 3,-1063.5 99,-1063.5 99,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"51\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"51\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"51\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n<text text-anchor=\"middle\" x=\"51\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M130.67,-1174.91C118.48,-1163.21 105.18,-1150.46 93,-1138.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"95.22,-1136.06 85.58,-1131.67 90.38,-1141.11 95.22,-1136.06\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#fbece1\" stroke=\"black\" points=\"228.5,-1139 117.5,-1139 117.5,-1056 228.5,-1056 228.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 18.5</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.995</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 11]</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173,-1174.91C173,-1166.65 173,-1157.86 173,-1149.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.5,-1149.02 173,-1139.02 169.5,-1149.02 176.5,-1149.02\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"96,-1012.5 0,-1012.5 0,-944.5 96,-944.5 96,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"48\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"48\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"48\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"48\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M129.63,-1055.91C117.14,-1044.21 103.51,-1031.46 91.03,-1019.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"93.13,-1016.95 83.43,-1012.67 88.34,-1022.06 93.13,-1016.95\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#edf6fd\" stroke=\"black\" points=\"232,-1020 114,-1020 114,-937 232,-937 232,-1020\"/>\n<text text-anchor=\"middle\" x=\"173\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 14.0</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.998</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 11]</text>\n<text text-anchor=\"middle\" x=\"173\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173,-1055.91C173,-1047.65 173,-1038.86 173,-1030.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.5,-1030.02 173,-1020.02 169.5,-1030.02 176.5,-1030.02\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"213,-893.5 117,-893.5 117,-825.5 213,-825.5 213,-893.5\"/>\n<text text-anchor=\"middle\" x=\"165\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"165\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"165\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n<text text-anchor=\"middle\" x=\"165\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.22,-936.91C169.49,-926.2 168.7,-914.62 167.96,-903.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"171.44,-903.4 167.27,-893.67 164.46,-903.88 171.44,-903.4\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#fae6d7\" stroke=\"black\" points=\"342.5,-901 231.5,-901 231.5,-818 342.5,-818 342.5,-901\"/>\n<text text-anchor=\"middle\" x=\"287\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 30.5</text>\n<text text-anchor=\"middle\" x=\"287\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.991</text>\n<text text-anchor=\"middle\" x=\"287\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"middle\" x=\"287\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 8]</text>\n<text text-anchor=\"middle\" x=\"287\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M212.55,-936.91C221.57,-927.65 231.24,-917.73 240.51,-908.21\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"243.05,-910.63 247.52,-901.02 238.03,-905.74 243.05,-910.63\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"337.5,-782 202.5,-782 202.5,-699 337.5,-699 337.5,-782\"/>\n<text text-anchor=\"middle\" x=\"270\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingECG &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"270\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"270\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"270\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 8]</text>\n<text text-anchor=\"middle\" x=\"270\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M281.1,-817.91C279.89,-809.56 278.6,-800.67 277.34,-792.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280.79,-791.41 275.89,-782.02 273.86,-792.42 280.79,-791.41\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"452,-774.5 356,-774.5 356,-706.5 452,-706.5 452,-774.5\"/>\n<text text-anchor=\"middle\" x=\"404\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"404\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"404\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n<text text-anchor=\"middle\" x=\"404\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 12&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>12&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M327.59,-817.91C339.29,-806.21 352.04,-793.46 363.72,-781.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"366.24,-784.21 370.83,-774.67 361.29,-779.26 366.24,-784.21\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#e6f3fc\" stroke=\"black\" points=\"330.5,-663 199.5,-663 199.5,-580 330.5,-580 330.5,-663\"/>\n<text text-anchor=\"middle\" x=\"265\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 52.0</text>\n<text text-anchor=\"middle\" x=\"265\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.997</text>\n<text text-anchor=\"middle\" x=\"265\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"middle\" x=\"265\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 8]</text>\n<text text-anchor=\"middle\" x=\"265\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.27,-698.91C267.91,-690.56 267.53,-681.67 267.16,-673.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"270.66,-672.86 266.73,-663.02 263.66,-673.16 270.66,-672.86\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"445,-655.5 349,-655.5 349,-587.5 445,-587.5 445,-655.5\"/>\n<text text-anchor=\"middle\" x=\"397\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"397\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"397\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"397\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 13&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>13&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M314.06,-698.91C326.88,-687.1 340.86,-674.22 353.64,-662.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"356.02,-665.02 361,-655.67 351.27,-659.87 356.02,-665.02\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#f8dbc6\" stroke=\"black\" points=\"312.5,-544 199.5,-544 199.5,-461 312.5,-461 312.5,-544\"/>\n<text text-anchor=\"middle\" x=\"256\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 35.0</text>\n<text text-anchor=\"middle\" x=\"256\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.98</text>\n<text text-anchor=\"middle\" x=\"256\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"middle\" x=\"256\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 5]</text>\n<text text-anchor=\"middle\" x=\"256\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M261.88,-579.91C261.24,-571.56 260.55,-562.67 259.89,-554.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"263.37,-553.72 259.12,-544.02 256.39,-554.26 263.37,-553.72\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"427,-536.5 331,-536.5 331,-468.5 427,-468.5 427,-536.5\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 14&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>14&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304.55,-579.91C315.84,-568.32 328.14,-555.7 339.43,-544.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"342.21,-546.27 346.68,-536.67 337.2,-541.39 342.21,-546.27\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#7bbeee\" stroke=\"black\" points=\"313.5,-425 162.5,-425 162.5,-342 313.5,-342 313.5,-425\"/>\n<text text-anchor=\"middle\" x=\"238\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ChestPainType &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"238\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.811</text>\n<text text-anchor=\"middle\" x=\"238\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"238\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\n<text text-anchor=\"middle\" x=\"238\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M249.75,-460.91C248.47,-452.56 247.1,-443.67 245.77,-435.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.21,-434.37 244.23,-425.02 242.3,-435.44 249.21,-434.37\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"#eeab7b\" stroke=\"black\" points=\"474.5,-425 331.5,-425 331.5,-342 474.5,-342 474.5,-425\"/>\n<text text-anchor=\"middle\" x=\"403\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 134.0</text>\n<text text-anchor=\"middle\" x=\"403\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.811</text>\n<text text-anchor=\"middle\" x=\"403\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"403\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n<text text-anchor=\"middle\" x=\"403\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 15&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>15&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M307,-460.91C318.97,-451.38 331.83,-441.15 344.11,-431.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"346.44,-433.99 352.09,-425.02 342.09,-428.51 346.44,-433.99\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"194,-298.5 98,-298.5 98,-230.5 194,-230.5 194,-298.5\"/>\n<text text-anchor=\"middle\" x=\"146\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"146\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"146\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n<text text-anchor=\"middle\" x=\"146\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M206.08,-341.91C197.14,-330.54 187.42,-318.18 178.45,-306.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"181.01,-304.36 172.08,-298.67 175.51,-308.69 181.01,-304.36\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"308,-298.5 212,-298.5 212,-230.5 308,-230.5 308,-298.5\"/>\n<text text-anchor=\"middle\" x=\"260\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"260\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"260\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"260\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M245.63,-341.91C247.65,-331.2 249.82,-319.62 251.86,-308.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"255.36,-309.14 253.76,-298.67 248.48,-307.85 255.36,-309.14\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"447,-298.5 351,-298.5 351,-230.5 447,-230.5 447,-298.5\"/>\n<text text-anchor=\"middle\" x=\"399\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n<text text-anchor=\"middle\" x=\"399\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M401.61,-341.91C401.25,-331.2 400.85,-319.62 400.48,-308.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"403.97,-308.54 400.13,-298.67 396.98,-308.78 403.97,-308.54\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"578.5,-306 465.5,-306 465.5,-223 578.5,-223 578.5,-306\"/>\n<text text-anchor=\"middle\" x=\"522\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 52.0</text>\n<text text-anchor=\"middle\" x=\"522\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"522\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"522\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"middle\" x=\"522\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 19&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>19&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M444.29,-341.91C453.7,-332.65 463.79,-322.73 473.48,-313.21\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"476.11,-315.53 480.79,-306.02 471.2,-310.54 476.11,-315.53\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"555,-179.5 459,-179.5 459,-111.5 555,-111.5 555,-179.5\"/>\n<text text-anchor=\"middle\" x=\"507\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"507\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"507\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"507\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M516.8,-222.91C515.42,-212.2 513.94,-200.62 512.55,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"516,-189.14 511.25,-179.67 509.05,-190.03 516,-189.14\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"669,-179.5 573,-179.5 573,-111.5 669,-111.5 669,-179.5\"/>\n<text text-anchor=\"middle\" x=\"621\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"621\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"621\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"621\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 21&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>21&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M556.35,-222.91C566.06,-211.43 576.63,-198.94 586.36,-187.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"589.15,-189.56 592.94,-179.67 583.8,-185.04 589.15,-189.56\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<polygon fill=\"#46a4e7\" stroke=\"black\" points=\"1064,-1615 946,-1615 946,-1532 1064,-1532 1064,-1615\"/>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 11.0</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.339</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 286</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 268]</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 31&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>31&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1063.12,-1650.91C1056.29,-1641.92 1048.98,-1632.32 1041.93,-1623.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1044.66,-1620.86 1035.82,-1615.02 1039.09,-1625.1 1044.66,-1620.86\"/>\n</g>\n<!-- 89 -->\n<g id=\"node90\" class=\"node\">\n<title>89</title>\n<polygon fill=\"#7bbeee\" stroke=\"black\" points=\"1384,-1615 1266,-1615 1266,-1532 1384,-1532 1384,-1615\"/>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 11.5</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.811</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 80</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 60]</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 31&#45;&gt;89 -->\n<g id=\"edge89\" class=\"edge\">\n<title>31&#45;&gt;89</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1152.59,-1661.82C1184.23,-1645.8 1223.48,-1625.92 1256.52,-1609.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1258.33,-1612.19 1265.67,-1604.55 1255.17,-1605.95 1258.33,-1612.19\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<polygon fill=\"#3c9ee5\" stroke=\"black\" points=\"768.5,-1496 655.5,-1496 655.5,-1413 768.5,-1413 768.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 24.5</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.1</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 77</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 76]</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 32&#45;&gt;33 -->\n<g id=\"edge33\" class=\"edge\">\n<title>32&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"black\" d=\"M945.71,-1548.82C897.17,-1529.44 828.54,-1502.04 778.21,-1481.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"779.3,-1478.61 768.72,-1478.15 776.7,-1485.11 779.3,-1478.61\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<polygon fill=\"#4ba6e7\" stroke=\"black\" points=\"1064,-1496 946,-1496 946,-1413 1064,-1413 1064,-1496\"/>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 26.5</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.407</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 209</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 192]</text>\n<text text-anchor=\"middle\" x=\"1005\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 32&#45;&gt;38 -->\n<g id=\"edge38\" class=\"edge\">\n<title>32&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1005,-1531.91C1005,-1523.65 1005,-1514.86 1005,-1506.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1008.5,-1506.02 1005,-1496.02 1001.5,-1506.02 1008.5,-1506.02\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<polygon fill=\"#45a3e7\" stroke=\"black\" points=\"638.5,-1377 525.5,-1377 525.5,-1294 638.5,-1294 638.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 23.5</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.31</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 17]</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 33&#45;&gt;34 -->\n<g id=\"edge34\" class=\"edge\">\n<title>33&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"black\" d=\"M666.9,-1412.91C656.51,-1403.56 645.38,-1393.54 634.7,-1383.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"636.8,-1381.11 627.02,-1377.02 632.11,-1386.31 636.8,-1381.11\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"763,-1369.5 661,-1369.5 661,-1301.5 763,-1301.5 763,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 59</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 59]</text>\n<text text-anchor=\"middle\" x=\"712\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 33&#45;&gt;37 -->\n<g id=\"edge37\" class=\"edge\">\n<title>33&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"black\" d=\"M712,-1412.91C712,-1402.2 712,-1390.62 712,-1379.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"715.5,-1379.67 712,-1369.67 708.5,-1379.67 715.5,-1379.67\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"516,-1250.5 414,-1250.5 414,-1182.5 516,-1182.5 516,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"465\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"465\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"465\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 17]</text>\n<text text-anchor=\"middle\" x=\"465\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 34&#45;&gt;35 -->\n<g id=\"edge35\" class=\"edge\">\n<title>34&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"black\" d=\"M541.41,-1293.91C529.71,-1282.21 516.96,-1269.46 505.28,-1257.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"507.71,-1255.26 498.17,-1250.67 502.76,-1260.21 507.71,-1255.26\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"630,-1250.5 534,-1250.5 534,-1182.5 630,-1182.5 630,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"582\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 34&#45;&gt;36 -->\n<g id=\"edge36\" class=\"edge\">\n<title>34&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"black\" d=\"M582,-1293.91C582,-1283.2 582,-1271.62 582,-1260.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"585.5,-1260.67 582,-1250.67 578.5,-1260.67 585.5,-1260.67\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<polygon fill=\"#58ace9\" stroke=\"black\" points=\"942.5,-1377 789.5,-1377 789.5,-1294 942.5,-1294 942.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ExerciseAngina &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.568</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 112</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 97]</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 38&#45;&gt;39 -->\n<g id=\"edge39\" class=\"edge\">\n<title>38&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"black\" d=\"M956.77,-1412.91C945.56,-1403.47 933.53,-1393.34 922.01,-1383.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"924.04,-1380.78 914.14,-1377.02 919.54,-1386.14 924.04,-1380.78\"/>\n</g>\n<!-- 78 -->\n<g id=\"node79\" class=\"node\">\n<title>78</title>\n<polygon fill=\"#3d9fe6\" stroke=\"black\" points=\"1133.5,-1377 1022.5,-1377 1022.5,-1294 1133.5,-1294 1133.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 46.5</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.145</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 97</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 95]</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 38&#45;&gt;78 -->\n<g id=\"edge78\" class=\"edge\">\n<title>38&#45;&gt;78</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1030.33,-1412.91C1035.82,-1404.1 1041.69,-1394.7 1047.36,-1385.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1050.39,-1387.36 1052.72,-1377.02 1044.45,-1383.65 1050.39,-1387.36\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<polygon fill=\"#94caf1\" stroke=\"black\" points=\"770,-1258 648,-1258 648,-1175 770,-1175 770,-1258\"/>\n<text text-anchor=\"middle\" x=\"709\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FastingBS &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"709\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.9</text>\n<text text-anchor=\"middle\" x=\"709\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"middle\" x=\"709\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 13]</text>\n<text text-anchor=\"middle\" x=\"709\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 39&#45;&gt;40 -->\n<g id=\"edge40\" class=\"edge\">\n<title>39&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"black\" d=\"M811.53,-1293.91C798.62,-1284.29 784.75,-1273.95 771.52,-1264.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"773.48,-1261.19 763.37,-1258.02 769.3,-1266.8 773.48,-1261.19\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<polygon fill=\"#4ea8e8\" stroke=\"black\" points=\"925,-1258 807,-1258 807,-1175 925,-1175 925,-1258\"/>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 13.5</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.459</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 93</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 84]</text>\n<text text-anchor=\"middle\" x=\"866\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 39&#45;&gt;49 -->\n<g id=\"edge49\" class=\"edge\">\n<title>39&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"black\" d=\"M866,-1293.91C866,-1285.65 866,-1276.86 866,-1268.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"869.5,-1268.02 866,-1258.02 862.5,-1268.02 869.5,-1268.02\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<polygon fill=\"#f5cdb0\" stroke=\"black\" points=\"486.5,-1139 373.5,-1139 373.5,-1056 486.5,-1056 486.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"430\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 35.5</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.954</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 3]</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 40&#45;&gt;41 -->\n<g id=\"edge41\" class=\"edge\">\n<title>40&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"black\" d=\"M647.94,-1179.14C644.95,-1177.68 641.96,-1176.3 639,-1175 589.55,-1153.35 573.6,-1157.8 523,-1139 514.18,-1135.72 504.99,-1132.05 495.97,-1128.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"497.22,-1125.02 486.65,-1124.35 494.5,-1131.46 497.22,-1125.02\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<polygon fill=\"#4da7e8\" stroke=\"black\" points=\"675.5,-1139 532.5,-1139 532.5,-1056 675.5,-1056 675.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"604\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 178.5</text>\n<text text-anchor=\"middle\" x=\"604\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.439</text>\n<text text-anchor=\"middle\" x=\"604\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"604\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 10]</text>\n<text text-anchor=\"middle\" x=\"604\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 40&#45;&gt;46 -->\n<g id=\"edge46\" class=\"edge\">\n<title>40&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"black\" d=\"M672.57,-1174.91C664.35,-1165.74 655.54,-1155.93 647.07,-1146.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"649.65,-1144.13 640.36,-1139.02 644.44,-1148.8 649.65,-1144.13\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"346,-1012.5 250,-1012.5 250,-944.5 346,-944.5 346,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"298\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"298\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"298\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"298\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 41&#45;&gt;42 -->\n<g id=\"edge42\" class=\"edge\">\n<title>41&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"black\" d=\"M384.2,-1055.91C370.88,-1044.1 356.35,-1031.22 343.07,-1019.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"345.22,-1016.68 335.42,-1012.67 340.58,-1021.92 345.22,-1016.68\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<polygon fill=\"#ea9a61\" stroke=\"black\" points=\"495.5,-1020 364.5,-1020 364.5,-937 495.5,-937 495.5,-1020\"/>\n<text text-anchor=\"middle\" x=\"430\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 14.5</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.65</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n<text text-anchor=\"middle\" x=\"430\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 41&#45;&gt;43 -->\n<g id=\"edge43\" class=\"edge\">\n<title>41&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"black\" d=\"M430,-1055.91C430,-1047.65 430,-1038.86 430,-1030.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"433.5,-1030.02 430,-1020.02 426.5,-1030.02 433.5,-1030.02\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"463,-893.5 367,-893.5 367,-825.5 463,-825.5 463,-893.5\"/>\n<text text-anchor=\"middle\" x=\"415\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"415\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"415\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"415\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 43&#45;&gt;44 -->\n<g id=\"edge44\" class=\"edge\">\n<title>43&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"black\" d=\"M424.8,-936.91C423.42,-926.2 421.94,-914.62 420.55,-903.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"424,-903.14 419.25,-893.67 417.05,-904.03 424,-903.14\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"577,-893.5 481,-893.5 481,-825.5 577,-825.5 577,-893.5\"/>\n<text text-anchor=\"middle\" x=\"529\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"529\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"529\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n<text text-anchor=\"middle\" x=\"529\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 43&#45;&gt;45 -->\n<g id=\"edge45\" class=\"edge\">\n<title>43&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"black\" d=\"M464.35,-936.91C474.06,-925.43 484.63,-912.94 494.36,-901.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"497.15,-903.56 500.94,-893.67 491.8,-899.04 497.15,-903.56\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"616,-1012.5 514,-1012.5 514,-944.5 616,-944.5 616,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"565\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"565\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"middle\" x=\"565\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 10]</text>\n<text text-anchor=\"middle\" x=\"565\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 46&#45;&gt;47 -->\n<g id=\"edge47\" class=\"edge\">\n<title>46&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"black\" d=\"M590.47,-1055.91C586.86,-1045.09 582.96,-1033.38 579.31,-1022.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"582.54,-1021.05 576.06,-1012.67 575.9,-1023.26 582.54,-1021.05\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"730,-1012.5 634,-1012.5 634,-944.5 730,-944.5 730,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"682\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"682\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"682\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"682\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 46&#45;&gt;48 -->\n<g id=\"edge48\" class=\"edge\">\n<title>46&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"black\" d=\"M631.06,-1055.91C638.57,-1044.65 646.72,-1032.42 654.26,-1021.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"657.25,-1022.93 659.89,-1012.67 651.43,-1019.05 657.25,-1022.93\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"790,-1131.5 694,-1131.5 694,-1063.5 790,-1063.5 790,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"742\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"742\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"742\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"742\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 49&#45;&gt;50 -->\n<g id=\"edge50\" class=\"edge\">\n<title>49&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"black\" d=\"M822.98,-1174.91C810.58,-1163.21 797.07,-1150.46 784.69,-1138.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"786.83,-1135.98 777.15,-1131.67 782.02,-1141.08 786.83,-1135.98\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<polygon fill=\"#4ca6e7\" stroke=\"black\" points=\"939.5,-1139 808.5,-1139 808.5,-1056 939.5,-1056 939.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"874\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 14.5</text>\n<text text-anchor=\"middle\" x=\"874\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.426</text>\n<text text-anchor=\"middle\" x=\"874\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 92</text>\n<text text-anchor=\"middle\" x=\"874\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 84]</text>\n<text text-anchor=\"middle\" x=\"874\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 49&#45;&gt;51 -->\n<g id=\"edge51\" class=\"edge\">\n<title>49&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"black\" d=\"M868.78,-1174.91C869.35,-1166.56 869.95,-1157.67 870.55,-1149.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"874.04,-1149.24 871.23,-1139.02 867.06,-1148.76 874.04,-1149.24\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"883.5,-1020 748.5,-1020 748.5,-937 883.5,-937 883.5,-1020\"/>\n<text text-anchor=\"middle\" x=\"816\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 29.5</text>\n<text text-anchor=\"middle\" x=\"816\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"816\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"816\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 6]</text>\n<text text-anchor=\"middle\" x=\"816\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 51&#45;&gt;52 -->\n<g id=\"edge52\" class=\"edge\">\n<title>51&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"black\" d=\"M853.88,-1055.91C849.6,-1047.29 845.04,-1038.09 840.63,-1029.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"843.66,-1027.43 836.09,-1020.02 837.39,-1030.53 843.66,-1027.43\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<polygon fill=\"#46a3e7\" stroke=\"black\" points=\"1024,-1020 902,-1020 902,-937 1024,-937 1024,-1020\"/>\n<text text-anchor=\"middle\" x=\"963\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FastingBS &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"963\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.328</text>\n<text text-anchor=\"middle\" x=\"963\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 83</text>\n<text text-anchor=\"middle\" x=\"963\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 78]</text>\n<text text-anchor=\"middle\" x=\"963\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 51&#45;&gt;57 -->\n<g id=\"edge57\" class=\"edge\">\n<title>51&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"black\" d=\"M904.88,-1055.91C911.71,-1046.92 919.02,-1037.32 926.07,-1028.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"928.91,-1030.1 932.18,-1020.02 923.34,-1025.86 928.91,-1030.1\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"742,-893.5 646,-893.5 646,-825.5 742,-825.5 742,-893.5\"/>\n<text text-anchor=\"middle\" x=\"694\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"694\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"694\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n<text text-anchor=\"middle\" x=\"694\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 52&#45;&gt;53 -->\n<g id=\"edge53\" class=\"edge\">\n<title>52&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"black\" d=\"M773.67,-936.91C761.48,-925.21 748.18,-912.46 736,-900.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"738.22,-898.06 728.58,-893.67 733.38,-903.11 738.22,-898.06\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<polygon fill=\"#eeab7b\" stroke=\"black\" points=\"879.5,-901 760.5,-901 760.5,-818 879.5,-818 879.5,-901\"/>\n<text text-anchor=\"middle\" x=\"820\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ST_Slope &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"820\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.811</text>\n<text text-anchor=\"middle\" x=\"820\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"820\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n<text text-anchor=\"middle\" x=\"820\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 52&#45;&gt;54 -->\n<g id=\"edge54\" class=\"edge\">\n<title>52&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"black\" d=\"M817.39,-936.91C817.67,-928.56 817.98,-919.67 818.27,-911.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"821.77,-911.13 818.61,-901.02 814.77,-910.9 821.77,-911.13\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"758,-774.5 662,-774.5 662,-706.5 758,-706.5 758,-774.5\"/>\n<text text-anchor=\"middle\" x=\"710\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"710\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"710\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"710\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 54&#45;&gt;55 -->\n<g id=\"edge55\" class=\"edge\">\n<title>54&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"black\" d=\"M781.84,-817.91C770.94,-806.32 759.07,-793.7 748.18,-782.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"750.58,-779.56 741.18,-774.67 745.48,-784.35 750.58,-779.56\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"872,-774.5 776,-774.5 776,-706.5 872,-706.5 872,-774.5\"/>\n<text text-anchor=\"middle\" x=\"824\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"824\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"824\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"824\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 54&#45;&gt;56 -->\n<g id=\"edge56\" class=\"edge\">\n<title>54&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"black\" d=\"M821.39,-817.91C821.75,-807.2 822.15,-795.62 822.52,-784.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"826.02,-784.78 822.87,-774.67 819.03,-784.54 826.02,-784.78\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<polygon fill=\"#4ca6e7\" stroke=\"black\" points=\"1015.5,-901 904.5,-901 904.5,-818 1015.5,-818 1015.5,-901\"/>\n<text text-anchor=\"middle\" x=\"960\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 32.5</text>\n<text text-anchor=\"middle\" x=\"960\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.424</text>\n<text text-anchor=\"middle\" x=\"960\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 58</text>\n<text text-anchor=\"middle\" x=\"960\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 53]</text>\n<text text-anchor=\"middle\" x=\"960\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 57&#45;&gt;58 -->\n<g id=\"edge58\" class=\"edge\">\n<title>57&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"black\" d=\"M961.96,-936.91C961.75,-928.56 961.52,-919.67 961.3,-911.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"964.79,-910.93 961.04,-901.02 957.8,-911.11 964.79,-910.93\"/>\n</g>\n<!-- 77 -->\n<g id=\"node78\" class=\"node\">\n<title>77</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1136,-893.5 1034,-893.5 1034,-825.5 1136,-825.5 1136,-893.5\"/>\n<text text-anchor=\"middle\" x=\"1085\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1085\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"1085\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 25]</text>\n<text text-anchor=\"middle\" x=\"1085\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 57&#45;&gt;77 -->\n<g id=\"edge77\" class=\"edge\">\n<title>57&#45;&gt;77</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1005.33,-936.91C1017.52,-925.21 1030.82,-912.46 1043,-900.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1045.62,-903.11 1050.42,-893.67 1040.78,-898.06 1045.62,-903.11\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<polygon fill=\"#52aae8\" stroke=\"black\" points=\"1003.5,-782 892.5,-782 892.5,-699 1003.5,-699 1003.5,-782\"/>\n<text text-anchor=\"middle\" x=\"948\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 26.5</text>\n<text text-anchor=\"middle\" x=\"948\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.511</text>\n<text text-anchor=\"middle\" x=\"948\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 44</text>\n<text text-anchor=\"middle\" x=\"948\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 39]</text>\n<text text-anchor=\"middle\" x=\"948\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 58&#45;&gt;59 -->\n<g id=\"edge59\" class=\"edge\">\n<title>58&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"black\" d=\"M955.84,-817.91C954.98,-809.56 954.07,-800.67 953.18,-792.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"956.66,-791.61 952.16,-782.02 949.69,-792.33 956.66,-791.61\"/>\n</g>\n<!-- 76 -->\n<g id=\"node77\" class=\"node\">\n<title>76</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1124,-774.5 1022,-774.5 1022,-706.5 1124,-706.5 1124,-774.5\"/>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 14]</text>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 58&#45;&gt;76 -->\n<g id=\"edge76\" class=\"edge\">\n<title>58&#45;&gt;76</title>\n<path fill=\"none\" stroke=\"black\" d=\"M999.2,-817.91C1010.39,-806.32 1022.59,-793.7 1033.78,-782.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1036.54,-784.29 1040.97,-774.67 1031.5,-779.43 1036.54,-784.29\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<polygon fill=\"#42a1e6\" stroke=\"black\" points=\"860,-663 756,-663 756,-580 860,-580 860,-663\"/>\n<text text-anchor=\"middle\" x=\"808\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 14.0</text>\n<text text-anchor=\"middle\" x=\"808\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.25</text>\n<text text-anchor=\"middle\" x=\"808\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"808\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 23]</text>\n<text text-anchor=\"middle\" x=\"808\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 59&#45;&gt;60 -->\n<g id=\"edge60\" class=\"edge\">\n<title>59&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"black\" d=\"M899.43,-698.91C888.13,-689.47 876.02,-679.34 864.42,-669.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"866.4,-666.75 856.49,-663.02 861.92,-672.12 866.4,-666.75\"/>\n</g>\n<!-- 65 -->\n<g id=\"node66\" class=\"node\">\n<title>65</title>\n<polygon fill=\"#6ab6ec\" stroke=\"black\" points=\"1021.5,-663 878.5,-663 878.5,-580 1021.5,-580 1021.5,-663\"/>\n<text text-anchor=\"middle\" x=\"950\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 155.5</text>\n<text text-anchor=\"middle\" x=\"950\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.722</text>\n<text text-anchor=\"middle\" x=\"950\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"middle\" x=\"950\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 16]</text>\n<text text-anchor=\"middle\" x=\"950\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 59&#45;&gt;65 -->\n<g id=\"edge65\" class=\"edge\">\n<title>59&#45;&gt;65</title>\n<path fill=\"none\" stroke=\"black\" d=\"M948.69,-698.91C948.84,-690.56 948.99,-681.67 949.14,-673.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"952.64,-673.08 949.31,-663.02 945.64,-672.96 952.64,-673.08\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"739.5,-544 608.5,-544 608.5,-461 739.5,-461 739.5,-544\"/>\n<text text-anchor=\"middle\" x=\"674\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 45.0</text>\n<text text-anchor=\"middle\" x=\"674\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"674\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"674\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"middle\" x=\"674\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 60&#45;&gt;61 -->\n<g id=\"edge61\" class=\"edge\">\n<title>60&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"black\" d=\"M761.51,-579.91C750.7,-570.47 739.1,-560.34 728,-550.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"730.24,-547.96 720.41,-544.02 725.64,-553.23 730.24,-547.96\"/>\n</g>\n<!-- 64 -->\n<g id=\"node65\" class=\"node\">\n<title>64</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"860,-536.5 758,-536.5 758,-468.5 860,-468.5 860,-536.5\"/>\n<text text-anchor=\"middle\" x=\"809\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"809\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"middle\" x=\"809\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 21]</text>\n<text text-anchor=\"middle\" x=\"809\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 60&#45;&gt;64 -->\n<g id=\"edge64\" class=\"edge\">\n<title>60&#45;&gt;64</title>\n<path fill=\"none\" stroke=\"black\" d=\"M808.35,-579.91C808.44,-569.2 808.54,-557.62 808.63,-546.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"812.13,-546.7 808.72,-536.67 805.13,-546.64 812.13,-546.7\"/>\n</g>\n<!-- 62 -->\n<g id=\"node63\" class=\"node\">\n<title>62</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"644,-417.5 548,-417.5 548,-349.5 644,-349.5 644,-417.5\"/>\n<text text-anchor=\"middle\" x=\"596\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"596\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"596\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"596\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 61&#45;&gt;62 -->\n<g id=\"edge62\" class=\"edge\">\n<title>61&#45;&gt;62</title>\n<path fill=\"none\" stroke=\"black\" d=\"M646.94,-460.91C639.43,-449.65 631.28,-437.42 623.74,-426.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"626.57,-424.05 618.11,-417.67 620.75,-427.93 626.57,-424.05\"/>\n</g>\n<!-- 63 -->\n<g id=\"node64\" class=\"node\">\n<title>63</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"758,-417.5 662,-417.5 662,-349.5 758,-349.5 758,-417.5\"/>\n<text text-anchor=\"middle\" x=\"710\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"710\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"710\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"710\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 61&#45;&gt;63 -->\n<g id=\"edge63\" class=\"edge\">\n<title>61&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"black\" d=\"M686.49,-460.91C689.82,-450.09 693.42,-438.38 696.79,-427.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"700.2,-428.25 699.79,-417.67 693.51,-426.2 700.2,-428.25\"/>\n</g>\n<!-- 66 -->\n<g id=\"node67\" class=\"node\">\n<title>66</title>\n<polygon fill=\"#5eafea\" stroke=\"black\" points=\"999.5,-544 886.5,-544 886.5,-461 999.5,-461 999.5,-544\"/>\n<text text-anchor=\"middle\" x=\"943\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 24.5</text>\n<text text-anchor=\"middle\" x=\"943\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.629</text>\n<text text-anchor=\"middle\" x=\"943\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"middle\" x=\"943\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 16]</text>\n<text text-anchor=\"middle\" x=\"943\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 65&#45;&gt;66 -->\n<g id=\"edge66\" class=\"edge\">\n<title>65&#45;&gt;66</title>\n<path fill=\"none\" stroke=\"black\" d=\"M947.57,-579.91C947.07,-571.56 946.54,-562.67 946.02,-554.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"949.52,-553.79 945.42,-544.02 942.53,-554.21 949.52,-553.79\"/>\n</g>\n<!-- 75 -->\n<g id=\"node76\" class=\"node\">\n<title>75</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1114,-536.5 1018,-536.5 1018,-468.5 1114,-468.5 1114,-536.5\"/>\n<text text-anchor=\"middle\" x=\"1066\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1066\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1066\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"1066\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 65&#45;&gt;75 -->\n<g id=\"edge75\" class=\"edge\">\n<title>65&#45;&gt;75</title>\n<path fill=\"none\" stroke=\"black\" d=\"M990.25,-579.91C1001.84,-568.21 1014.49,-555.46 1026.06,-543.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1028.56,-546.23 1033.12,-536.67 1023.59,-541.3 1028.56,-546.23\"/>\n</g>\n<!-- 67 -->\n<g id=\"node68\" class=\"node\">\n<title>67</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"935,-417.5 839,-417.5 839,-349.5 935,-349.5 935,-417.5\"/>\n<text text-anchor=\"middle\" x=\"887\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"887\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"887\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"887\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 66&#45;&gt;67 -->\n<g id=\"edge67\" class=\"edge\">\n<title>66&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"black\" d=\"M923.57,-460.91C918.29,-449.87 912.56,-437.9 907.23,-426.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"910.35,-425.18 902.87,-417.67 904.04,-428.2 910.35,-425.18\"/>\n</g>\n<!-- 68 -->\n<g id=\"node69\" class=\"node\">\n<title>68</title>\n<polygon fill=\"#52a9e8\" stroke=\"black\" points=\"1084.5,-425 953.5,-425 953.5,-342 1084.5,-342 1084.5,-425\"/>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 58.5</text>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.503</text>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 16]</text>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 66&#45;&gt;68 -->\n<g id=\"edge68\" class=\"edge\">\n<title>66&#45;&gt;68</title>\n<path fill=\"none\" stroke=\"black\" d=\"M969.37,-460.91C975.09,-452.1 981.19,-442.7 987.1,-433.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"990.17,-435.31 992.68,-425.02 984.3,-431.5 990.17,-435.31\"/>\n</g>\n<!-- 69 -->\n<g id=\"node70\" class=\"node\">\n<title>69</title>\n<polygon fill=\"#45a3e7\" stroke=\"black\" points=\"981,-306 863,-306 863,-223 981,-223 981,-306\"/>\n<text text-anchor=\"middle\" x=\"922\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 15.5</text>\n<text text-anchor=\"middle\" x=\"922\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.323</text>\n<text text-anchor=\"middle\" x=\"922\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"922\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 16]</text>\n<text text-anchor=\"middle\" x=\"922\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 68&#45;&gt;69 -->\n<g id=\"edge69\" class=\"edge\">\n<title>68&#45;&gt;69</title>\n<path fill=\"none\" stroke=\"black\" d=\"M985.35,-341.91C977.82,-332.83 969.77,-323.12 962.02,-313.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"964.67,-311.49 955.59,-306.02 959.28,-315.95 964.67,-311.49\"/>\n</g>\n<!-- 74 -->\n<g id=\"node75\" class=\"node\">\n<title>74</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1095,-298.5 999,-298.5 999,-230.5 1095,-230.5 1095,-298.5\"/>\n<text text-anchor=\"middle\" x=\"1047\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1047\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1047\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"1047\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 68&#45;&gt;74 -->\n<g id=\"edge74\" class=\"edge\">\n<title>68&#45;&gt;74</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1028.71,-341.91C1031.3,-331.09 1034.11,-319.38 1036.72,-308.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1040.14,-309.21 1039.06,-298.67 1033.33,-307.58 1040.14,-309.21\"/>\n</g>\n<!-- 70 -->\n<g id=\"node71\" class=\"node\">\n<title>70</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"866.5,-187 731.5,-187 731.5,-104 866.5,-104 866.5,-187\"/>\n<text text-anchor=\"middle\" x=\"799\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 43.5</text>\n<text text-anchor=\"middle\" x=\"799\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"799\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"799\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"middle\" x=\"799\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 69&#45;&gt;70 -->\n<g id=\"edge70\" class=\"edge\">\n<title>69&#45;&gt;70</title>\n<path fill=\"none\" stroke=\"black\" d=\"M879.33,-222.91C869.5,-213.56 858.96,-203.54 848.86,-193.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"851.26,-191.38 841.6,-187.02 846.43,-196.45 851.26,-191.38\"/>\n</g>\n<!-- 73 -->\n<g id=\"node74\" class=\"node\">\n<title>73</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"987,-179.5 885,-179.5 885,-111.5 987,-111.5 987,-179.5\"/>\n<text text-anchor=\"middle\" x=\"936\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"936\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"middle\" x=\"936\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 15]</text>\n<text text-anchor=\"middle\" x=\"936\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 69&#45;&gt;73 -->\n<g id=\"edge73\" class=\"edge\">\n<title>69&#45;&gt;73</title>\n<path fill=\"none\" stroke=\"black\" d=\"M926.86,-222.91C928.14,-212.2 929.52,-200.62 930.82,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"934.32,-190.01 932.03,-179.67 927.37,-189.18 934.32,-190.01\"/>\n</g>\n<!-- 71 -->\n<g id=\"node72\" class=\"node\">\n<title>71</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"790,-68 694,-68 694,0 790,0 790,-68\"/>\n<text text-anchor=\"middle\" x=\"742\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"742\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"742\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"742\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 70&#45;&gt;71 -->\n<g id=\"edge71\" class=\"edge\">\n<title>70&#45;&gt;71</title>\n<path fill=\"none\" stroke=\"black\" d=\"M777.78,-103.73C773.26,-95.06 768.49,-85.9 763.96,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"767.06,-75.55 759.33,-68.3 760.85,-78.79 767.06,-75.55\"/>\n</g>\n<!-- 72 -->\n<g id=\"node73\" class=\"node\">\n<title>72</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"904,-68 808,-68 808,0 904,0 904,-68\"/>\n<text text-anchor=\"middle\" x=\"856\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"856\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"856\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"856\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 70&#45;&gt;72 -->\n<g id=\"edge72\" class=\"edge\">\n<title>70&#45;&gt;72</title>\n<path fill=\"none\" stroke=\"black\" d=\"M820.22,-103.73C824.74,-95.06 829.51,-85.9 834.04,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"837.15,-78.79 838.67,-68.3 830.94,-75.55 837.15,-78.79\"/>\n</g>\n<!-- 79 -->\n<g id=\"node80\" class=\"node\">\n<title>79</title>\n<polygon fill=\"#3b9ee5\" stroke=\"black\" points=\"1143.5,-1258 1012.5,-1258 1012.5,-1175 1143.5,-1175 1143.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 25.5</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.085</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 94</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 93]</text>\n<text text-anchor=\"middle\" x=\"1078\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 78&#45;&gt;79 -->\n<g id=\"edge79\" class=\"edge\">\n<title>78&#45;&gt;79</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1078,-1293.91C1078,-1285.65 1078,-1276.86 1078,-1268.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1081.5,-1268.02 1078,-1258.02 1074.5,-1268.02 1081.5,-1268.02\"/>\n</g>\n<!-- 86 -->\n<g id=\"node87\" class=\"node\">\n<title>86</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"1334,-1258 1216,-1258 1216,-1175 1334,-1175 1334,-1258\"/>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 34.5</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 78&#45;&gt;86 -->\n<g id=\"edge86\" class=\"edge\">\n<title>78&#45;&gt;86</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1133.66,-1301.44C1156.46,-1287.9 1183.07,-1272.1 1207,-1257.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1208.88,-1260.84 1215.69,-1252.73 1205.3,-1254.82 1208.88,-1260.84\"/>\n</g>\n<!-- 80 -->\n<g id=\"node81\" class=\"node\">\n<title>80</title>\n<polygon fill=\"#45a3e7\" stroke=\"black\" points=\"1088.5,-1139 957.5,-1139 957.5,-1056 1088.5,-1056 1088.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"1023\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 24.0</text>\n<text text-anchor=\"middle\" x=\"1023\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.323</text>\n<text text-anchor=\"middle\" x=\"1023\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"1023\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 16]</text>\n<text text-anchor=\"middle\" x=\"1023\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 79&#45;&gt;80 -->\n<g id=\"edge80\" class=\"edge\">\n<title>79&#45;&gt;80</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1058.92,-1174.91C1054.87,-1166.29 1050.54,-1157.09 1046.35,-1148.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1049.47,-1146.58 1042.05,-1139.02 1043.14,-1149.56 1049.47,-1146.58\"/>\n</g>\n<!-- 85 -->\n<g id=\"node86\" class=\"node\">\n<title>85</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1209,-1131.5 1107,-1131.5 1107,-1063.5 1209,-1063.5 1209,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"1158\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1158\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 77</text>\n<text text-anchor=\"middle\" x=\"1158\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 77]</text>\n<text text-anchor=\"middle\" x=\"1158\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 79&#45;&gt;85 -->\n<g id=\"edge85\" class=\"edge\">\n<title>79&#45;&gt;85</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1105.76,-1174.91C1113.45,-1163.65 1121.82,-1151.42 1129.55,-1140.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1132.57,-1141.9 1135.32,-1131.67 1126.79,-1137.95 1132.57,-1141.9\"/>\n</g>\n<!-- 81 -->\n<g id=\"node82\" class=\"node\">\n<title>81</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1144,-1012.5 1042,-1012.5 1042,-944.5 1144,-944.5 1144,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"1093\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1093\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"middle\" x=\"1093\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 15]</text>\n<text text-anchor=\"middle\" x=\"1093\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 80&#45;&gt;81 -->\n<g id=\"edge81\" class=\"edge\">\n<title>80&#45;&gt;81</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1047.29,-1055.91C1053.95,-1044.76 1061.2,-1032.66 1067.91,-1021.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1071.03,-1023.05 1073.16,-1012.67 1065.02,-1019.45 1071.03,-1023.05\"/>\n</g>\n<!-- 82 -->\n<g id=\"node83\" class=\"node\">\n<title>82</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1280,-1020 1162,-1020 1162,-937 1280,-937 1280,-1020\"/>\n<text text-anchor=\"middle\" x=\"1221\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 34.5</text>\n<text text-anchor=\"middle\" x=\"1221\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"1221\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1221\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"middle\" x=\"1221\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 80&#45;&gt;82 -->\n<g id=\"edge82\" class=\"edge\">\n<title>80&#45;&gt;82</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1088.51,-1058.04C1109.16,-1045.9 1132.04,-1032.41 1153,-1020 1153.09,-1019.95 1153.18,-1019.89 1153.27,-1019.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1154.86,-1022.97 1161.67,-1014.86 1151.29,-1016.95 1154.86,-1022.97\"/>\n</g>\n<!-- 83 -->\n<g id=\"node84\" class=\"node\">\n<title>83</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1252,-893.5 1156,-893.5 1156,-825.5 1252,-825.5 1252,-893.5\"/>\n<text text-anchor=\"middle\" x=\"1204\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1204\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1204\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"1204\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 82&#45;&gt;83 -->\n<g id=\"edge83\" class=\"edge\">\n<title>82&#45;&gt;83</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1215.1,-936.91C1213.55,-926.2 1211.86,-914.62 1210.29,-903.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1213.72,-903.06 1208.82,-893.67 1206.79,-904.07 1213.72,-903.06\"/>\n</g>\n<!-- 84 -->\n<g id=\"node85\" class=\"node\">\n<title>84</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1366,-893.5 1270,-893.5 1270,-825.5 1366,-825.5 1366,-893.5\"/>\n<text text-anchor=\"middle\" x=\"1318\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1318\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1318\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"1318\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 82&#45;&gt;84 -->\n<g id=\"edge84\" class=\"edge\">\n<title>82&#45;&gt;84</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1254.65,-936.91C1264.17,-925.43 1274.53,-912.94 1284.06,-901.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1286.81,-903.6 1290.5,-893.67 1281.43,-899.13 1286.81,-903.6\"/>\n</g>\n<!-- 87 -->\n<g id=\"node88\" class=\"node\">\n<title>87</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1323,-1131.5 1227,-1131.5 1227,-1063.5 1323,-1063.5 1323,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"1275\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 86&#45;&gt;87 -->\n<g id=\"edge87\" class=\"edge\">\n<title>86&#45;&gt;87</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1275,-1174.91C1275,-1164.2 1275,-1152.62 1275,-1141.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1278.5,-1141.67 1275,-1131.67 1271.5,-1141.67 1278.5,-1141.67\"/>\n</g>\n<!-- 88 -->\n<g id=\"node89\" class=\"node\">\n<title>88</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1437,-1131.5 1341,-1131.5 1341,-1063.5 1437,-1063.5 1437,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"1389\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1389\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1389\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"1389\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 86&#45;&gt;88 -->\n<g id=\"edge88\" class=\"edge\">\n<title>86&#45;&gt;88</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1314.55,-1174.91C1325.84,-1163.32 1338.14,-1150.7 1349.43,-1139.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1352.21,-1141.27 1356.68,-1131.67 1347.2,-1136.39 1352.21,-1141.27\"/>\n</g>\n<!-- 90 -->\n<g id=\"node91\" class=\"node\">\n<title>90</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1376,-1488.5 1274,-1488.5 1274,-1420.5 1376,-1420.5 1376,-1488.5\"/>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1473.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1458.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1443.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 19]</text>\n<text text-anchor=\"middle\" x=\"1325\" y=\"-1428.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 89&#45;&gt;90 -->\n<g id=\"edge90\" class=\"edge\">\n<title>89&#45;&gt;90</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1325,-1531.91C1325,-1521.2 1325,-1509.62 1325,-1498.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1328.5,-1498.67 1325,-1488.67 1321.5,-1498.67 1328.5,-1498.67\"/>\n</g>\n<!-- 91 -->\n<g id=\"node92\" class=\"node\">\n<title>91</title>\n<polygon fill=\"#9acdf2\" stroke=\"black\" points=\"1619,-1496 1497,-1496 1497,-1413 1619,-1413 1619,-1496\"/>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FastingBS &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.913</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 41]</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 89&#45;&gt;91 -->\n<g id=\"edge91\" class=\"edge\">\n<title>89&#45;&gt;91</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1384.1,-1542.82C1415.65,-1526.98 1454.68,-1507.38 1487.77,-1490.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1489.57,-1493.78 1496.93,-1486.16 1486.43,-1487.52 1489.57,-1493.78\"/>\n</g>\n<!-- 92 -->\n<g id=\"node93\" class=\"node\">\n<title>92</title>\n<polygon fill=\"#d9ecfa\" stroke=\"black\" points=\"1625.5,-1377 1490.5,-1377 1490.5,-1294 1625.5,-1294 1625.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingECG &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.992</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 21]</text>\n<text text-anchor=\"middle\" x=\"1558\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 91&#45;&gt;92 -->\n<g id=\"edge92\" class=\"edge\">\n<title>91&#45;&gt;92</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1558,-1412.91C1558,-1404.65 1558,-1395.86 1558,-1387.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1561.5,-1387.02 1558,-1377.02 1554.5,-1387.02 1561.5,-1387.02\"/>\n</g>\n<!-- 115 -->\n<g id=\"node116\" class=\"node\">\n<title>115</title>\n<polygon fill=\"#57ace9\" stroke=\"black\" points=\"1841.5,-1377 1690.5,-1377 1690.5,-1294 1841.5,-1294 1841.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ChestPainType &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.559</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 20]</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 91&#45;&gt;115 -->\n<g id=\"edge115\" class=\"edge\">\n<title>91&#45;&gt;115</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1619,-1419.19C1639.65,-1407.57 1663.05,-1394.41 1685,-1382.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1686.98,-1384.96 1693.98,-1377.01 1683.55,-1378.86 1686.98,-1384.96\"/>\n</g>\n<!-- 93 -->\n<g id=\"node94\" class=\"node\">\n<title>93</title>\n<polygon fill=\"#fdf8f3\" stroke=\"black\" points=\"1582.5,-1258 1439.5,-1258 1439.5,-1175 1582.5,-1175 1582.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 154.5</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 16]</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 92&#45;&gt;93 -->\n<g id=\"edge93\" class=\"edge\">\n<title>92&#45;&gt;93</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1541.69,-1293.91C1538.27,-1285.38 1534.61,-1276.28 1531.07,-1267.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1534.25,-1266 1527.28,-1258.02 1527.76,-1268.6 1534.25,-1266\"/>\n</g>\n<!-- 114 -->\n<g id=\"node115\" class=\"node\">\n<title>114</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1697,-1250.5 1601,-1250.5 1601,-1182.5 1697,-1182.5 1697,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"1649\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1649\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1649\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n<text text-anchor=\"middle\" x=\"1649\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 92&#45;&gt;114 -->\n<g id=\"edge114\" class=\"edge\">\n<title>92&#45;&gt;114</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1589.57,-1293.91C1598.41,-1282.54 1608.03,-1270.18 1616.9,-1258.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1619.83,-1260.71 1623.2,-1250.67 1614.3,-1256.41 1619.83,-1260.71\"/>\n</g>\n<!-- 94 -->\n<g id=\"node95\" class=\"node\">\n<title>94</title>\n<polygon fill=\"#e6f3fc\" stroke=\"black\" points=\"1566.5,-1139 1455.5,-1139 1455.5,-1056 1566.5,-1056 1566.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 8.5</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.997</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 16]</text>\n<text text-anchor=\"middle\" x=\"1511\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 93&#45;&gt;94 -->\n<g id=\"edge94\" class=\"edge\">\n<title>93&#45;&gt;94</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1511,-1174.91C1511,-1166.65 1511,-1157.86 1511,-1149.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1514.5,-1149.02 1511,-1139.02 1507.5,-1149.02 1514.5,-1149.02\"/>\n</g>\n<!-- 113 -->\n<g id=\"node114\" class=\"node\">\n<title>113</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1681,-1131.5 1585,-1131.5 1585,-1063.5 1681,-1063.5 1681,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"1633\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1633\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1633\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"1633\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 93&#45;&gt;113 -->\n<g id=\"edge113\" class=\"edge\">\n<title>93&#45;&gt;113</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1553.33,-1174.91C1565.52,-1163.21 1578.82,-1150.46 1591,-1138.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1593.62,-1141.11 1598.42,-1131.67 1588.78,-1136.06 1593.62,-1141.11\"/>\n</g>\n<!-- 95 -->\n<g id=\"node96\" class=\"node\">\n<title>95</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1477,-1012.5 1381,-1012.5 1381,-944.5 1477,-944.5 1477,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"1429\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1429\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1429\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"1429\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 94&#45;&gt;95 -->\n<g id=\"edge95\" class=\"edge\">\n<title>94&#45;&gt;95</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1482.55,-1055.91C1474.66,-1044.65 1466.09,-1032.42 1458.16,-1021.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1460.85,-1018.85 1452.25,-1012.67 1455.12,-1022.86 1460.85,-1018.85\"/>\n</g>\n<!-- 96 -->\n<g id=\"node97\" class=\"node\">\n<title>96</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1608.5,-1020 1495.5,-1020 1495.5,-937 1608.5,-937 1608.5,-1020\"/>\n<text text-anchor=\"middle\" x=\"1552\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 77.0</text>\n<text text-anchor=\"middle\" x=\"1552\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"1552\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n<text text-anchor=\"middle\" x=\"1552\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 14]</text>\n<text text-anchor=\"middle\" x=\"1552\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 94&#45;&gt;96 -->\n<g id=\"edge96\" class=\"edge\">\n<title>94&#45;&gt;96</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1525.22,-1055.91C1528.18,-1047.47 1531.33,-1038.48 1534.4,-1029.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1537.8,-1030.62 1537.8,-1020.02 1531.19,-1028.3 1537.8,-1030.62\"/>\n</g>\n<!-- 97 -->\n<g id=\"node98\" class=\"node\">\n<title>97</title>\n<polygon fill=\"#a5d2f3\" stroke=\"black\" points=\"1516.5,-901 1385.5,-901 1385.5,-818 1516.5,-818 1516.5,-901\"/>\n<text text-anchor=\"middle\" x=\"1451\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 12.0</text>\n<text text-anchor=\"middle\" x=\"1451\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.937</text>\n<text text-anchor=\"middle\" x=\"1451\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"1451\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 11]</text>\n<text text-anchor=\"middle\" x=\"1451\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 96&#45;&gt;97 -->\n<g id=\"edge97\" class=\"edge\">\n<title>96&#45;&gt;97</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1516.96,-936.91C1509.12,-927.83 1500.74,-918.12 1492.67,-908.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1495.16,-906.3 1485.98,-901.02 1489.86,-910.88 1495.16,-906.3\"/>\n</g>\n<!-- 108 -->\n<g id=\"node109\" class=\"node\">\n<title>108</title>\n<polygon fill=\"#efb083\" stroke=\"black\" points=\"1665.5,-901 1534.5,-901 1534.5,-818 1665.5,-818 1665.5,-901\"/>\n<text text-anchor=\"middle\" x=\"1600\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 18.0</text>\n<text text-anchor=\"middle\" x=\"1600\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.845</text>\n<text text-anchor=\"middle\" x=\"1600\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"1600\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 3]</text>\n<text text-anchor=\"middle\" x=\"1600\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 96&#45;&gt;108 -->\n<g id=\"edge108\" class=\"edge\">\n<title>96&#45;&gt;108</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1568.65,-936.91C1572.15,-928.38 1575.88,-919.28 1579.51,-910.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1582.82,-911.6 1583.38,-901.02 1576.34,-908.94 1582.82,-911.6\"/>\n</g>\n<!-- 98 -->\n<g id=\"node99\" class=\"node\">\n<title>98</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1359,-774.5 1263,-774.5 1263,-706.5 1359,-706.5 1359,-774.5\"/>\n<text text-anchor=\"middle\" x=\"1311\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1311\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1311\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"1311\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 97&#45;&gt;98 -->\n<g id=\"edge98\" class=\"edge\">\n<title>97&#45;&gt;98</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1402.43,-817.91C1388.17,-805.99 1372.59,-792.98 1358.41,-781.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1360.6,-778.39 1350.69,-774.67 1356.12,-783.77 1360.6,-778.39\"/>\n</g>\n<!-- 99 -->\n<g id=\"node100\" class=\"node\">\n<title>99</title>\n<polygon fill=\"#6fb8ec\" stroke=\"black\" points=\"1528.5,-782 1377.5,-782 1377.5,-699 1528.5,-699 1528.5,-782\"/>\n<text text-anchor=\"middle\" x=\"1453\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ChestPainType &lt;= 2.5</text>\n<text text-anchor=\"middle\" x=\"1453\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.75</text>\n<text text-anchor=\"middle\" x=\"1453\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"1453\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 11]</text>\n<text text-anchor=\"middle\" x=\"1453\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 97&#45;&gt;99 -->\n<g id=\"edge99\" class=\"edge\">\n<title>97&#45;&gt;99</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1451.69,-817.91C1451.84,-809.56 1451.99,-800.67 1452.14,-792.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1455.64,-792.08 1452.31,-782.02 1448.64,-791.96 1455.64,-792.08\"/>\n</g>\n<!-- 100 -->\n<g id=\"node101\" class=\"node\">\n<title>100</title>\n<polygon fill=\"#4da7e8\" stroke=\"black\" points=\"1415.5,-663 1280.5,-663 1280.5,-580 1415.5,-580 1415.5,-663\"/>\n<text text-anchor=\"middle\" x=\"1348\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 46.5</text>\n<text text-anchor=\"middle\" x=\"1348\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.439</text>\n<text text-anchor=\"middle\" x=\"1348\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"1348\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 10]</text>\n<text text-anchor=\"middle\" x=\"1348\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 99&#45;&gt;100 -->\n<g id=\"edge100\" class=\"edge\">\n<title>99&#45;&gt;100</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1416.57,-698.91C1408.35,-689.74 1399.54,-679.93 1391.07,-670.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1393.65,-668.13 1384.36,-663.02 1388.44,-672.8 1393.65,-668.13\"/>\n</g>\n<!-- 105 -->\n<g id=\"node106\" class=\"node\">\n<title>105</title>\n<polygon fill=\"#f2c09c\" stroke=\"black\" points=\"1568.5,-663 1433.5,-663 1433.5,-580 1568.5,-580 1568.5,-663\"/>\n<text text-anchor=\"middle\" x=\"1501\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingECG &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1501\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"1501\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1501\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n<text text-anchor=\"middle\" x=\"1501\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 99&#45;&gt;105 -->\n<g id=\"edge105\" class=\"edge\">\n<title>99&#45;&gt;105</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1469.65,-698.91C1473.15,-690.38 1476.88,-681.28 1480.51,-672.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1483.82,-673.6 1484.38,-663.02 1477.34,-670.94 1483.82,-673.6\"/>\n</g>\n<!-- 101 -->\n<g id=\"node102\" class=\"node\">\n<title>101</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"1291.5,-544 1178.5,-544 1178.5,-461 1291.5,-461 1291.5,-544\"/>\n<text text-anchor=\"middle\" x=\"1235\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 69.5</text>\n<text text-anchor=\"middle\" x=\"1235\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"1235\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1235\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"middle\" x=\"1235\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 100&#45;&gt;101 -->\n<g id=\"edge101\" class=\"edge\">\n<title>100&#45;&gt;101</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1308.8,-579.91C1299.94,-570.74 1290.46,-560.93 1281.35,-551.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1283.6,-548.78 1274.14,-544.02 1278.57,-553.65 1283.6,-548.78\"/>\n</g>\n<!-- 104 -->\n<g id=\"node105\" class=\"node\">\n<title>104</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1406,-536.5 1310,-536.5 1310,-468.5 1406,-468.5 1406,-536.5\"/>\n<text text-anchor=\"middle\" x=\"1358\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1358\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"1358\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n<text text-anchor=\"middle\" x=\"1358\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 100&#45;&gt;104 -->\n<g id=\"edge104\" class=\"edge\">\n<title>100&#45;&gt;104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1351.47,-579.91C1352.38,-569.2 1353.37,-557.62 1354.3,-546.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1357.8,-546.93 1355.17,-536.67 1350.83,-546.33 1357.8,-546.93\"/>\n</g>\n<!-- 102 -->\n<g id=\"node103\" class=\"node\">\n<title>102</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1226,-417.5 1130,-417.5 1130,-349.5 1226,-349.5 1226,-417.5\"/>\n<text text-anchor=\"middle\" x=\"1178\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1178\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1178\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"1178\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 101&#45;&gt;102 -->\n<g id=\"edge102\" class=\"edge\">\n<title>101&#45;&gt;102</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1215.22,-460.91C1209.85,-449.87 1204.01,-437.9 1198.59,-426.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1201.68,-425.12 1194.16,-417.67 1195.39,-428.19 1201.68,-425.12\"/>\n</g>\n<!-- 103 -->\n<g id=\"node104\" class=\"node\">\n<title>103</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1340,-417.5 1244,-417.5 1244,-349.5 1340,-349.5 1340,-417.5\"/>\n<text text-anchor=\"middle\" x=\"1292\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1292\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1292\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"1292\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 101&#45;&gt;103 -->\n<g id=\"edge103\" class=\"edge\">\n<title>101&#45;&gt;103</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1254.78,-460.91C1260.15,-449.87 1265.99,-437.9 1271.41,-426.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1274.61,-428.19 1275.84,-417.67 1268.32,-425.12 1274.61,-428.19\"/>\n</g>\n<!-- 106 -->\n<g id=\"node107\" class=\"node\">\n<title>106</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1539,-536.5 1443,-536.5 1443,-468.5 1539,-468.5 1539,-536.5\"/>\n<text text-anchor=\"middle\" x=\"1491\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1491\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1491\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n<text text-anchor=\"middle\" x=\"1491\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 105&#45;&gt;106 -->\n<g id=\"edge106\" class=\"edge\">\n<title>105&#45;&gt;106</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1497.53,-579.91C1496.62,-569.2 1495.63,-557.62 1494.7,-546.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1498.17,-546.33 1493.83,-536.67 1491.2,-546.93 1498.17,-546.33\"/>\n</g>\n<!-- 107 -->\n<g id=\"node108\" class=\"node\">\n<title>107</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1653,-536.5 1557,-536.5 1557,-468.5 1653,-468.5 1653,-536.5\"/>\n<text text-anchor=\"middle\" x=\"1605\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1605\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1605\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"1605\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 105&#45;&gt;107 -->\n<g id=\"edge107\" class=\"edge\">\n<title>105&#45;&gt;107</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1537.08,-579.91C1547.28,-568.43 1558.39,-555.94 1568.61,-544.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1571.49,-546.47 1575.52,-536.67 1566.26,-541.82 1571.49,-546.47\"/>\n</g>\n<!-- 109 -->\n<g id=\"node110\" class=\"node\">\n<title>109</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1646,-774.5 1550,-774.5 1550,-706.5 1646,-706.5 1646,-774.5\"/>\n<text text-anchor=\"middle\" x=\"1598\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1598\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1598\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"1598\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 108&#45;&gt;109 -->\n<g id=\"edge109\" class=\"edge\">\n<title>108&#45;&gt;109</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1599.31,-817.91C1599.12,-807.2 1598.93,-795.62 1598.74,-784.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1602.24,-784.61 1598.57,-774.67 1595.24,-784.73 1602.24,-784.61\"/>\n</g>\n<!-- 110 -->\n<g id=\"node111\" class=\"node\">\n<title>110</title>\n<polygon fill=\"#e89152\" stroke=\"black\" points=\"1807.5,-782 1664.5,-782 1664.5,-699 1807.5,-699 1807.5,-782\"/>\n<text text-anchor=\"middle\" x=\"1736\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 141.5</text>\n<text text-anchor=\"middle\" x=\"1736\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.503</text>\n<text text-anchor=\"middle\" x=\"1736\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"1736\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 1]</text>\n<text text-anchor=\"middle\" x=\"1736\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 108&#45;&gt;110 -->\n<g id=\"edge110\" class=\"edge\">\n<title>108&#45;&gt;110</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1647.18,-817.91C1658.16,-808.47 1669.93,-798.34 1681.19,-788.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1683.6,-791.2 1688.9,-782.02 1679.04,-785.89 1683.6,-791.2\"/>\n</g>\n<!-- 111 -->\n<g id=\"node112\" class=\"node\">\n<title>111</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1757,-655.5 1661,-655.5 1661,-587.5 1757,-587.5 1757,-655.5\"/>\n<text text-anchor=\"middle\" x=\"1709\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1709\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"1709\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n<text text-anchor=\"middle\" x=\"1709\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 110&#45;&gt;111 -->\n<g id=\"edge111\" class=\"edge\">\n<title>110&#45;&gt;111</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1726.63,-698.91C1724.14,-688.09 1721.43,-676.38 1718.91,-665.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1722.31,-664.62 1716.65,-655.67 1715.49,-666.2 1722.31,-664.62\"/>\n</g>\n<!-- 112 -->\n<g id=\"node113\" class=\"node\">\n<title>112</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1871,-655.5 1775,-655.5 1775,-587.5 1871,-587.5 1871,-655.5\"/>\n<text text-anchor=\"middle\" x=\"1823\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1823\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1823\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"1823\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 110&#45;&gt;112 -->\n<g id=\"edge112\" class=\"edge\">\n<title>110&#45;&gt;112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1766.18,-698.91C1774.64,-687.54 1783.83,-675.18 1792.31,-663.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1795.18,-665.78 1798.34,-655.67 1789.56,-661.6 1795.18,-665.78\"/>\n</g>\n<!-- 116 -->\n<g id=\"node117\" class=\"node\">\n<title>116</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1817,-1250.5 1715,-1250.5 1715,-1182.5 1817,-1182.5 1817,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 14]</text>\n<text text-anchor=\"middle\" x=\"1766\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 115&#45;&gt;116 -->\n<g id=\"edge116\" class=\"edge\">\n<title>115&#45;&gt;116</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1766,-1293.91C1766,-1283.2 1766,-1271.62 1766,-1260.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1769.5,-1260.67 1766,-1250.67 1762.5,-1260.67 1769.5,-1260.67\"/>\n</g>\n<!-- 117 -->\n<g id=\"node118\" class=\"node\">\n<title>117</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"1946.5,-1258 1835.5,-1258 1835.5,-1175 1946.5,-1175 1946.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"1891\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 33.5</text>\n<text text-anchor=\"middle\" x=\"1891\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"1891\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"1891\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 6]</text>\n<text text-anchor=\"middle\" x=\"1891\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 115&#45;&gt;117 -->\n<g id=\"edge117\" class=\"edge\">\n<title>115&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1809.37,-1293.91C1819.35,-1284.56 1830.06,-1274.54 1840.33,-1264.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1842.8,-1267.41 1847.71,-1258.02 1838.02,-1262.3 1842.8,-1267.41\"/>\n</g>\n<!-- 118 -->\n<g id=\"node119\" class=\"node\">\n<title>118</title>\n<polygon fill=\"#5aade9\" stroke=\"black\" points=\"1830.5,-1139 1699.5,-1139 1699.5,-1056 1830.5,-1056 1830.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"1765\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 25.5</text>\n<text text-anchor=\"middle\" x=\"1765\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.592</text>\n<text text-anchor=\"middle\" x=\"1765\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"middle\" x=\"1765\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 6]</text>\n<text text-anchor=\"middle\" x=\"1765\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 117&#45;&gt;118 -->\n<g id=\"edge118\" class=\"edge\">\n<title>117&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1847.28,-1174.91C1837.22,-1165.56 1826.43,-1155.54 1816.08,-1145.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1818.35,-1143.26 1808.64,-1139.02 1813.58,-1148.39 1818.35,-1143.26\"/>\n</g>\n<!-- 123 -->\n<g id=\"node124\" class=\"node\">\n<title>123</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1945,-1131.5 1849,-1131.5 1849,-1063.5 1945,-1063.5 1945,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"1897\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1897\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1897\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n<text text-anchor=\"middle\" x=\"1897\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 117&#45;&gt;123 -->\n<g id=\"edge123\" class=\"edge\">\n<title>117&#45;&gt;123</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1893.08,-1174.91C1893.63,-1164.2 1894.22,-1152.62 1894.78,-1141.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1898.28,-1141.83 1895.3,-1131.67 1891.29,-1141.47 1898.28,-1141.83\"/>\n</g>\n<!-- 119 -->\n<g id=\"node120\" class=\"node\">\n<title>119</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1816.5,-1020 1681.5,-1020 1681.5,-937 1816.5,-937 1816.5,-1020\"/>\n<text text-anchor=\"middle\" x=\"1749\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 41.0</text>\n<text text-anchor=\"middle\" x=\"1749\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"1749\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1749\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"middle\" x=\"1749\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 118&#45;&gt;119 -->\n<g id=\"edge119\" class=\"edge\">\n<title>118&#45;&gt;119</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1759.45,-1055.91C1758.31,-1047.56 1757.09,-1038.67 1755.91,-1030.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1759.36,-1029.45 1754.54,-1020.02 1752.43,-1030.4 1759.36,-1029.45\"/>\n</g>\n<!-- 122 -->\n<g id=\"node123\" class=\"node\">\n<title>122</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1931,-1012.5 1835,-1012.5 1835,-944.5 1931,-944.5 1931,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"1883\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1883\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1883\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n<text text-anchor=\"middle\" x=\"1883\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 118&#45;&gt;122 -->\n<g id=\"edge122\" class=\"edge\">\n<title>118&#45;&gt;122</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1805.94,-1055.91C1817.74,-1044.21 1830.6,-1031.46 1842.38,-1019.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1844.91,-1022.19 1849.55,-1012.67 1839.98,-1017.22 1844.91,-1022.19\"/>\n</g>\n<!-- 120 -->\n<g id=\"node121\" class=\"node\">\n<title>120</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"1781,-893.5 1685,-893.5 1685,-825.5 1781,-825.5 1781,-893.5\"/>\n<text text-anchor=\"middle\" x=\"1733\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1733\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1733\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"1733\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 119&#45;&gt;120 -->\n<g id=\"edge120\" class=\"edge\">\n<title>119&#45;&gt;120</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1743.45,-936.91C1741.99,-926.2 1740.4,-914.62 1738.92,-903.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1742.36,-903.1 1737.54,-893.67 1735.42,-904.05 1742.36,-903.1\"/>\n</g>\n<!-- 121 -->\n<g id=\"node122\" class=\"node\">\n<title>121</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"1895,-893.5 1799,-893.5 1799,-825.5 1895,-825.5 1895,-893.5\"/>\n<text text-anchor=\"middle\" x=\"1847\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1847\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1847\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"1847\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 119&#45;&gt;121 -->\n<g id=\"edge121\" class=\"edge\">\n<title>119&#45;&gt;121</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1783,-936.91C1792.61,-925.43 1803.08,-912.94 1812.71,-901.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1815.48,-903.58 1819.22,-893.67 1810.11,-899.09 1815.48,-903.58\"/>\n</g>\n<!-- 125 -->\n<g id=\"node126\" class=\"node\">\n<title>125</title>\n<polygon fill=\"#87c4ef\" stroke=\"black\" points=\"2170,-1734 2048,-1734 2048,-1651 2170,-1651 2170,-1734\"/>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1718.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FastingBS &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1703.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.859</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1688.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1673.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 33]</text>\n<text text-anchor=\"middle\" x=\"2109\" y=\"-1658.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 124&#45;&gt;125 -->\n<g id=\"edge125\" class=\"edge\">\n<title>124&#45;&gt;125</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2109,-1769.91C2109,-1761.65 2109,-1752.86 2109,-1744.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2112.5,-1744.02 2109,-1734.02 2105.5,-1744.02 2112.5,-1744.02\"/>\n</g>\n<!-- 140 -->\n<g id=\"node141\" class=\"node\">\n<title>140</title>\n<polygon fill=\"#e78b49\" stroke=\"black\" points=\"2689,-1734 2571,-1734 2571,-1651 2689,-1651 2689,-1734\"/>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1718.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 17.5</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1703.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.378</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1688.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 273</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1673.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [253, 20]</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1658.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 124&#45;&gt;140 -->\n<g id=\"edge140\" class=\"edge\">\n<title>124&#45;&gt;140</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2173.15,-1796.09C2271.72,-1773.96 2459.66,-1731.75 2561.05,-1708.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2561.9,-1712.38 2570.89,-1706.77 2560.37,-1705.55 2561.9,-1712.38\"/>\n</g>\n<!-- 126 -->\n<g id=\"node127\" class=\"node\">\n<title>126</title>\n<polygon fill=\"#f9e2d1\" stroke=\"black\" points=\"2102.5,-1615 1989.5,-1615 1989.5,-1532 2102.5,-1532 2102.5,-1615\"/>\n<text text-anchor=\"middle\" x=\"2046\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 29.0</text>\n<text text-anchor=\"middle\" x=\"2046\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.988</text>\n<text text-anchor=\"middle\" x=\"2046\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"middle\" x=\"2046\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 10]</text>\n<text text-anchor=\"middle\" x=\"2046\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 125&#45;&gt;126 -->\n<g id=\"edge126\" class=\"edge\">\n<title>125&#45;&gt;126</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2087.14,-1650.91C2082.45,-1642.2 2077.44,-1632.9 2072.6,-1623.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2075.64,-1622.17 2067.82,-1615.02 2069.48,-1625.48 2075.64,-1622.17\"/>\n</g>\n<!-- 139 -->\n<g id=\"node140\" class=\"node\">\n<title>139</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2223,-1607.5 2121,-1607.5 2121,-1539.5 2223,-1539.5 2223,-1607.5\"/>\n<text text-anchor=\"middle\" x=\"2172\" y=\"-1592.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2172\" y=\"-1577.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"middle\" x=\"2172\" y=\"-1562.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 23]</text>\n<text text-anchor=\"middle\" x=\"2172\" y=\"-1547.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 125&#45;&gt;139 -->\n<g id=\"edge139\" class=\"edge\">\n<title>125&#45;&gt;139</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2130.86,-1650.91C2136.8,-1639.87 2143.25,-1627.9 2149.24,-1616.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2152.48,-1618.13 2154.14,-1607.67 2146.32,-1614.81 2152.48,-1618.13\"/>\n</g>\n<!-- 127 -->\n<g id=\"node128\" class=\"node\">\n<title>127</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2033,-1488.5 1937,-1488.5 1937,-1420.5 2033,-1420.5 2033,-1488.5\"/>\n<text text-anchor=\"middle\" x=\"1985\" y=\"-1473.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1985\" y=\"-1458.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1985\" y=\"-1443.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n<text text-anchor=\"middle\" x=\"1985\" y=\"-1428.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 126&#45;&gt;127 -->\n<g id=\"edge127\" class=\"edge\">\n<title>126&#45;&gt;127</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2024.84,-1531.91C2019.08,-1520.87 2012.84,-1508.9 2007.04,-1497.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2010.02,-1495.92 2002.29,-1488.67 2003.81,-1499.15 2010.02,-1495.92\"/>\n</g>\n<!-- 128 -->\n<g id=\"node129\" class=\"node\">\n<title>128</title>\n<polygon fill=\"#f3c5a4\" stroke=\"black\" points=\"2164.5,-1496 2051.5,-1496 2051.5,-1413 2164.5,-1413 2164.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"2108\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 45.0</text>\n<text text-anchor=\"middle\" x=\"2108\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.934</text>\n<text text-anchor=\"middle\" x=\"2108\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"middle\" x=\"2108\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 7]</text>\n<text text-anchor=\"middle\" x=\"2108\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 126&#45;&gt;128 -->\n<g id=\"edge128\" class=\"edge\">\n<title>126&#45;&gt;128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2067.51,-1531.91C2072.13,-1523.2 2077.05,-1513.9 2081.83,-1504.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2084.94,-1506.5 2086.53,-1496.02 2078.75,-1503.22 2084.94,-1506.5\"/>\n</g>\n<!-- 129 -->\n<g id=\"node130\" class=\"node\">\n<title>129</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2095,-1369.5 1999,-1369.5 1999,-1301.5 2095,-1301.5 2095,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"2047\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2047\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"2047\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n<text text-anchor=\"middle\" x=\"2047\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 128&#45;&gt;129 -->\n<g id=\"edge129\" class=\"edge\">\n<title>128&#45;&gt;129</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2086.84,-1412.91C2081.08,-1401.87 2074.84,-1389.9 2069.04,-1378.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2072.02,-1376.92 2064.29,-1369.67 2065.81,-1380.15 2072.02,-1376.92\"/>\n</g>\n<!-- 130 -->\n<g id=\"node131\" class=\"node\">\n<title>130</title>\n<polygon fill=\"#f9e3d3\" stroke=\"black\" points=\"2226.5,-1377 2113.5,-1377 2113.5,-1294 2226.5,-1294 2226.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"2170\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 53.0</text>\n<text text-anchor=\"middle\" x=\"2170\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.989</text>\n<text text-anchor=\"middle\" x=\"2170\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"2170\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 7]</text>\n<text text-anchor=\"middle\" x=\"2170\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 128&#45;&gt;130 -->\n<g id=\"edge130\" class=\"edge\">\n<title>128&#45;&gt;130</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2129.51,-1412.91C2134.13,-1404.2 2139.05,-1394.9 2143.83,-1385.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2146.94,-1387.5 2148.53,-1377.02 2140.75,-1384.22 2146.94,-1387.5\"/>\n</g>\n<!-- 131 -->\n<g id=\"node132\" class=\"node\">\n<title>131</title>\n<polygon fill=\"#6ab6ec\" stroke=\"black\" points=\"2155.5,-1258 2044.5,-1258 2044.5,-1175 2155.5,-1175 2155.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"2100\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Oldpeak &lt;= 9.0</text>\n<text text-anchor=\"middle\" x=\"2100\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.722</text>\n<text text-anchor=\"middle\" x=\"2100\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"2100\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 4]</text>\n<text text-anchor=\"middle\" x=\"2100\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 130&#45;&gt;131 -->\n<g id=\"edge131\" class=\"edge\">\n<title>130&#45;&gt;131</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2145.71,-1293.91C2140.45,-1285.1 2134.82,-1275.7 2129.38,-1266.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2132.38,-1264.81 2124.24,-1258.02 2126.37,-1268.4 2132.38,-1264.81\"/>\n</g>\n<!-- 134 -->\n<g id=\"node135\" class=\"node\">\n<title>134</title>\n<polygon fill=\"#efb083\" stroke=\"black\" points=\"2308.5,-1258 2173.5,-1258 2173.5,-1175 2308.5,-1175 2308.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"2241\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingECG &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"2241\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.845</text>\n<text text-anchor=\"middle\" x=\"2241\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"2241\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 3]</text>\n<text text-anchor=\"middle\" x=\"2241\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 130&#45;&gt;134 -->\n<g id=\"edge134\" class=\"edge\">\n<title>130&#45;&gt;134</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2194.63,-1293.91C2199.97,-1285.1 2205.68,-1275.7 2211.2,-1266.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2214.21,-1268.39 2216.41,-1258.02 2208.23,-1264.75 2214.21,-1268.39\"/>\n</g>\n<!-- 132 -->\n<g id=\"node133\" class=\"node\">\n<title>132</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2059,-1131.5 1963,-1131.5 1963,-1063.5 2059,-1063.5 2059,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"2011\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2011\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"2011\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"2011\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 131&#45;&gt;132 -->\n<g id=\"edge132\" class=\"edge\">\n<title>131&#45;&gt;132</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2069.12,-1174.91C2060.48,-1163.54 2051.07,-1151.18 2042.4,-1139.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2045.07,-1137.51 2036.23,-1131.67 2039.5,-1141.74 2045.07,-1137.51\"/>\n</g>\n<!-- 133 -->\n<g id=\"node134\" class=\"node\">\n<title>133</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2173,-1131.5 2077,-1131.5 2077,-1063.5 2173,-1063.5 2173,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"2125\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2125\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"2125\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n<text text-anchor=\"middle\" x=\"2125\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 131&#45;&gt;133 -->\n<g id=\"edge133\" class=\"edge\">\n<title>131&#45;&gt;133</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2108.67,-1174.91C2110.96,-1164.2 2113.44,-1152.62 2115.75,-1141.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2119.25,-1142.18 2117.91,-1131.67 2112.4,-1140.71 2119.25,-1142.18\"/>\n</g>\n<!-- 135 -->\n<g id=\"node136\" class=\"node\">\n<title>135</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2287,-1131.5 2191,-1131.5 2191,-1063.5 2287,-1063.5 2287,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"2239\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2239\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"2239\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\n<text text-anchor=\"middle\" x=\"2239\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 134&#45;&gt;135 -->\n<g id=\"edge135\" class=\"edge\">\n<title>134&#45;&gt;135</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2240.31,-1174.91C2240.12,-1164.2 2239.93,-1152.62 2239.74,-1141.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2243.24,-1141.61 2239.57,-1131.67 2236.24,-1141.73 2243.24,-1141.61\"/>\n</g>\n<!-- 136 -->\n<g id=\"node137\" class=\"node\">\n<title>136</title>\n<polygon fill=\"#bddef6\" stroke=\"black\" points=\"2416.5,-1139 2305.5,-1139 2305.5,-1056 2416.5,-1056 2416.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"2361\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 25.5</text>\n<text text-anchor=\"middle\" x=\"2361\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.971</text>\n<text text-anchor=\"middle\" x=\"2361\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"2361\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n<text text-anchor=\"middle\" x=\"2361\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 134&#45;&gt;136 -->\n<g id=\"edge136\" class=\"edge\">\n<title>134&#45;&gt;136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2282.63,-1174.91C2292.13,-1165.65 2302.3,-1155.73 2312.07,-1146.21\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2314.72,-1148.51 2319.44,-1139.02 2309.84,-1143.5 2314.72,-1148.51\"/>\n</g>\n<!-- 137 -->\n<g id=\"node138\" class=\"node\">\n<title>137</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2302,-1012.5 2206,-1012.5 2206,-944.5 2302,-944.5 2302,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"2254\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2254\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"2254\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n<text text-anchor=\"middle\" x=\"2254\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 136&#45;&gt;137 -->\n<g id=\"edge137\" class=\"edge\">\n<title>136&#45;&gt;137</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2323.88,-1055.91C2313.28,-1044.32 2301.74,-1031.7 2291.14,-1020.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2293.66,-1017.68 2284.33,-1012.67 2288.5,-1022.41 2293.66,-1017.68\"/>\n</g>\n<!-- 138 -->\n<g id=\"node139\" class=\"node\">\n<title>138</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2416,-1012.5 2320,-1012.5 2320,-944.5 2416,-944.5 2416,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"2368\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2368\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"2368\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n<text text-anchor=\"middle\" x=\"2368\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 136&#45;&gt;138 -->\n<g id=\"edge138\" class=\"edge\">\n<title>136&#45;&gt;138</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2363.43,-1055.91C2364.07,-1045.2 2364.76,-1033.62 2365.41,-1022.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2368.91,-1022.86 2366.02,-1012.67 2361.92,-1022.44 2368.91,-1022.86\"/>\n</g>\n<!-- 141 -->\n<g id=\"node142\" class=\"node\">\n<title>141</title>\n<polygon fill=\"#e68540\" stroke=\"black\" points=\"2697.5,-1615 2562.5,-1615 2562.5,-1532 2697.5,-1532 2697.5,-1615\"/>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingECG &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.212</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 238</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [230, 8]</text>\n<text text-anchor=\"middle\" x=\"2630\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 140&#45;&gt;141 -->\n<g id=\"edge141\" class=\"edge\">\n<title>140&#45;&gt;141</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2630,-1650.91C2630,-1642.65 2630,-1633.86 2630,-1625.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2633.5,-1625.02 2630,-1615.02 2626.5,-1625.02 2633.5,-1625.02\"/>\n</g>\n<!-- 170 -->\n<g id=\"node171\" class=\"node\">\n<title>170</title>\n<polygon fill=\"#f3c3a0\" stroke=\"black\" points=\"3173.5,-1615 3022.5,-1615 3022.5,-1532 3173.5,-1532 3173.5,-1615\"/>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1599.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ChestPainType &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1584.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.928</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1569.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1554.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [23, 12]</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1539.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 140&#45;&gt;170 -->\n<g id=\"edge170\" class=\"edge\">\n<title>140&#45;&gt;170</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2689.27,-1676.68C2770.99,-1656.25 2918.76,-1619.31 3012.45,-1595.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3013.34,-1599.27 3022.19,-1593.45 3011.64,-1592.48 3013.34,-1599.27\"/>\n</g>\n<!-- 142 -->\n<g id=\"node143\" class=\"node\">\n<title>142</title>\n<polygon fill=\"#ea9b62\" stroke=\"black\" points=\"2620.5,-1496 2489.5,-1496 2489.5,-1413 2620.5,-1413 2620.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"2555\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 54.0</text>\n<text text-anchor=\"middle\" x=\"2555\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.663</text>\n<text text-anchor=\"middle\" x=\"2555\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"middle\" x=\"2555\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [24, 5]</text>\n<text text-anchor=\"middle\" x=\"2555\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 141&#45;&gt;142 -->\n<g id=\"edge142\" class=\"edge\">\n<title>141&#45;&gt;142</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2603.98,-1531.91C2598.34,-1523.1 2592.31,-1513.7 2586.48,-1504.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2589.32,-1502.55 2580.97,-1496.02 2583.43,-1506.33 2589.32,-1502.55\"/>\n</g>\n<!-- 155 -->\n<g id=\"node156\" class=\"node\">\n<title>155</title>\n<polygon fill=\"#e5833c\" stroke=\"black\" points=\"2773.5,-1496 2638.5,-1496 2638.5,-1413 2773.5,-1413 2773.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"2706\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 80.5</text>\n<text text-anchor=\"middle\" x=\"2706\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.108</text>\n<text text-anchor=\"middle\" x=\"2706\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 209</text>\n<text text-anchor=\"middle\" x=\"2706\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [206, 3]</text>\n<text text-anchor=\"middle\" x=\"2706\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 141&#45;&gt;155 -->\n<g id=\"edge155\" class=\"edge\">\n<title>141&#45;&gt;155</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2656.37,-1531.91C2662.09,-1523.1 2668.19,-1513.7 2674.1,-1504.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2677.17,-1506.31 2679.68,-1496.02 2671.3,-1502.5 2677.17,-1506.31\"/>\n</g>\n<!-- 143 -->\n<g id=\"node144\" class=\"node\">\n<title>143</title>\n<polygon fill=\"#e9965a\" stroke=\"black\" points=\"2500.5,-1377 2387.5,-1377 2387.5,-1294 2500.5,-1294 2500.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"2444\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 72.5</text>\n<text text-anchor=\"middle\" x=\"2444\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.592</text>\n<text text-anchor=\"middle\" x=\"2444\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n<text text-anchor=\"middle\" x=\"2444\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [24, 4]</text>\n<text text-anchor=\"middle\" x=\"2444\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 142&#45;&gt;143 -->\n<g id=\"edge143\" class=\"edge\">\n<title>142&#45;&gt;143</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2516.49,-1412.91C2507.79,-1403.74 2498.48,-1393.93 2489.53,-1384.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2491.86,-1381.87 2482.44,-1377.02 2486.79,-1386.68 2491.86,-1381.87\"/>\n</g>\n<!-- 154 -->\n<g id=\"node155\" class=\"node\">\n<title>154</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2615,-1369.5 2519,-1369.5 2519,-1301.5 2615,-1301.5 2615,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"2567\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2567\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"2567\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"2567\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 142&#45;&gt;154 -->\n<g id=\"edge154\" class=\"edge\">\n<title>142&#45;&gt;154</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2559.16,-1412.91C2560.26,-1402.2 2561.45,-1390.62 2562.56,-1379.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2566.06,-1379.97 2563.6,-1369.67 2559.1,-1379.26 2566.06,-1379.97\"/>\n</g>\n<!-- 144 -->\n<g id=\"node145\" class=\"node\">\n<title>144</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2453,-1250.5 2351,-1250.5 2351,-1182.5 2453,-1182.5 2453,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"2402\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2402\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"middle\" x=\"2402\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n<text text-anchor=\"middle\" x=\"2402\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 143&#45;&gt;144 -->\n<g id=\"edge144\" class=\"edge\">\n<title>143&#45;&gt;144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2429.43,-1293.91C2425.51,-1282.98 2421.25,-1271.14 2417.29,-1260.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2420.58,-1258.9 2413.91,-1250.67 2413.99,-1261.26 2420.58,-1258.9\"/>\n</g>\n<!-- 145 -->\n<g id=\"node146\" class=\"node\">\n<title>145</title>\n<polygon fill=\"#eeab7b\" stroke=\"black\" points=\"2591,-1258 2471,-1258 2471,-1175 2591,-1175 2591,-1258\"/>\n<text text-anchor=\"middle\" x=\"2531\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 104.5</text>\n<text text-anchor=\"middle\" x=\"2531\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.811</text>\n<text text-anchor=\"middle\" x=\"2531\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"2531\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 4]</text>\n<text text-anchor=\"middle\" x=\"2531\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 143&#45;&gt;145 -->\n<g id=\"edge145\" class=\"edge\">\n<title>143&#45;&gt;145</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2474.18,-1293.91C2480.86,-1284.92 2488.01,-1275.32 2494.9,-1266.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2497.71,-1268.13 2500.87,-1258.02 2492.09,-1263.96 2497.71,-1268.13\"/>\n</g>\n<!-- 146 -->\n<g id=\"node147\" class=\"node\">\n<title>146</title>\n<polygon fill=\"#f6d5bd\" stroke=\"black\" points=\"2585.5,-1139 2434.5,-1139 2434.5,-1056 2585.5,-1056 2585.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"2510\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ChestPainType &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"2510\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.971</text>\n<text text-anchor=\"middle\" x=\"2510\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"middle\" x=\"2510\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 4]</text>\n<text text-anchor=\"middle\" x=\"2510\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 145&#45;&gt;146 -->\n<g id=\"edge146\" class=\"edge\">\n<title>145&#45;&gt;146</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2523.71,-1174.91C2522.22,-1166.56 2520.62,-1157.67 2519.07,-1149.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2522.48,-1148.25 2517.27,-1139.02 2515.59,-1149.48 2522.48,-1148.25\"/>\n</g>\n<!-- 153 -->\n<g id=\"node154\" class=\"node\">\n<title>153</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2700,-1131.5 2604,-1131.5 2604,-1063.5 2700,-1063.5 2700,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"2652\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2652\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"2652\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\n<text text-anchor=\"middle\" x=\"2652\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 145&#45;&gt;153 -->\n<g id=\"edge153\" class=\"edge\">\n<title>145&#45;&gt;153</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2572.98,-1174.91C2585.08,-1163.21 2598.27,-1150.46 2610.34,-1138.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2612.94,-1141.13 2617.7,-1131.67 2608.08,-1136.1 2612.94,-1141.13\"/>\n</g>\n<!-- 147 -->\n<g id=\"node148\" class=\"node\">\n<title>147</title>\n<polygon fill=\"#cee6f8\" stroke=\"black\" points=\"2558.5,-1020 2447.5,-1020 2447.5,-937 2558.5,-937 2558.5,-1020\"/>\n<text text-anchor=\"middle\" x=\"2503\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"2503\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.985</text>\n<text text-anchor=\"middle\" x=\"2503\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"middle\" x=\"2503\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 4]</text>\n<text text-anchor=\"middle\" x=\"2503\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 146&#45;&gt;147 -->\n<g id=\"edge147\" class=\"edge\">\n<title>146&#45;&gt;147</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2507.57,-1055.91C2507.07,-1047.56 2506.54,-1038.67 2506.02,-1030.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2509.52,-1029.79 2505.42,-1020.02 2502.53,-1030.21 2509.52,-1029.79\"/>\n</g>\n<!-- 152 -->\n<g id=\"node153\" class=\"node\">\n<title>152</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2673,-1012.5 2577,-1012.5 2577,-944.5 2673,-944.5 2673,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"2625\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2625\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"2625\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"2625\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 146&#45;&gt;152 -->\n<g id=\"edge152\" class=\"edge\">\n<title>146&#45;&gt;152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2549.9,-1055.91C2561.29,-1044.32 2573.69,-1031.7 2585.08,-1020.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2587.89,-1022.25 2592.4,-1012.67 2582.89,-1017.35 2587.89,-1022.25\"/>\n</g>\n<!-- 148 -->\n<g id=\"node149\" class=\"node\">\n<title>148</title>\n<polygon fill=\"#f6d5bd\" stroke=\"black\" points=\"2497.5,-901 2386.5,-901 2386.5,-818 2497.5,-818 2497.5,-901\"/>\n<text text-anchor=\"middle\" x=\"2442\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age &lt;= 29.5</text>\n<text text-anchor=\"middle\" x=\"2442\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.971</text>\n<text text-anchor=\"middle\" x=\"2442\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"2442\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n<text text-anchor=\"middle\" x=\"2442\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 147&#45;&gt;148 -->\n<g id=\"edge148\" class=\"edge\">\n<title>147&#45;&gt;148</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2481.84,-936.91C2477.29,-928.2 2472.45,-918.9 2467.75,-909.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2470.85,-908.27 2463.13,-901.02 2464.65,-911.51 2470.85,-908.27\"/>\n</g>\n<!-- 151 -->\n<g id=\"node152\" class=\"node\">\n<title>151</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2612,-893.5 2516,-893.5 2516,-825.5 2612,-825.5 2612,-893.5\"/>\n<text text-anchor=\"middle\" x=\"2564\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2564\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"2564\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"2564\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 147&#45;&gt;151 -->\n<g id=\"edge151\" class=\"edge\">\n<title>147&#45;&gt;151</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2524.16,-936.91C2529.92,-925.87 2536.16,-913.9 2541.96,-902.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2545.19,-904.15 2546.71,-893.67 2538.98,-900.92 2545.19,-904.15\"/>\n</g>\n<!-- 149 -->\n<g id=\"node150\" class=\"node\">\n<title>149</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2433,-774.5 2337,-774.5 2337,-706.5 2433,-706.5 2433,-774.5\"/>\n<text text-anchor=\"middle\" x=\"2385\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2385\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"2385\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"2385\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 148&#45;&gt;149 -->\n<g id=\"edge149\" class=\"edge\">\n<title>148&#45;&gt;149</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2422.22,-817.91C2416.85,-806.87 2411.01,-794.9 2405.59,-783.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2408.68,-782.12 2401.16,-774.67 2402.39,-785.19 2408.68,-782.12\"/>\n</g>\n<!-- 150 -->\n<g id=\"node151\" class=\"node\">\n<title>150</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2547,-774.5 2451,-774.5 2451,-706.5 2547,-706.5 2547,-774.5\"/>\n<text text-anchor=\"middle\" x=\"2499\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2499\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"2499\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"2499\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 148&#45;&gt;150 -->\n<g id=\"edge150\" class=\"edge\">\n<title>148&#45;&gt;150</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2461.78,-817.91C2467.15,-806.87 2472.99,-794.9 2478.41,-783.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2481.61,-785.19 2482.84,-774.67 2475.32,-782.12 2481.61,-785.19\"/>\n</g>\n<!-- 156 -->\n<g id=\"node157\" class=\"node\">\n<title>156</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2752,-1369.5 2642,-1369.5 2642,-1301.5 2752,-1301.5 2752,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"2697\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2697\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 101</text>\n<text text-anchor=\"middle\" x=\"2697\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [101, 0]</text>\n<text text-anchor=\"middle\" x=\"2697\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 155&#45;&gt;156 -->\n<g id=\"edge156\" class=\"edge\">\n<title>155&#45;&gt;156</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2702.88,-1412.91C2702.05,-1402.2 2701.16,-1390.62 2700.33,-1379.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2703.81,-1379.37 2699.55,-1369.67 2696.83,-1379.91 2703.81,-1379.37\"/>\n</g>\n<!-- 157 -->\n<g id=\"node158\" class=\"node\">\n<title>157</title>\n<polygon fill=\"#e6853f\" stroke=\"black\" points=\"2913.5,-1377 2770.5,-1377 2770.5,-1294 2913.5,-1294 2913.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"2842\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 120.0</text>\n<text text-anchor=\"middle\" x=\"2842\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.183</text>\n<text text-anchor=\"middle\" x=\"2842\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 108</text>\n<text text-anchor=\"middle\" x=\"2842\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [105, 3]</text>\n<text text-anchor=\"middle\" x=\"2842\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 155&#45;&gt;157 -->\n<g id=\"edge157\" class=\"edge\">\n<title>155&#45;&gt;157</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2753.18,-1412.91C2764.16,-1403.47 2775.93,-1393.34 2787.19,-1383.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2789.6,-1386.2 2794.9,-1377.02 2785.04,-1380.89 2789.6,-1386.2\"/>\n</g>\n<!-- 158 -->\n<g id=\"node159\" class=\"node\">\n<title>158</title>\n<polygon fill=\"#e78845\" stroke=\"black\" points=\"2846.5,-1258 2703.5,-1258 2703.5,-1175 2846.5,-1175 2846.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 118.5</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.31</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 3]</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 157&#45;&gt;158 -->\n<g id=\"edge158\" class=\"edge\">\n<title>157&#45;&gt;158</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2818.75,-1293.91C2813.77,-1285.2 2808.44,-1275.9 2803.29,-1266.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2806.21,-1264.96 2798.2,-1258.02 2800.14,-1268.44 2806.21,-1264.96\"/>\n</g>\n<!-- 169 -->\n<g id=\"node170\" class=\"node\">\n<title>169</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2967,-1250.5 2865,-1250.5 2865,-1182.5 2967,-1182.5 2967,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"2916\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2916\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"middle\" x=\"2916\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [54, 0]</text>\n<text text-anchor=\"middle\" x=\"2916\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 157&#45;&gt;169 -->\n<g id=\"edge169\" class=\"edge\">\n<title>157&#45;&gt;169</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2867.67,-1293.91C2874.72,-1282.76 2882.38,-1270.66 2889.47,-1259.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2892.64,-1260.99 2895.02,-1250.67 2886.72,-1257.25 2892.64,-1260.99\"/>\n</g>\n<!-- 159 -->\n<g id=\"node160\" class=\"node\">\n<title>159</title>\n<polygon fill=\"#e68641\" stroke=\"black\" points=\"2831.5,-1139 2718.5,-1139 2718.5,-1056 2831.5,-1056 2831.5,-1139\"/>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 77.5</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.232</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1093.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 53</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1078.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 2]</text>\n<text text-anchor=\"middle\" x=\"2775\" y=\"-1063.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 158&#45;&gt;159 -->\n<g id=\"edge159\" class=\"edge\">\n<title>158&#45;&gt;159</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2775,-1174.91C2775,-1166.65 2775,-1157.86 2775,-1149.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2778.5,-1149.02 2775,-1139.02 2771.5,-1149.02 2778.5,-1149.02\"/>\n</g>\n<!-- 168 -->\n<g id=\"node169\" class=\"node\">\n<title>168</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2946,-1131.5 2850,-1131.5 2850,-1063.5 2946,-1063.5 2946,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"2898\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2898\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"2898\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"2898\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 158&#45;&gt;168 -->\n<g id=\"edge168\" class=\"edge\">\n<title>158&#45;&gt;168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2817.67,-1174.91C2829.97,-1163.21 2843.38,-1150.46 2855.65,-1138.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2858.3,-1141.1 2863.13,-1131.67 2853.47,-1136.02 2858.3,-1141.1\"/>\n</g>\n<!-- 160 -->\n<g id=\"node161\" class=\"node\">\n<title>160</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2813,-1012.5 2711,-1012.5 2711,-944.5 2813,-944.5 2813,-1012.5\"/>\n<text text-anchor=\"middle\" x=\"2762\" y=\"-997.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2762\" y=\"-982.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"middle\" x=\"2762\" y=\"-967.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 0]</text>\n<text text-anchor=\"middle\" x=\"2762\" y=\"-952.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 159&#45;&gt;160 -->\n<g id=\"edge160\" class=\"edge\">\n<title>159&#45;&gt;160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2770.49,-1055.91C2769.3,-1045.2 2768.01,-1033.62 2766.81,-1022.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2770.27,-1022.22 2765.69,-1012.67 2763.31,-1022.99 2770.27,-1022.22\"/>\n</g>\n<!-- 161 -->\n<g id=\"node162\" class=\"node\">\n<title>161</title>\n<polygon fill=\"#e78d4c\" stroke=\"black\" points=\"2944.5,-1020 2831.5,-1020 2831.5,-937 2944.5,-937 2944.5,-1020\"/>\n<text text-anchor=\"middle\" x=\"2888\" y=\"-1004.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 78.5</text>\n<text text-anchor=\"middle\" x=\"2888\" y=\"-989.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.426</text>\n<text text-anchor=\"middle\" x=\"2888\" y=\"-974.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"middle\" x=\"2888\" y=\"-959.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 2]</text>\n<text text-anchor=\"middle\" x=\"2888\" y=\"-944.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 159&#45;&gt;161 -->\n<g id=\"edge161\" class=\"edge\">\n<title>159&#45;&gt;161</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2814.2,-1055.91C2823.06,-1046.74 2832.54,-1036.93 2841.65,-1027.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2844.43,-1029.65 2848.86,-1020.02 2839.4,-1024.78 2844.43,-1029.65\"/>\n</g>\n<!-- 162 -->\n<g id=\"node163\" class=\"node\">\n<title>162</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"2870,-893.5 2774,-893.5 2774,-825.5 2870,-825.5 2870,-893.5\"/>\n<text text-anchor=\"middle\" x=\"2822\" y=\"-878.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2822\" y=\"-863.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"2822\" y=\"-848.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"2822\" y=\"-833.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 161&#45;&gt;162 -->\n<g id=\"edge162\" class=\"edge\">\n<title>161&#45;&gt;162</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2865.1,-936.91C2858.81,-925.76 2851.99,-913.66 2845.66,-902.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2848.67,-900.66 2840.71,-893.67 2842.57,-904.1 2848.67,-900.66\"/>\n</g>\n<!-- 163 -->\n<g id=\"node164\" class=\"node\">\n<title>163</title>\n<polygon fill=\"#e68742\" stroke=\"black\" points=\"3019.5,-901 2888.5,-901 2888.5,-818 3019.5,-818 3019.5,-901\"/>\n<text text-anchor=\"middle\" x=\"2954\" y=\"-885.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RestingBP &lt;= 49.5</text>\n<text text-anchor=\"middle\" x=\"2954\" y=\"-870.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.267</text>\n<text text-anchor=\"middle\" x=\"2954\" y=\"-855.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"middle\" x=\"2954\" y=\"-840.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 1]</text>\n<text text-anchor=\"middle\" x=\"2954\" y=\"-825.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 161&#45;&gt;163 -->\n<g id=\"edge163\" class=\"edge\">\n<title>161&#45;&gt;163</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2910.9,-936.91C2915.81,-928.2 2921.06,-918.9 2926.14,-909.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2929.28,-911.45 2931.14,-901.02 2923.18,-908.01 2929.28,-911.45\"/>\n</g>\n<!-- 164 -->\n<g id=\"node165\" class=\"node\">\n<title>164</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"2946,-774.5 2844,-774.5 2844,-706.5 2946,-706.5 2946,-774.5\"/>\n<text text-anchor=\"middle\" x=\"2895\" y=\"-759.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2895\" y=\"-744.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"middle\" x=\"2895\" y=\"-729.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 0]</text>\n<text text-anchor=\"middle\" x=\"2895\" y=\"-714.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 163&#45;&gt;164 -->\n<g id=\"edge164\" class=\"edge\">\n<title>163&#45;&gt;164</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2933.53,-817.91C2927.97,-806.87 2921.93,-794.9 2916.32,-783.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2919.35,-782.02 2911.73,-774.67 2913.1,-785.17 2919.35,-782.02\"/>\n</g>\n<!-- 165 -->\n<g id=\"node166\" class=\"node\">\n<title>165</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"3060,-782 2964,-782 2964,-699 3060,-699 3060,-782\"/>\n<text text-anchor=\"middle\" x=\"3012\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"3012\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"3012\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"3012\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"middle\" x=\"3012\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 163&#45;&gt;165 -->\n<g id=\"edge165\" class=\"edge\">\n<title>163&#45;&gt;165</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2974.12,-817.91C2978.4,-809.29 2982.96,-800.09 2987.37,-791.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2990.61,-792.53 2991.91,-782.02 2984.34,-789.43 2990.61,-792.53\"/>\n</g>\n<!-- 166 -->\n<g id=\"node167\" class=\"node\">\n<title>166</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"3003,-655.5 2907,-655.5 2907,-587.5 3003,-587.5 3003,-655.5\"/>\n<text text-anchor=\"middle\" x=\"2955\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"2955\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"2955\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"2955\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 165&#45;&gt;166 -->\n<g id=\"edge166\" class=\"edge\">\n<title>165&#45;&gt;166</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2992.22,-698.91C2986.85,-687.87 2981.01,-675.9 2975.59,-664.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2978.68,-663.12 2971.16,-655.67 2972.39,-666.19 2978.68,-663.12\"/>\n</g>\n<!-- 167 -->\n<g id=\"node168\" class=\"node\">\n<title>167</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"3117,-655.5 3021,-655.5 3021,-587.5 3117,-587.5 3117,-655.5\"/>\n<text text-anchor=\"middle\" x=\"3069\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3069\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"3069\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"3069\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 165&#45;&gt;167 -->\n<g id=\"edge167\" class=\"edge\">\n<title>165&#45;&gt;167</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3031.78,-698.91C3037.15,-687.87 3042.99,-675.9 3048.41,-664.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3051.61,-666.19 3052.84,-655.67 3045.32,-663.12 3051.61,-666.19\"/>\n</g>\n<!-- 171 -->\n<g id=\"node172\" class=\"node\">\n<title>171</title>\n<polygon fill=\"#88c4ef\" stroke=\"black\" points=\"3174.5,-1496 3021.5,-1496 3021.5,-1413 3174.5,-1413 3174.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ExerciseAngina &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.863</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 10]</text>\n<text text-anchor=\"middle\" x=\"3098\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 170&#45;&gt;171 -->\n<g id=\"edge171\" class=\"edge\">\n<title>170&#45;&gt;171</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3098,-1531.91C3098,-1523.65 3098,-1514.86 3098,-1506.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3101.5,-1506.02 3098,-1496.02 3094.5,-1506.02 3101.5,-1506.02\"/>\n</g>\n<!-- 178 -->\n<g id=\"node179\" class=\"node\">\n<title>178</title>\n<polygon fill=\"#e88e4e\" stroke=\"black\" points=\"3370.5,-1496 3257.5,-1496 3257.5,-1413 3370.5,-1413 3370.5,-1496\"/>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1480.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 53.0</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1465.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.454</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1450.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1435.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [19, 2]</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1420.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 170&#45;&gt;178 -->\n<g id=\"edge178\" class=\"edge\">\n<title>170&#45;&gt;178</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3172.94,-1531.91C3197.47,-1518.62 3224.51,-1503.97 3248.3,-1491.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3250.12,-1494.08 3257.25,-1486.24 3246.79,-1487.93 3250.12,-1494.08\"/>\n</g>\n<!-- 172 -->\n<g id=\"node173\" class=\"node\">\n<title>172</title>\n<polygon fill=\"#eca06a\" stroke=\"black\" points=\"3104.5,-1377 2961.5,-1377 2961.5,-1294 3104.5,-1294 3104.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol &lt;= 117.5</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.722</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 171&#45;&gt;172 -->\n<g id=\"edge172\" class=\"edge\">\n<title>171&#45;&gt;172</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3075.45,-1412.91C3070.61,-1404.2 3065.44,-1394.9 3060.44,-1385.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3063.43,-1384.06 3055.51,-1377.02 3057.31,-1387.46 3063.43,-1384.06\"/>\n</g>\n<!-- 177 -->\n<g id=\"node178\" class=\"node\">\n<title>177</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"3219,-1369.5 3123,-1369.5 3123,-1301.5 3219,-1301.5 3219,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"3171\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3171\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"3171\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n<text text-anchor=\"middle\" x=\"3171\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 171&#45;&gt;177 -->\n<g id=\"edge177\" class=\"edge\">\n<title>171&#45;&gt;177</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3123.33,-1412.91C3130.28,-1401.76 3137.83,-1389.66 3144.83,-1378.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3147.98,-1380 3150.31,-1369.67 3142.04,-1376.3 3147.98,-1380\"/>\n</g>\n<!-- 173 -->\n<g id=\"node174\" class=\"node\">\n<title>173</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"3081,-1250.5 2985,-1250.5 2985,-1182.5 3081,-1182.5 3081,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n<text text-anchor=\"middle\" x=\"3033\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 172&#45;&gt;173 -->\n<g id=\"edge173\" class=\"edge\">\n<title>172&#45;&gt;173</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3033,-1293.91C3033,-1283.2 3033,-1271.62 3033,-1260.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3036.5,-1260.67 3033,-1250.67 3029.5,-1260.67 3036.5,-1260.67\"/>\n</g>\n<!-- 174 -->\n<g id=\"node175\" class=\"node\">\n<title>174</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"3212.5,-1258 3099.5,-1258 3099.5,-1175 3212.5,-1175 3212.5,-1258\"/>\n<text text-anchor=\"middle\" x=\"3156\" y=\"-1242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxHR &lt;= 63.0</text>\n<text text-anchor=\"middle\" x=\"3156\" y=\"-1227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"3156\" y=\"-1212.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"3156\" y=\"-1197.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"middle\" x=\"3156\" y=\"-1182.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 172&#45;&gt;174 -->\n<g id=\"edge174\" class=\"edge\">\n<title>172&#45;&gt;174</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3075.67,-1293.91C3085.5,-1284.56 3096.04,-1274.54 3106.14,-1264.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3108.57,-1267.45 3113.4,-1258.02 3103.74,-1262.38 3108.57,-1267.45\"/>\n</g>\n<!-- 175 -->\n<g id=\"node176\" class=\"node\">\n<title>175</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"3147,-1131.5 3051,-1131.5 3051,-1063.5 3147,-1063.5 3147,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"3099\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3099\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"3099\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"3099\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 174&#45;&gt;175 -->\n<g id=\"edge175\" class=\"edge\">\n<title>174&#45;&gt;175</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3136.22,-1174.91C3130.85,-1163.87 3125.01,-1151.9 3119.59,-1140.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3122.68,-1139.12 3115.16,-1131.67 3116.39,-1142.19 3122.68,-1139.12\"/>\n</g>\n<!-- 176 -->\n<g id=\"node177\" class=\"node\">\n<title>176</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"3261,-1131.5 3165,-1131.5 3165,-1063.5 3261,-1063.5 3261,-1131.5\"/>\n<text text-anchor=\"middle\" x=\"3213\" y=\"-1116.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3213\" y=\"-1101.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"3213\" y=\"-1086.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n<text text-anchor=\"middle\" x=\"3213\" y=\"-1071.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 174&#45;&gt;176 -->\n<g id=\"edge176\" class=\"edge\">\n<title>174&#45;&gt;176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3175.78,-1174.91C3181.15,-1163.87 3186.99,-1151.9 3192.41,-1140.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3195.61,-1142.19 3196.84,-1131.67 3189.32,-1139.12 3195.61,-1142.19\"/>\n</g>\n<!-- 179 -->\n<g id=\"node180\" class=\"node\">\n<title>179</title>\n<polygon fill=\"#9ccef2\" stroke=\"black\" points=\"3390.5,-1377 3237.5,-1377 3237.5,-1294 3390.5,-1294 3390.5,-1377\"/>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1361.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ExerciseAngina &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1346.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1331.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1316.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n<text text-anchor=\"middle\" x=\"3314\" y=\"-1301.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 178&#45;&gt;179 -->\n<g id=\"edge179\" class=\"edge\">\n<title>178&#45;&gt;179</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3314,-1412.91C3314,-1404.65 3314,-1395.86 3314,-1387.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3317.5,-1387.02 3314,-1377.02 3310.5,-1387.02 3317.5,-1387.02\"/>\n</g>\n<!-- 182 -->\n<g id=\"node183\" class=\"node\">\n<title>182</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"3511,-1369.5 3409,-1369.5 3409,-1301.5 3511,-1301.5 3511,-1369.5\"/>\n<text text-anchor=\"middle\" x=\"3460\" y=\"-1354.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3460\" y=\"-1339.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"middle\" x=\"3460\" y=\"-1324.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 0]</text>\n<text text-anchor=\"middle\" x=\"3460\" y=\"-1309.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 178&#45;&gt;182 -->\n<g id=\"edge182\" class=\"edge\">\n<title>178&#45;&gt;182</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3364.65,-1412.91C3379.53,-1400.99 3395.77,-1387.98 3410.56,-1376.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3413,-1378.65 3418.61,-1369.67 3408.62,-1373.19 3413,-1378.65\"/>\n</g>\n<!-- 180 -->\n<g id=\"node181\" class=\"node\">\n<title>180</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"3345,-1250.5 3249,-1250.5 3249,-1182.5 3345,-1182.5 3345,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"3297\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3297\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"3297\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n<text text-anchor=\"middle\" x=\"3297\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = e</text>\n</g>\n<!-- 179&#45;&gt;180 -->\n<g id=\"edge180\" class=\"edge\">\n<title>179&#45;&gt;180</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3308.1,-1293.91C3306.55,-1283.2 3304.86,-1271.62 3303.29,-1260.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3306.72,-1260.06 3301.82,-1250.67 3299.79,-1261.07 3306.72,-1260.06\"/>\n</g>\n<!-- 181 -->\n<g id=\"node182\" class=\"node\">\n<title>181</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"3459,-1250.5 3363,-1250.5 3363,-1182.5 3459,-1182.5 3459,-1250.5\"/>\n<text text-anchor=\"middle\" x=\"3411\" y=\"-1235.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"3411\" y=\"-1220.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"3411\" y=\"-1205.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n<text text-anchor=\"middle\" x=\"3411\" y=\"-1190.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = H</text>\n</g>\n<!-- 179&#45;&gt;181 -->\n<g id=\"edge181\" class=\"edge\">\n<title>179&#45;&gt;181</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3347.65,-1293.91C3357.17,-1282.43 3367.53,-1269.94 3377.06,-1258.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3379.81,-1260.6 3383.5,-1250.67 3374.43,-1256.13 3379.81,-1260.6\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7c23d559e6e0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import graphviz\n",
        "from sklearn import tree\n",
        "# DOT data\n",
        "dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                                feature_names=feature_col_tree,\n",
        "                                class_names=target,\n",
        "                                filled=True)\n",
        "\n",
        "# Draw graph\n",
        "graph = graphviz.Source(dot_data, format=\"png\")\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_gVG0oiZJeB"
      },
      "source": [
        "# K-fold Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgVj74lCZOpl",
        "outputId": "b66e3751-6554-4e1f-8d20-ce7289e6fc58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7632753985020166, 0.7885827271780306, 0.7758628927452029, 0.7451373401328654, 0.7786754556895222, 0.7593965218596932, 0.7755802841970122, 0.7676809273586542, 0.7875102821616452, 0.7785622199176901, 0.7869302759863636, 0.7815619631609086, 0.7785329664640007, 0.7901071876562072, 0.7989159429280397, 0.8036663286004055, 0.7797671780992619, 0.7940242019189389, 0.7987142857142856, 0.7923830409356727, 0.776235611261355, 0.7831503627400436, 0.7991168689698102, 0.7840042016806723, 0.7906545209176786, 0.7974009096816116, 0.7953559493973027, 0.7825831482018093, 0.7882164404223228, 0.7985747648935504, 0.7885216346153846, 0.7882430069930071, 0.802510234863176, 0.7934755720470007, 0.7910293410293412, 0.797881172881173, 0.7845404595404595, 0.7873856912318452, 0.7773732517482517, 0.7931519699812384, 0.7879171754171753, 0.7897639182522905, 0.7805670339761247, 0.7968742985409653, 0.7870004391743524, 0.7876262626262627, 0.7886468855218856, 0.7877319109461965, 0.7867575757575755]\n"
          ]
        }
      ],
      "source": [
        "feature_col_tree=df_tree.columns.to_list()\n",
        "feature_col_tree.remove(target)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "acc_aver_Dtree = []\n",
        "\n",
        "for i in range(2,51):\n",
        "  acc_Dtree = []\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "      X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "      y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "      y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "      clf=DecisionTreeClassifier(criterion=\"entropy\")\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_Dtree.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "  acc_aver_Dtree.append(Average(acc_Dtree))\n",
        "print(acc_aver_Dtree)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D5w7Ut2UFya",
        "outputId": "a7a2d134-ee80-4161-fb3e-c09de88ce25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8036663286004055\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "print((max(acc_aver_Dtree)))\n",
        "print(acc_aver_Dtree.index((max(acc_aver_Dtree)))+1)\n",
        "#print(acc_aver_Dtree.index(0.8534884599478273)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "OxSiG25WaeTM",
        "outputId": "c4627bde-8eff-425a-ad0f-acb9262a67b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(k_value,acc_aver_Dtree,'ro-')\n",
        "plt.title(\"Tree Base Algorithm\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHmivSGzTY16"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrLq8UgTTaIo",
        "outputId": "ac1657f8-dd14-495b-8555-d30fdbd56976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85        82\n",
            "           1       0.92      0.81      0.86       102\n",
            "\n",
            "    accuracy                           0.86       184\n",
            "   macro avg       0.86      0.86      0.86       184\n",
            "weighted avg       0.87      0.86      0.86       184\n",
            "\n",
            "The accuracy for 1 : 0.864179818268771\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84        82\n",
            "           1       0.91      0.80      0.85       102\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.85      0.85      0.85       184\n",
            "weighted avg       0.86      0.85      0.85       184\n",
            "\n",
            "The accuracy for 2 : 0.8531802965088474\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.62      0.76        82\n",
            "           1       0.77      0.99      0.86       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.87      0.81      0.81       184\n",
            "weighted avg       0.86      0.83      0.82       184\n",
            "\n",
            "The accuracy for 3 : 0.8060736489717839\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.77      0.82        82\n",
            "           1       0.83      0.92      0.87       101\n",
            "\n",
            "    accuracy                           0.85       183\n",
            "   macro avg       0.86      0.84      0.85       183\n",
            "weighted avg       0.86      0.85      0.85       183\n",
            "\n",
            "The accuracy for 4 : 0.844542381067375\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.82      0.76        82\n",
            "           1       0.83      0.73      0.78       101\n",
            "\n",
            "    accuracy                           0.77       183\n",
            "   macro avg       0.77      0.77      0.77       183\n",
            "weighted avg       0.78      0.77      0.77       183\n",
            "\n",
            "The accuracy for 5 : 0.77487321902922\n",
            "0.8285698727691994\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "acc_RandF=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "    X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "    y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "    y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "    clf=RandomForestClassifier(n_estimators=200,criterion=\"entropy\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_RandF.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "print(Average(acc_RandF))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYfTKUqYdhsH"
      },
      "source": [
        "# K-fold Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "uDnTMfDZdib5",
        "outputId": "923874a5-1a98-4eae-b4c6-c83febe2e51d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-9c17dc08bf95>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m#print(f\"The fold is : {fold} : \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "acc_aver_RandF = []\n",
        "for i in range(2,51):\n",
        "  acc_RandF=[]\n",
        "  kf=model_selection.StratifiedKFold(n_splits=i)\n",
        "  for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "      X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "      y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "      X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "      y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "      clf=RandomForestClassifier(n_estimators=200,criterion=\"entropy\")\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred=clf.predict(X_valid)\n",
        "      #print(f\"The fold is : {fold} : \")\n",
        "      #print(classification_report(y_valid,y_pred))\n",
        "      acc=roc_auc_score(y_valid,y_pred)\n",
        "      acc_RandF.append(acc)\n",
        "      #print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "  acc_aver_RandF.append(Average(acc_RandF))\n",
        "print(acc_aver_RandF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCI9Cq78UYQu"
      },
      "outputs": [],
      "source": [
        "print((max(acc_aver_RandF)))\n",
        "print(acc_aver_RandF.index((max(acc_aver_RandF)))+1)\n",
        "print(acc_aver_RandF.index(0.8649405575531495)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9z97OPgd9ma"
      },
      "outputs": [],
      "source": [
        "plt.plot(k_value,acc_aver_RandF,'ro-')\n",
        "plt.title(\"Random Forest Classifier\")\n",
        "plt.xlabel(\"Average Accuracy value\")\n",
        "plt.ylabel(\"K Fold value\")\n",
        "plt.grid(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFarCodRTiAM"
      },
      "outputs": [],
      "source": [
        "## Checking Feature importance\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "importance = clf.feature_importances_\n",
        "idxs = np.argsort(importance)\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.barh(range(len(idxs)),importance[idxs],align=\"center\")\n",
        "plt.yticks(range(len(idxs)),[feature_col_tree[i] for i in idxs])\n",
        "plt.xlabel(\"Random Forest Feature Importance\")\n",
        "#plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsmMCUolToUO"
      },
      "source": [
        "# XGBoost\n",
        "XGBoost (eXtreme Gradient Boosting) is an optimized and scalable implementation of gradient boosting for tree-based models. It is designed for both efficiency and performance and is widely used for large-scale machine learning tasks such as classification and regression.\n",
        "\n",
        "XGBoost is notable for its parallel processing capabilities, its ability to handle missing data, and its advanced features for model tuning. Additionally, it provides a flexible and expressive syntax for defining models, making it accessible to both novice and expert users."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters Tuning**\n",
        "- Tree-specific parameters : *max_depth,min_child_weight, gamma, subsample, colsample_bytree*\n",
        "- Regularization parameters : *lambda, alpha*\n",
        "- Learning rate"
      ],
      "metadata": {
        "id": "7IuDD4pSRviK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_test1 = {\n",
        "   # 'max_depth' : range(3,10,1),\n",
        "    #'min_child_weight' : range(0,20,1),\n",
        "    #'gamma' : [i/10 for i in range(0,10)],\n",
        "    #'subsample' : [i/10 for i in range(5,10)],\n",
        "    #'colsample_bytree' : [i/10 for i in range(5,10)],\n",
        "    #'alpha' : [1e-5, 1e-2, 0.1, 1 ,100],\n",
        "    #'lambda' : [1e-5, 1e-2, 0.1, 1 ,100],\n",
        "    #'learning_rate' : [0.1,0.01,0.001]\n",
        "    #'n_estimators' : [1,10,50,100,500,1000]\n",
        "}\n",
        "X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "clf=XGBClassifier(learning_rate =0.1)\n",
        "grid_search = GridSearchCV(clf, param_test1, cv=5, scoring='accuracy')\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_GX1goiKvn7",
        "outputId": "88151a68-5f31-4667-ff82-c96af4bf7811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best set of hyperparameters:  {}\n",
            "Best score:  0.8329545454545455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification**"
      ],
      "metadata": {
        "id": "D4-k_l_MSq80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-_xyoHYTp6q",
        "outputId": "c4183e55-80f9-469d-ab67-fe3f2786b492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.87        82\n",
            "           1       0.92      0.85      0.88       102\n",
            "\n",
            "    accuracy                           0.88       184\n",
            "   macro avg       0.87      0.88      0.87       184\n",
            "weighted avg       0.88      0.88      0.88       184\n",
            "\n",
            "The accuracy for 1 : 0.8776901004304162\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.93      0.84        82\n",
            "           1       0.93      0.76      0.84       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "The accuracy for 2 : 0.845767575322812\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.70      0.80        82\n",
            "           1       0.80      0.97      0.88       102\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.87      0.83      0.84       184\n",
            "weighted avg       0.87      0.85      0.84       184\n",
            "\n",
            "The accuracy for 3 : 0.832855093256815\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80        82\n",
            "           1       0.82      0.89      0.85       101\n",
            "\n",
            "    accuracy                           0.83       183\n",
            "   macro avg       0.83      0.82      0.83       183\n",
            "weighted avg       0.83      0.83      0.83       183\n",
            "\n",
            "The accuracy for 4 : 0.8235933349432504\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71        82\n",
            "           1       0.77      0.73      0.75       101\n",
            "\n",
            "    accuracy                           0.73       183\n",
            "   macro avg       0.73      0.73      0.73       183\n",
            "weighted avg       0.73      0.73      0.73       183\n",
            "\n",
            "The accuracy for 5 : 0.7321902921999517\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "acc_XGB=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "    X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "    y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "    y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "    clf=XGBClassifier(learning_rate =0.1, max_depth=5, min_child_weight=15,\n",
        "                      gamma=0.6, subsample=0.9,colsample_bytree=0.8,\n",
        "                      reg_alpha=0.01,reg_lambda = 100)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_XGB.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzH7XIQnx4DB"
      },
      "source": [
        "**Average Accuracy of XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCt2k8Zux2AG",
        "outputId": "601334ad-0b8b-4c1d-86da-d11020860986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8224192792306491\n"
          ]
        }
      ],
      "source": [
        "print(Average(acc_XGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh0JxpW1Tv7q"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(30, 30))\n",
        "from xgboost import plot_tree\n",
        "plot_tree(clf,num_trees=0,rankdir=\"LR\",ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFkkRO_AmrzG"
      },
      "source": [
        "# CatBoost\n",
        "CatBoost is a gradient boosting library that is well suited for working with categorical data. It is an open-source library developed by Yandex and is designed to be fast and scalable for large datasets.\n",
        "\n",
        "One of the main features of CatBoost is its ability to handle categorical features without the need for one-hot encoding. This is achieved by using an ordered encoding of the categorical features and incorporating the order information into the learning process. This approach results in more accurate models and reduced overfitting, compared to traditional one-hot encoding methods.\n",
        "\n",
        "CatBoost also includes advanced features for model tuning, such as support for parallel computing, various loss functions, and an efficient implementation of the gradient boosting algorithm. It also provides a simple and intuitive API for defining and training models, making it accessible to both novice and expert users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwrFqAqnp-Z6",
        "outputId": "09a74833-1dc1-4976-f186-2d623b09f34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "#catboost library installation\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning**"
      ],
      "metadata": {
        "id": "9ULtO9Ai-t_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_test1 = {\n",
        "               'iterations' : [i for i in range(0,50)]\n",
        "}\n",
        "X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "clf=CatBoostClassifier(learning_rate = 1, l2_leaf_reg = 24, depth = 8)\n",
        "grid_search = GridSearchCV(clf, param_test1, cv=5, scoring='accuracy')\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mvROJYm-xw2",
        "outputId": "cbffcc8c-e5a2-4dff-9e31-413c78adb6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "14:\tlearn: 0.2747341\ttotal: 31.8ms\tremaining: 14.8ms\n",
            "15:\tlearn: 0.2702568\ttotal: 33.3ms\tremaining: 12.5ms\n",
            "16:\tlearn: 0.2650537\ttotal: 35.1ms\tremaining: 10.3ms\n",
            "17:\tlearn: 0.2601005\ttotal: 37.3ms\tremaining: 8.28ms\n",
            "18:\tlearn: 0.2560578\ttotal: 39.3ms\tremaining: 6.2ms\n",
            "19:\tlearn: 0.2530381\ttotal: 41.1ms\tremaining: 4.11ms\n",
            "20:\tlearn: 0.2498453\ttotal: 43.4ms\tremaining: 2.06ms\n",
            "21:\tlearn: 0.2461646\ttotal: 46ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.75ms\tremaining: 36.8ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.11ms\tremaining: 21.1ms\n",
            "2:\tlearn: 0.3788145\ttotal: 3.71ms\tremaining: 23.5ms\n",
            "3:\tlearn: 0.3658016\ttotal: 5.48ms\tremaining: 24.6ms\n",
            "4:\tlearn: 0.3428474\ttotal: 6.21ms\tremaining: 21.1ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.1ms\tremaining: 18.9ms\n",
            "6:\tlearn: 0.3158416\ttotal: 8.73ms\tremaining: 18.7ms\n",
            "7:\tlearn: 0.3097739\ttotal: 11ms\tremaining: 19.3ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.4ms\tremaining: 19.4ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.2ms\tremaining: 18.2ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17ms\tremaining: 17ms\n",
            "11:\tlearn: 0.2845372\ttotal: 18.6ms\tremaining: 15.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 21.1ms\tremaining: 14.6ms\n",
            "13:\tlearn: 0.2740314\ttotal: 25.8ms\tremaining: 14.8ms\n",
            "14:\tlearn: 0.2705542\ttotal: 27.7ms\tremaining: 12.9ms\n",
            "15:\tlearn: 0.2673919\ttotal: 29.5ms\tremaining: 11.1ms\n",
            "16:\tlearn: 0.2623365\ttotal: 31.3ms\tremaining: 9.19ms\n",
            "17:\tlearn: 0.2595719\ttotal: 34.7ms\tremaining: 7.72ms\n",
            "18:\tlearn: 0.2545713\ttotal: 36.6ms\tremaining: 5.78ms\n",
            "19:\tlearn: 0.2510766\ttotal: 38.4ms\tremaining: 3.84ms\n",
            "20:\tlearn: 0.2477056\ttotal: 40.2ms\tremaining: 1.91ms\n",
            "21:\tlearn: 0.2437884\ttotal: 42.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.65ms\tremaining: 55.7ms\n",
            "1:\tlearn: 0.4107278\ttotal: 6.39ms\tremaining: 63.9ms\n",
            "2:\tlearn: 0.3698157\ttotal: 7.52ms\tremaining: 47.7ms\n",
            "3:\tlearn: 0.3518120\ttotal: 11.1ms\tremaining: 49.8ms\n",
            "4:\tlearn: 0.3441195\ttotal: 16ms\tremaining: 54.3ms\n",
            "5:\tlearn: 0.3328396\ttotal: 20.9ms\tremaining: 55.7ms\n",
            "6:\tlearn: 0.3256704\ttotal: 26.2ms\tremaining: 56.1ms\n",
            "7:\tlearn: 0.3174441\ttotal: 29.4ms\tremaining: 51.5ms\n",
            "8:\tlearn: 0.3090762\ttotal: 34.3ms\tremaining: 49.6ms\n",
            "9:\tlearn: 0.3028459\ttotal: 39.8ms\tremaining: 47.7ms\n",
            "10:\tlearn: 0.2958541\ttotal: 42.8ms\tremaining: 42.8ms\n",
            "11:\tlearn: 0.2901166\ttotal: 45.9ms\tremaining: 38.3ms\n",
            "12:\tlearn: 0.2841803\ttotal: 49.6ms\tremaining: 34.3ms\n",
            "13:\tlearn: 0.2789751\ttotal: 52.3ms\tremaining: 29.9ms\n",
            "14:\tlearn: 0.2715599\ttotal: 54.6ms\tremaining: 25.5ms\n",
            "15:\tlearn: 0.2663544\ttotal: 56.4ms\tremaining: 21.1ms\n",
            "16:\tlearn: 0.2615546\ttotal: 58.3ms\tremaining: 17.1ms\n",
            "17:\tlearn: 0.2560079\ttotal: 60ms\tremaining: 13.3ms\n",
            "18:\tlearn: 0.2507480\ttotal: 66.5ms\tremaining: 10.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 68.2ms\tremaining: 6.82ms\n",
            "20:\tlearn: 0.2413892\ttotal: 69.9ms\tremaining: 3.33ms\n",
            "21:\tlearn: 0.2378437\ttotal: 71.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 8.44ms\tremaining: 177ms\n",
            "1:\tlearn: 0.3745079\ttotal: 9.52ms\tremaining: 95.2ms\n",
            "2:\tlearn: 0.3383999\ttotal: 13.4ms\tremaining: 85ms\n",
            "3:\tlearn: 0.3266560\ttotal: 18.7ms\tremaining: 84.3ms\n",
            "4:\tlearn: 0.3080259\ttotal: 23.7ms\tremaining: 80.5ms\n",
            "5:\tlearn: 0.2907443\ttotal: 30.7ms\tremaining: 81.8ms\n",
            "6:\tlearn: 0.2818467\ttotal: 35.3ms\tremaining: 75.7ms\n",
            "7:\tlearn: 0.2691784\ttotal: 38.9ms\tremaining: 68ms\n",
            "8:\tlearn: 0.2611618\ttotal: 42.8ms\tremaining: 61.8ms\n",
            "9:\tlearn: 0.2519898\ttotal: 47.6ms\tremaining: 57.1ms\n",
            "10:\tlearn: 0.2462992\ttotal: 52.3ms\tremaining: 52.3ms\n",
            "11:\tlearn: 0.2416348\ttotal: 57.2ms\tremaining: 47.6ms\n",
            "12:\tlearn: 0.2368688\ttotal: 60ms\tremaining: 41.5ms\n",
            "13:\tlearn: 0.2320170\ttotal: 64.9ms\tremaining: 37.1ms\n",
            "14:\tlearn: 0.2262186\ttotal: 69.7ms\tremaining: 32.5ms\n",
            "15:\tlearn: 0.2215380\ttotal: 74.6ms\tremaining: 28ms\n",
            "16:\tlearn: 0.2176313\ttotal: 79.7ms\tremaining: 23.4ms\n",
            "17:\tlearn: 0.2138494\ttotal: 85.6ms\tremaining: 19ms\n",
            "18:\tlearn: 0.2100966\ttotal: 89.9ms\tremaining: 14.2ms\n",
            "19:\tlearn: 0.2068557\ttotal: 94.9ms\tremaining: 9.49ms\n",
            "20:\tlearn: 0.2029945\ttotal: 100ms\tremaining: 4.76ms\n",
            "21:\tlearn: 0.2001044\ttotal: 105ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 2.61ms\tremaining: 54.8ms\n",
            "1:\tlearn: 0.3687510\ttotal: 6.43ms\tremaining: 64.3ms\n",
            "2:\tlearn: 0.3203557\ttotal: 8.16ms\tremaining: 51.7ms\n",
            "3:\tlearn: 0.3063743\ttotal: 11.2ms\tremaining: 50.2ms\n",
            "4:\tlearn: 0.2970911\ttotal: 16.6ms\tremaining: 56.3ms\n",
            "5:\tlearn: 0.2891054\ttotal: 21.4ms\tremaining: 57ms\n",
            "6:\tlearn: 0.2792409\ttotal: 26.1ms\tremaining: 55.9ms\n",
            "7:\tlearn: 0.2716618\ttotal: 31ms\tremaining: 54.2ms\n",
            "8:\tlearn: 0.2621352\ttotal: 35.7ms\tremaining: 51.6ms\n",
            "9:\tlearn: 0.2537973\ttotal: 40.5ms\tremaining: 48.5ms\n",
            "10:\tlearn: 0.2473429\ttotal: 45.1ms\tremaining: 45.1ms\n",
            "11:\tlearn: 0.2416695\ttotal: 51.1ms\tremaining: 42.6ms\n",
            "12:\tlearn: 0.2366343\ttotal: 55.1ms\tremaining: 38.1ms\n",
            "13:\tlearn: 0.2298385\ttotal: 60ms\tremaining: 34.3ms\n",
            "14:\tlearn: 0.2249545\ttotal: 64.8ms\tremaining: 30.3ms\n",
            "15:\tlearn: 0.2192054\ttotal: 69.9ms\tremaining: 26.2ms\n",
            "16:\tlearn: 0.2150242\ttotal: 74.5ms\tremaining: 21.9ms\n",
            "17:\tlearn: 0.2094516\ttotal: 82.5ms\tremaining: 18.3ms\n",
            "18:\tlearn: 0.2056324\ttotal: 88.1ms\tremaining: 13.9ms\n",
            "19:\tlearn: 0.2021225\ttotal: 91.5ms\tremaining: 9.15ms\n",
            "20:\tlearn: 0.1989042\ttotal: 98.4ms\tremaining: 4.68ms\n",
            "21:\tlearn: 0.1961040\ttotal: 103ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 5.95ms\tremaining: 131ms\n",
            "1:\tlearn: 0.4229987\ttotal: 7.24ms\tremaining: 76ms\n",
            "2:\tlearn: 0.3843342\ttotal: 11.2ms\tremaining: 74.8ms\n",
            "3:\tlearn: 0.3652888\ttotal: 16.7ms\tremaining: 79.2ms\n",
            "4:\tlearn: 0.3496343\ttotal: 19.9ms\tremaining: 71.7ms\n",
            "5:\tlearn: 0.3393969\ttotal: 24.8ms\tremaining: 70.2ms\n",
            "6:\tlearn: 0.3300914\ttotal: 29.6ms\tremaining: 67.6ms\n",
            "7:\tlearn: 0.3229079\ttotal: 34.3ms\tremaining: 64.3ms\n",
            "8:\tlearn: 0.3148279\ttotal: 39ms\tremaining: 60.6ms\n",
            "9:\tlearn: 0.3054626\ttotal: 43.7ms\tremaining: 56.9ms\n",
            "10:\tlearn: 0.2983658\ttotal: 48.7ms\tremaining: 53.1ms\n",
            "11:\tlearn: 0.2903440\ttotal: 57.9ms\tremaining: 53ms\n",
            "12:\tlearn: 0.2852979\ttotal: 60.4ms\tremaining: 46.5ms\n",
            "13:\tlearn: 0.2798563\ttotal: 65ms\tremaining: 41.8ms\n",
            "14:\tlearn: 0.2747341\ttotal: 66.8ms\tremaining: 35.6ms\n",
            "15:\tlearn: 0.2702568\ttotal: 68.5ms\tremaining: 29.9ms\n",
            "16:\tlearn: 0.2650537\ttotal: 70.5ms\tremaining: 24.9ms\n",
            "17:\tlearn: 0.2601005\ttotal: 73ms\tremaining: 20.3ms\n",
            "18:\tlearn: 0.2560578\ttotal: 74.7ms\tremaining: 15.7ms\n",
            "19:\tlearn: 0.2530381\ttotal: 76.3ms\tremaining: 11.4ms\n",
            "20:\tlearn: 0.2498453\ttotal: 77.8ms\tremaining: 7.41ms\n",
            "21:\tlearn: 0.2461646\ttotal: 79.8ms\tremaining: 3.63ms\n",
            "22:\tlearn: 0.2424369\ttotal: 82.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.83ms\tremaining: 40.3ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.2ms\tremaining: 23.1ms\n",
            "2:\tlearn: 0.3788145\ttotal: 3.94ms\tremaining: 26.2ms\n",
            "3:\tlearn: 0.3658016\ttotal: 5.69ms\tremaining: 27ms\n",
            "4:\tlearn: 0.3428474\ttotal: 6.5ms\tremaining: 23.4ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.45ms\tremaining: 21.1ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10.1ms\tremaining: 23ms\n",
            "7:\tlearn: 0.3097739\ttotal: 11.8ms\tremaining: 22.2ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.6ms\tremaining: 21.2ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.4ms\tremaining: 20ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17.7ms\tremaining: 19.3ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.2ms\tremaining: 18.6ms\n",
            "12:\tlearn: 0.2794184\ttotal: 22.1ms\tremaining: 17ms\n",
            "13:\tlearn: 0.2740314\ttotal: 23.9ms\tremaining: 15.4ms\n",
            "14:\tlearn: 0.2705542\ttotal: 25.9ms\tremaining: 13.8ms\n",
            "15:\tlearn: 0.2673919\ttotal: 27.9ms\tremaining: 12.2ms\n",
            "16:\tlearn: 0.2623365\ttotal: 30.4ms\tremaining: 10.7ms\n",
            "17:\tlearn: 0.2595719\ttotal: 32.8ms\tremaining: 9.11ms\n",
            "18:\tlearn: 0.2545713\ttotal: 34.6ms\tremaining: 7.28ms\n",
            "19:\tlearn: 0.2510766\ttotal: 36.4ms\tremaining: 5.46ms\n",
            "20:\tlearn: 0.2477056\ttotal: 38.3ms\tremaining: 3.65ms\n",
            "21:\tlearn: 0.2437884\ttotal: 40.9ms\tremaining: 1.86ms\n",
            "22:\tlearn: 0.2404080\ttotal: 42.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.74ms\tremaining: 38.2ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.12ms\tremaining: 22.3ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.62ms\tremaining: 17.5ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.4ms\tremaining: 20.9ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.52ms\tremaining: 23.5ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.04ms\tremaining: 25.6ms\n",
            "6:\tlearn: 0.3256704\ttotal: 10.8ms\tremaining: 24.7ms\n",
            "7:\tlearn: 0.3174441\ttotal: 12.6ms\tremaining: 23.6ms\n",
            "8:\tlearn: 0.3090762\ttotal: 14.3ms\tremaining: 22.3ms\n",
            "9:\tlearn: 0.3028459\ttotal: 16.2ms\tremaining: 21ms\n",
            "10:\tlearn: 0.2958541\ttotal: 18.7ms\tremaining: 20.4ms\n",
            "11:\tlearn: 0.2901166\ttotal: 20.7ms\tremaining: 19ms\n",
            "12:\tlearn: 0.2841803\ttotal: 22.6ms\tremaining: 17.3ms\n",
            "13:\tlearn: 0.2789751\ttotal: 24.3ms\tremaining: 15.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 26.7ms\tremaining: 14.3ms\n",
            "15:\tlearn: 0.2663544\ttotal: 29.4ms\tremaining: 12.8ms\n",
            "16:\tlearn: 0.2615546\ttotal: 31.3ms\tremaining: 11ms\n",
            "17:\tlearn: 0.2560079\ttotal: 33.1ms\tremaining: 9.21ms\n",
            "18:\tlearn: 0.2507480\ttotal: 34.9ms\tremaining: 7.35ms\n",
            "19:\tlearn: 0.2450678\ttotal: 37.4ms\tremaining: 5.6ms\n",
            "20:\tlearn: 0.2413892\ttotal: 39.7ms\tremaining: 3.78ms\n",
            "21:\tlearn: 0.2378437\ttotal: 41.5ms\tremaining: 1.89ms\n",
            "22:\tlearn: 0.2344010\ttotal: 43.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.81ms\tremaining: 39.8ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.18ms\tremaining: 22.9ms\n",
            "2:\tlearn: 0.3383999\ttotal: 3.94ms\tremaining: 26.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 5.75ms\tremaining: 27.3ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.25ms\tremaining: 29.7ms\n",
            "5:\tlearn: 0.2907443\ttotal: 10.3ms\tremaining: 29.3ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12.1ms\tremaining: 27.7ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.2ms\tremaining: 24.8ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15ms\tremaining: 23.4ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.6ms\tremaining: 22.9ms\n",
            "10:\tlearn: 0.2462992\ttotal: 20ms\tremaining: 21.8ms\n",
            "11:\tlearn: 0.2416348\ttotal: 21.7ms\tremaining: 19.9ms\n",
            "12:\tlearn: 0.2368688\ttotal: 23.4ms\tremaining: 18ms\n",
            "13:\tlearn: 0.2320170\ttotal: 25.2ms\tremaining: 16.2ms\n",
            "14:\tlearn: 0.2262186\ttotal: 27.9ms\tremaining: 14.9ms\n",
            "15:\tlearn: 0.2215380\ttotal: 34.9ms\tremaining: 15.2ms\n",
            "16:\tlearn: 0.2176313\ttotal: 36.7ms\tremaining: 13ms\n",
            "17:\tlearn: 0.2138494\ttotal: 38.4ms\tremaining: 10.7ms\n",
            "18:\tlearn: 0.2100966\ttotal: 40.2ms\tremaining: 8.46ms\n",
            "19:\tlearn: 0.2068557\ttotal: 42.8ms\tremaining: 6.42ms\n",
            "20:\tlearn: 0.2029945\ttotal: 45.1ms\tremaining: 4.29ms\n",
            "21:\tlearn: 0.2001044\ttotal: 46.8ms\tremaining: 2.13ms\n",
            "22:\tlearn: 0.1970766\ttotal: 48.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.92ms\tremaining: 42.1ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.29ms\tremaining: 24.1ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.77ms\tremaining: 18.5ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.54ms\tremaining: 21.6ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.81ms\tremaining: 24.5ms\n",
            "5:\tlearn: 0.2891054\ttotal: 9.2ms\tremaining: 26.1ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.9ms\tremaining: 24.8ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.7ms\tremaining: 23.9ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.8ms\tremaining: 23ms\n",
            "9:\tlearn: 0.2537973\ttotal: 17.8ms\tremaining: 23.1ms\n",
            "10:\tlearn: 0.2473429\ttotal: 19.6ms\tremaining: 21.4ms\n",
            "11:\tlearn: 0.2416695\ttotal: 21.5ms\tremaining: 19.7ms\n",
            "12:\tlearn: 0.2366343\ttotal: 23.4ms\tremaining: 18ms\n",
            "13:\tlearn: 0.2298385\ttotal: 26.1ms\tremaining: 16.8ms\n",
            "14:\tlearn: 0.2249545\ttotal: 27.9ms\tremaining: 14.9ms\n",
            "15:\tlearn: 0.2192054\ttotal: 29.8ms\tremaining: 13ms\n",
            "16:\tlearn: 0.2150242\ttotal: 31.5ms\tremaining: 11.1ms\n",
            "17:\tlearn: 0.2094516\ttotal: 33.9ms\tremaining: 9.42ms\n",
            "18:\tlearn: 0.2056324\ttotal: 36.2ms\tremaining: 7.63ms\n",
            "19:\tlearn: 0.2021225\ttotal: 37.9ms\tremaining: 5.68ms\n",
            "20:\tlearn: 0.1989042\ttotal: 39.5ms\tremaining: 3.76ms\n",
            "21:\tlearn: 0.1961040\ttotal: 41.3ms\tremaining: 1.88ms\n",
            "22:\tlearn: 0.1934794\ttotal: 43.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 3.69ms\tremaining: 85ms\n",
            "1:\tlearn: 0.4229987\ttotal: 5.06ms\tremaining: 55.7ms\n",
            "2:\tlearn: 0.3843342\ttotal: 8.54ms\tremaining: 59.8ms\n",
            "3:\tlearn: 0.3652888\ttotal: 11.5ms\tremaining: 57.7ms\n",
            "4:\tlearn: 0.3496343\ttotal: 16.6ms\tremaining: 62.9ms\n",
            "5:\tlearn: 0.3393969\ttotal: 21.2ms\tremaining: 63.6ms\n",
            "6:\tlearn: 0.3300914\ttotal: 32.3ms\tremaining: 78.3ms\n",
            "7:\tlearn: 0.3229079\ttotal: 34.4ms\tremaining: 68.8ms\n",
            "8:\tlearn: 0.3148279\ttotal: 37.5ms\tremaining: 62.5ms\n",
            "9:\tlearn: 0.3054626\ttotal: 40.2ms\tremaining: 56.3ms\n",
            "10:\tlearn: 0.2983658\ttotal: 42.8ms\tremaining: 50.5ms\n",
            "11:\tlearn: 0.2903440\ttotal: 46.4ms\tremaining: 46.4ms\n",
            "12:\tlearn: 0.2852979\ttotal: 53ms\tremaining: 44.8ms\n",
            "13:\tlearn: 0.2798563\ttotal: 57.2ms\tremaining: 40.8ms\n",
            "14:\tlearn: 0.2747341\ttotal: 59.8ms\tremaining: 35.9ms\n",
            "15:\tlearn: 0.2702568\ttotal: 64.9ms\tremaining: 32.4ms\n",
            "16:\tlearn: 0.2650537\ttotal: 69.4ms\tremaining: 28.6ms\n",
            "17:\tlearn: 0.2601005\ttotal: 74.1ms\tremaining: 24.7ms\n",
            "18:\tlearn: 0.2560578\ttotal: 79.2ms\tremaining: 20.8ms\n",
            "19:\tlearn: 0.2530381\ttotal: 81.7ms\tremaining: 16.3ms\n",
            "20:\tlearn: 0.2498453\ttotal: 83.8ms\tremaining: 12ms\n",
            "21:\tlearn: 0.2461646\ttotal: 85.4ms\tremaining: 7.77ms\n",
            "22:\tlearn: 0.2424369\ttotal: 87ms\tremaining: 3.78ms\n",
            "23:\tlearn: 0.2392835\ttotal: 88.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.88ms\tremaining: 43.3ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.23ms\tremaining: 24.5ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.97ms\tremaining: 34.8ms\n",
            "3:\tlearn: 0.3658016\ttotal: 7.08ms\tremaining: 35.4ms\n",
            "4:\tlearn: 0.3428474\ttotal: 8.08ms\tremaining: 30.7ms\n",
            "5:\tlearn: 0.3234303\ttotal: 9.14ms\tremaining: 27.4ms\n",
            "6:\tlearn: 0.3158416\ttotal: 11.1ms\tremaining: 26.9ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12.9ms\tremaining: 25.8ms\n",
            "8:\tlearn: 0.3040041\ttotal: 14.7ms\tremaining: 24.5ms\n",
            "9:\tlearn: 0.2975585\ttotal: 16.6ms\tremaining: 23.2ms\n",
            "10:\tlearn: 0.2898709\ttotal: 19.2ms\tremaining: 22.7ms\n",
            "11:\tlearn: 0.2845372\ttotal: 21.3ms\tremaining: 21.3ms\n",
            "12:\tlearn: 0.2794184\ttotal: 23.1ms\tremaining: 19.6ms\n",
            "13:\tlearn: 0.2740314\ttotal: 24.9ms\tremaining: 17.8ms\n",
            "14:\tlearn: 0.2705542\ttotal: 26.8ms\tremaining: 16.1ms\n",
            "15:\tlearn: 0.2673919\ttotal: 29.2ms\tremaining: 14.6ms\n",
            "16:\tlearn: 0.2623365\ttotal: 34.9ms\tremaining: 14.4ms\n",
            "17:\tlearn: 0.2595719\ttotal: 36.8ms\tremaining: 12.3ms\n",
            "18:\tlearn: 0.2545713\ttotal: 38.5ms\tremaining: 10.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 41ms\tremaining: 8.2ms\n",
            "20:\tlearn: 0.2477056\ttotal: 42.6ms\tremaining: 6.09ms\n",
            "21:\tlearn: 0.2437884\ttotal: 45.2ms\tremaining: 4.11ms\n",
            "22:\tlearn: 0.2404080\ttotal: 47.2ms\tremaining: 2.05ms\n",
            "23:\tlearn: 0.2369058\ttotal: 48.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.71ms\tremaining: 39.4ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.07ms\tremaining: 22.8ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.57ms\tremaining: 18ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.44ms\tremaining: 22.2ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.1ms\tremaining: 23.2ms\n",
            "5:\tlearn: 0.3328396\ttotal: 16.3ms\tremaining: 48.8ms\n",
            "6:\tlearn: 0.3256704\ttotal: 18ms\tremaining: 43.6ms\n",
            "7:\tlearn: 0.3174441\ttotal: 25.9ms\tremaining: 51.9ms\n",
            "8:\tlearn: 0.3090762\ttotal: 27.7ms\tremaining: 46.2ms\n",
            "9:\tlearn: 0.3028459\ttotal: 29.5ms\tremaining: 41.3ms\n",
            "10:\tlearn: 0.2958541\ttotal: 31.6ms\tremaining: 37.3ms\n",
            "11:\tlearn: 0.2901166\ttotal: 34.2ms\tremaining: 34.2ms\n",
            "12:\tlearn: 0.2841803\ttotal: 36.2ms\tremaining: 30.6ms\n",
            "13:\tlearn: 0.2789751\ttotal: 37.8ms\tremaining: 27ms\n",
            "14:\tlearn: 0.2715599\ttotal: 39.7ms\tremaining: 23.8ms\n",
            "15:\tlearn: 0.2663544\ttotal: 41.5ms\tremaining: 20.7ms\n",
            "16:\tlearn: 0.2615546\ttotal: 43.6ms\tremaining: 17.9ms\n",
            "17:\tlearn: 0.2560079\ttotal: 45.3ms\tremaining: 15.1ms\n",
            "18:\tlearn: 0.2507480\ttotal: 47.7ms\tremaining: 12.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 49.9ms\tremaining: 9.99ms\n",
            "20:\tlearn: 0.2413892\ttotal: 51.5ms\tremaining: 7.36ms\n",
            "21:\tlearn: 0.2378437\ttotal: 53.1ms\tremaining: 4.83ms\n",
            "22:\tlearn: 0.2344010\ttotal: 54.8ms\tremaining: 2.38ms\n",
            "23:\tlearn: 0.2304940\ttotal: 56.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.74ms\tremaining: 39.9ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.13ms\tremaining: 23.4ms\n",
            "2:\tlearn: 0.3383999\ttotal: 3.76ms\tremaining: 26.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 5.54ms\tremaining: 27.7ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8ms\tremaining: 30.4ms\n",
            "5:\tlearn: 0.2907443\ttotal: 9.94ms\tremaining: 29.8ms\n",
            "6:\tlearn: 0.2818467\ttotal: 11.7ms\tremaining: 28.3ms\n",
            "7:\tlearn: 0.2691784\ttotal: 12.7ms\tremaining: 25.3ms\n",
            "8:\tlearn: 0.2611618\ttotal: 14.4ms\tremaining: 24ms\n",
            "9:\tlearn: 0.2519898\ttotal: 16.6ms\tremaining: 23.2ms\n",
            "10:\tlearn: 0.2462992\ttotal: 19.1ms\tremaining: 22.6ms\n",
            "11:\tlearn: 0.2416348\ttotal: 21ms\tremaining: 21ms\n",
            "12:\tlearn: 0.2368688\ttotal: 22.6ms\tremaining: 19.1ms\n",
            "13:\tlearn: 0.2320170\ttotal: 24.4ms\tremaining: 17.4ms\n",
            "14:\tlearn: 0.2262186\ttotal: 26.1ms\tremaining: 15.7ms\n",
            "15:\tlearn: 0.2215380\ttotal: 28.4ms\tremaining: 14.2ms\n",
            "16:\tlearn: 0.2176313\ttotal: 31ms\tremaining: 12.8ms\n",
            "17:\tlearn: 0.2138494\ttotal: 32.7ms\tremaining: 10.9ms\n",
            "18:\tlearn: 0.2100966\ttotal: 34.4ms\tremaining: 9.04ms\n",
            "19:\tlearn: 0.2068557\ttotal: 36.1ms\tremaining: 7.21ms\n",
            "20:\tlearn: 0.2029945\ttotal: 38.2ms\tremaining: 5.46ms\n",
            "21:\tlearn: 0.2001044\ttotal: 40.7ms\tremaining: 3.7ms\n",
            "22:\tlearn: 0.1970766\ttotal: 42.6ms\tremaining: 1.85ms\n",
            "23:\tlearn: 0.1940285\ttotal: 44.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.58ms\tremaining: 36.4ms\n",
            "1:\tlearn: 0.3687510\ttotal: 1.95ms\tremaining: 21.5ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.42ms\tremaining: 16.9ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.13ms\tremaining: 20.6ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.29ms\tremaining: 23.9ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.9ms\tremaining: 26.7ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.5ms\tremaining: 25.6ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.3ms\tremaining: 24.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.1ms\tremaining: 23.4ms\n",
            "9:\tlearn: 0.2537973\ttotal: 16.5ms\tremaining: 23ms\n",
            "10:\tlearn: 0.2473429\ttotal: 19ms\tremaining: 22.4ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20.5ms\tremaining: 20.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 22.2ms\tremaining: 18.8ms\n",
            "13:\tlearn: 0.2298385\ttotal: 23.8ms\tremaining: 17ms\n",
            "14:\tlearn: 0.2249545\ttotal: 25.8ms\tremaining: 15.5ms\n",
            "15:\tlearn: 0.2192054\ttotal: 28.3ms\tremaining: 14.2ms\n",
            "16:\tlearn: 0.2150242\ttotal: 30.1ms\tremaining: 12.4ms\n",
            "17:\tlearn: 0.2094516\ttotal: 32ms\tremaining: 10.7ms\n",
            "18:\tlearn: 0.2056324\ttotal: 33.6ms\tremaining: 8.84ms\n",
            "19:\tlearn: 0.2021225\ttotal: 35.3ms\tremaining: 7.05ms\n",
            "20:\tlearn: 0.1989042\ttotal: 37.7ms\tremaining: 5.38ms\n",
            "21:\tlearn: 0.1961040\ttotal: 39.9ms\tremaining: 3.62ms\n",
            "22:\tlearn: 0.1934794\ttotal: 41.4ms\tremaining: 1.8ms\n",
            "23:\tlearn: 0.1902438\ttotal: 43ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.94ms\tremaining: 46.7ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.35ms\tremaining: 27ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.33ms\tremaining: 31.7ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.24ms\tremaining: 32.8ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.96ms\tremaining: 35.8ms\n",
            "5:\tlearn: 0.3393969\ttotal: 11.1ms\tremaining: 35.2ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.9ms\tremaining: 33.3ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.7ms\tremaining: 31.2ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.5ms\tremaining: 29.3ms\n",
            "9:\tlearn: 0.3054626\ttotal: 19.1ms\tremaining: 28.6ms\n",
            "10:\tlearn: 0.2983658\ttotal: 21.1ms\tremaining: 26.9ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.9ms\tremaining: 24.8ms\n",
            "12:\tlearn: 0.2852979\ttotal: 27.8ms\tremaining: 25.6ms\n",
            "13:\tlearn: 0.2798563\ttotal: 32.7ms\tremaining: 25.7ms\n",
            "14:\tlearn: 0.2747341\ttotal: 40.5ms\tremaining: 27ms\n",
            "15:\tlearn: 0.2702568\ttotal: 42.2ms\tremaining: 23.7ms\n",
            "16:\tlearn: 0.2650537\ttotal: 43.8ms\tremaining: 20.6ms\n",
            "17:\tlearn: 0.2601005\ttotal: 46.4ms\tremaining: 18.1ms\n",
            "18:\tlearn: 0.2560578\ttotal: 48.9ms\tremaining: 15.4ms\n",
            "19:\tlearn: 0.2530381\ttotal: 52.4ms\tremaining: 13.1ms\n",
            "20:\tlearn: 0.2498453\ttotal: 54.1ms\tremaining: 10.3ms\n",
            "21:\tlearn: 0.2461646\ttotal: 59ms\tremaining: 8.04ms\n",
            "22:\tlearn: 0.2424369\ttotal: 60.7ms\tremaining: 5.28ms\n",
            "23:\tlearn: 0.2392835\ttotal: 62.4ms\tremaining: 2.6ms\n",
            "24:\tlearn: 0.2339070\ttotal: 64.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 5.53ms\tremaining: 133ms\n",
            "1:\tlearn: 0.4049315\ttotal: 8.59ms\tremaining: 98.8ms\n",
            "2:\tlearn: 0.3788145\ttotal: 11.4ms\tremaining: 83.7ms\n",
            "3:\tlearn: 0.3658016\ttotal: 16.6ms\tremaining: 87.2ms\n",
            "4:\tlearn: 0.3428474\ttotal: 19.9ms\tremaining: 79.5ms\n",
            "5:\tlearn: 0.3234303\ttotal: 21.6ms\tremaining: 68.4ms\n",
            "6:\tlearn: 0.3158416\ttotal: 25ms\tremaining: 64.3ms\n",
            "7:\tlearn: 0.3097739\ttotal: 30.2ms\tremaining: 64.1ms\n",
            "8:\tlearn: 0.3040041\ttotal: 35ms\tremaining: 62.2ms\n",
            "9:\tlearn: 0.2975585\ttotal: 39.8ms\tremaining: 59.7ms\n",
            "10:\tlearn: 0.2898709\ttotal: 44.7ms\tremaining: 56.9ms\n",
            "11:\tlearn: 0.2845372\ttotal: 50ms\tremaining: 54.2ms\n",
            "12:\tlearn: 0.2794184\ttotal: 53.3ms\tremaining: 49.2ms\n",
            "13:\tlearn: 0.2740314\ttotal: 58.3ms\tremaining: 45.8ms\n",
            "14:\tlearn: 0.2705542\ttotal: 63.2ms\tremaining: 42.2ms\n",
            "15:\tlearn: 0.2673919\ttotal: 68.9ms\tremaining: 38.8ms\n",
            "16:\tlearn: 0.2623365\ttotal: 72.7ms\tremaining: 34.2ms\n",
            "17:\tlearn: 0.2595719\ttotal: 77.7ms\tremaining: 30.2ms\n",
            "18:\tlearn: 0.2545713\ttotal: 90ms\tremaining: 28.4ms\n",
            "19:\tlearn: 0.2510766\ttotal: 94.7ms\tremaining: 23.7ms\n",
            "20:\tlearn: 0.2477056\ttotal: 99.7ms\tremaining: 19ms\n",
            "21:\tlearn: 0.2437884\ttotal: 105ms\tremaining: 14.3ms\n",
            "22:\tlearn: 0.2404080\ttotal: 109ms\tremaining: 9.51ms\n",
            "23:\tlearn: 0.2369058\ttotal: 111ms\tremaining: 4.64ms\n",
            "24:\tlearn: 0.2331119\ttotal: 114ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.7ms\tremaining: 64.9ms\n",
            "1:\tlearn: 0.4107278\ttotal: 6.39ms\tremaining: 73.6ms\n",
            "2:\tlearn: 0.3698157\ttotal: 7.58ms\tremaining: 55.6ms\n",
            "3:\tlearn: 0.3518120\ttotal: 11.6ms\tremaining: 61.1ms\n",
            "4:\tlearn: 0.3441195\ttotal: 14.5ms\tremaining: 58.2ms\n",
            "5:\tlearn: 0.3328396\ttotal: 19.3ms\tremaining: 61.2ms\n",
            "6:\tlearn: 0.3256704\ttotal: 24.1ms\tremaining: 62ms\n",
            "7:\tlearn: 0.3174441\ttotal: 29.2ms\tremaining: 62.1ms\n",
            "8:\tlearn: 0.3090762\ttotal: 34.2ms\tremaining: 60.7ms\n",
            "9:\tlearn: 0.3028459\ttotal: 39.2ms\tremaining: 58.8ms\n",
            "10:\tlearn: 0.2958541\ttotal: 44.1ms\tremaining: 56.1ms\n",
            "11:\tlearn: 0.2901166\ttotal: 48.9ms\tremaining: 53ms\n",
            "12:\tlearn: 0.2841803\ttotal: 53.6ms\tremaining: 49.5ms\n",
            "13:\tlearn: 0.2789751\ttotal: 58.2ms\tremaining: 45.8ms\n",
            "14:\tlearn: 0.2715599\ttotal: 63.2ms\tremaining: 42.1ms\n",
            "15:\tlearn: 0.2663544\ttotal: 68.1ms\tremaining: 38.3ms\n",
            "16:\tlearn: 0.2615546\ttotal: 73ms\tremaining: 34.4ms\n",
            "17:\tlearn: 0.2560079\ttotal: 77.8ms\tremaining: 30.3ms\n",
            "18:\tlearn: 0.2507480\ttotal: 80.2ms\tremaining: 25.3ms\n",
            "19:\tlearn: 0.2450678\ttotal: 82.2ms\tremaining: 20.5ms\n",
            "20:\tlearn: 0.2413892\ttotal: 83.8ms\tremaining: 16ms\n",
            "21:\tlearn: 0.2378437\ttotal: 85.6ms\tremaining: 11.7ms\n",
            "22:\tlearn: 0.2344010\ttotal: 87.2ms\tremaining: 7.58ms\n",
            "23:\tlearn: 0.2304940\ttotal: 89.3ms\tremaining: 3.72ms\n",
            "24:\tlearn: 0.2269540\ttotal: 91.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.85ms\tremaining: 44.5ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.26ms\tremaining: 26ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.01ms\tremaining: 29.4ms\n",
            "3:\tlearn: 0.3266560\ttotal: 5.82ms\tremaining: 30.5ms\n",
            "4:\tlearn: 0.3080259\ttotal: 14ms\tremaining: 55.9ms\n",
            "5:\tlearn: 0.2907443\ttotal: 15.7ms\tremaining: 49.8ms\n",
            "6:\tlearn: 0.2818467\ttotal: 17.4ms\tremaining: 44.8ms\n",
            "7:\tlearn: 0.2691784\ttotal: 18.5ms\tremaining: 39.3ms\n",
            "8:\tlearn: 0.2611618\ttotal: 20.8ms\tremaining: 37ms\n",
            "9:\tlearn: 0.2519898\ttotal: 23.4ms\tremaining: 35.1ms\n",
            "10:\tlearn: 0.2462992\ttotal: 25ms\tremaining: 31.8ms\n",
            "11:\tlearn: 0.2416348\ttotal: 26.8ms\tremaining: 29ms\n",
            "12:\tlearn: 0.2368688\ttotal: 28.4ms\tremaining: 26.2ms\n",
            "13:\tlearn: 0.2320170\ttotal: 30.8ms\tremaining: 24.2ms\n",
            "14:\tlearn: 0.2262186\ttotal: 33.3ms\tremaining: 22.2ms\n",
            "15:\tlearn: 0.2215380\ttotal: 35ms\tremaining: 19.7ms\n",
            "16:\tlearn: 0.2176313\ttotal: 36.9ms\tremaining: 17.4ms\n",
            "17:\tlearn: 0.2138494\ttotal: 38.7ms\tremaining: 15.1ms\n",
            "18:\tlearn: 0.2100966\ttotal: 41.2ms\tremaining: 13ms\n",
            "19:\tlearn: 0.2068557\ttotal: 43.2ms\tremaining: 10.8ms\n",
            "20:\tlearn: 0.2029945\ttotal: 45ms\tremaining: 8.57ms\n",
            "21:\tlearn: 0.2001044\ttotal: 46.8ms\tremaining: 6.39ms\n",
            "22:\tlearn: 0.1970766\ttotal: 49.3ms\tremaining: 4.28ms\n",
            "23:\tlearn: 0.1940285\ttotal: 51.6ms\tremaining: 2.15ms\n",
            "24:\tlearn: 0.1910934\ttotal: 53.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.82ms\tremaining: 43.8ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.23ms\tremaining: 25.6ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.7ms\tremaining: 19.8ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.35ms\tremaining: 22.8ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.4ms\tremaining: 25.6ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.81ms\tremaining: 27.9ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.6ms\tremaining: 27.2ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.3ms\tremaining: 26.1ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14ms\tremaining: 24.9ms\n",
            "9:\tlearn: 0.2537973\ttotal: 15.7ms\tremaining: 23.5ms\n",
            "10:\tlearn: 0.2473429\ttotal: 18.1ms\tremaining: 23ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20.2ms\tremaining: 21.9ms\n",
            "12:\tlearn: 0.2366343\ttotal: 21.9ms\tremaining: 20.2ms\n",
            "13:\tlearn: 0.2298385\ttotal: 23.5ms\tremaining: 18.4ms\n",
            "14:\tlearn: 0.2249545\ttotal: 25.4ms\tremaining: 17ms\n",
            "15:\tlearn: 0.2192054\ttotal: 27.9ms\tremaining: 15.7ms\n",
            "16:\tlearn: 0.2150242\ttotal: 30.3ms\tremaining: 14.2ms\n",
            "17:\tlearn: 0.2094516\ttotal: 32.1ms\tremaining: 12.5ms\n",
            "18:\tlearn: 0.2056324\ttotal: 34ms\tremaining: 10.7ms\n",
            "19:\tlearn: 0.2021225\ttotal: 35.7ms\tremaining: 8.94ms\n",
            "20:\tlearn: 0.1989042\ttotal: 38.4ms\tremaining: 7.31ms\n",
            "21:\tlearn: 0.1961040\ttotal: 40.2ms\tremaining: 5.48ms\n",
            "22:\tlearn: 0.1934794\ttotal: 41.8ms\tremaining: 3.64ms\n",
            "23:\tlearn: 0.1902438\ttotal: 43.6ms\tremaining: 1.82ms\n",
            "24:\tlearn: 0.1874921\ttotal: 45.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.71ms\tremaining: 42.8ms\n",
            "1:\tlearn: 0.4229987\ttotal: 4.68ms\tremaining: 56.1ms\n",
            "2:\tlearn: 0.3843342\ttotal: 7.6ms\tremaining: 58.2ms\n",
            "3:\tlearn: 0.3652888\ttotal: 13.5ms\tremaining: 74.3ms\n",
            "4:\tlearn: 0.3496343\ttotal: 17.3ms\tremaining: 72.6ms\n",
            "5:\tlearn: 0.3393969\ttotal: 20.7ms\tremaining: 68.9ms\n",
            "6:\tlearn: 0.3300914\ttotal: 23.4ms\tremaining: 63.4ms\n",
            "7:\tlearn: 0.3229079\ttotal: 28.2ms\tremaining: 63.5ms\n",
            "8:\tlearn: 0.3148279\ttotal: 33ms\tremaining: 62.3ms\n",
            "9:\tlearn: 0.3054626\ttotal: 37.8ms\tremaining: 60.4ms\n",
            "10:\tlearn: 0.2983658\ttotal: 50.7ms\tremaining: 69.1ms\n",
            "11:\tlearn: 0.2903440\ttotal: 56.4ms\tremaining: 65.8ms\n",
            "12:\tlearn: 0.2852979\ttotal: 60.1ms\tremaining: 60.1ms\n",
            "13:\tlearn: 0.2798563\ttotal: 64.7ms\tremaining: 55.5ms\n",
            "14:\tlearn: 0.2747341\ttotal: 67.3ms\tremaining: 49.4ms\n",
            "15:\tlearn: 0.2702568\ttotal: 69.3ms\tremaining: 43.3ms\n",
            "16:\tlearn: 0.2650537\ttotal: 70.9ms\tremaining: 37.5ms\n",
            "17:\tlearn: 0.2601005\ttotal: 72.7ms\tremaining: 32.3ms\n",
            "18:\tlearn: 0.2560578\ttotal: 74.3ms\tremaining: 27.4ms\n",
            "19:\tlearn: 0.2530381\ttotal: 76.7ms\tremaining: 23ms\n",
            "20:\tlearn: 0.2498453\ttotal: 78.8ms\tremaining: 18.8ms\n",
            "21:\tlearn: 0.2461646\ttotal: 81.3ms\tremaining: 14.8ms\n",
            "22:\tlearn: 0.2424369\ttotal: 82.9ms\tremaining: 10.8ms\n",
            "23:\tlearn: 0.2392835\ttotal: 84.6ms\tremaining: 7.05ms\n",
            "24:\tlearn: 0.2339070\ttotal: 87.8ms\tremaining: 3.51ms\n",
            "25:\tlearn: 0.2301706\ttotal: 90.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.8ms\tremaining: 45.1ms\n",
            "1:\tlearn: 0.4049315\ttotal: 4.87ms\tremaining: 58.5ms\n",
            "2:\tlearn: 0.3788145\ttotal: 7.67ms\tremaining: 58.8ms\n",
            "3:\tlearn: 0.3658016\ttotal: 12.5ms\tremaining: 69ms\n",
            "4:\tlearn: 0.3428474\ttotal: 15.6ms\tremaining: 65.7ms\n",
            "5:\tlearn: 0.3234303\ttotal: 17.3ms\tremaining: 57.5ms\n",
            "6:\tlearn: 0.3158416\ttotal: 20.6ms\tremaining: 55.9ms\n",
            "7:\tlearn: 0.3097739\ttotal: 25.6ms\tremaining: 57.6ms\n",
            "8:\tlearn: 0.3040041\ttotal: 32.7ms\tremaining: 61.8ms\n",
            "9:\tlearn: 0.2975585\ttotal: 37.1ms\tremaining: 59.3ms\n",
            "10:\tlearn: 0.2898709\ttotal: 42ms\tremaining: 57.3ms\n",
            "11:\tlearn: 0.2845372\ttotal: 46.9ms\tremaining: 54.7ms\n",
            "12:\tlearn: 0.2794184\ttotal: 51.8ms\tremaining: 51.8ms\n",
            "13:\tlearn: 0.2740314\ttotal: 53.9ms\tremaining: 46.2ms\n",
            "14:\tlearn: 0.2705542\ttotal: 58.3ms\tremaining: 42.7ms\n",
            "15:\tlearn: 0.2673919\ttotal: 61.1ms\tremaining: 38.2ms\n",
            "16:\tlearn: 0.2623365\ttotal: 73.3ms\tremaining: 38.8ms\n",
            "17:\tlearn: 0.2595719\ttotal: 77.8ms\tremaining: 34.6ms\n",
            "18:\tlearn: 0.2545713\ttotal: 83.1ms\tremaining: 30.6ms\n",
            "19:\tlearn: 0.2510766\ttotal: 88ms\tremaining: 26.4ms\n",
            "20:\tlearn: 0.2477056\ttotal: 92.9ms\tremaining: 22.1ms\n",
            "21:\tlearn: 0.2437884\ttotal: 98.5ms\tremaining: 17.9ms\n",
            "22:\tlearn: 0.2404080\ttotal: 102ms\tremaining: 13.3ms\n",
            "23:\tlearn: 0.2369058\ttotal: 114ms\tremaining: 9.54ms\n",
            "24:\tlearn: 0.2331119\ttotal: 118ms\tremaining: 4.72ms\n",
            "25:\tlearn: 0.2293455\ttotal: 123ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.85ms\tremaining: 46.4ms\n",
            "1:\tlearn: 0.4107278\ttotal: 3.51ms\tremaining: 42.1ms\n",
            "2:\tlearn: 0.3698157\ttotal: 4.61ms\tremaining: 35.4ms\n",
            "3:\tlearn: 0.3518120\ttotal: 7.77ms\tremaining: 42.7ms\n",
            "4:\tlearn: 0.3441195\ttotal: 15.2ms\tremaining: 63.9ms\n",
            "5:\tlearn: 0.3328396\ttotal: 20.2ms\tremaining: 67.2ms\n",
            "6:\tlearn: 0.3256704\ttotal: 25ms\tremaining: 68ms\n",
            "7:\tlearn: 0.3174441\ttotal: 29.9ms\tremaining: 67.2ms\n",
            "8:\tlearn: 0.3090762\ttotal: 35.3ms\tremaining: 66.7ms\n",
            "9:\tlearn: 0.3028459\ttotal: 39.5ms\tremaining: 63.1ms\n",
            "10:\tlearn: 0.2958541\ttotal: 44.3ms\tremaining: 60.4ms\n",
            "11:\tlearn: 0.2901166\ttotal: 49.1ms\tremaining: 57.3ms\n",
            "12:\tlearn: 0.2841803\ttotal: 53.8ms\tremaining: 53.8ms\n",
            "13:\tlearn: 0.2789751\ttotal: 58.5ms\tremaining: 50.2ms\n",
            "14:\tlearn: 0.2715599\ttotal: 63.5ms\tremaining: 46.6ms\n",
            "15:\tlearn: 0.2663544\ttotal: 68.5ms\tremaining: 42.8ms\n",
            "16:\tlearn: 0.2615546\ttotal: 73.2ms\tremaining: 38.7ms\n",
            "17:\tlearn: 0.2560079\ttotal: 77.8ms\tremaining: 34.6ms\n",
            "18:\tlearn: 0.2507480\ttotal: 82.6ms\tremaining: 30.4ms\n",
            "19:\tlearn: 0.2450678\ttotal: 87.3ms\tremaining: 26.2ms\n",
            "20:\tlearn: 0.2413892\ttotal: 91.9ms\tremaining: 21.9ms\n",
            "21:\tlearn: 0.2378437\ttotal: 96.9ms\tremaining: 17.6ms\n",
            "22:\tlearn: 0.2344010\ttotal: 102ms\tremaining: 13.3ms\n",
            "23:\tlearn: 0.2304940\ttotal: 107ms\tremaining: 8.9ms\n",
            "24:\tlearn: 0.2269540\ttotal: 112ms\tremaining: 4.46ms\n",
            "25:\tlearn: 0.2232713\ttotal: 116ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 3.46ms\tremaining: 86.5ms\n",
            "1:\tlearn: 0.3745079\ttotal: 3.94ms\tremaining: 47.3ms\n",
            "2:\tlearn: 0.3383999\ttotal: 10.8ms\tremaining: 82.5ms\n",
            "3:\tlearn: 0.3266560\ttotal: 15.7ms\tremaining: 86.5ms\n",
            "4:\tlearn: 0.3080259\ttotal: 21.7ms\tremaining: 91ms\n",
            "5:\tlearn: 0.2907443\ttotal: 25.5ms\tremaining: 85.1ms\n",
            "6:\tlearn: 0.2818467\ttotal: 29ms\tremaining: 78.6ms\n",
            "7:\tlearn: 0.2691784\ttotal: 30.6ms\tremaining: 68.9ms\n",
            "8:\tlearn: 0.2611618\ttotal: 35.1ms\tremaining: 66.3ms\n",
            "9:\tlearn: 0.2519898\ttotal: 38.4ms\tremaining: 61.5ms\n",
            "10:\tlearn: 0.2462992\ttotal: 43.3ms\tremaining: 59ms\n",
            "11:\tlearn: 0.2416348\ttotal: 48ms\tremaining: 56ms\n",
            "12:\tlearn: 0.2368688\ttotal: 52.7ms\tremaining: 52.7ms\n",
            "13:\tlearn: 0.2320170\ttotal: 57.6ms\tremaining: 49.4ms\n",
            "14:\tlearn: 0.2262186\ttotal: 62.5ms\tremaining: 45.8ms\n",
            "15:\tlearn: 0.2215380\ttotal: 67.2ms\tremaining: 42ms\n",
            "16:\tlearn: 0.2176313\ttotal: 71.9ms\tremaining: 38.1ms\n",
            "17:\tlearn: 0.2138494\ttotal: 73.6ms\tremaining: 32.7ms\n",
            "18:\tlearn: 0.2100966\ttotal: 77.2ms\tremaining: 28.4ms\n",
            "19:\tlearn: 0.2068557\ttotal: 82.3ms\tremaining: 24.7ms\n",
            "20:\tlearn: 0.2029945\ttotal: 87.8ms\tremaining: 20.9ms\n",
            "21:\tlearn: 0.2001044\ttotal: 91.8ms\tremaining: 16.7ms\n",
            "22:\tlearn: 0.1970766\ttotal: 97.1ms\tremaining: 12.7ms\n",
            "23:\tlearn: 0.1940285\ttotal: 102ms\tremaining: 8.54ms\n",
            "24:\tlearn: 0.1910934\ttotal: 105ms\tremaining: 4.21ms\n",
            "25:\tlearn: 0.1879112\ttotal: 110ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 3.63ms\tremaining: 90.8ms\n",
            "1:\tlearn: 0.3687510\ttotal: 5.38ms\tremaining: 64.5ms\n",
            "2:\tlearn: 0.3203557\ttotal: 6.29ms\tremaining: 48.2ms\n",
            "3:\tlearn: 0.3063743\ttotal: 9.21ms\tremaining: 50.7ms\n",
            "4:\tlearn: 0.2970911\ttotal: 13.9ms\tremaining: 58.3ms\n",
            "5:\tlearn: 0.2891054\ttotal: 18.5ms\tremaining: 61.7ms\n",
            "6:\tlearn: 0.2792409\ttotal: 22.9ms\tremaining: 62.2ms\n",
            "7:\tlearn: 0.2716618\ttotal: 29.1ms\tremaining: 65.6ms\n",
            "8:\tlearn: 0.2621352\ttotal: 32.8ms\tremaining: 61.9ms\n",
            "9:\tlearn: 0.2537973\ttotal: 37.2ms\tremaining: 59.5ms\n",
            "10:\tlearn: 0.2473429\ttotal: 47.2ms\tremaining: 64.3ms\n",
            "11:\tlearn: 0.2416695\ttotal: 52.2ms\tremaining: 60.8ms\n",
            "12:\tlearn: 0.2366343\ttotal: 56.8ms\tremaining: 56.8ms\n",
            "13:\tlearn: 0.2298385\ttotal: 61.7ms\tremaining: 52.9ms\n",
            "14:\tlearn: 0.2249545\ttotal: 66.5ms\tremaining: 48.8ms\n",
            "15:\tlearn: 0.2192054\ttotal: 71.3ms\tremaining: 44.6ms\n",
            "16:\tlearn: 0.2150242\ttotal: 75.6ms\tremaining: 40ms\n",
            "17:\tlearn: 0.2094516\ttotal: 80.8ms\tremaining: 35.9ms\n",
            "18:\tlearn: 0.2056324\ttotal: 86.1ms\tremaining: 31.7ms\n",
            "19:\tlearn: 0.2021225\ttotal: 91.1ms\tremaining: 27.3ms\n",
            "20:\tlearn: 0.1989042\ttotal: 96.2ms\tremaining: 22.9ms\n",
            "21:\tlearn: 0.1961040\ttotal: 101ms\tremaining: 18.4ms\n",
            "22:\tlearn: 0.1934794\ttotal: 105ms\tremaining: 13.8ms\n",
            "23:\tlearn: 0.1902438\ttotal: 111ms\tremaining: 9.22ms\n",
            "24:\tlearn: 0.1874921\ttotal: 115ms\tremaining: 4.62ms\n",
            "25:\tlearn: 0.1829904\ttotal: 120ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 4.18ms\tremaining: 109ms\n",
            "1:\tlearn: 0.4229987\ttotal: 5.68ms\tremaining: 71ms\n",
            "2:\tlearn: 0.3843342\ttotal: 9.24ms\tremaining: 73.9ms\n",
            "3:\tlearn: 0.3652888\ttotal: 13.5ms\tremaining: 77.8ms\n",
            "4:\tlearn: 0.3496343\ttotal: 18.5ms\tremaining: 81.4ms\n",
            "5:\tlearn: 0.3393969\ttotal: 23.3ms\tremaining: 81.6ms\n",
            "6:\tlearn: 0.3300914\ttotal: 27.9ms\tremaining: 79.9ms\n",
            "7:\tlearn: 0.3229079\ttotal: 32.9ms\tremaining: 78.1ms\n",
            "8:\tlearn: 0.3148279\ttotal: 38.2ms\tremaining: 76.5ms\n",
            "9:\tlearn: 0.3054626\ttotal: 43.2ms\tremaining: 73.5ms\n",
            "10:\tlearn: 0.2983658\ttotal: 48ms\tremaining: 69.9ms\n",
            "11:\tlearn: 0.2903440\ttotal: 52.7ms\tremaining: 65.8ms\n",
            "12:\tlearn: 0.2852979\ttotal: 57.6ms\tremaining: 62ms\n",
            "13:\tlearn: 0.2798563\ttotal: 62.5ms\tremaining: 58ms\n",
            "14:\tlearn: 0.2747341\ttotal: 67ms\tremaining: 53.6ms\n",
            "15:\tlearn: 0.2702568\ttotal: 72ms\tremaining: 49.5ms\n",
            "16:\tlearn: 0.2650537\ttotal: 76.9ms\tremaining: 45.3ms\n",
            "17:\tlearn: 0.2601005\ttotal: 88ms\tremaining: 44ms\n",
            "18:\tlearn: 0.2560578\ttotal: 90.8ms\tremaining: 38.2ms\n",
            "19:\tlearn: 0.2530381\ttotal: 96.2ms\tremaining: 33.7ms\n",
            "20:\tlearn: 0.2498453\ttotal: 102ms\tremaining: 29.1ms\n",
            "21:\tlearn: 0.2461646\ttotal: 106ms\tremaining: 24.1ms\n",
            "22:\tlearn: 0.2424369\ttotal: 108ms\tremaining: 18.8ms\n",
            "23:\tlearn: 0.2392835\ttotal: 111ms\tremaining: 13.8ms\n",
            "24:\tlearn: 0.2339070\ttotal: 113ms\tremaining: 9.03ms\n",
            "25:\tlearn: 0.2301706\ttotal: 115ms\tremaining: 4.41ms\n",
            "26:\tlearn: 0.2263007\ttotal: 116ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.98ms\tremaining: 51.6ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.39ms\tremaining: 29.9ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.32ms\tremaining: 34.5ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.44ms\tremaining: 37ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.46ms\tremaining: 32.8ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.41ms\tremaining: 29.4ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10.3ms\tremaining: 29.4ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12ms\tremaining: 28.6ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.8ms\tremaining: 27.6ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.9ms\tremaining: 27.1ms\n",
            "10:\tlearn: 0.2898709\ttotal: 18.5ms\tremaining: 26.9ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.4ms\tremaining: 25.4ms\n",
            "12:\tlearn: 0.2794184\ttotal: 22.3ms\tremaining: 24ms\n",
            "13:\tlearn: 0.2740314\ttotal: 24.1ms\tremaining: 22.4ms\n",
            "14:\tlearn: 0.2705542\ttotal: 26ms\tremaining: 20.8ms\n",
            "15:\tlearn: 0.2673919\ttotal: 28.6ms\tremaining: 19.6ms\n",
            "16:\tlearn: 0.2623365\ttotal: 30.8ms\tremaining: 18.1ms\n",
            "17:\tlearn: 0.2595719\ttotal: 32.6ms\tremaining: 16.3ms\n",
            "18:\tlearn: 0.2545713\ttotal: 34.4ms\tremaining: 14.5ms\n",
            "19:\tlearn: 0.2510766\ttotal: 36.2ms\tremaining: 12.7ms\n",
            "20:\tlearn: 0.2477056\ttotal: 38.8ms\tremaining: 11.1ms\n",
            "21:\tlearn: 0.2437884\ttotal: 41.2ms\tremaining: 9.36ms\n",
            "22:\tlearn: 0.2404080\ttotal: 43.1ms\tremaining: 7.5ms\n",
            "23:\tlearn: 0.2369058\ttotal: 44.9ms\tremaining: 5.61ms\n",
            "24:\tlearn: 0.2331119\ttotal: 46.7ms\tremaining: 3.73ms\n",
            "25:\tlearn: 0.2293455\ttotal: 51.2ms\tremaining: 1.97ms\n",
            "26:\tlearn: 0.2256418\ttotal: 53ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 3.25ms\tremaining: 84.6ms\n",
            "1:\tlearn: 0.4107278\ttotal: 6.67ms\tremaining: 83.4ms\n",
            "2:\tlearn: 0.3698157\ttotal: 7.34ms\tremaining: 58.8ms\n",
            "3:\tlearn: 0.3518120\ttotal: 11.2ms\tremaining: 64.7ms\n",
            "4:\tlearn: 0.3441195\ttotal: 15.6ms\tremaining: 68.7ms\n",
            "5:\tlearn: 0.3328396\ttotal: 21ms\tremaining: 73.5ms\n",
            "6:\tlearn: 0.3256704\ttotal: 26.1ms\tremaining: 74.7ms\n",
            "7:\tlearn: 0.3174441\ttotal: 30.3ms\tremaining: 72ms\n",
            "8:\tlearn: 0.3090762\ttotal: 34.1ms\tremaining: 68.2ms\n",
            "9:\tlearn: 0.3028459\ttotal: 50.2ms\tremaining: 85.3ms\n",
            "10:\tlearn: 0.2958541\ttotal: 55.6ms\tremaining: 80.8ms\n",
            "11:\tlearn: 0.2901166\ttotal: 60.7ms\tremaining: 75.9ms\n",
            "12:\tlearn: 0.2841803\ttotal: 65.8ms\tremaining: 70.8ms\n",
            "13:\tlearn: 0.2789751\ttotal: 71.1ms\tremaining: 66ms\n",
            "14:\tlearn: 0.2715599\ttotal: 74.7ms\tremaining: 59.7ms\n",
            "15:\tlearn: 0.2663544\ttotal: 80.6ms\tremaining: 55.4ms\n",
            "16:\tlearn: 0.2615546\ttotal: 84.1ms\tremaining: 49.5ms\n",
            "17:\tlearn: 0.2560079\ttotal: 89ms\tremaining: 44.5ms\n",
            "18:\tlearn: 0.2507480\ttotal: 93.9ms\tremaining: 39.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 98.7ms\tremaining: 34.6ms\n",
            "20:\tlearn: 0.2413892\ttotal: 104ms\tremaining: 29.6ms\n",
            "21:\tlearn: 0.2378437\ttotal: 108ms\tremaining: 24.6ms\n",
            "22:\tlearn: 0.2344010\ttotal: 114ms\tremaining: 19.8ms\n",
            "23:\tlearn: 0.2304940\ttotal: 117ms\tremaining: 14.6ms\n",
            "24:\tlearn: 0.2269540\ttotal: 122ms\tremaining: 9.76ms\n",
            "25:\tlearn: 0.2232713\ttotal: 127ms\tremaining: 4.87ms\n",
            "26:\tlearn: 0.2208577\ttotal: 131ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 5.53ms\tremaining: 144ms\n",
            "1:\tlearn: 0.3745079\ttotal: 8.4ms\tremaining: 105ms\n",
            "2:\tlearn: 0.3383999\ttotal: 11.9ms\tremaining: 94.8ms\n",
            "3:\tlearn: 0.3266560\ttotal: 14.7ms\tremaining: 84.8ms\n",
            "4:\tlearn: 0.3080259\ttotal: 20.2ms\tremaining: 89ms\n",
            "5:\tlearn: 0.2907443\ttotal: 22.7ms\tremaining: 79.3ms\n",
            "6:\tlearn: 0.2818467\ttotal: 29ms\tremaining: 82.7ms\n",
            "7:\tlearn: 0.2691784\ttotal: 30.7ms\tremaining: 72.9ms\n",
            "8:\tlearn: 0.2611618\ttotal: 34ms\tremaining: 68.1ms\n",
            "9:\tlearn: 0.2519898\ttotal: 37.2ms\tremaining: 63.3ms\n",
            "10:\tlearn: 0.2462992\ttotal: 42.4ms\tremaining: 61.7ms\n",
            "11:\tlearn: 0.2416348\ttotal: 47.1ms\tremaining: 58.9ms\n",
            "12:\tlearn: 0.2368688\ttotal: 51.7ms\tremaining: 55.7ms\n",
            "13:\tlearn: 0.2320170\ttotal: 56.5ms\tremaining: 52.5ms\n",
            "14:\tlearn: 0.2262186\ttotal: 61.2ms\tremaining: 49ms\n",
            "15:\tlearn: 0.2215380\ttotal: 66.1ms\tremaining: 45.5ms\n",
            "16:\tlearn: 0.2176313\ttotal: 77.1ms\tremaining: 45.4ms\n",
            "17:\tlearn: 0.2138494\ttotal: 80.7ms\tremaining: 40.3ms\n",
            "18:\tlearn: 0.2100966\ttotal: 85.8ms\tremaining: 36.1ms\n",
            "19:\tlearn: 0.2068557\ttotal: 90.5ms\tremaining: 31.7ms\n",
            "20:\tlearn: 0.2029945\ttotal: 95.5ms\tremaining: 27.3ms\n",
            "21:\tlearn: 0.2001044\ttotal: 100ms\tremaining: 22.8ms\n",
            "22:\tlearn: 0.1970766\ttotal: 105ms\tremaining: 18.2ms\n",
            "23:\tlearn: 0.1940285\ttotal: 109ms\tremaining: 13.7ms\n",
            "24:\tlearn: 0.1910934\ttotal: 115ms\tremaining: 9.18ms\n",
            "25:\tlearn: 0.1879112\ttotal: 117ms\tremaining: 4.51ms\n",
            "26:\tlearn: 0.1852765\ttotal: 120ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 2.51ms\tremaining: 65.4ms\n",
            "1:\tlearn: 0.3687510\ttotal: 6.27ms\tremaining: 78.4ms\n",
            "2:\tlearn: 0.3203557\ttotal: 7.11ms\tremaining: 56.9ms\n",
            "3:\tlearn: 0.3063743\ttotal: 11.1ms\tremaining: 63.7ms\n",
            "4:\tlearn: 0.2970911\ttotal: 13.7ms\tremaining: 60.1ms\n",
            "5:\tlearn: 0.2891054\ttotal: 18.8ms\tremaining: 65.6ms\n",
            "6:\tlearn: 0.2792409\ttotal: 23.5ms\tremaining: 67.3ms\n",
            "7:\tlearn: 0.2716618\ttotal: 28.4ms\tremaining: 67.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 33ms\tremaining: 66ms\n",
            "9:\tlearn: 0.2537973\ttotal: 37.6ms\tremaining: 64ms\n",
            "10:\tlearn: 0.2473429\ttotal: 42.6ms\tremaining: 62ms\n",
            "11:\tlearn: 0.2416695\ttotal: 46.6ms\tremaining: 58.3ms\n",
            "12:\tlearn: 0.2366343\ttotal: 51.4ms\tremaining: 55.3ms\n",
            "13:\tlearn: 0.2298385\ttotal: 53.9ms\tremaining: 50ms\n",
            "14:\tlearn: 0.2249545\ttotal: 55.6ms\tremaining: 44.5ms\n",
            "15:\tlearn: 0.2192054\ttotal: 57.3ms\tremaining: 39.4ms\n",
            "16:\tlearn: 0.2150242\ttotal: 59.5ms\tremaining: 35ms\n",
            "17:\tlearn: 0.2094516\ttotal: 61.9ms\tremaining: 31ms\n",
            "18:\tlearn: 0.2056324\ttotal: 63.5ms\tremaining: 26.8ms\n",
            "19:\tlearn: 0.2021225\ttotal: 65.1ms\tremaining: 22.8ms\n",
            "20:\tlearn: 0.1989042\ttotal: 66.9ms\tremaining: 19.1ms\n",
            "21:\tlearn: 0.1961040\ttotal: 68.5ms\tremaining: 15.6ms\n",
            "22:\tlearn: 0.1934794\ttotal: 70.9ms\tremaining: 12.3ms\n",
            "23:\tlearn: 0.1902438\ttotal: 76.6ms\tremaining: 9.57ms\n",
            "24:\tlearn: 0.1874921\ttotal: 80.9ms\tremaining: 6.47ms\n",
            "25:\tlearn: 0.1829904\ttotal: 82.7ms\tremaining: 3.18ms\n",
            "26:\tlearn: 0.1804169\ttotal: 84.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 4.67ms\tremaining: 126ms\n",
            "1:\tlearn: 0.4229987\ttotal: 5.62ms\tremaining: 73ms\n",
            "2:\tlearn: 0.3843342\ttotal: 8.56ms\tremaining: 71.3ms\n",
            "3:\tlearn: 0.3652888\ttotal: 13.6ms\tremaining: 81.4ms\n",
            "4:\tlearn: 0.3496343\ttotal: 18.6ms\tremaining: 85.4ms\n",
            "5:\tlearn: 0.3393969\ttotal: 23.4ms\tremaining: 85.8ms\n",
            "6:\tlearn: 0.3300914\ttotal: 28.4ms\tremaining: 85.2ms\n",
            "7:\tlearn: 0.3229079\ttotal: 33.6ms\tremaining: 84ms\n",
            "8:\tlearn: 0.3148279\ttotal: 39.7ms\tremaining: 83.9ms\n",
            "9:\tlearn: 0.3054626\ttotal: 43.8ms\tremaining: 78.8ms\n",
            "10:\tlearn: 0.2983658\ttotal: 49ms\tremaining: 75.7ms\n",
            "11:\tlearn: 0.2903440\ttotal: 54.1ms\tremaining: 72.1ms\n",
            "12:\tlearn: 0.2852979\ttotal: 59.3ms\tremaining: 68.4ms\n",
            "13:\tlearn: 0.2798563\ttotal: 64ms\tremaining: 64ms\n",
            "14:\tlearn: 0.2747341\ttotal: 69ms\tremaining: 59.8ms\n",
            "15:\tlearn: 0.2702568\ttotal: 73.9ms\tremaining: 55.4ms\n",
            "16:\tlearn: 0.2650537\ttotal: 78.7ms\tremaining: 50.9ms\n",
            "17:\tlearn: 0.2601005\ttotal: 83.3ms\tremaining: 46.3ms\n",
            "18:\tlearn: 0.2560578\ttotal: 88.1ms\tremaining: 41.7ms\n",
            "19:\tlearn: 0.2530381\ttotal: 92.6ms\tremaining: 37ms\n",
            "20:\tlearn: 0.2498453\ttotal: 97.9ms\tremaining: 32.6ms\n",
            "21:\tlearn: 0.2461646\ttotal: 102ms\tremaining: 27.8ms\n",
            "22:\tlearn: 0.2424369\ttotal: 107ms\tremaining: 23.2ms\n",
            "23:\tlearn: 0.2392835\ttotal: 112ms\tremaining: 18.6ms\n",
            "24:\tlearn: 0.2339070\ttotal: 117ms\tremaining: 14ms\n",
            "25:\tlearn: 0.2301706\ttotal: 122ms\tremaining: 9.39ms\n",
            "26:\tlearn: 0.2263007\ttotal: 125ms\tremaining: 4.64ms\n",
            "27:\tlearn: 0.2223209\ttotal: 131ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 5.53ms\tremaining: 149ms\n",
            "1:\tlearn: 0.4049315\ttotal: 8.56ms\tremaining: 111ms\n",
            "2:\tlearn: 0.3788145\ttotal: 11.3ms\tremaining: 93.9ms\n",
            "3:\tlearn: 0.3658016\ttotal: 17.2ms\tremaining: 103ms\n",
            "4:\tlearn: 0.3428474\ttotal: 19.6ms\tremaining: 90.1ms\n",
            "5:\tlearn: 0.3234303\ttotal: 21.4ms\tremaining: 78.4ms\n",
            "6:\tlearn: 0.3158416\ttotal: 25ms\tremaining: 75.1ms\n",
            "7:\tlearn: 0.3097739\ttotal: 35.8ms\tremaining: 89.5ms\n",
            "8:\tlearn: 0.3040041\ttotal: 38.3ms\tremaining: 81ms\n",
            "9:\tlearn: 0.2975585\ttotal: 40.5ms\tremaining: 72.8ms\n",
            "10:\tlearn: 0.2898709\ttotal: 42.2ms\tremaining: 65.2ms\n",
            "11:\tlearn: 0.2845372\ttotal: 44ms\tremaining: 58.6ms\n",
            "12:\tlearn: 0.2794184\ttotal: 45.8ms\tremaining: 52.9ms\n",
            "13:\tlearn: 0.2740314\ttotal: 48.6ms\tremaining: 48.6ms\n",
            "14:\tlearn: 0.2705542\ttotal: 51ms\tremaining: 44.2ms\n",
            "15:\tlearn: 0.2673919\ttotal: 52.9ms\tremaining: 39.7ms\n",
            "16:\tlearn: 0.2623365\ttotal: 54.7ms\tremaining: 35.4ms\n",
            "17:\tlearn: 0.2595719\ttotal: 56.6ms\tremaining: 31.4ms\n",
            "18:\tlearn: 0.2545713\ttotal: 59.4ms\tremaining: 28.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 61.5ms\tremaining: 24.6ms\n",
            "20:\tlearn: 0.2477056\ttotal: 63.4ms\tremaining: 21.1ms\n",
            "21:\tlearn: 0.2437884\ttotal: 65.2ms\tremaining: 17.8ms\n",
            "22:\tlearn: 0.2404080\ttotal: 67.4ms\tremaining: 14.7ms\n",
            "23:\tlearn: 0.2369058\ttotal: 70.1ms\tremaining: 11.7ms\n",
            "24:\tlearn: 0.2331119\ttotal: 77.9ms\tremaining: 9.35ms\n",
            "25:\tlearn: 0.2293455\ttotal: 80ms\tremaining: 6.15ms\n",
            "26:\tlearn: 0.2256418\ttotal: 82.5ms\tremaining: 3.06ms\n",
            "27:\tlearn: 0.2221119\ttotal: 84.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.81ms\tremaining: 49ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.18ms\tremaining: 28.4ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.69ms\tremaining: 22.4ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.47ms\tremaining: 26.8ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.67ms\tremaining: 30.7ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.17ms\tremaining: 33.6ms\n",
            "6:\tlearn: 0.3256704\ttotal: 10.9ms\tremaining: 32.6ms\n",
            "7:\tlearn: 0.3174441\ttotal: 12.8ms\tremaining: 32ms\n",
            "8:\tlearn: 0.3090762\ttotal: 14.7ms\tremaining: 31ms\n",
            "9:\tlearn: 0.3028459\ttotal: 17.2ms\tremaining: 30.9ms\n",
            "10:\tlearn: 0.2958541\ttotal: 19.9ms\tremaining: 30.8ms\n",
            "11:\tlearn: 0.2901166\ttotal: 21.8ms\tremaining: 29.1ms\n",
            "12:\tlearn: 0.2841803\ttotal: 23.8ms\tremaining: 27.4ms\n",
            "13:\tlearn: 0.2789751\ttotal: 25.8ms\tremaining: 25.8ms\n",
            "14:\tlearn: 0.2715599\ttotal: 28.5ms\tremaining: 24.7ms\n",
            "15:\tlearn: 0.2663544\ttotal: 30.9ms\tremaining: 23.2ms\n",
            "16:\tlearn: 0.2615546\ttotal: 32.9ms\tremaining: 21.3ms\n",
            "17:\tlearn: 0.2560079\ttotal: 34.9ms\tremaining: 19.4ms\n",
            "18:\tlearn: 0.2507480\ttotal: 36.7ms\tremaining: 17.4ms\n",
            "19:\tlearn: 0.2450678\ttotal: 39.3ms\tremaining: 15.7ms\n",
            "20:\tlearn: 0.2413892\ttotal: 41.2ms\tremaining: 13.7ms\n",
            "21:\tlearn: 0.2378437\ttotal: 42.9ms\tremaining: 11.7ms\n",
            "22:\tlearn: 0.2344010\ttotal: 44.8ms\tremaining: 9.73ms\n",
            "23:\tlearn: 0.2304940\ttotal: 46.6ms\tremaining: 7.76ms\n",
            "24:\tlearn: 0.2269540\ttotal: 49.6ms\tremaining: 5.95ms\n",
            "25:\tlearn: 0.2232713\ttotal: 51.7ms\tremaining: 3.97ms\n",
            "26:\tlearn: 0.2208577\ttotal: 54.2ms\tremaining: 2.01ms\n",
            "27:\tlearn: 0.2181825\ttotal: 56.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.74ms\tremaining: 47.1ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.11ms\tremaining: 27.4ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.13ms\tremaining: 34.5ms\n",
            "3:\tlearn: 0.3266560\ttotal: 5.87ms\tremaining: 35.2ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.38ms\tremaining: 38.5ms\n",
            "5:\tlearn: 0.2907443\ttotal: 10.4ms\tremaining: 38.2ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12.1ms\tremaining: 36.4ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.3ms\tremaining: 33.1ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15ms\tremaining: 31.7ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.4ms\tremaining: 31.3ms\n",
            "10:\tlearn: 0.2462992\ttotal: 27.8ms\tremaining: 42.9ms\n",
            "11:\tlearn: 0.2416348\ttotal: 35.2ms\tremaining: 46.9ms\n",
            "12:\tlearn: 0.2368688\ttotal: 37.5ms\tremaining: 43.3ms\n",
            "13:\tlearn: 0.2320170\ttotal: 39.8ms\tremaining: 39.8ms\n",
            "14:\tlearn: 0.2262186\ttotal: 41.4ms\tremaining: 35.9ms\n",
            "15:\tlearn: 0.2215380\ttotal: 43.6ms\tremaining: 32.7ms\n",
            "16:\tlearn: 0.2176313\ttotal: 46ms\tremaining: 29.8ms\n",
            "17:\tlearn: 0.2138494\ttotal: 47.6ms\tremaining: 26.4ms\n",
            "18:\tlearn: 0.2100966\ttotal: 49.3ms\tremaining: 23.4ms\n",
            "19:\tlearn: 0.2068557\ttotal: 50.9ms\tremaining: 20.4ms\n",
            "20:\tlearn: 0.2029945\ttotal: 53.1ms\tremaining: 17.7ms\n",
            "21:\tlearn: 0.2001044\ttotal: 55.5ms\tremaining: 15.1ms\n",
            "22:\tlearn: 0.1970766\ttotal: 57.2ms\tremaining: 12.4ms\n",
            "23:\tlearn: 0.1940285\ttotal: 58.9ms\tremaining: 9.81ms\n",
            "24:\tlearn: 0.1910934\ttotal: 60.5ms\tremaining: 7.25ms\n",
            "25:\tlearn: 0.1879112\ttotal: 62.6ms\tremaining: 4.82ms\n",
            "26:\tlearn: 0.1852765\ttotal: 65.1ms\tremaining: 2.41ms\n",
            "27:\tlearn: 0.1827068\ttotal: 67.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.73ms\tremaining: 46.8ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.11ms\tremaining: 27.4ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.59ms\tremaining: 21.6ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.31ms\tremaining: 25.8ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.23ms\tremaining: 28.6ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.83ms\tremaining: 32.4ms\n",
            "6:\tlearn: 0.2792409\ttotal: 11.2ms\tremaining: 33.6ms\n",
            "7:\tlearn: 0.2716618\ttotal: 13ms\tremaining: 32.6ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.8ms\tremaining: 31.3ms\n",
            "9:\tlearn: 0.2537973\ttotal: 16.7ms\tremaining: 30ms\n",
            "10:\tlearn: 0.2473429\ttotal: 19.4ms\tremaining: 29.9ms\n",
            "11:\tlearn: 0.2416695\ttotal: 21.4ms\tremaining: 28.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 23.1ms\tremaining: 26.7ms\n",
            "13:\tlearn: 0.2298385\ttotal: 25ms\tremaining: 25ms\n",
            "14:\tlearn: 0.2249545\ttotal: 28.6ms\tremaining: 24.8ms\n",
            "15:\tlearn: 0.2192054\ttotal: 31.4ms\tremaining: 23.6ms\n",
            "16:\tlearn: 0.2150242\ttotal: 33.5ms\tremaining: 21.7ms\n",
            "17:\tlearn: 0.2094516\ttotal: 36ms\tremaining: 20ms\n",
            "18:\tlearn: 0.2056324\ttotal: 37.7ms\tremaining: 17.8ms\n",
            "19:\tlearn: 0.2021225\ttotal: 39.3ms\tremaining: 15.7ms\n",
            "20:\tlearn: 0.1989042\ttotal: 40.9ms\tremaining: 13.6ms\n",
            "21:\tlearn: 0.1961040\ttotal: 43.2ms\tremaining: 11.8ms\n",
            "22:\tlearn: 0.1934794\ttotal: 45.6ms\tremaining: 9.92ms\n",
            "23:\tlearn: 0.1902438\ttotal: 47.5ms\tremaining: 7.91ms\n",
            "24:\tlearn: 0.1874921\ttotal: 49.3ms\tremaining: 5.91ms\n",
            "25:\tlearn: 0.1829904\ttotal: 50.9ms\tremaining: 3.92ms\n",
            "26:\tlearn: 0.1804169\ttotal: 53.2ms\tremaining: 1.97ms\n",
            "27:\tlearn: 0.1776989\ttotal: 55.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.63ms\tremaining: 45.6ms\n",
            "1:\tlearn: 0.4229987\ttotal: 1.97ms\tremaining: 26.6ms\n",
            "2:\tlearn: 0.3843342\ttotal: 3.59ms\tremaining: 31.1ms\n",
            "3:\tlearn: 0.3652888\ttotal: 5.75ms\tremaining: 35.9ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.34ms\tremaining: 40.1ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.2ms\tremaining: 39.1ms\n",
            "6:\tlearn: 0.3300914\ttotal: 11.8ms\tremaining: 37ms\n",
            "7:\tlearn: 0.3229079\ttotal: 13.4ms\tremaining: 35.3ms\n",
            "8:\tlearn: 0.3148279\ttotal: 15.2ms\tremaining: 33.7ms\n",
            "9:\tlearn: 0.3054626\ttotal: 26.1ms\tremaining: 49.6ms\n",
            "10:\tlearn: 0.2983658\ttotal: 28.9ms\tremaining: 47.2ms\n",
            "11:\tlearn: 0.2903440\ttotal: 31.4ms\tremaining: 44.5ms\n",
            "12:\tlearn: 0.2852979\ttotal: 33.4ms\tremaining: 41.2ms\n",
            "13:\tlearn: 0.2798563\ttotal: 35.1ms\tremaining: 37.6ms\n",
            "14:\tlearn: 0.2747341\ttotal: 36.7ms\tremaining: 34.3ms\n",
            "15:\tlearn: 0.2702568\ttotal: 38.4ms\tremaining: 31.2ms\n",
            "16:\tlearn: 0.2650537\ttotal: 40.6ms\tremaining: 28.6ms\n",
            "17:\tlearn: 0.2601005\ttotal: 42.2ms\tremaining: 25.8ms\n",
            "18:\tlearn: 0.2560578\ttotal: 44.9ms\tremaining: 23.6ms\n",
            "19:\tlearn: 0.2530381\ttotal: 47.4ms\tremaining: 21.3ms\n",
            "20:\tlearn: 0.2498453\ttotal: 49ms\tremaining: 18.7ms\n",
            "21:\tlearn: 0.2461646\ttotal: 50.6ms\tremaining: 16.1ms\n",
            "22:\tlearn: 0.2424369\ttotal: 52.4ms\tremaining: 13.7ms\n",
            "23:\tlearn: 0.2392835\ttotal: 54.9ms\tremaining: 11.4ms\n",
            "24:\tlearn: 0.2339070\ttotal: 56.9ms\tremaining: 9.1ms\n",
            "25:\tlearn: 0.2301706\ttotal: 58.6ms\tremaining: 6.76ms\n",
            "26:\tlearn: 0.2263007\ttotal: 60.3ms\tremaining: 4.46ms\n",
            "27:\tlearn: 0.2223209\ttotal: 62.3ms\tremaining: 2.23ms\n",
            "28:\tlearn: 0.2190932\ttotal: 64.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 3.93ms\tremaining: 110ms\n",
            "1:\tlearn: 0.4049315\ttotal: 4.55ms\tremaining: 61.5ms\n",
            "2:\tlearn: 0.3788145\ttotal: 7.66ms\tremaining: 66.4ms\n",
            "3:\tlearn: 0.3658016\ttotal: 12.8ms\tremaining: 79.7ms\n",
            "4:\tlearn: 0.3428474\ttotal: 16ms\tremaining: 76.7ms\n",
            "5:\tlearn: 0.3234303\ttotal: 17.6ms\tremaining: 67.6ms\n",
            "6:\tlearn: 0.3158416\ttotal: 21ms\tremaining: 65.9ms\n",
            "7:\tlearn: 0.3097739\ttotal: 25.8ms\tremaining: 67.7ms\n",
            "8:\tlearn: 0.3040041\ttotal: 30.8ms\tremaining: 68.4ms\n",
            "9:\tlearn: 0.2975585\ttotal: 35.6ms\tremaining: 67.7ms\n",
            "10:\tlearn: 0.2898709\ttotal: 40.3ms\tremaining: 66ms\n",
            "11:\tlearn: 0.2845372\ttotal: 44.9ms\tremaining: 63.7ms\n",
            "12:\tlearn: 0.2794184\ttotal: 49.5ms\tremaining: 61ms\n",
            "13:\tlearn: 0.2740314\ttotal: 54.3ms\tremaining: 58.2ms\n",
            "14:\tlearn: 0.2705542\ttotal: 59.1ms\tremaining: 55.2ms\n",
            "15:\tlearn: 0.2673919\ttotal: 64ms\tremaining: 52ms\n",
            "16:\tlearn: 0.2623365\ttotal: 68.8ms\tremaining: 48.6ms\n",
            "17:\tlearn: 0.2595719\ttotal: 73.6ms\tremaining: 45ms\n",
            "18:\tlearn: 0.2545713\ttotal: 78.2ms\tremaining: 41.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 82.8ms\tremaining: 37.3ms\n",
            "20:\tlearn: 0.2477056\ttotal: 84.6ms\tremaining: 32.2ms\n",
            "21:\tlearn: 0.2437884\ttotal: 86.7ms\tremaining: 27.6ms\n",
            "22:\tlearn: 0.2404080\ttotal: 89.2ms\tremaining: 23.3ms\n",
            "23:\tlearn: 0.2369058\ttotal: 91.3ms\tremaining: 19ms\n",
            "24:\tlearn: 0.2331119\ttotal: 93.2ms\tremaining: 14.9ms\n",
            "25:\tlearn: 0.2293455\ttotal: 95ms\tremaining: 11ms\n",
            "26:\tlearn: 0.2256418\ttotal: 97ms\tremaining: 7.18ms\n",
            "27:\tlearn: 0.2221119\ttotal: 99.5ms\tremaining: 3.55ms\n",
            "28:\tlearn: 0.2190925\ttotal: 101ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.69ms\tremaining: 75.5ms\n",
            "1:\tlearn: 0.4107278\ttotal: 3.6ms\tremaining: 48.6ms\n",
            "2:\tlearn: 0.3698157\ttotal: 4.11ms\tremaining: 35.6ms\n",
            "3:\tlearn: 0.3518120\ttotal: 5.95ms\tremaining: 37.2ms\n",
            "4:\tlearn: 0.3441195\ttotal: 7.73ms\tremaining: 37.1ms\n",
            "5:\tlearn: 0.3328396\ttotal: 10.1ms\tremaining: 38.6ms\n",
            "6:\tlearn: 0.3256704\ttotal: 12.2ms\tremaining: 38.2ms\n",
            "7:\tlearn: 0.3174441\ttotal: 13.9ms\tremaining: 36.4ms\n",
            "8:\tlearn: 0.3090762\ttotal: 15.5ms\tremaining: 34.4ms\n",
            "9:\tlearn: 0.3028459\ttotal: 17.3ms\tremaining: 32.9ms\n",
            "10:\tlearn: 0.2958541\ttotal: 19.7ms\tremaining: 32.2ms\n",
            "11:\tlearn: 0.2901166\ttotal: 22ms\tremaining: 31.1ms\n",
            "12:\tlearn: 0.2841803\ttotal: 23.7ms\tremaining: 29.1ms\n",
            "13:\tlearn: 0.2789751\ttotal: 25.8ms\tremaining: 27.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 27.7ms\tremaining: 25.8ms\n",
            "15:\tlearn: 0.2663544\ttotal: 29.9ms\tremaining: 24.3ms\n",
            "16:\tlearn: 0.2615546\ttotal: 32.4ms\tremaining: 22.8ms\n",
            "17:\tlearn: 0.2560079\ttotal: 34.2ms\tremaining: 20.9ms\n",
            "18:\tlearn: 0.2507480\ttotal: 35.8ms\tremaining: 18.8ms\n",
            "19:\tlearn: 0.2450678\ttotal: 37.5ms\tremaining: 16.9ms\n",
            "20:\tlearn: 0.2413892\ttotal: 39.4ms\tremaining: 15ms\n",
            "21:\tlearn: 0.2378437\ttotal: 41.8ms\tremaining: 13.3ms\n",
            "22:\tlearn: 0.2344010\ttotal: 43.8ms\tremaining: 11.4ms\n",
            "23:\tlearn: 0.2304940\ttotal: 45.4ms\tremaining: 9.45ms\n",
            "24:\tlearn: 0.2269540\ttotal: 47.2ms\tremaining: 7.55ms\n",
            "25:\tlearn: 0.2232713\ttotal: 48.7ms\tremaining: 5.62ms\n",
            "26:\tlearn: 0.2208577\ttotal: 51.1ms\tremaining: 3.79ms\n",
            "27:\tlearn: 0.2181825\ttotal: 53.5ms\tremaining: 1.91ms\n",
            "28:\tlearn: 0.2149071\ttotal: 55.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 5.53ms\tremaining: 155ms\n",
            "1:\tlearn: 0.3745079\ttotal: 6.21ms\tremaining: 83.9ms\n",
            "2:\tlearn: 0.3383999\ttotal: 8.78ms\tremaining: 76.1ms\n",
            "3:\tlearn: 0.3266560\ttotal: 10.9ms\tremaining: 67.9ms\n",
            "4:\tlearn: 0.3080259\ttotal: 12.7ms\tremaining: 60.8ms\n",
            "5:\tlearn: 0.2907443\ttotal: 14.4ms\tremaining: 55.1ms\n",
            "6:\tlearn: 0.2818467\ttotal: 16.6ms\tremaining: 52ms\n",
            "7:\tlearn: 0.2691784\ttotal: 18ms\tremaining: 47.3ms\n",
            "8:\tlearn: 0.2611618\ttotal: 20.1ms\tremaining: 44.7ms\n",
            "9:\tlearn: 0.2519898\ttotal: 21.9ms\tremaining: 41.6ms\n",
            "10:\tlearn: 0.2462992\ttotal: 23.7ms\tremaining: 38.8ms\n",
            "11:\tlearn: 0.2416348\ttotal: 28.1ms\tremaining: 39.8ms\n",
            "12:\tlearn: 0.2368688\ttotal: 30.9ms\tremaining: 38ms\n",
            "13:\tlearn: 0.2320170\ttotal: 33.2ms\tremaining: 35.5ms\n",
            "14:\tlearn: 0.2262186\ttotal: 35.9ms\tremaining: 33.5ms\n",
            "15:\tlearn: 0.2215380\ttotal: 38.2ms\tremaining: 31ms\n",
            "16:\tlearn: 0.2176313\ttotal: 40.4ms\tremaining: 28.5ms\n",
            "17:\tlearn: 0.2138494\ttotal: 43ms\tremaining: 26.2ms\n",
            "18:\tlearn: 0.2100966\ttotal: 44.7ms\tremaining: 23.5ms\n",
            "19:\tlearn: 0.2068557\ttotal: 47ms\tremaining: 21.2ms\n",
            "20:\tlearn: 0.2029945\ttotal: 49.8ms\tremaining: 19ms\n",
            "21:\tlearn: 0.2001044\ttotal: 61.2ms\tremaining: 19.5ms\n",
            "22:\tlearn: 0.1970766\ttotal: 63ms\tremaining: 16.4ms\n",
            "23:\tlearn: 0.1940285\ttotal: 65.4ms\tremaining: 13.6ms\n",
            "24:\tlearn: 0.1910934\ttotal: 67.4ms\tremaining: 10.8ms\n",
            "25:\tlearn: 0.1879112\ttotal: 69.9ms\tremaining: 8.07ms\n",
            "26:\tlearn: 0.1852765\ttotal: 71.9ms\tremaining: 5.32ms\n",
            "27:\tlearn: 0.1827068\ttotal: 73.7ms\tremaining: 2.63ms\n",
            "28:\tlearn: 0.1803359\ttotal: 75.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 2.8ms\tremaining: 78.5ms\n",
            "1:\tlearn: 0.3687510\ttotal: 3.71ms\tremaining: 50.2ms\n",
            "2:\tlearn: 0.3203557\ttotal: 4.48ms\tremaining: 38.8ms\n",
            "3:\tlearn: 0.3063743\ttotal: 7.04ms\tremaining: 44ms\n",
            "4:\tlearn: 0.2970911\ttotal: 8.79ms\tremaining: 42.2ms\n",
            "5:\tlearn: 0.2891054\ttotal: 10.5ms\tremaining: 40.1ms\n",
            "6:\tlearn: 0.2792409\ttotal: 12.1ms\tremaining: 38ms\n",
            "7:\tlearn: 0.2716618\ttotal: 14.4ms\tremaining: 37.9ms\n",
            "8:\tlearn: 0.2621352\ttotal: 17ms\tremaining: 37.7ms\n",
            "9:\tlearn: 0.2537973\ttotal: 18.8ms\tremaining: 35.7ms\n",
            "10:\tlearn: 0.2473429\ttotal: 20.3ms\tremaining: 33.2ms\n",
            "11:\tlearn: 0.2416695\ttotal: 22ms\tremaining: 31.1ms\n",
            "12:\tlearn: 0.2366343\ttotal: 23.7ms\tremaining: 29.2ms\n",
            "13:\tlearn: 0.2298385\ttotal: 26.1ms\tremaining: 27.9ms\n",
            "14:\tlearn: 0.2249545\ttotal: 28.2ms\tremaining: 26.3ms\n",
            "15:\tlearn: 0.2192054\ttotal: 29.7ms\tremaining: 24.2ms\n",
            "16:\tlearn: 0.2150242\ttotal: 31.4ms\tremaining: 22.2ms\n",
            "17:\tlearn: 0.2094516\ttotal: 33ms\tremaining: 20.1ms\n",
            "18:\tlearn: 0.2056324\ttotal: 36ms\tremaining: 18.9ms\n",
            "19:\tlearn: 0.2021225\ttotal: 38.2ms\tremaining: 17.2ms\n",
            "20:\tlearn: 0.1989042\ttotal: 39.7ms\tremaining: 15.1ms\n",
            "21:\tlearn: 0.1961040\ttotal: 41.2ms\tremaining: 13.1ms\n",
            "22:\tlearn: 0.1934794\ttotal: 43.1ms\tremaining: 11.2ms\n",
            "23:\tlearn: 0.1902438\ttotal: 44.9ms\tremaining: 9.36ms\n",
            "24:\tlearn: 0.1874921\ttotal: 47.4ms\tremaining: 7.58ms\n",
            "25:\tlearn: 0.1829904\ttotal: 49ms\tremaining: 5.66ms\n",
            "26:\tlearn: 0.1804169\ttotal: 50.7ms\tremaining: 3.75ms\n",
            "27:\tlearn: 0.1776989\ttotal: 52.3ms\tremaining: 1.87ms\n",
            "28:\tlearn: 0.1751387\ttotal: 54.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.96ms\tremaining: 56.7ms\n",
            "1:\tlearn: 0.4229987\ttotal: 4.68ms\tremaining: 65.5ms\n",
            "2:\tlearn: 0.3843342\ttotal: 7.41ms\tremaining: 66.7ms\n",
            "3:\tlearn: 0.3652888\ttotal: 12.4ms\tremaining: 80.7ms\n",
            "4:\tlearn: 0.3496343\ttotal: 17.2ms\tremaining: 86.2ms\n",
            "5:\tlearn: 0.3393969\ttotal: 21.8ms\tremaining: 87.3ms\n",
            "6:\tlearn: 0.3300914\ttotal: 26.2ms\tremaining: 86.2ms\n",
            "7:\tlearn: 0.3229079\ttotal: 31ms\tremaining: 85.2ms\n",
            "8:\tlearn: 0.3148279\ttotal: 35.4ms\tremaining: 82.6ms\n",
            "9:\tlearn: 0.3054626\ttotal: 40.3ms\tremaining: 80.7ms\n",
            "10:\tlearn: 0.2983658\ttotal: 44.9ms\tremaining: 77.5ms\n",
            "11:\tlearn: 0.2903440\ttotal: 47.2ms\tremaining: 70.8ms\n",
            "12:\tlearn: 0.2852979\ttotal: 50.3ms\tremaining: 65.8ms\n",
            "13:\tlearn: 0.2798563\ttotal: 55.6ms\tremaining: 63.6ms\n",
            "14:\tlearn: 0.2747341\ttotal: 58.1ms\tremaining: 58.1ms\n",
            "15:\tlearn: 0.2702568\ttotal: 63.5ms\tremaining: 55.5ms\n",
            "16:\tlearn: 0.2650537\ttotal: 66ms\tremaining: 50.5ms\n",
            "17:\tlearn: 0.2601005\ttotal: 71.1ms\tremaining: 47.4ms\n",
            "18:\tlearn: 0.2560578\ttotal: 76ms\tremaining: 44ms\n",
            "19:\tlearn: 0.2530381\ttotal: 80.5ms\tremaining: 40.3ms\n",
            "20:\tlearn: 0.2498453\ttotal: 85ms\tremaining: 36.4ms\n",
            "21:\tlearn: 0.2461646\ttotal: 90ms\tremaining: 32.7ms\n",
            "22:\tlearn: 0.2424369\ttotal: 94.9ms\tremaining: 28.9ms\n",
            "23:\tlearn: 0.2392835\ttotal: 101ms\tremaining: 25.3ms\n",
            "24:\tlearn: 0.2339070\ttotal: 114ms\tremaining: 22.7ms\n",
            "25:\tlearn: 0.2301706\ttotal: 116ms\tremaining: 17.8ms\n",
            "26:\tlearn: 0.2263007\ttotal: 118ms\tremaining: 13.1ms\n",
            "27:\tlearn: 0.2223209\ttotal: 120ms\tremaining: 8.6ms\n",
            "28:\tlearn: 0.2190932\ttotal: 122ms\tremaining: 4.21ms\n",
            "29:\tlearn: 0.2159010\ttotal: 124ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 5.89ms\tremaining: 171ms\n",
            "1:\tlearn: 0.4049315\ttotal: 6.66ms\tremaining: 93.2ms\n",
            "2:\tlearn: 0.3788145\ttotal: 8.98ms\tremaining: 80.8ms\n",
            "3:\tlearn: 0.3658016\ttotal: 10.8ms\tremaining: 70.1ms\n",
            "4:\tlearn: 0.3428474\ttotal: 11.6ms\tremaining: 58ms\n",
            "5:\tlearn: 0.3234303\ttotal: 12.5ms\tremaining: 50.1ms\n",
            "6:\tlearn: 0.3158416\ttotal: 15.3ms\tremaining: 50.2ms\n",
            "7:\tlearn: 0.3097739\ttotal: 19.8ms\tremaining: 54.4ms\n",
            "8:\tlearn: 0.3040041\ttotal: 24.8ms\tremaining: 57.8ms\n",
            "9:\tlearn: 0.2975585\ttotal: 29.5ms\tremaining: 59.1ms\n",
            "10:\tlearn: 0.2898709\ttotal: 34.5ms\tremaining: 59.5ms\n",
            "11:\tlearn: 0.2845372\ttotal: 39.2ms\tremaining: 58.9ms\n",
            "12:\tlearn: 0.2794184\ttotal: 44.3ms\tremaining: 57.9ms\n",
            "13:\tlearn: 0.2740314\ttotal: 52.3ms\tremaining: 59.7ms\n",
            "14:\tlearn: 0.2705542\ttotal: 55ms\tremaining: 55ms\n",
            "15:\tlearn: 0.2673919\ttotal: 60.1ms\tremaining: 52.6ms\n",
            "16:\tlearn: 0.2623365\ttotal: 65ms\tremaining: 49.7ms\n",
            "17:\tlearn: 0.2595719\ttotal: 69.8ms\tremaining: 46.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 74.6ms\tremaining: 43.2ms\n",
            "19:\tlearn: 0.2510766\ttotal: 79.6ms\tremaining: 39.8ms\n",
            "20:\tlearn: 0.2477056\ttotal: 84.3ms\tremaining: 36.1ms\n",
            "21:\tlearn: 0.2437884\ttotal: 89.2ms\tremaining: 32.4ms\n",
            "22:\tlearn: 0.2404080\ttotal: 94.2ms\tremaining: 28.7ms\n",
            "23:\tlearn: 0.2369058\ttotal: 99.1ms\tremaining: 24.8ms\n",
            "24:\tlearn: 0.2331119\ttotal: 104ms\tremaining: 20.8ms\n",
            "25:\tlearn: 0.2293455\ttotal: 109ms\tremaining: 16.8ms\n",
            "26:\tlearn: 0.2256418\ttotal: 114ms\tremaining: 12.7ms\n",
            "27:\tlearn: 0.2221119\ttotal: 119ms\tremaining: 8.53ms\n",
            "28:\tlearn: 0.2190925\ttotal: 123ms\tremaining: 4.24ms\n",
            "29:\tlearn: 0.2161731\ttotal: 128ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 4.27ms\tremaining: 124ms\n",
            "1:\tlearn: 0.4107278\ttotal: 5.25ms\tremaining: 73.5ms\n",
            "2:\tlearn: 0.3698157\ttotal: 5.77ms\tremaining: 51.9ms\n",
            "3:\tlearn: 0.3518120\ttotal: 8.17ms\tremaining: 53.1ms\n",
            "4:\tlearn: 0.3441195\ttotal: 10.7ms\tremaining: 53.7ms\n",
            "5:\tlearn: 0.3328396\ttotal: 12.6ms\tremaining: 50.2ms\n",
            "6:\tlearn: 0.3256704\ttotal: 14.5ms\tremaining: 47.6ms\n",
            "7:\tlearn: 0.3174441\ttotal: 16.4ms\tremaining: 45.1ms\n",
            "8:\tlearn: 0.3090762\ttotal: 18.6ms\tremaining: 43.5ms\n",
            "9:\tlearn: 0.3028459\ttotal: 26.2ms\tremaining: 52.5ms\n",
            "10:\tlearn: 0.2958541\ttotal: 28ms\tremaining: 48.4ms\n",
            "11:\tlearn: 0.2901166\ttotal: 29.8ms\tremaining: 44.7ms\n",
            "12:\tlearn: 0.2841803\ttotal: 31.8ms\tremaining: 41.6ms\n",
            "13:\tlearn: 0.2789751\ttotal: 34.5ms\tremaining: 39.5ms\n",
            "14:\tlearn: 0.2715599\ttotal: 36.6ms\tremaining: 36.6ms\n",
            "15:\tlearn: 0.2663544\ttotal: 38.4ms\tremaining: 33.6ms\n",
            "16:\tlearn: 0.2615546\ttotal: 40.2ms\tremaining: 30.8ms\n",
            "17:\tlearn: 0.2560079\ttotal: 41.9ms\tremaining: 27.9ms\n",
            "18:\tlearn: 0.2507480\ttotal: 44.4ms\tremaining: 25.7ms\n",
            "19:\tlearn: 0.2450678\ttotal: 46.4ms\tremaining: 23.2ms\n",
            "20:\tlearn: 0.2413892\ttotal: 48.2ms\tremaining: 20.6ms\n",
            "21:\tlearn: 0.2378437\ttotal: 50ms\tremaining: 18.2ms\n",
            "22:\tlearn: 0.2344010\ttotal: 52.2ms\tremaining: 15.9ms\n",
            "23:\tlearn: 0.2304940\ttotal: 53.9ms\tremaining: 13.5ms\n",
            "24:\tlearn: 0.2269540\ttotal: 56ms\tremaining: 11.2ms\n",
            "25:\tlearn: 0.2232713\ttotal: 58.4ms\tremaining: 8.99ms\n",
            "26:\tlearn: 0.2208577\ttotal: 60.4ms\tremaining: 6.71ms\n",
            "27:\tlearn: 0.2181825\ttotal: 62.2ms\tremaining: 4.44ms\n",
            "28:\tlearn: 0.2149071\ttotal: 63.9ms\tremaining: 2.2ms\n",
            "29:\tlearn: 0.2123638\ttotal: 65.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 2.53ms\tremaining: 73.5ms\n",
            "1:\tlearn: 0.3745079\ttotal: 6.24ms\tremaining: 87.3ms\n",
            "2:\tlearn: 0.3383999\ttotal: 9.33ms\tremaining: 84ms\n",
            "3:\tlearn: 0.3266560\ttotal: 14.6ms\tremaining: 95.2ms\n",
            "4:\tlearn: 0.3080259\ttotal: 19.4ms\tremaining: 97.2ms\n",
            "5:\tlearn: 0.2907443\ttotal: 23.8ms\tremaining: 95.2ms\n",
            "6:\tlearn: 0.2818467\ttotal: 28.4ms\tremaining: 93.4ms\n",
            "7:\tlearn: 0.2691784\ttotal: 32ms\tremaining: 88.1ms\n",
            "8:\tlearn: 0.2611618\ttotal: 35.7ms\tremaining: 83.2ms\n",
            "9:\tlearn: 0.2519898\ttotal: 40.5ms\tremaining: 81ms\n",
            "10:\tlearn: 0.2462992\ttotal: 45.3ms\tremaining: 78.2ms\n",
            "11:\tlearn: 0.2416348\ttotal: 50.2ms\tremaining: 75.4ms\n",
            "12:\tlearn: 0.2368688\ttotal: 55.2ms\tremaining: 72.1ms\n",
            "13:\tlearn: 0.2320170\ttotal: 59.9ms\tremaining: 68.4ms\n",
            "14:\tlearn: 0.2262186\ttotal: 64.6ms\tremaining: 64.6ms\n",
            "15:\tlearn: 0.2215380\ttotal: 69.5ms\tremaining: 60.8ms\n",
            "16:\tlearn: 0.2176313\ttotal: 75.5ms\tremaining: 57.8ms\n",
            "17:\tlearn: 0.2138494\ttotal: 79.1ms\tremaining: 52.7ms\n",
            "18:\tlearn: 0.2100966\ttotal: 84ms\tremaining: 48.7ms\n",
            "19:\tlearn: 0.2068557\ttotal: 91.2ms\tremaining: 45.6ms\n",
            "20:\tlearn: 0.2029945\ttotal: 96.2ms\tremaining: 41.2ms\n",
            "21:\tlearn: 0.2001044\ttotal: 101ms\tremaining: 36.9ms\n",
            "22:\tlearn: 0.1970766\ttotal: 112ms\tremaining: 34.2ms\n",
            "23:\tlearn: 0.1940285\ttotal: 116ms\tremaining: 29.1ms\n",
            "24:\tlearn: 0.1910934\ttotal: 123ms\tremaining: 24.7ms\n",
            "25:\tlearn: 0.1879112\ttotal: 130ms\tremaining: 20ms\n",
            "26:\tlearn: 0.1852765\ttotal: 135ms\tremaining: 14.9ms\n",
            "27:\tlearn: 0.1827068\ttotal: 140ms\tremaining: 9.97ms\n",
            "28:\tlearn: 0.1803359\ttotal: 144ms\tremaining: 4.98ms\n",
            "29:\tlearn: 0.1779549\ttotal: 149ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 3.84ms\tremaining: 111ms\n",
            "1:\tlearn: 0.3687510\ttotal: 7.64ms\tremaining: 107ms\n",
            "2:\tlearn: 0.3203557\ttotal: 8.46ms\tremaining: 76.1ms\n",
            "3:\tlearn: 0.3063743\ttotal: 12ms\tremaining: 78ms\n",
            "4:\tlearn: 0.2970911\ttotal: 17.3ms\tremaining: 86.7ms\n",
            "5:\tlearn: 0.2891054\ttotal: 22.4ms\tremaining: 89.5ms\n",
            "6:\tlearn: 0.2792409\ttotal: 26.8ms\tremaining: 87.9ms\n",
            "7:\tlearn: 0.2716618\ttotal: 31.8ms\tremaining: 87.3ms\n",
            "8:\tlearn: 0.2621352\ttotal: 36.4ms\tremaining: 84.9ms\n",
            "9:\tlearn: 0.2537973\ttotal: 41.7ms\tremaining: 83.4ms\n",
            "10:\tlearn: 0.2473429\ttotal: 44.2ms\tremaining: 76.3ms\n",
            "11:\tlearn: 0.2416695\ttotal: 49ms\tremaining: 73.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 53.6ms\tremaining: 70.1ms\n",
            "13:\tlearn: 0.2298385\ttotal: 58.5ms\tremaining: 66.8ms\n",
            "14:\tlearn: 0.2249545\ttotal: 60.1ms\tremaining: 60.1ms\n",
            "15:\tlearn: 0.2192054\ttotal: 62.8ms\tremaining: 54.9ms\n",
            "16:\tlearn: 0.2150242\ttotal: 64.7ms\tremaining: 49.5ms\n",
            "17:\tlearn: 0.2094516\ttotal: 66.4ms\tremaining: 44.3ms\n",
            "18:\tlearn: 0.2056324\ttotal: 68.1ms\tremaining: 39.4ms\n",
            "19:\tlearn: 0.2021225\ttotal: 69.8ms\tremaining: 34.9ms\n",
            "20:\tlearn: 0.1989042\ttotal: 72.4ms\tremaining: 31ms\n",
            "21:\tlearn: 0.1961040\ttotal: 74.6ms\tremaining: 27.1ms\n",
            "22:\tlearn: 0.1934794\ttotal: 76.3ms\tremaining: 23.2ms\n",
            "23:\tlearn: 0.1902438\ttotal: 78.1ms\tremaining: 19.5ms\n",
            "24:\tlearn: 0.1874921\ttotal: 79.8ms\tremaining: 16ms\n",
            "25:\tlearn: 0.1829904\ttotal: 82.3ms\tremaining: 12.7ms\n",
            "26:\tlearn: 0.1804169\ttotal: 86.2ms\tremaining: 9.58ms\n",
            "27:\tlearn: 0.1776989\ttotal: 87.9ms\tremaining: 6.28ms\n",
            "28:\tlearn: 0.1751387\ttotal: 90.5ms\tremaining: 3.12ms\n",
            "29:\tlearn: 0.1727570\ttotal: 92.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.78ms\tremaining: 53.4ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.14ms\tremaining: 31ms\n",
            "2:\tlearn: 0.3843342\ttotal: 3.87ms\tremaining: 36.1ms\n",
            "3:\tlearn: 0.3652888\ttotal: 5.63ms\tremaining: 38ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.12ms\tremaining: 42.2ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.1ms\tremaining: 42ms\n",
            "6:\tlearn: 0.3300914\ttotal: 11.7ms\tremaining: 40.2ms\n",
            "7:\tlearn: 0.3229079\ttotal: 13.5ms\tremaining: 38.7ms\n",
            "8:\tlearn: 0.3148279\ttotal: 15.6ms\tremaining: 38.1ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.1ms\tremaining: 38.1ms\n",
            "10:\tlearn: 0.2983658\ttotal: 19.9ms\tremaining: 36.1ms\n",
            "11:\tlearn: 0.2903440\ttotal: 21.7ms\tremaining: 34.3ms\n",
            "12:\tlearn: 0.2852979\ttotal: 23.4ms\tremaining: 32.4ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.5ms\tremaining: 30.9ms\n",
            "14:\tlearn: 0.2747341\ttotal: 28.1ms\tremaining: 30ms\n",
            "15:\tlearn: 0.2702568\ttotal: 29.9ms\tremaining: 28.1ms\n",
            "16:\tlearn: 0.2650537\ttotal: 31.7ms\tremaining: 26.1ms\n",
            "17:\tlearn: 0.2601005\ttotal: 33.3ms\tremaining: 24.1ms\n",
            "18:\tlearn: 0.2560578\ttotal: 35ms\tremaining: 22.1ms\n",
            "19:\tlearn: 0.2530381\ttotal: 37.6ms\tremaining: 20.7ms\n",
            "20:\tlearn: 0.2498453\ttotal: 39.7ms\tremaining: 18.9ms\n",
            "21:\tlearn: 0.2461646\ttotal: 41.7ms\tremaining: 17ms\n",
            "22:\tlearn: 0.2424369\ttotal: 43.4ms\tremaining: 15.1ms\n",
            "23:\tlearn: 0.2392835\ttotal: 55.7ms\tremaining: 16.3ms\n",
            "24:\tlearn: 0.2339070\ttotal: 58.1ms\tremaining: 14ms\n",
            "25:\tlearn: 0.2301706\ttotal: 60.1ms\tremaining: 11.6ms\n",
            "26:\tlearn: 0.2263007\ttotal: 66.3ms\tremaining: 9.82ms\n",
            "27:\tlearn: 0.2223209\ttotal: 68.7ms\tremaining: 7.36ms\n",
            "28:\tlearn: 0.2190932\ttotal: 72.5ms\tremaining: 5ms\n",
            "29:\tlearn: 0.2159010\ttotal: 76.9ms\tremaining: 2.56ms\n",
            "30:\tlearn: 0.2132954\ttotal: 82.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 7.15ms\tremaining: 214ms\n",
            "1:\tlearn: 0.4049315\ttotal: 7.63ms\tremaining: 111ms\n",
            "2:\tlearn: 0.3788145\ttotal: 9.78ms\tremaining: 91.3ms\n",
            "3:\tlearn: 0.3658016\ttotal: 12.1ms\tremaining: 81.9ms\n",
            "4:\tlearn: 0.3428474\ttotal: 12.9ms\tremaining: 67ms\n",
            "5:\tlearn: 0.3234303\ttotal: 13.6ms\tremaining: 56.8ms\n",
            "6:\tlearn: 0.3158416\ttotal: 15.8ms\tremaining: 54.3ms\n",
            "7:\tlearn: 0.3097739\ttotal: 17.8ms\tremaining: 51.2ms\n",
            "8:\tlearn: 0.3040041\ttotal: 19.9ms\tremaining: 48.7ms\n",
            "9:\tlearn: 0.2975585\ttotal: 22.8ms\tremaining: 47.8ms\n",
            "10:\tlearn: 0.2898709\ttotal: 31.4ms\tremaining: 57.1ms\n",
            "11:\tlearn: 0.2845372\ttotal: 38.2ms\tremaining: 60.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 40.6ms\tremaining: 56.3ms\n",
            "13:\tlearn: 0.2740314\ttotal: 43.6ms\tremaining: 52.9ms\n",
            "14:\tlearn: 0.2705542\ttotal: 45.9ms\tremaining: 48.9ms\n",
            "15:\tlearn: 0.2673919\ttotal: 48.4ms\tremaining: 45.4ms\n",
            "16:\tlearn: 0.2623365\ttotal: 50.3ms\tremaining: 41.4ms\n",
            "17:\tlearn: 0.2595719\ttotal: 52.5ms\tremaining: 37.9ms\n",
            "18:\tlearn: 0.2545713\ttotal: 58.2ms\tremaining: 36.7ms\n",
            "19:\tlearn: 0.2510766\ttotal: 64.7ms\tremaining: 35.6ms\n",
            "20:\tlearn: 0.2477056\ttotal: 66.5ms\tremaining: 31.7ms\n",
            "21:\tlearn: 0.2437884\ttotal: 68.8ms\tremaining: 28.2ms\n",
            "22:\tlearn: 0.2404080\ttotal: 73.4ms\tremaining: 25.5ms\n",
            "23:\tlearn: 0.2369058\ttotal: 75.3ms\tremaining: 22ms\n",
            "24:\tlearn: 0.2331119\ttotal: 77.1ms\tremaining: 18.5ms\n",
            "25:\tlearn: 0.2293455\ttotal: 84.6ms\tremaining: 16.3ms\n",
            "26:\tlearn: 0.2256418\ttotal: 89ms\tremaining: 13.2ms\n",
            "27:\tlearn: 0.2221119\ttotal: 92.8ms\tremaining: 9.94ms\n",
            "28:\tlearn: 0.2190925\ttotal: 96.6ms\tremaining: 6.66ms\n",
            "29:\tlearn: 0.2161731\ttotal: 98.6ms\tremaining: 3.29ms\n",
            "30:\tlearn: 0.2135041\ttotal: 109ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.99ms\tremaining: 89.8ms\n",
            "1:\tlearn: 0.4107278\ttotal: 3.36ms\tremaining: 48.7ms\n",
            "2:\tlearn: 0.3698157\ttotal: 3.98ms\tremaining: 37.2ms\n",
            "3:\tlearn: 0.3518120\ttotal: 8.81ms\tremaining: 59.5ms\n",
            "4:\tlearn: 0.3441195\ttotal: 12.9ms\tremaining: 67ms\n",
            "5:\tlearn: 0.3328396\ttotal: 17.7ms\tremaining: 73.8ms\n",
            "6:\tlearn: 0.3256704\ttotal: 19.5ms\tremaining: 66.8ms\n",
            "7:\tlearn: 0.3174441\ttotal: 23.4ms\tremaining: 67.3ms\n",
            "8:\tlearn: 0.3090762\ttotal: 29.5ms\tremaining: 72ms\n",
            "9:\tlearn: 0.3028459\ttotal: 31.7ms\tremaining: 66.6ms\n",
            "10:\tlearn: 0.2958541\ttotal: 39.2ms\tremaining: 71.3ms\n",
            "11:\tlearn: 0.2901166\ttotal: 40.9ms\tremaining: 64.8ms\n",
            "12:\tlearn: 0.2841803\ttotal: 48.5ms\tremaining: 67.2ms\n",
            "13:\tlearn: 0.2789751\ttotal: 54.9ms\tremaining: 66.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 56.9ms\tremaining: 60.6ms\n",
            "15:\tlearn: 0.2663544\ttotal: 58.6ms\tremaining: 54.9ms\n",
            "16:\tlearn: 0.2615546\ttotal: 60.4ms\tremaining: 49.7ms\n",
            "17:\tlearn: 0.2560079\ttotal: 62.2ms\tremaining: 45ms\n",
            "18:\tlearn: 0.2507480\ttotal: 70.1ms\tremaining: 44.2ms\n",
            "19:\tlearn: 0.2450678\ttotal: 71.9ms\tremaining: 39.6ms\n",
            "20:\tlearn: 0.2413892\ttotal: 73.6ms\tremaining: 35.1ms\n",
            "21:\tlearn: 0.2378437\ttotal: 75.7ms\tremaining: 31ms\n",
            "22:\tlearn: 0.2344010\ttotal: 77.6ms\tremaining: 27ms\n",
            "23:\tlearn: 0.2304940\ttotal: 79.5ms\tremaining: 23.2ms\n",
            "24:\tlearn: 0.2269540\ttotal: 81.5ms\tremaining: 19.6ms\n",
            "25:\tlearn: 0.2232713\ttotal: 85.5ms\tremaining: 16.4ms\n",
            "26:\tlearn: 0.2208577\ttotal: 87.7ms\tremaining: 13ms\n",
            "27:\tlearn: 0.2181825\ttotal: 90.2ms\tremaining: 9.66ms\n",
            "28:\tlearn: 0.2149071\ttotal: 101ms\tremaining: 6.96ms\n",
            "29:\tlearn: 0.2123638\ttotal: 103ms\tremaining: 3.43ms\n",
            "30:\tlearn: 0.2094640\ttotal: 105ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.76ms\tremaining: 52.7ms\n",
            "1:\tlearn: 0.3745079\ttotal: 4.03ms\tremaining: 58.5ms\n",
            "2:\tlearn: 0.3383999\ttotal: 6.1ms\tremaining: 56.9ms\n",
            "3:\tlearn: 0.3266560\ttotal: 15.1ms\tremaining: 102ms\n",
            "4:\tlearn: 0.3080259\ttotal: 16.9ms\tremaining: 87.7ms\n",
            "5:\tlearn: 0.2907443\ttotal: 25.6ms\tremaining: 107ms\n",
            "6:\tlearn: 0.2818467\ttotal: 27.3ms\tremaining: 93.7ms\n",
            "7:\tlearn: 0.2691784\ttotal: 28.4ms\tremaining: 81.7ms\n",
            "8:\tlearn: 0.2611618\ttotal: 30.2ms\tremaining: 73.9ms\n",
            "9:\tlearn: 0.2519898\ttotal: 32ms\tremaining: 67.3ms\n",
            "10:\tlearn: 0.2462992\ttotal: 33.8ms\tremaining: 61.4ms\n",
            "11:\tlearn: 0.2416348\ttotal: 41.6ms\tremaining: 65.8ms\n",
            "12:\tlearn: 0.2368688\ttotal: 43.4ms\tremaining: 60.1ms\n",
            "13:\tlearn: 0.2320170\ttotal: 45.8ms\tremaining: 55.6ms\n",
            "14:\tlearn: 0.2262186\ttotal: 47.6ms\tremaining: 50.7ms\n",
            "15:\tlearn: 0.2215380\ttotal: 49.5ms\tremaining: 46.4ms\n",
            "16:\tlearn: 0.2176313\ttotal: 51.9ms\tremaining: 42.7ms\n",
            "17:\tlearn: 0.2138494\ttotal: 54ms\tremaining: 39ms\n",
            "18:\tlearn: 0.2100966\ttotal: 60.5ms\tremaining: 38.2ms\n",
            "19:\tlearn: 0.2068557\ttotal: 64ms\tremaining: 35.2ms\n",
            "20:\tlearn: 0.2029945\ttotal: 65.9ms\tremaining: 31.4ms\n",
            "21:\tlearn: 0.2001044\ttotal: 68.3ms\tremaining: 27.9ms\n",
            "22:\tlearn: 0.1970766\ttotal: 70.2ms\tremaining: 24.4ms\n",
            "23:\tlearn: 0.1940285\ttotal: 74.8ms\tremaining: 21.8ms\n",
            "24:\tlearn: 0.1910934\ttotal: 81ms\tremaining: 19.4ms\n",
            "25:\tlearn: 0.1879112\ttotal: 86.2ms\tremaining: 16.6ms\n",
            "26:\tlearn: 0.1852765\ttotal: 88.1ms\tremaining: 13ms\n",
            "27:\tlearn: 0.1827068\ttotal: 90ms\tremaining: 9.64ms\n",
            "28:\tlearn: 0.1803359\ttotal: 91.8ms\tremaining: 6.33ms\n",
            "29:\tlearn: 0.1779549\ttotal: 93.6ms\tremaining: 3.12ms\n",
            "30:\tlearn: 0.1757984\ttotal: 99.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 6.89ms\tremaining: 207ms\n",
            "1:\tlearn: 0.3687510\ttotal: 7.45ms\tremaining: 108ms\n",
            "2:\tlearn: 0.3203557\ttotal: 8.14ms\tremaining: 75.9ms\n",
            "3:\tlearn: 0.3063743\ttotal: 10.7ms\tremaining: 72.2ms\n",
            "4:\tlearn: 0.2970911\ttotal: 23.5ms\tremaining: 122ms\n",
            "5:\tlearn: 0.2891054\ttotal: 25.7ms\tremaining: 107ms\n",
            "6:\tlearn: 0.2792409\ttotal: 28ms\tremaining: 96.1ms\n",
            "7:\tlearn: 0.2716618\ttotal: 30.1ms\tremaining: 86.4ms\n",
            "8:\tlearn: 0.2621352\ttotal: 32.4ms\tremaining: 79.2ms\n",
            "9:\tlearn: 0.2537973\ttotal: 41.4ms\tremaining: 86.9ms\n",
            "10:\tlearn: 0.2473429\ttotal: 43.6ms\tremaining: 79.3ms\n",
            "11:\tlearn: 0.2416695\ttotal: 50.6ms\tremaining: 80.2ms\n",
            "12:\tlearn: 0.2366343\ttotal: 53.4ms\tremaining: 73.9ms\n",
            "13:\tlearn: 0.2298385\ttotal: 56ms\tremaining: 68ms\n",
            "14:\tlearn: 0.2249545\ttotal: 63.1ms\tremaining: 67.3ms\n",
            "15:\tlearn: 0.2192054\ttotal: 65.1ms\tremaining: 61ms\n",
            "16:\tlearn: 0.2150242\ttotal: 66.8ms\tremaining: 55ms\n",
            "17:\tlearn: 0.2094516\ttotal: 69.3ms\tremaining: 50.1ms\n",
            "18:\tlearn: 0.2056324\ttotal: 71ms\tremaining: 44.8ms\n",
            "19:\tlearn: 0.2021225\ttotal: 83ms\tremaining: 45.6ms\n",
            "20:\tlearn: 0.1989042\ttotal: 84.8ms\tremaining: 40.4ms\n",
            "21:\tlearn: 0.1961040\ttotal: 87.5ms\tremaining: 35.8ms\n",
            "22:\tlearn: 0.1934794\ttotal: 90ms\tremaining: 31.3ms\n",
            "23:\tlearn: 0.1902438\ttotal: 100ms\tremaining: 29.2ms\n",
            "24:\tlearn: 0.1874921\ttotal: 103ms\tremaining: 24.6ms\n",
            "25:\tlearn: 0.1829904\ttotal: 105ms\tremaining: 20.2ms\n",
            "26:\tlearn: 0.1804169\ttotal: 107ms\tremaining: 15.9ms\n",
            "27:\tlearn: 0.1776989\ttotal: 111ms\tremaining: 11.9ms\n",
            "28:\tlearn: 0.1751387\ttotal: 115ms\tremaining: 7.96ms\n",
            "29:\tlearn: 0.1727570\ttotal: 120ms\tremaining: 3.99ms\n",
            "30:\tlearn: 0.1693663\ttotal: 124ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 2.66ms\tremaining: 82.4ms\n",
            "1:\tlearn: 0.4229987\ttotal: 4.51ms\tremaining: 67.7ms\n",
            "2:\tlearn: 0.3843342\ttotal: 7.25ms\tremaining: 70.1ms\n",
            "3:\tlearn: 0.3652888\ttotal: 13.1ms\tremaining: 91.9ms\n",
            "4:\tlearn: 0.3496343\ttotal: 15.8ms\tremaining: 85.5ms\n",
            "5:\tlearn: 0.3393969\ttotal: 27.6ms\tremaining: 120ms\n",
            "6:\tlearn: 0.3300914\ttotal: 32.3ms\tremaining: 115ms\n",
            "7:\tlearn: 0.3229079\ttotal: 37ms\tremaining: 111ms\n",
            "8:\tlearn: 0.3148279\ttotal: 48.9ms\tremaining: 125ms\n",
            "9:\tlearn: 0.3054626\ttotal: 54.6ms\tremaining: 120ms\n",
            "10:\tlearn: 0.2983658\ttotal: 57.2ms\tremaining: 109ms\n",
            "11:\tlearn: 0.2903440\ttotal: 68.8ms\tremaining: 115ms\n",
            "12:\tlearn: 0.2852979\ttotal: 74ms\tremaining: 108ms\n",
            "13:\tlearn: 0.2798563\ttotal: 82.4ms\tremaining: 106ms\n",
            "14:\tlearn: 0.2747341\ttotal: 94.2ms\tremaining: 107ms\n",
            "15:\tlearn: 0.2702568\ttotal: 98.5ms\tremaining: 98.5ms\n",
            "16:\tlearn: 0.2650537\ttotal: 103ms\tremaining: 91.2ms\n",
            "17:\tlearn: 0.2601005\ttotal: 116ms\tremaining: 89.9ms\n",
            "18:\tlearn: 0.2560578\ttotal: 121ms\tremaining: 82.9ms\n",
            "19:\tlearn: 0.2530381\ttotal: 125ms\tremaining: 75.2ms\n",
            "20:\tlearn: 0.2498453\ttotal: 133ms\tremaining: 69.4ms\n",
            "21:\tlearn: 0.2461646\ttotal: 137ms\tremaining: 62.5ms\n",
            "22:\tlearn: 0.2424369\ttotal: 142ms\tremaining: 55.6ms\n",
            "23:\tlearn: 0.2392835\ttotal: 145ms\tremaining: 48.3ms\n",
            "24:\tlearn: 0.2339070\ttotal: 152ms\tremaining: 42.5ms\n",
            "25:\tlearn: 0.2301706\ttotal: 155ms\tremaining: 35.8ms\n",
            "26:\tlearn: 0.2263007\ttotal: 158ms\tremaining: 29.3ms\n",
            "27:\tlearn: 0.2223209\ttotal: 163ms\tremaining: 23.3ms\n",
            "28:\tlearn: 0.2190932\ttotal: 168ms\tremaining: 17.4ms\n",
            "29:\tlearn: 0.2159010\ttotal: 173ms\tremaining: 11.5ms\n",
            "30:\tlearn: 0.2132954\ttotal: 178ms\tremaining: 5.73ms\n",
            "31:\tlearn: 0.2102299\ttotal: 182ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 2.64ms\tremaining: 81.8ms\n",
            "1:\tlearn: 0.4049315\ttotal: 5.17ms\tremaining: 77.5ms\n",
            "2:\tlearn: 0.3788145\ttotal: 13.2ms\tremaining: 127ms\n",
            "3:\tlearn: 0.3658016\ttotal: 17.2ms\tremaining: 121ms\n",
            "4:\tlearn: 0.3428474\ttotal: 20.5ms\tremaining: 111ms\n",
            "5:\tlearn: 0.3234303\ttotal: 22.1ms\tremaining: 96ms\n",
            "6:\tlearn: 0.3158416\ttotal: 25.2ms\tremaining: 90ms\n",
            "7:\tlearn: 0.3097739\ttotal: 29.8ms\tremaining: 89.4ms\n",
            "8:\tlearn: 0.3040041\ttotal: 36.5ms\tremaining: 93.2ms\n",
            "9:\tlearn: 0.2975585\ttotal: 41.2ms\tremaining: 90.7ms\n",
            "10:\tlearn: 0.2898709\ttotal: 46.2ms\tremaining: 88.2ms\n",
            "11:\tlearn: 0.2845372\ttotal: 52.2ms\tremaining: 86.9ms\n",
            "12:\tlearn: 0.2794184\ttotal: 56.6ms\tremaining: 82.8ms\n",
            "13:\tlearn: 0.2740314\ttotal: 59.7ms\tremaining: 76.8ms\n",
            "14:\tlearn: 0.2705542\ttotal: 63.9ms\tremaining: 72.5ms\n",
            "15:\tlearn: 0.2673919\ttotal: 66.3ms\tremaining: 66.3ms\n",
            "16:\tlearn: 0.2623365\ttotal: 71.4ms\tremaining: 63ms\n",
            "17:\tlearn: 0.2595719\ttotal: 76.7ms\tremaining: 59.7ms\n",
            "18:\tlearn: 0.2545713\ttotal: 81.1ms\tremaining: 55.5ms\n",
            "19:\tlearn: 0.2510766\ttotal: 85.8ms\tremaining: 51.5ms\n",
            "20:\tlearn: 0.2477056\ttotal: 90.3ms\tremaining: 47.3ms\n",
            "21:\tlearn: 0.2437884\ttotal: 94.7ms\tremaining: 43ms\n",
            "22:\tlearn: 0.2404080\ttotal: 99.3ms\tremaining: 38.9ms\n",
            "23:\tlearn: 0.2369058\ttotal: 104ms\tremaining: 34.6ms\n",
            "24:\tlearn: 0.2331119\ttotal: 111ms\tremaining: 31.1ms\n",
            "25:\tlearn: 0.2293455\ttotal: 118ms\tremaining: 27.3ms\n",
            "26:\tlearn: 0.2256418\ttotal: 120ms\tremaining: 22.3ms\n",
            "27:\tlearn: 0.2221119\ttotal: 125ms\tremaining: 17.9ms\n",
            "28:\tlearn: 0.2190925\ttotal: 129ms\tremaining: 13.4ms\n",
            "29:\tlearn: 0.2161731\ttotal: 134ms\tremaining: 8.91ms\n",
            "30:\tlearn: 0.2135041\ttotal: 138ms\tremaining: 4.46ms\n",
            "31:\tlearn: 0.2113382\ttotal: 143ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 3.36ms\tremaining: 104ms\n",
            "1:\tlearn: 0.4107278\ttotal: 5.79ms\tremaining: 86.9ms\n",
            "2:\tlearn: 0.3698157\ttotal: 6.68ms\tremaining: 64.6ms\n",
            "3:\tlearn: 0.3518120\ttotal: 14.2ms\tremaining: 99.4ms\n",
            "4:\tlearn: 0.3441195\ttotal: 18.4ms\tremaining: 99.6ms\n",
            "5:\tlearn: 0.3328396\ttotal: 23.7ms\tremaining: 103ms\n",
            "6:\tlearn: 0.3256704\ttotal: 26.6ms\tremaining: 94.9ms\n",
            "7:\tlearn: 0.3174441\ttotal: 31.2ms\tremaining: 93.6ms\n",
            "8:\tlearn: 0.3090762\ttotal: 43.6ms\tremaining: 111ms\n",
            "9:\tlearn: 0.3028459\ttotal: 48.4ms\tremaining: 106ms\n",
            "10:\tlearn: 0.2958541\ttotal: 60.3ms\tremaining: 115ms\n",
            "11:\tlearn: 0.2901166\ttotal: 64.7ms\tremaining: 108ms\n",
            "12:\tlearn: 0.2841803\ttotal: 69.8ms\tremaining: 102ms\n",
            "13:\tlearn: 0.2789751\ttotal: 74.5ms\tremaining: 95.8ms\n",
            "14:\tlearn: 0.2715599\ttotal: 79.4ms\tremaining: 90ms\n",
            "15:\tlearn: 0.2663544\ttotal: 84.3ms\tremaining: 84.3ms\n",
            "16:\tlearn: 0.2615546\ttotal: 89.4ms\tremaining: 78.9ms\n",
            "17:\tlearn: 0.2560079\ttotal: 93.5ms\tremaining: 72.7ms\n",
            "18:\tlearn: 0.2507480\ttotal: 96.1ms\tremaining: 65.8ms\n",
            "19:\tlearn: 0.2450678\ttotal: 102ms\tremaining: 61ms\n",
            "20:\tlearn: 0.2413892\ttotal: 105ms\tremaining: 55ms\n",
            "21:\tlearn: 0.2378437\ttotal: 110ms\tremaining: 50ms\n",
            "22:\tlearn: 0.2344010\ttotal: 116ms\tremaining: 45.4ms\n",
            "23:\tlearn: 0.2304940\ttotal: 123ms\tremaining: 41ms\n",
            "24:\tlearn: 0.2269540\ttotal: 127ms\tremaining: 35.4ms\n",
            "25:\tlearn: 0.2232713\ttotal: 130ms\tremaining: 30ms\n",
            "26:\tlearn: 0.2208577\ttotal: 135ms\tremaining: 25ms\n",
            "27:\tlearn: 0.2181825\ttotal: 139ms\tremaining: 19.9ms\n",
            "28:\tlearn: 0.2149071\ttotal: 150ms\tremaining: 15.5ms\n",
            "29:\tlearn: 0.2123638\ttotal: 160ms\tremaining: 10.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 163ms\tremaining: 5.26ms\n",
            "31:\tlearn: 0.2071716\ttotal: 169ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 2.81ms\tremaining: 87.3ms\n",
            "1:\tlearn: 0.3745079\ttotal: 4.96ms\tremaining: 74.3ms\n",
            "2:\tlearn: 0.3383999\ttotal: 7.62ms\tremaining: 73.7ms\n",
            "3:\tlearn: 0.3266560\ttotal: 18.8ms\tremaining: 132ms\n",
            "4:\tlearn: 0.3080259\ttotal: 23.3ms\tremaining: 126ms\n",
            "5:\tlearn: 0.2907443\ttotal: 27.9ms\tremaining: 121ms\n",
            "6:\tlearn: 0.2818467\ttotal: 32.4ms\tremaining: 116ms\n",
            "7:\tlearn: 0.2691784\ttotal: 36.2ms\tremaining: 109ms\n",
            "8:\tlearn: 0.2611618\ttotal: 39.9ms\tremaining: 102ms\n",
            "9:\tlearn: 0.2519898\ttotal: 45.8ms\tremaining: 101ms\n",
            "10:\tlearn: 0.2462992\ttotal: 50.5ms\tremaining: 96.4ms\n",
            "11:\tlearn: 0.2416348\ttotal: 55.3ms\tremaining: 92.1ms\n",
            "12:\tlearn: 0.2368688\ttotal: 60.2ms\tremaining: 88ms\n",
            "13:\tlearn: 0.2320170\ttotal: 70.8ms\tremaining: 91ms\n",
            "14:\tlearn: 0.2262186\ttotal: 73.5ms\tremaining: 83.4ms\n",
            "15:\tlearn: 0.2215380\ttotal: 78.7ms\tremaining: 78.7ms\n",
            "16:\tlearn: 0.2176313\ttotal: 84.3ms\tremaining: 74.3ms\n",
            "17:\tlearn: 0.2138494\ttotal: 91.7ms\tremaining: 71.3ms\n",
            "18:\tlearn: 0.2100966\ttotal: 94.2ms\tremaining: 64.5ms\n",
            "19:\tlearn: 0.2068557\ttotal: 99.2ms\tremaining: 59.5ms\n",
            "20:\tlearn: 0.2029945\ttotal: 104ms\tremaining: 54.4ms\n",
            "21:\tlearn: 0.2001044\ttotal: 109ms\tremaining: 49.3ms\n",
            "22:\tlearn: 0.1970766\ttotal: 113ms\tremaining: 44.3ms\n",
            "23:\tlearn: 0.1940285\ttotal: 118ms\tremaining: 39.3ms\n",
            "24:\tlearn: 0.1910934\ttotal: 123ms\tremaining: 34.3ms\n",
            "25:\tlearn: 0.1879112\ttotal: 127ms\tremaining: 29.3ms\n",
            "26:\tlearn: 0.1852765\ttotal: 132ms\tremaining: 24.4ms\n",
            "27:\tlearn: 0.1827068\ttotal: 137ms\tremaining: 19.6ms\n",
            "28:\tlearn: 0.1803359\ttotal: 140ms\tremaining: 14.5ms\n",
            "29:\tlearn: 0.1779549\ttotal: 145ms\tremaining: 9.7ms\n",
            "30:\tlearn: 0.1757984\ttotal: 150ms\tremaining: 4.85ms\n",
            "31:\tlearn: 0.1724570\ttotal: 155ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 3.14ms\tremaining: 97.4ms\n",
            "1:\tlearn: 0.3687510\ttotal: 5.62ms\tremaining: 84.3ms\n",
            "2:\tlearn: 0.3203557\ttotal: 6.64ms\tremaining: 64.2ms\n",
            "3:\tlearn: 0.3063743\ttotal: 9.63ms\tremaining: 67.4ms\n",
            "4:\tlearn: 0.2970911\ttotal: 14.8ms\tremaining: 80.2ms\n",
            "5:\tlearn: 0.2891054\ttotal: 19.2ms\tremaining: 83.4ms\n",
            "6:\tlearn: 0.2792409\ttotal: 23.4ms\tremaining: 83.4ms\n",
            "7:\tlearn: 0.2716618\ttotal: 27.8ms\tremaining: 83.4ms\n",
            "8:\tlearn: 0.2621352\ttotal: 32.3ms\tremaining: 82.5ms\n",
            "9:\tlearn: 0.2537973\ttotal: 39.8ms\tremaining: 87.6ms\n",
            "10:\tlearn: 0.2473429\ttotal: 43.9ms\tremaining: 83.8ms\n",
            "11:\tlearn: 0.2416695\ttotal: 48.3ms\tremaining: 80.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 58.5ms\tremaining: 85.6ms\n",
            "13:\tlearn: 0.2298385\ttotal: 63ms\tremaining: 81ms\n",
            "14:\tlearn: 0.2249545\ttotal: 67.2ms\tremaining: 76.1ms\n",
            "15:\tlearn: 0.2192054\ttotal: 71.7ms\tremaining: 71.7ms\n",
            "16:\tlearn: 0.2150242\ttotal: 82.7ms\tremaining: 72.9ms\n",
            "17:\tlearn: 0.2094516\ttotal: 93.9ms\tremaining: 73ms\n",
            "18:\tlearn: 0.2056324\ttotal: 97.4ms\tremaining: 66.6ms\n",
            "19:\tlearn: 0.2021225\ttotal: 102ms\tremaining: 61.2ms\n",
            "20:\tlearn: 0.1989042\ttotal: 104ms\tremaining: 54.3ms\n",
            "21:\tlearn: 0.1961040\ttotal: 109ms\tremaining: 49.7ms\n",
            "22:\tlearn: 0.1934794\ttotal: 118ms\tremaining: 46ms\n",
            "23:\tlearn: 0.1902438\ttotal: 123ms\tremaining: 41.2ms\n",
            "24:\tlearn: 0.1874921\ttotal: 129ms\tremaining: 36.2ms\n",
            "25:\tlearn: 0.1829904\ttotal: 135ms\tremaining: 31.2ms\n",
            "26:\tlearn: 0.1804169\ttotal: 142ms\tremaining: 26.3ms\n",
            "27:\tlearn: 0.1776989\ttotal: 145ms\tremaining: 20.7ms\n",
            "28:\tlearn: 0.1751387\ttotal: 152ms\tremaining: 15.7ms\n",
            "29:\tlearn: 0.1727570\ttotal: 155ms\tremaining: 10.3ms\n",
            "30:\tlearn: 0.1693663\ttotal: 164ms\tremaining: 5.3ms\n",
            "31:\tlearn: 0.1661883\ttotal: 170ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.82ms\tremaining: 58.3ms\n",
            "1:\tlearn: 0.4229987\ttotal: 13.2ms\tremaining: 204ms\n",
            "2:\tlearn: 0.3843342\ttotal: 20.1ms\tremaining: 201ms\n",
            "3:\tlearn: 0.3652888\ttotal: 23.3ms\tremaining: 169ms\n",
            "4:\tlearn: 0.3496343\ttotal: 35.6ms\tremaining: 199ms\n",
            "5:\tlearn: 0.3393969\ttotal: 41.5ms\tremaining: 187ms\n",
            "6:\tlearn: 0.3300914\ttotal: 45.6ms\tremaining: 169ms\n",
            "7:\tlearn: 0.3229079\ttotal: 55.1ms\tremaining: 172ms\n",
            "8:\tlearn: 0.3148279\ttotal: 63.2ms\tremaining: 169ms\n",
            "9:\tlearn: 0.3054626\ttotal: 68.3ms\tremaining: 157ms\n",
            "10:\tlearn: 0.2983658\ttotal: 73.2ms\tremaining: 146ms\n",
            "11:\tlearn: 0.2903440\ttotal: 85.2ms\tremaining: 149ms\n",
            "12:\tlearn: 0.2852979\ttotal: 89.7ms\tremaining: 138ms\n",
            "13:\tlearn: 0.2798563\ttotal: 95.5ms\tremaining: 130ms\n",
            "14:\tlearn: 0.2747341\ttotal: 101ms\tremaining: 121ms\n",
            "15:\tlearn: 0.2702568\ttotal: 112ms\tremaining: 119ms\n",
            "16:\tlearn: 0.2650537\ttotal: 118ms\tremaining: 111ms\n",
            "17:\tlearn: 0.2601005\ttotal: 121ms\tremaining: 101ms\n",
            "18:\tlearn: 0.2560578\ttotal: 125ms\tremaining: 91.8ms\n",
            "19:\tlearn: 0.2530381\ttotal: 128ms\tremaining: 83.1ms\n",
            "20:\tlearn: 0.2498453\ttotal: 130ms\tremaining: 74.5ms\n",
            "21:\tlearn: 0.2461646\ttotal: 136ms\tremaining: 67.8ms\n",
            "22:\tlearn: 0.2424369\ttotal: 141ms\tremaining: 61.3ms\n",
            "23:\tlearn: 0.2392835\ttotal: 144ms\tremaining: 54.1ms\n",
            "24:\tlearn: 0.2339070\ttotal: 150ms\tremaining: 47.9ms\n",
            "25:\tlearn: 0.2301706\ttotal: 152ms\tremaining: 41ms\n",
            "26:\tlearn: 0.2263007\ttotal: 161ms\tremaining: 35.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 165ms\tremaining: 29.4ms\n",
            "28:\tlearn: 0.2190932\ttotal: 171ms\tremaining: 23.6ms\n",
            "29:\tlearn: 0.2159010\ttotal: 177ms\tremaining: 17.7ms\n",
            "30:\tlearn: 0.2132954\ttotal: 183ms\tremaining: 11.8ms\n",
            "31:\tlearn: 0.2102299\ttotal: 187ms\tremaining: 5.84ms\n",
            "32:\tlearn: 0.2076280\ttotal: 193ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 2.95ms\tremaining: 94.5ms\n",
            "1:\tlearn: 0.4049315\ttotal: 5.46ms\tremaining: 84.6ms\n",
            "2:\tlearn: 0.3788145\ttotal: 15.7ms\tremaining: 157ms\n",
            "3:\tlearn: 0.3658016\ttotal: 20.1ms\tremaining: 146ms\n",
            "4:\tlearn: 0.3428474\ttotal: 23.9ms\tremaining: 134ms\n",
            "5:\tlearn: 0.3234303\ttotal: 25.4ms\tremaining: 114ms\n",
            "6:\tlearn: 0.3158416\ttotal: 28.8ms\tremaining: 107ms\n",
            "7:\tlearn: 0.3097739\ttotal: 34.3ms\tremaining: 107ms\n",
            "8:\tlearn: 0.3040041\ttotal: 36.7ms\tremaining: 97.8ms\n",
            "9:\tlearn: 0.2975585\ttotal: 50.5ms\tremaining: 116ms\n",
            "10:\tlearn: 0.2898709\ttotal: 54.3ms\tremaining: 109ms\n",
            "11:\tlearn: 0.2845372\ttotal: 59.4ms\tremaining: 104ms\n",
            "12:\tlearn: 0.2794184\ttotal: 65.9ms\tremaining: 101ms\n",
            "13:\tlearn: 0.2740314\ttotal: 70.4ms\tremaining: 95.6ms\n",
            "14:\tlearn: 0.2705542\ttotal: 73.9ms\tremaining: 88.7ms\n",
            "15:\tlearn: 0.2673919\ttotal: 81.5ms\tremaining: 86.6ms\n",
            "16:\tlearn: 0.2623365\ttotal: 83.7ms\tremaining: 78.8ms\n",
            "17:\tlearn: 0.2595719\ttotal: 90.6ms\tremaining: 75.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 93.8ms\tremaining: 69.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 103ms\tremaining: 67.2ms\n",
            "20:\tlearn: 0.2477056\ttotal: 114ms\tremaining: 65.4ms\n",
            "21:\tlearn: 0.2437884\ttotal: 126ms\tremaining: 62.9ms\n",
            "22:\tlearn: 0.2404080\ttotal: 139ms\tremaining: 60.5ms\n",
            "23:\tlearn: 0.2369058\ttotal: 142ms\tremaining: 53.1ms\n",
            "24:\tlearn: 0.2331119\ttotal: 149ms\tremaining: 47.7ms\n",
            "25:\tlearn: 0.2293455\ttotal: 152ms\tremaining: 40.8ms\n",
            "26:\tlearn: 0.2256418\ttotal: 159ms\tremaining: 35.3ms\n",
            "27:\tlearn: 0.2221119\ttotal: 161ms\tremaining: 28.8ms\n",
            "28:\tlearn: 0.2190925\ttotal: 163ms\tremaining: 22.5ms\n",
            "29:\tlearn: 0.2161731\ttotal: 167ms\tremaining: 16.7ms\n",
            "30:\tlearn: 0.2135041\ttotal: 173ms\tremaining: 11.2ms\n",
            "31:\tlearn: 0.2113382\ttotal: 177ms\tremaining: 5.54ms\n",
            "32:\tlearn: 0.2083485\ttotal: 183ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 3.58ms\tremaining: 115ms\n",
            "1:\tlearn: 0.4107278\ttotal: 4.38ms\tremaining: 67.8ms\n",
            "2:\tlearn: 0.3698157\ttotal: 5.49ms\tremaining: 54.9ms\n",
            "3:\tlearn: 0.3518120\ttotal: 9.78ms\tremaining: 70.9ms\n",
            "4:\tlearn: 0.3441195\ttotal: 14.8ms\tremaining: 83ms\n",
            "5:\tlearn: 0.3328396\ttotal: 19.3ms\tremaining: 86.8ms\n",
            "6:\tlearn: 0.3256704\ttotal: 21.8ms\tremaining: 80.8ms\n",
            "7:\tlearn: 0.3174441\ttotal: 24.5ms\tremaining: 76.5ms\n",
            "8:\tlearn: 0.3090762\ttotal: 27ms\tremaining: 72ms\n",
            "9:\tlearn: 0.3028459\ttotal: 29.3ms\tremaining: 67.4ms\n",
            "10:\tlearn: 0.2958541\ttotal: 31.8ms\tremaining: 63.5ms\n",
            "11:\tlearn: 0.2901166\ttotal: 34.5ms\tremaining: 60.3ms\n",
            "12:\tlearn: 0.2841803\ttotal: 37.1ms\tremaining: 57.1ms\n",
            "13:\tlearn: 0.2789751\ttotal: 39.4ms\tremaining: 53.5ms\n",
            "14:\tlearn: 0.2715599\ttotal: 41.7ms\tremaining: 50.1ms\n",
            "15:\tlearn: 0.2663544\ttotal: 58.1ms\tremaining: 61.7ms\n",
            "16:\tlearn: 0.2615546\ttotal: 60.2ms\tremaining: 56.7ms\n",
            "17:\tlearn: 0.2560079\ttotal: 69.3ms\tremaining: 57.7ms\n",
            "18:\tlearn: 0.2507480\ttotal: 71.4ms\tremaining: 52.6ms\n",
            "19:\tlearn: 0.2450678\ttotal: 82.1ms\tremaining: 53.4ms\n",
            "20:\tlearn: 0.2413892\ttotal: 86.4ms\tremaining: 49.4ms\n",
            "21:\tlearn: 0.2378437\ttotal: 91.3ms\tremaining: 45.7ms\n",
            "22:\tlearn: 0.2344010\ttotal: 102ms\tremaining: 44.5ms\n",
            "23:\tlearn: 0.2304940\ttotal: 107ms\tremaining: 40ms\n",
            "24:\tlearn: 0.2269540\ttotal: 111ms\tremaining: 35.5ms\n",
            "25:\tlearn: 0.2232713\ttotal: 117ms\tremaining: 31.6ms\n",
            "26:\tlearn: 0.2208577\ttotal: 119ms\tremaining: 26.5ms\n",
            "27:\tlearn: 0.2181825\ttotal: 124ms\tremaining: 22.1ms\n",
            "28:\tlearn: 0.2149071\ttotal: 126ms\tremaining: 17.3ms\n",
            "29:\tlearn: 0.2123638\ttotal: 128ms\tremaining: 12.8ms\n",
            "30:\tlearn: 0.2094640\ttotal: 147ms\tremaining: 9.45ms\n",
            "31:\tlearn: 0.2071716\ttotal: 151ms\tremaining: 4.71ms\n",
            "32:\tlearn: 0.2045371\ttotal: 154ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 6.03ms\tremaining: 193ms\n",
            "1:\tlearn: 0.3745079\ttotal: 6.57ms\tremaining: 102ms\n",
            "2:\tlearn: 0.3383999\ttotal: 20.7ms\tremaining: 207ms\n",
            "3:\tlearn: 0.3266560\ttotal: 32ms\tremaining: 232ms\n",
            "4:\tlearn: 0.3080259\ttotal: 34.7ms\tremaining: 194ms\n",
            "5:\tlearn: 0.2907443\ttotal: 37.1ms\tremaining: 167ms\n",
            "6:\tlearn: 0.2818467\ttotal: 42.4ms\tremaining: 158ms\n",
            "7:\tlearn: 0.2691784\ttotal: 50ms\tremaining: 156ms\n",
            "8:\tlearn: 0.2611618\ttotal: 59.3ms\tremaining: 158ms\n",
            "9:\tlearn: 0.2519898\ttotal: 62.4ms\tremaining: 144ms\n",
            "10:\tlearn: 0.2462992\ttotal: 66.3ms\tremaining: 133ms\n",
            "11:\tlearn: 0.2416348\ttotal: 76.9ms\tremaining: 135ms\n",
            "12:\tlearn: 0.2368688\ttotal: 81.6ms\tremaining: 126ms\n",
            "13:\tlearn: 0.2320170\ttotal: 85.2ms\tremaining: 116ms\n",
            "14:\tlearn: 0.2262186\ttotal: 95.1ms\tremaining: 114ms\n",
            "15:\tlearn: 0.2215380\ttotal: 98.8ms\tremaining: 105ms\n",
            "16:\tlearn: 0.2176313\ttotal: 103ms\tremaining: 97.4ms\n",
            "17:\tlearn: 0.2138494\ttotal: 116ms\tremaining: 96.3ms\n",
            "18:\tlearn: 0.2100966\ttotal: 120ms\tremaining: 88.4ms\n",
            "19:\tlearn: 0.2068557\ttotal: 123ms\tremaining: 80ms\n",
            "20:\tlearn: 0.2029945\ttotal: 135ms\tremaining: 76.9ms\n",
            "21:\tlearn: 0.2001044\ttotal: 138ms\tremaining: 69ms\n",
            "22:\tlearn: 0.1970766\ttotal: 150ms\tremaining: 65.1ms\n",
            "23:\tlearn: 0.1940285\ttotal: 155ms\tremaining: 58.1ms\n",
            "24:\tlearn: 0.1910934\ttotal: 160ms\tremaining: 51.2ms\n",
            "25:\tlearn: 0.1879112\ttotal: 167ms\tremaining: 44.8ms\n",
            "26:\tlearn: 0.1852765\ttotal: 172ms\tremaining: 38.1ms\n",
            "27:\tlearn: 0.1827068\ttotal: 178ms\tremaining: 31.7ms\n",
            "28:\tlearn: 0.1803359\ttotal: 181ms\tremaining: 25ms\n",
            "29:\tlearn: 0.1779549\ttotal: 188ms\tremaining: 18.8ms\n",
            "30:\tlearn: 0.1757984\ttotal: 192ms\tremaining: 12.4ms\n",
            "31:\tlearn: 0.1724570\ttotal: 204ms\tremaining: 6.38ms\n",
            "32:\tlearn: 0.1703672\ttotal: 207ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 3.31ms\tremaining: 106ms\n",
            "1:\tlearn: 0.3687510\ttotal: 4.01ms\tremaining: 62.2ms\n",
            "2:\tlearn: 0.3203557\ttotal: 5ms\tremaining: 50ms\n",
            "3:\tlearn: 0.3063743\ttotal: 8.2ms\tremaining: 59.4ms\n",
            "4:\tlearn: 0.2970911\ttotal: 14.5ms\tremaining: 81ms\n",
            "5:\tlearn: 0.2891054\ttotal: 19.7ms\tremaining: 88.8ms\n",
            "6:\tlearn: 0.2792409\ttotal: 22.6ms\tremaining: 84ms\n",
            "7:\tlearn: 0.2716618\ttotal: 26.1ms\tremaining: 81.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 31.7ms\tremaining: 84.6ms\n",
            "9:\tlearn: 0.2537973\ttotal: 36.6ms\tremaining: 84.3ms\n",
            "10:\tlearn: 0.2473429\ttotal: 39ms\tremaining: 78ms\n",
            "11:\tlearn: 0.2416695\ttotal: 43.9ms\tremaining: 76.8ms\n",
            "12:\tlearn: 0.2366343\ttotal: 46.3ms\tremaining: 71.2ms\n",
            "13:\tlearn: 0.2298385\ttotal: 50.5ms\tremaining: 68.5ms\n",
            "14:\tlearn: 0.2249545\ttotal: 54.7ms\tremaining: 65.6ms\n",
            "15:\tlearn: 0.2192054\ttotal: 59.1ms\tremaining: 62.8ms\n",
            "16:\tlearn: 0.2150242\ttotal: 67.6ms\tremaining: 63.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 71.8ms\tremaining: 59.8ms\n",
            "18:\tlearn: 0.2056324\ttotal: 76.1ms\tremaining: 56.1ms\n",
            "19:\tlearn: 0.2021225\ttotal: 79.3ms\tremaining: 51.5ms\n",
            "20:\tlearn: 0.1989042\ttotal: 84.5ms\tremaining: 48.3ms\n",
            "21:\tlearn: 0.1961040\ttotal: 88.8ms\tremaining: 44.4ms\n",
            "22:\tlearn: 0.1934794\ttotal: 99.9ms\tremaining: 43.4ms\n",
            "23:\tlearn: 0.1902438\ttotal: 104ms\tremaining: 38.8ms\n",
            "24:\tlearn: 0.1874921\ttotal: 111ms\tremaining: 35.5ms\n",
            "25:\tlearn: 0.1829904\ttotal: 123ms\tremaining: 33.2ms\n",
            "26:\tlearn: 0.1804169\ttotal: 127ms\tremaining: 28.3ms\n",
            "27:\tlearn: 0.1776989\ttotal: 134ms\tremaining: 23.9ms\n",
            "28:\tlearn: 0.1751387\ttotal: 137ms\tremaining: 18.9ms\n",
            "29:\tlearn: 0.1727570\ttotal: 141ms\tremaining: 14.1ms\n",
            "30:\tlearn: 0.1693663\ttotal: 144ms\tremaining: 9.3ms\n",
            "31:\tlearn: 0.1661883\ttotal: 147ms\tremaining: 4.61ms\n",
            "32:\tlearn: 0.1641011\ttotal: 157ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 9.32ms\tremaining: 307ms\n",
            "1:\tlearn: 0.4229987\ttotal: 10.1ms\tremaining: 161ms\n",
            "2:\tlearn: 0.3843342\ttotal: 13ms\tremaining: 135ms\n",
            "3:\tlearn: 0.3652888\ttotal: 18.3ms\tremaining: 137ms\n",
            "4:\tlearn: 0.3496343\ttotal: 23.2ms\tremaining: 135ms\n",
            "5:\tlearn: 0.3393969\ttotal: 28.3ms\tremaining: 132ms\n",
            "6:\tlearn: 0.3300914\ttotal: 33.2ms\tremaining: 128ms\n",
            "7:\tlearn: 0.3229079\ttotal: 38.8ms\tremaining: 126ms\n",
            "8:\tlearn: 0.3148279\ttotal: 42.8ms\tremaining: 119ms\n",
            "9:\tlearn: 0.3054626\ttotal: 47.8ms\tremaining: 115ms\n",
            "10:\tlearn: 0.2983658\ttotal: 52.6ms\tremaining: 110ms\n",
            "11:\tlearn: 0.2903440\ttotal: 62.3ms\tremaining: 114ms\n",
            "12:\tlearn: 0.2852979\ttotal: 66.6ms\tremaining: 108ms\n",
            "13:\tlearn: 0.2798563\ttotal: 71.1ms\tremaining: 102ms\n",
            "14:\tlearn: 0.2747341\ttotal: 75.1ms\tremaining: 95.1ms\n",
            "15:\tlearn: 0.2702568\ttotal: 80.6ms\tremaining: 90.7ms\n",
            "16:\tlearn: 0.2650537\ttotal: 85.3ms\tremaining: 85.3ms\n",
            "17:\tlearn: 0.2601005\ttotal: 93.4ms\tremaining: 83ms\n",
            "18:\tlearn: 0.2560578\ttotal: 102ms\tremaining: 80.4ms\n",
            "19:\tlearn: 0.2530381\ttotal: 107ms\tremaining: 74.8ms\n",
            "20:\tlearn: 0.2498453\ttotal: 113ms\tremaining: 69.9ms\n",
            "21:\tlearn: 0.2461646\ttotal: 116ms\tremaining: 63.5ms\n",
            "22:\tlearn: 0.2424369\ttotal: 121ms\tremaining: 58.1ms\n",
            "23:\tlearn: 0.2392835\ttotal: 127ms\tremaining: 53ms\n",
            "24:\tlearn: 0.2339070\ttotal: 130ms\tremaining: 46.8ms\n",
            "25:\tlearn: 0.2301706\ttotal: 137ms\tremaining: 42.2ms\n",
            "26:\tlearn: 0.2263007\ttotal: 142ms\tremaining: 36.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 146ms\tremaining: 31.3ms\n",
            "28:\tlearn: 0.2190932\ttotal: 149ms\tremaining: 25.7ms\n",
            "29:\tlearn: 0.2159010\ttotal: 154ms\tremaining: 20.5ms\n",
            "30:\tlearn: 0.2132954\ttotal: 159ms\tremaining: 15.4ms\n",
            "31:\tlearn: 0.2102299\ttotal: 167ms\tremaining: 10.5ms\n",
            "32:\tlearn: 0.2076280\ttotal: 172ms\tremaining: 5.21ms\n",
            "33:\tlearn: 0.2043188\ttotal: 177ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 9.75ms\tremaining: 322ms\n",
            "1:\tlearn: 0.4049315\ttotal: 13.8ms\tremaining: 221ms\n",
            "2:\tlearn: 0.3788145\ttotal: 26.6ms\tremaining: 275ms\n",
            "3:\tlearn: 0.3658016\ttotal: 30.5ms\tremaining: 229ms\n",
            "4:\tlearn: 0.3428474\ttotal: 39.5ms\tremaining: 229ms\n",
            "5:\tlearn: 0.3234303\ttotal: 44.2ms\tremaining: 206ms\n",
            "6:\tlearn: 0.3158416\ttotal: 55.4ms\tremaining: 214ms\n",
            "7:\tlearn: 0.3097739\ttotal: 57.5ms\tremaining: 187ms\n",
            "8:\tlearn: 0.3040041\ttotal: 69.3ms\tremaining: 193ms\n",
            "9:\tlearn: 0.2975585\ttotal: 74.2ms\tremaining: 178ms\n",
            "10:\tlearn: 0.2898709\ttotal: 92.4ms\tremaining: 193ms\n",
            "11:\tlearn: 0.2845372\ttotal: 97.9ms\tremaining: 179ms\n",
            "12:\tlearn: 0.2794184\ttotal: 101ms\tremaining: 163ms\n",
            "13:\tlearn: 0.2740314\ttotal: 104ms\tremaining: 148ms\n",
            "14:\tlearn: 0.2705542\ttotal: 112ms\tremaining: 142ms\n",
            "15:\tlearn: 0.2673919\ttotal: 117ms\tremaining: 131ms\n",
            "16:\tlearn: 0.2623365\ttotal: 127ms\tremaining: 127ms\n",
            "17:\tlearn: 0.2595719\ttotal: 130ms\tremaining: 115ms\n",
            "18:\tlearn: 0.2545713\ttotal: 141ms\tremaining: 111ms\n",
            "19:\tlearn: 0.2510766\ttotal: 145ms\tremaining: 101ms\n",
            "20:\tlearn: 0.2477056\ttotal: 147ms\tremaining: 91.3ms\n",
            "21:\tlearn: 0.2437884\ttotal: 152ms\tremaining: 83ms\n",
            "22:\tlearn: 0.2404080\ttotal: 165ms\tremaining: 78.7ms\n",
            "23:\tlearn: 0.2369058\ttotal: 169ms\tremaining: 70.3ms\n",
            "24:\tlearn: 0.2331119\ttotal: 173ms\tremaining: 62.2ms\n",
            "25:\tlearn: 0.2293455\ttotal: 177ms\tremaining: 54.4ms\n",
            "26:\tlearn: 0.2256418\ttotal: 185ms\tremaining: 47.9ms\n",
            "27:\tlearn: 0.2221119\ttotal: 192ms\tremaining: 41.1ms\n",
            "28:\tlearn: 0.2190925\ttotal: 198ms\tremaining: 34.1ms\n",
            "29:\tlearn: 0.2161731\ttotal: 202ms\tremaining: 26.9ms\n",
            "30:\tlearn: 0.2135041\ttotal: 215ms\tremaining: 20.8ms\n",
            "31:\tlearn: 0.2113382\ttotal: 224ms\tremaining: 14ms\n",
            "32:\tlearn: 0.2083485\ttotal: 231ms\tremaining: 7.01ms\n",
            "33:\tlearn: 0.2058588\ttotal: 235ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 5.3ms\tremaining: 175ms\n",
            "1:\tlearn: 0.4107278\ttotal: 12.2ms\tremaining: 195ms\n",
            "2:\tlearn: 0.3698157\ttotal: 13.2ms\tremaining: 137ms\n",
            "3:\tlearn: 0.3518120\ttotal: 17.1ms\tremaining: 128ms\n",
            "4:\tlearn: 0.3441195\ttotal: 22ms\tremaining: 127ms\n",
            "5:\tlearn: 0.3328396\ttotal: 33.2ms\tremaining: 155ms\n",
            "6:\tlearn: 0.3256704\ttotal: 37.9ms\tremaining: 146ms\n",
            "7:\tlearn: 0.3174441\ttotal: 42.6ms\tremaining: 139ms\n",
            "8:\tlearn: 0.3090762\ttotal: 54.4ms\tremaining: 151ms\n",
            "9:\tlearn: 0.3028459\ttotal: 57.9ms\tremaining: 139ms\n",
            "10:\tlearn: 0.2958541\ttotal: 62.2ms\tremaining: 130ms\n",
            "11:\tlearn: 0.2901166\ttotal: 67.1ms\tremaining: 123ms\n",
            "12:\tlearn: 0.2841803\ttotal: 73.3ms\tremaining: 118ms\n",
            "13:\tlearn: 0.2789751\ttotal: 77ms\tremaining: 110ms\n",
            "14:\tlearn: 0.2715599\ttotal: 80.5ms\tremaining: 102ms\n",
            "15:\tlearn: 0.2663544\ttotal: 88ms\tremaining: 99ms\n",
            "16:\tlearn: 0.2615546\ttotal: 93.7ms\tremaining: 93.7ms\n",
            "17:\tlearn: 0.2560079\ttotal: 98.1ms\tremaining: 87.2ms\n",
            "18:\tlearn: 0.2507480\ttotal: 103ms\tremaining: 81.3ms\n",
            "19:\tlearn: 0.2450678\ttotal: 108ms\tremaining: 75.5ms\n",
            "20:\tlearn: 0.2413892\ttotal: 113ms\tremaining: 70.2ms\n",
            "21:\tlearn: 0.2378437\ttotal: 118ms\tremaining: 64.1ms\n",
            "22:\tlearn: 0.2344010\ttotal: 124ms\tremaining: 59.1ms\n",
            "23:\tlearn: 0.2304940\ttotal: 127ms\tremaining: 53ms\n",
            "24:\tlearn: 0.2269540\ttotal: 139ms\tremaining: 50.1ms\n",
            "25:\tlearn: 0.2232713\ttotal: 144ms\tremaining: 44.4ms\n",
            "26:\tlearn: 0.2208577\ttotal: 147ms\tremaining: 38.2ms\n",
            "27:\tlearn: 0.2181825\ttotal: 152ms\tremaining: 32.6ms\n",
            "28:\tlearn: 0.2149071\ttotal: 155ms\tremaining: 26.7ms\n",
            "29:\tlearn: 0.2123638\ttotal: 163ms\tremaining: 21.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 169ms\tremaining: 16.4ms\n",
            "31:\tlearn: 0.2071716\ttotal: 174ms\tremaining: 10.9ms\n",
            "32:\tlearn: 0.2045371\ttotal: 186ms\tremaining: 5.64ms\n",
            "33:\tlearn: 0.2018712\ttotal: 191ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 4.1ms\tremaining: 135ms\n",
            "1:\tlearn: 0.3745079\ttotal: 8.18ms\tremaining: 131ms\n",
            "2:\tlearn: 0.3383999\ttotal: 10.9ms\tremaining: 112ms\n",
            "3:\tlearn: 0.3266560\ttotal: 16ms\tremaining: 120ms\n",
            "4:\tlearn: 0.3080259\ttotal: 19.8ms\tremaining: 115ms\n",
            "5:\tlearn: 0.2907443\ttotal: 24.5ms\tremaining: 114ms\n",
            "6:\tlearn: 0.2818467\ttotal: 27.8ms\tremaining: 107ms\n",
            "7:\tlearn: 0.2691784\ttotal: 31.7ms\tremaining: 103ms\n",
            "8:\tlearn: 0.2611618\ttotal: 35.4ms\tremaining: 98.2ms\n",
            "9:\tlearn: 0.2519898\ttotal: 39.9ms\tremaining: 95.7ms\n",
            "10:\tlearn: 0.2462992\ttotal: 48.5ms\tremaining: 101ms\n",
            "11:\tlearn: 0.2416348\ttotal: 51.3ms\tremaining: 94ms\n",
            "12:\tlearn: 0.2368688\ttotal: 56.4ms\tremaining: 91.2ms\n",
            "13:\tlearn: 0.2320170\ttotal: 61.3ms\tremaining: 87.6ms\n",
            "14:\tlearn: 0.2262186\ttotal: 63.6ms\tremaining: 80.6ms\n",
            "15:\tlearn: 0.2215380\ttotal: 74ms\tremaining: 83.3ms\n",
            "16:\tlearn: 0.2176313\ttotal: 80.7ms\tremaining: 80.7ms\n",
            "17:\tlearn: 0.2138494\ttotal: 90.7ms\tremaining: 80.6ms\n",
            "18:\tlearn: 0.2100966\ttotal: 98.7ms\tremaining: 77.9ms\n",
            "19:\tlearn: 0.2068557\ttotal: 102ms\tremaining: 71.5ms\n",
            "20:\tlearn: 0.2029945\ttotal: 115ms\tremaining: 71.3ms\n",
            "21:\tlearn: 0.2001044\ttotal: 119ms\tremaining: 64.8ms\n",
            "22:\tlearn: 0.1970766\ttotal: 123ms\tremaining: 59ms\n",
            "23:\tlearn: 0.1940285\ttotal: 128ms\tremaining: 53.3ms\n",
            "24:\tlearn: 0.1910934\ttotal: 133ms\tremaining: 47.7ms\n",
            "25:\tlearn: 0.1879112\ttotal: 137ms\tremaining: 42.1ms\n",
            "26:\tlearn: 0.1852765\ttotal: 142ms\tremaining: 36.8ms\n",
            "27:\tlearn: 0.1827068\ttotal: 147ms\tremaining: 31.6ms\n",
            "28:\tlearn: 0.1803359\ttotal: 150ms\tremaining: 25.8ms\n",
            "29:\tlearn: 0.1779549\ttotal: 155ms\tremaining: 20.6ms\n",
            "30:\tlearn: 0.1757984\ttotal: 160ms\tremaining: 15.5ms\n",
            "31:\tlearn: 0.1724570\ttotal: 165ms\tremaining: 10.3ms\n",
            "32:\tlearn: 0.1703672\ttotal: 169ms\tremaining: 5.12ms\n",
            "33:\tlearn: 0.1685175\ttotal: 174ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 7.79ms\tremaining: 257ms\n",
            "1:\tlearn: 0.3687510\ttotal: 12.8ms\tremaining: 205ms\n",
            "2:\tlearn: 0.3203557\ttotal: 15.7ms\tremaining: 162ms\n",
            "3:\tlearn: 0.3063743\ttotal: 24ms\tremaining: 180ms\n",
            "4:\tlearn: 0.2970911\ttotal: 32.5ms\tremaining: 188ms\n",
            "5:\tlearn: 0.2891054\ttotal: 40ms\tremaining: 187ms\n",
            "6:\tlearn: 0.2792409\ttotal: 48.2ms\tremaining: 186ms\n",
            "7:\tlearn: 0.2716618\ttotal: 57.9ms\tremaining: 188ms\n",
            "8:\tlearn: 0.2621352\ttotal: 60.5ms\tremaining: 168ms\n",
            "9:\tlearn: 0.2537973\ttotal: 64.5ms\tremaining: 155ms\n",
            "10:\tlearn: 0.2473429\ttotal: 74.9ms\tremaining: 157ms\n",
            "11:\tlearn: 0.2416695\ttotal: 77.7ms\tremaining: 142ms\n",
            "12:\tlearn: 0.2366343\ttotal: 80.2ms\tremaining: 130ms\n",
            "13:\tlearn: 0.2298385\ttotal: 85.1ms\tremaining: 122ms\n",
            "14:\tlearn: 0.2249545\ttotal: 94.7ms\tremaining: 120ms\n",
            "15:\tlearn: 0.2192054\ttotal: 96.7ms\tremaining: 109ms\n",
            "16:\tlearn: 0.2150242\ttotal: 98.9ms\tremaining: 98.9ms\n",
            "17:\tlearn: 0.2094516\ttotal: 107ms\tremaining: 94.8ms\n",
            "18:\tlearn: 0.2056324\ttotal: 109ms\tremaining: 86ms\n",
            "19:\tlearn: 0.2021225\ttotal: 111ms\tremaining: 77.8ms\n",
            "20:\tlearn: 0.1989042\ttotal: 115ms\tremaining: 71.2ms\n",
            "21:\tlearn: 0.1961040\ttotal: 117ms\tremaining: 63.9ms\n",
            "22:\tlearn: 0.1934794\ttotal: 131ms\tremaining: 62.8ms\n",
            "23:\tlearn: 0.1902438\ttotal: 133ms\tremaining: 55.5ms\n",
            "24:\tlearn: 0.1874921\ttotal: 135ms\tremaining: 48.8ms\n",
            "25:\tlearn: 0.1829904\ttotal: 138ms\tremaining: 42.4ms\n",
            "26:\tlearn: 0.1804169\ttotal: 141ms\tremaining: 36.5ms\n",
            "27:\tlearn: 0.1776989\ttotal: 150ms\tremaining: 32.1ms\n",
            "28:\tlearn: 0.1751387\ttotal: 152ms\tremaining: 26.3ms\n",
            "29:\tlearn: 0.1727570\ttotal: 157ms\tremaining: 21ms\n",
            "30:\tlearn: 0.1693663\ttotal: 167ms\tremaining: 16.2ms\n",
            "31:\tlearn: 0.1661883\ttotal: 169ms\tremaining: 10.6ms\n",
            "32:\tlearn: 0.1641011\ttotal: 171ms\tremaining: 5.19ms\n",
            "33:\tlearn: 0.1616271\ttotal: 179ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 2.24ms\tremaining: 76.1ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.85ms\tremaining: 47.1ms\n",
            "2:\tlearn: 0.3843342\ttotal: 10.2ms\tremaining: 109ms\n",
            "3:\tlearn: 0.3652888\ttotal: 12.8ms\tremaining: 99.5ms\n",
            "4:\tlearn: 0.3496343\ttotal: 14.8ms\tremaining: 89ms\n",
            "5:\tlearn: 0.3393969\ttotal: 17.2ms\tremaining: 82.9ms\n",
            "6:\tlearn: 0.3300914\ttotal: 26.3ms\tremaining: 105ms\n",
            "7:\tlearn: 0.3229079\ttotal: 28.2ms\tremaining: 95ms\n",
            "8:\tlearn: 0.3148279\ttotal: 30.5ms\tremaining: 88ms\n",
            "9:\tlearn: 0.3054626\ttotal: 32.9ms\tremaining: 82.2ms\n",
            "10:\tlearn: 0.2983658\ttotal: 40.1ms\tremaining: 87.6ms\n",
            "11:\tlearn: 0.2903440\ttotal: 46.6ms\tremaining: 89.3ms\n",
            "12:\tlearn: 0.2852979\ttotal: 48.8ms\tremaining: 82.6ms\n",
            "13:\tlearn: 0.2798563\ttotal: 58.1ms\tremaining: 87.2ms\n",
            "14:\tlearn: 0.2747341\ttotal: 60.1ms\tremaining: 80.1ms\n",
            "15:\tlearn: 0.2702568\ttotal: 62.4ms\tremaining: 74ms\n",
            "16:\tlearn: 0.2650537\ttotal: 74.5ms\tremaining: 78.9ms\n",
            "17:\tlearn: 0.2601005\ttotal: 81.5ms\tremaining: 76.9ms\n",
            "18:\tlearn: 0.2560578\ttotal: 89.1ms\tremaining: 75ms\n",
            "19:\tlearn: 0.2530381\ttotal: 91.5ms\tremaining: 68.6ms\n",
            "20:\tlearn: 0.2498453\ttotal: 93.9ms\tremaining: 62.6ms\n",
            "21:\tlearn: 0.2461646\ttotal: 103ms\tremaining: 60.8ms\n",
            "22:\tlearn: 0.2424369\ttotal: 105ms\tremaining: 55ms\n",
            "23:\tlearn: 0.2392835\ttotal: 107ms\tremaining: 49.1ms\n",
            "24:\tlearn: 0.2339070\ttotal: 115ms\tremaining: 46.2ms\n",
            "25:\tlearn: 0.2301706\ttotal: 118ms\tremaining: 40.8ms\n",
            "26:\tlearn: 0.2263007\ttotal: 120ms\tremaining: 35.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 129ms\tremaining: 32.3ms\n",
            "28:\tlearn: 0.2190932\ttotal: 131ms\tremaining: 27.1ms\n",
            "29:\tlearn: 0.2159010\ttotal: 133ms\tremaining: 22.2ms\n",
            "30:\tlearn: 0.2132954\ttotal: 135ms\tremaining: 17.5ms\n",
            "31:\tlearn: 0.2102299\ttotal: 145ms\tremaining: 13.6ms\n",
            "32:\tlearn: 0.2076280\ttotal: 146ms\tremaining: 8.88ms\n",
            "33:\tlearn: 0.2043188\ttotal: 149ms\tremaining: 4.38ms\n",
            "34:\tlearn: 0.2017849\ttotal: 156ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 2.67ms\tremaining: 90.6ms\n",
            "1:\tlearn: 0.4049315\ttotal: 3.11ms\tremaining: 51.3ms\n",
            "2:\tlearn: 0.3788145\ttotal: 11.4ms\tremaining: 121ms\n",
            "3:\tlearn: 0.3658016\ttotal: 13.5ms\tremaining: 105ms\n",
            "4:\tlearn: 0.3428474\ttotal: 14.5ms\tremaining: 86.8ms\n",
            "5:\tlearn: 0.3234303\ttotal: 15.2ms\tremaining: 73.5ms\n",
            "6:\tlearn: 0.3158416\ttotal: 17.5ms\tremaining: 69.8ms\n",
            "7:\tlearn: 0.3097739\ttotal: 19.4ms\tremaining: 65.6ms\n",
            "8:\tlearn: 0.3040041\ttotal: 22.2ms\tremaining: 64ms\n",
            "9:\tlearn: 0.2975585\ttotal: 24.9ms\tremaining: 62.3ms\n",
            "10:\tlearn: 0.2898709\ttotal: 27.7ms\tremaining: 60.4ms\n",
            "11:\tlearn: 0.2845372\ttotal: 29.9ms\tremaining: 57.4ms\n",
            "12:\tlearn: 0.2794184\ttotal: 32.3ms\tremaining: 54.7ms\n",
            "13:\tlearn: 0.2740314\ttotal: 34.7ms\tremaining: 52.1ms\n",
            "14:\tlearn: 0.2705542\ttotal: 37.4ms\tremaining: 49.9ms\n",
            "15:\tlearn: 0.2673919\ttotal: 40.2ms\tremaining: 47.7ms\n",
            "16:\tlearn: 0.2623365\ttotal: 42.2ms\tremaining: 44.7ms\n",
            "17:\tlearn: 0.2595719\ttotal: 44.9ms\tremaining: 42.4ms\n",
            "18:\tlearn: 0.2545713\ttotal: 47ms\tremaining: 39.6ms\n",
            "19:\tlearn: 0.2510766\ttotal: 49.4ms\tremaining: 37ms\n",
            "20:\tlearn: 0.2477056\ttotal: 51.7ms\tremaining: 34.5ms\n",
            "21:\tlearn: 0.2437884\ttotal: 53.6ms\tremaining: 31.7ms\n",
            "22:\tlearn: 0.2404080\ttotal: 56.2ms\tremaining: 29.3ms\n",
            "23:\tlearn: 0.2369058\ttotal: 62.1ms\tremaining: 28.5ms\n",
            "24:\tlearn: 0.2331119\ttotal: 71.8ms\tremaining: 28.7ms\n",
            "25:\tlearn: 0.2293455\ttotal: 81.2ms\tremaining: 28.1ms\n",
            "26:\tlearn: 0.2256418\ttotal: 89ms\tremaining: 26.4ms\n",
            "27:\tlearn: 0.2221119\ttotal: 93.3ms\tremaining: 23.3ms\n",
            "28:\tlearn: 0.2190925\ttotal: 96.7ms\tremaining: 20ms\n",
            "29:\tlearn: 0.2161731\ttotal: 99.5ms\tremaining: 16.6ms\n",
            "30:\tlearn: 0.2135041\ttotal: 102ms\tremaining: 13.1ms\n",
            "31:\tlearn: 0.2113382\ttotal: 104ms\tremaining: 9.71ms\n",
            "32:\tlearn: 0.2083485\ttotal: 105ms\tremaining: 6.38ms\n",
            "33:\tlearn: 0.2058588\ttotal: 107ms\tremaining: 3.15ms\n",
            "34:\tlearn: 0.2024895\ttotal: 109ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.47ms\tremaining: 84.1ms\n",
            "1:\tlearn: 0.4107278\ttotal: 3ms\tremaining: 49.4ms\n",
            "2:\tlearn: 0.3698157\ttotal: 3.79ms\tremaining: 40.4ms\n",
            "3:\tlearn: 0.3518120\ttotal: 6.2ms\tremaining: 48.1ms\n",
            "4:\tlearn: 0.3441195\ttotal: 8.93ms\tremaining: 53.6ms\n",
            "5:\tlearn: 0.3328396\ttotal: 11.6ms\tremaining: 56.2ms\n",
            "6:\tlearn: 0.3256704\ttotal: 13.7ms\tremaining: 54.7ms\n",
            "7:\tlearn: 0.3174441\ttotal: 16.1ms\tremaining: 54.4ms\n",
            "8:\tlearn: 0.3090762\ttotal: 18.5ms\tremaining: 53.5ms\n",
            "9:\tlearn: 0.3028459\ttotal: 23.8ms\tremaining: 59.5ms\n",
            "10:\tlearn: 0.2958541\ttotal: 25.8ms\tremaining: 56.3ms\n",
            "11:\tlearn: 0.2901166\ttotal: 28.1ms\tremaining: 53.8ms\n",
            "12:\tlearn: 0.2841803\ttotal: 31ms\tremaining: 52.4ms\n",
            "13:\tlearn: 0.2789751\ttotal: 33.6ms\tremaining: 50.4ms\n",
            "14:\tlearn: 0.2715599\ttotal: 36.2ms\tremaining: 48.3ms\n",
            "15:\tlearn: 0.2663544\ttotal: 39.3ms\tremaining: 46.6ms\n",
            "16:\tlearn: 0.2615546\ttotal: 41.8ms\tremaining: 44.2ms\n",
            "17:\tlearn: 0.2560079\ttotal: 43.7ms\tremaining: 41.3ms\n",
            "18:\tlearn: 0.2507480\ttotal: 45.8ms\tremaining: 38.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 48.3ms\tremaining: 36.2ms\n",
            "20:\tlearn: 0.2413892\ttotal: 50.8ms\tremaining: 33.9ms\n",
            "21:\tlearn: 0.2378437\ttotal: 53ms\tremaining: 31.3ms\n",
            "22:\tlearn: 0.2344010\ttotal: 55ms\tremaining: 28.7ms\n",
            "23:\tlearn: 0.2304940\ttotal: 57.5ms\tremaining: 26.4ms\n",
            "24:\tlearn: 0.2269540\ttotal: 59.9ms\tremaining: 24ms\n",
            "25:\tlearn: 0.2232713\ttotal: 62.2ms\tremaining: 21.5ms\n",
            "26:\tlearn: 0.2208577\ttotal: 64.5ms\tremaining: 19.1ms\n",
            "27:\tlearn: 0.2181825\ttotal: 77.5ms\tremaining: 19.4ms\n",
            "28:\tlearn: 0.2149071\ttotal: 79.5ms\tremaining: 16.4ms\n",
            "29:\tlearn: 0.2123638\ttotal: 88.1ms\tremaining: 14.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 90ms\tremaining: 11.6ms\n",
            "31:\tlearn: 0.2071716\ttotal: 97.4ms\tremaining: 9.13ms\n",
            "32:\tlearn: 0.2045371\ttotal: 103ms\tremaining: 6.22ms\n",
            "33:\tlearn: 0.2018712\ttotal: 113ms\tremaining: 3.31ms\n",
            "34:\tlearn: 0.1995442\ttotal: 123ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 2.04ms\tremaining: 69.5ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.58ms\tremaining: 42.6ms\n",
            "2:\tlearn: 0.3383999\ttotal: 5.19ms\tremaining: 55.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 7.78ms\tremaining: 60.3ms\n",
            "4:\tlearn: 0.3080259\ttotal: 16.8ms\tremaining: 101ms\n",
            "5:\tlearn: 0.2907443\ttotal: 27.5ms\tremaining: 133ms\n",
            "6:\tlearn: 0.2818467\ttotal: 29.2ms\tremaining: 117ms\n",
            "7:\tlearn: 0.2691784\ttotal: 30.3ms\tremaining: 102ms\n",
            "8:\tlearn: 0.2611618\ttotal: 32ms\tremaining: 92.6ms\n",
            "9:\tlearn: 0.2519898\ttotal: 42.6ms\tremaining: 107ms\n",
            "10:\tlearn: 0.2462992\ttotal: 44.6ms\tremaining: 97.3ms\n",
            "11:\tlearn: 0.2416348\ttotal: 47.4ms\tremaining: 90.8ms\n",
            "12:\tlearn: 0.2368688\ttotal: 51.6ms\tremaining: 87.3ms\n",
            "13:\tlearn: 0.2320170\ttotal: 55.9ms\tremaining: 83.8ms\n",
            "14:\tlearn: 0.2262186\ttotal: 63.6ms\tremaining: 84.8ms\n",
            "15:\tlearn: 0.2215380\ttotal: 67.4ms\tremaining: 80.1ms\n",
            "16:\tlearn: 0.2176313\ttotal: 69.9ms\tremaining: 74ms\n",
            "17:\tlearn: 0.2138494\ttotal: 73.8ms\tremaining: 69.7ms\n",
            "18:\tlearn: 0.2100966\ttotal: 78ms\tremaining: 65.7ms\n",
            "19:\tlearn: 0.2068557\ttotal: 84.2ms\tremaining: 63.2ms\n",
            "20:\tlearn: 0.2029945\ttotal: 88.4ms\tremaining: 58.9ms\n",
            "21:\tlearn: 0.2001044\ttotal: 91.4ms\tremaining: 54ms\n",
            "22:\tlearn: 0.1970766\ttotal: 93.4ms\tremaining: 48.7ms\n",
            "23:\tlearn: 0.1940285\ttotal: 95.7ms\tremaining: 43.9ms\n",
            "24:\tlearn: 0.1910934\ttotal: 97.9ms\tremaining: 39.2ms\n",
            "25:\tlearn: 0.1879112\ttotal: 100ms\tremaining: 34.7ms\n",
            "26:\tlearn: 0.1852765\ttotal: 102ms\tremaining: 30.4ms\n",
            "27:\tlearn: 0.1827068\ttotal: 108ms\tremaining: 27ms\n",
            "28:\tlearn: 0.1803359\ttotal: 111ms\tremaining: 23ms\n",
            "29:\tlearn: 0.1779549\ttotal: 113ms\tremaining: 18.8ms\n",
            "30:\tlearn: 0.1757984\ttotal: 116ms\tremaining: 15ms\n",
            "31:\tlearn: 0.1724570\ttotal: 130ms\tremaining: 12.2ms\n",
            "32:\tlearn: 0.1703672\ttotal: 132ms\tremaining: 7.98ms\n",
            "33:\tlearn: 0.1685175\ttotal: 143ms\tremaining: 4.19ms\n",
            "34:\tlearn: 0.1666049\ttotal: 145ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 2.3ms\tremaining: 78.2ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.75ms\tremaining: 45.4ms\n",
            "2:\tlearn: 0.3203557\ttotal: 3.44ms\tremaining: 36.8ms\n",
            "3:\tlearn: 0.3063743\ttotal: 5.52ms\tremaining: 42.8ms\n",
            "4:\tlearn: 0.2970911\ttotal: 7.93ms\tremaining: 47.6ms\n",
            "5:\tlearn: 0.2891054\ttotal: 10.4ms\tremaining: 50.1ms\n",
            "6:\tlearn: 0.2792409\ttotal: 19ms\tremaining: 75.9ms\n",
            "7:\tlearn: 0.2716618\ttotal: 20.9ms\tremaining: 70.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 22.6ms\tremaining: 65.3ms\n",
            "9:\tlearn: 0.2537973\ttotal: 25.1ms\tremaining: 62.9ms\n",
            "10:\tlearn: 0.2473429\ttotal: 27.4ms\tremaining: 59.7ms\n",
            "11:\tlearn: 0.2416695\ttotal: 29.5ms\tremaining: 56.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 31.6ms\tremaining: 53.5ms\n",
            "13:\tlearn: 0.2298385\ttotal: 34.2ms\tremaining: 51.3ms\n",
            "14:\tlearn: 0.2249545\ttotal: 36.5ms\tremaining: 48.7ms\n",
            "15:\tlearn: 0.2192054\ttotal: 38.6ms\tremaining: 45.8ms\n",
            "16:\tlearn: 0.2150242\ttotal: 42.1ms\tremaining: 44.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 44.6ms\tremaining: 42.1ms\n",
            "18:\tlearn: 0.2056324\ttotal: 47ms\tremaining: 39.6ms\n",
            "19:\tlearn: 0.2021225\ttotal: 48.8ms\tremaining: 36.6ms\n",
            "20:\tlearn: 0.1989042\ttotal: 51.4ms\tremaining: 34.3ms\n",
            "21:\tlearn: 0.1961040\ttotal: 53.7ms\tremaining: 31.7ms\n",
            "22:\tlearn: 0.1934794\ttotal: 55.5ms\tremaining: 29ms\n",
            "23:\tlearn: 0.1902438\ttotal: 57.9ms\tremaining: 26.5ms\n",
            "24:\tlearn: 0.1874921\ttotal: 81.3ms\tremaining: 32.5ms\n",
            "25:\tlearn: 0.1829904\ttotal: 83.7ms\tremaining: 29ms\n",
            "26:\tlearn: 0.1804169\ttotal: 86.1ms\tremaining: 25.5ms\n",
            "27:\tlearn: 0.1776989\ttotal: 88.5ms\tremaining: 22.1ms\n",
            "28:\tlearn: 0.1751387\ttotal: 90.3ms\tremaining: 18.7ms\n",
            "29:\tlearn: 0.1727570\ttotal: 104ms\tremaining: 17.3ms\n",
            "30:\tlearn: 0.1693663\ttotal: 114ms\tremaining: 14.8ms\n",
            "31:\tlearn: 0.1661883\ttotal: 117ms\tremaining: 11ms\n",
            "32:\tlearn: 0.1641011\ttotal: 119ms\tremaining: 7.22ms\n",
            "33:\tlearn: 0.1616271\ttotal: 122ms\tremaining: 3.58ms\n",
            "34:\tlearn: 0.1593621\ttotal: 147ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 3.69ms\tremaining: 129ms\n",
            "1:\tlearn: 0.4229987\ttotal: 5.1ms\tremaining: 86.8ms\n",
            "2:\tlearn: 0.3843342\ttotal: 8.55ms\tremaining: 94ms\n",
            "3:\tlearn: 0.3652888\ttotal: 12.8ms\tremaining: 102ms\n",
            "4:\tlearn: 0.3496343\ttotal: 19.4ms\tremaining: 121ms\n",
            "5:\tlearn: 0.3393969\ttotal: 21.3ms\tremaining: 106ms\n",
            "6:\tlearn: 0.3300914\ttotal: 26.1ms\tremaining: 108ms\n",
            "7:\tlearn: 0.3229079\ttotal: 33.7ms\tremaining: 118ms\n",
            "8:\tlearn: 0.3148279\ttotal: 37.9ms\tremaining: 114ms\n",
            "9:\tlearn: 0.3054626\ttotal: 52.9ms\tremaining: 137ms\n",
            "10:\tlearn: 0.2983658\ttotal: 54.8ms\tremaining: 125ms\n",
            "11:\tlearn: 0.2903440\ttotal: 56.6ms\tremaining: 113ms\n",
            "12:\tlearn: 0.2852979\ttotal: 65.9ms\tremaining: 117ms\n",
            "13:\tlearn: 0.2798563\ttotal: 68.5ms\tremaining: 108ms\n",
            "14:\tlearn: 0.2747341\ttotal: 72.6ms\tremaining: 102ms\n",
            "15:\tlearn: 0.2702568\ttotal: 81ms\tremaining: 101ms\n",
            "16:\tlearn: 0.2650537\ttotal: 82.7ms\tremaining: 92.5ms\n",
            "17:\tlearn: 0.2601005\ttotal: 94.5ms\tremaining: 94.5ms\n",
            "18:\tlearn: 0.2560578\ttotal: 99.2ms\tremaining: 88.8ms\n",
            "19:\tlearn: 0.2530381\ttotal: 116ms\tremaining: 92.7ms\n",
            "20:\tlearn: 0.2498453\ttotal: 119ms\tremaining: 84.8ms\n",
            "21:\tlearn: 0.2461646\ttotal: 124ms\tremaining: 78.9ms\n",
            "22:\tlearn: 0.2424369\ttotal: 132ms\tremaining: 74.5ms\n",
            "23:\tlearn: 0.2392835\ttotal: 136ms\tremaining: 67.9ms\n",
            "24:\tlearn: 0.2339070\ttotal: 140ms\tremaining: 61.7ms\n",
            "25:\tlearn: 0.2301706\ttotal: 146ms\tremaining: 56ms\n",
            "26:\tlearn: 0.2263007\ttotal: 151ms\tremaining: 50.2ms\n",
            "27:\tlearn: 0.2223209\ttotal: 156ms\tremaining: 44.5ms\n",
            "28:\tlearn: 0.2190932\ttotal: 161ms\tremaining: 38.8ms\n",
            "29:\tlearn: 0.2159010\ttotal: 165ms\tremaining: 33ms\n",
            "30:\tlearn: 0.2132954\ttotal: 171ms\tremaining: 27.5ms\n",
            "31:\tlearn: 0.2102299\ttotal: 176ms\tremaining: 22ms\n",
            "32:\tlearn: 0.2076280\ttotal: 181ms\tremaining: 16.4ms\n",
            "33:\tlearn: 0.2043188\ttotal: 185ms\tremaining: 10.9ms\n",
            "34:\tlearn: 0.2017849\ttotal: 191ms\tremaining: 5.45ms\n",
            "35:\tlearn: 0.1993718\ttotal: 196ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 4.46ms\tremaining: 156ms\n",
            "1:\tlearn: 0.4049315\ttotal: 6.8ms\tremaining: 116ms\n",
            "2:\tlearn: 0.3788145\ttotal: 14.1ms\tremaining: 155ms\n",
            "3:\tlearn: 0.3658016\ttotal: 18.7ms\tremaining: 150ms\n",
            "4:\tlearn: 0.3428474\ttotal: 22.6ms\tremaining: 140ms\n",
            "5:\tlearn: 0.3234303\ttotal: 24.5ms\tremaining: 123ms\n",
            "6:\tlearn: 0.3158416\ttotal: 28.3ms\tremaining: 117ms\n",
            "7:\tlearn: 0.3097739\ttotal: 33.8ms\tremaining: 118ms\n",
            "8:\tlearn: 0.3040041\ttotal: 36.4ms\tremaining: 109ms\n",
            "9:\tlearn: 0.2975585\ttotal: 38.4ms\tremaining: 99.9ms\n",
            "10:\tlearn: 0.2898709\ttotal: 40.3ms\tremaining: 91.7ms\n",
            "11:\tlearn: 0.2845372\ttotal: 42.8ms\tremaining: 85.6ms\n",
            "12:\tlearn: 0.2794184\ttotal: 47.2ms\tremaining: 83.5ms\n",
            "13:\tlearn: 0.2740314\ttotal: 50.3ms\tremaining: 79ms\n",
            "14:\tlearn: 0.2705542\ttotal: 52.2ms\tremaining: 73.1ms\n",
            "15:\tlearn: 0.2673919\ttotal: 54.6ms\tremaining: 68.2ms\n",
            "16:\tlearn: 0.2623365\ttotal: 56.6ms\tremaining: 63.2ms\n",
            "17:\tlearn: 0.2595719\ttotal: 58.5ms\tremaining: 58.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 60.4ms\tremaining: 54.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 62.7ms\tremaining: 50.1ms\n",
            "20:\tlearn: 0.2477056\ttotal: 64.9ms\tremaining: 46.4ms\n",
            "21:\tlearn: 0.2437884\ttotal: 66.9ms\tremaining: 42.6ms\n",
            "22:\tlearn: 0.2404080\ttotal: 68.9ms\tremaining: 39ms\n",
            "23:\tlearn: 0.2369058\ttotal: 70.9ms\tremaining: 35.4ms\n",
            "24:\tlearn: 0.2331119\ttotal: 72.8ms\tremaining: 32ms\n",
            "25:\tlearn: 0.2293455\ttotal: 74.8ms\tremaining: 28.8ms\n",
            "26:\tlearn: 0.2256418\ttotal: 81.7ms\tremaining: 27.2ms\n",
            "27:\tlearn: 0.2221119\ttotal: 83.6ms\tremaining: 23.9ms\n",
            "28:\tlearn: 0.2190925\ttotal: 86.5ms\tremaining: 20.9ms\n",
            "29:\tlearn: 0.2161731\ttotal: 89.1ms\tremaining: 17.8ms\n",
            "30:\tlearn: 0.2135041\ttotal: 90.9ms\tremaining: 14.7ms\n",
            "31:\tlearn: 0.2113382\ttotal: 93.5ms\tremaining: 11.7ms\n",
            "32:\tlearn: 0.2083485\ttotal: 95.5ms\tremaining: 8.68ms\n",
            "33:\tlearn: 0.2058588\ttotal: 97.4ms\tremaining: 5.73ms\n",
            "34:\tlearn: 0.2024895\ttotal: 99.3ms\tremaining: 2.84ms\n",
            "35:\tlearn: 0.1997586\ttotal: 101ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.92ms\tremaining: 67.1ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.32ms\tremaining: 39.5ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.87ms\tremaining: 31.5ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.75ms\tremaining: 38ms\n",
            "4:\tlearn: 0.3441195\ttotal: 13.6ms\tremaining: 84ms\n",
            "5:\tlearn: 0.3328396\ttotal: 16.2ms\tremaining: 80.8ms\n",
            "6:\tlearn: 0.3256704\ttotal: 23.4ms\tremaining: 96.9ms\n",
            "7:\tlearn: 0.3174441\ttotal: 25.2ms\tremaining: 88.1ms\n",
            "8:\tlearn: 0.3090762\ttotal: 27.2ms\tremaining: 81.5ms\n",
            "9:\tlearn: 0.3028459\ttotal: 29ms\tremaining: 75.5ms\n",
            "10:\tlearn: 0.2958541\ttotal: 31.9ms\tremaining: 72.6ms\n",
            "11:\tlearn: 0.2901166\ttotal: 34ms\tremaining: 67.9ms\n",
            "12:\tlearn: 0.2841803\ttotal: 36ms\tremaining: 63.7ms\n",
            "13:\tlearn: 0.2789751\ttotal: 37.9ms\tremaining: 59.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 39.9ms\tremaining: 55.9ms\n",
            "15:\tlearn: 0.2663544\ttotal: 42.2ms\tremaining: 52.8ms\n",
            "16:\tlearn: 0.2615546\ttotal: 45.8ms\tremaining: 51.2ms\n",
            "17:\tlearn: 0.2560079\ttotal: 47.8ms\tremaining: 47.8ms\n",
            "18:\tlearn: 0.2507480\ttotal: 49.7ms\tremaining: 44.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 52.5ms\tremaining: 42ms\n",
            "20:\tlearn: 0.2413892\ttotal: 58.4ms\tremaining: 41.7ms\n",
            "21:\tlearn: 0.2378437\ttotal: 60.3ms\tremaining: 38.4ms\n",
            "22:\tlearn: 0.2344010\ttotal: 62.2ms\tremaining: 35.2ms\n",
            "23:\tlearn: 0.2304940\ttotal: 64.1ms\tremaining: 32ms\n",
            "24:\tlearn: 0.2269540\ttotal: 66.8ms\tremaining: 29.4ms\n",
            "25:\tlearn: 0.2232713\ttotal: 69.8ms\tremaining: 26.8ms\n",
            "26:\tlearn: 0.2208577\ttotal: 72.1ms\tremaining: 24ms\n",
            "27:\tlearn: 0.2181825\ttotal: 74.2ms\tremaining: 21.2ms\n",
            "28:\tlearn: 0.2149071\ttotal: 77ms\tremaining: 18.6ms\n",
            "29:\tlearn: 0.2123638\ttotal: 88.3ms\tremaining: 17.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 90.2ms\tremaining: 14.5ms\n",
            "31:\tlearn: 0.2071716\ttotal: 92.1ms\tremaining: 11.5ms\n",
            "32:\tlearn: 0.2045371\ttotal: 94.5ms\tremaining: 8.6ms\n",
            "33:\tlearn: 0.2018712\ttotal: 96.8ms\tremaining: 5.7ms\n",
            "34:\tlearn: 0.1995442\ttotal: 98.7ms\tremaining: 2.82ms\n",
            "35:\tlearn: 0.1970515\ttotal: 101ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 5.54ms\tremaining: 194ms\n",
            "1:\tlearn: 0.3745079\ttotal: 7.14ms\tremaining: 121ms\n",
            "2:\tlearn: 0.3383999\ttotal: 11.3ms\tremaining: 125ms\n",
            "3:\tlearn: 0.3266560\ttotal: 20.4ms\tremaining: 163ms\n",
            "4:\tlearn: 0.3080259\ttotal: 22ms\tremaining: 136ms\n",
            "5:\tlearn: 0.2907443\ttotal: 23.7ms\tremaining: 119ms\n",
            "6:\tlearn: 0.2818467\ttotal: 25.5ms\tremaining: 106ms\n",
            "7:\tlearn: 0.2691784\ttotal: 26.6ms\tremaining: 93ms\n",
            "8:\tlearn: 0.2611618\ttotal: 28.6ms\tremaining: 85.7ms\n",
            "9:\tlearn: 0.2519898\ttotal: 30.8ms\tremaining: 80.1ms\n",
            "10:\tlearn: 0.2462992\ttotal: 32.7ms\tremaining: 74.3ms\n",
            "11:\tlearn: 0.2416348\ttotal: 34.6ms\tremaining: 69.2ms\n",
            "12:\tlearn: 0.2368688\ttotal: 36.8ms\tremaining: 65.1ms\n",
            "13:\tlearn: 0.2320170\ttotal: 38.6ms\tremaining: 60.7ms\n",
            "14:\tlearn: 0.2262186\ttotal: 40.4ms\tremaining: 56.6ms\n",
            "15:\tlearn: 0.2215380\ttotal: 42.3ms\tremaining: 52.9ms\n",
            "16:\tlearn: 0.2176313\ttotal: 44.2ms\tremaining: 49.4ms\n",
            "17:\tlearn: 0.2138494\ttotal: 45.9ms\tremaining: 45.9ms\n",
            "18:\tlearn: 0.2100966\ttotal: 48.2ms\tremaining: 43.2ms\n",
            "19:\tlearn: 0.2068557\ttotal: 50ms\tremaining: 40ms\n",
            "20:\tlearn: 0.2029945\ttotal: 51.7ms\tremaining: 36.9ms\n",
            "21:\tlearn: 0.2001044\ttotal: 53.4ms\tremaining: 34ms\n",
            "22:\tlearn: 0.1970766\ttotal: 55.1ms\tremaining: 31.1ms\n",
            "23:\tlearn: 0.1940285\ttotal: 57ms\tremaining: 28.5ms\n",
            "24:\tlearn: 0.1910934\ttotal: 58.8ms\tremaining: 25.9ms\n",
            "25:\tlearn: 0.1879112\ttotal: 60.7ms\tremaining: 23.3ms\n",
            "26:\tlearn: 0.1852765\ttotal: 62.7ms\tremaining: 20.9ms\n",
            "27:\tlearn: 0.1827068\ttotal: 64.7ms\tremaining: 18.5ms\n",
            "28:\tlearn: 0.1803359\ttotal: 66.7ms\tremaining: 16.1ms\n",
            "29:\tlearn: 0.1779549\ttotal: 69.2ms\tremaining: 13.8ms\n",
            "30:\tlearn: 0.1757984\ttotal: 71.8ms\tremaining: 11.6ms\n",
            "31:\tlearn: 0.1724570\ttotal: 73.6ms\tremaining: 9.21ms\n",
            "32:\tlearn: 0.1703672\ttotal: 75.4ms\tremaining: 6.86ms\n",
            "33:\tlearn: 0.1685175\ttotal: 77.6ms\tremaining: 4.56ms\n",
            "34:\tlearn: 0.1666049\ttotal: 79.4ms\tremaining: 2.27ms\n",
            "35:\tlearn: 0.1648374\ttotal: 81.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 3.1ms\tremaining: 109ms\n",
            "1:\tlearn: 0.3687510\ttotal: 3.66ms\tremaining: 62.2ms\n",
            "2:\tlearn: 0.3203557\ttotal: 4.38ms\tremaining: 48.2ms\n",
            "3:\tlearn: 0.3063743\ttotal: 7.16ms\tremaining: 57.3ms\n",
            "4:\tlearn: 0.2970911\ttotal: 10.5ms\tremaining: 65.1ms\n",
            "5:\tlearn: 0.2891054\ttotal: 20.8ms\tremaining: 104ms\n",
            "6:\tlearn: 0.2792409\ttotal: 22.5ms\tremaining: 93.4ms\n",
            "7:\tlearn: 0.2716618\ttotal: 24.4ms\tremaining: 85.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 26.3ms\tremaining: 78.8ms\n",
            "9:\tlearn: 0.2537973\ttotal: 29ms\tremaining: 75.3ms\n",
            "10:\tlearn: 0.2473429\ttotal: 30.5ms\tremaining: 69.4ms\n",
            "11:\tlearn: 0.2416695\ttotal: 37.7ms\tremaining: 75.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 39.5ms\tremaining: 69.8ms\n",
            "13:\tlearn: 0.2298385\ttotal: 41.2ms\tremaining: 64.8ms\n",
            "14:\tlearn: 0.2249545\ttotal: 42.9ms\tremaining: 60.1ms\n",
            "15:\tlearn: 0.2192054\ttotal: 47.8ms\tremaining: 59.8ms\n",
            "16:\tlearn: 0.2150242\ttotal: 49.5ms\tremaining: 55.3ms\n",
            "17:\tlearn: 0.2094516\ttotal: 51.3ms\tremaining: 51.3ms\n",
            "18:\tlearn: 0.2056324\ttotal: 53.1ms\tremaining: 47.5ms\n",
            "19:\tlearn: 0.2021225\ttotal: 54.8ms\tremaining: 43.8ms\n",
            "20:\tlearn: 0.1989042\ttotal: 56.6ms\tremaining: 40.4ms\n",
            "21:\tlearn: 0.1961040\ttotal: 58.3ms\tremaining: 37.1ms\n",
            "22:\tlearn: 0.1934794\ttotal: 60.7ms\tremaining: 34.3ms\n",
            "23:\tlearn: 0.1902438\ttotal: 62.5ms\tremaining: 31.2ms\n",
            "24:\tlearn: 0.1874921\ttotal: 64.3ms\tremaining: 28.3ms\n",
            "25:\tlearn: 0.1829904\ttotal: 66.1ms\tremaining: 25.4ms\n",
            "26:\tlearn: 0.1804169\ttotal: 67.9ms\tremaining: 22.6ms\n",
            "27:\tlearn: 0.1776989\ttotal: 69.8ms\tremaining: 19.9ms\n",
            "28:\tlearn: 0.1751387\ttotal: 71.5ms\tremaining: 17.3ms\n",
            "29:\tlearn: 0.1727570\ttotal: 73.2ms\tremaining: 14.6ms\n",
            "30:\tlearn: 0.1693663\ttotal: 74.9ms\tremaining: 12.1ms\n",
            "31:\tlearn: 0.1661883\ttotal: 76.7ms\tremaining: 9.58ms\n",
            "32:\tlearn: 0.1641011\ttotal: 78.5ms\tremaining: 7.14ms\n",
            "33:\tlearn: 0.1616271\ttotal: 80.5ms\tremaining: 4.73ms\n",
            "34:\tlearn: 0.1593621\ttotal: 82.3ms\tremaining: 2.35ms\n",
            "35:\tlearn: 0.1576181\ttotal: 84ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.92ms\tremaining: 69.2ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.31ms\tremaining: 40.4ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.21ms\tremaining: 47.8ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.82ms\tremaining: 56.2ms\n",
            "4:\tlearn: 0.3496343\ttotal: 9.51ms\tremaining: 60.9ms\n",
            "5:\tlearn: 0.3393969\ttotal: 11.2ms\tremaining: 58ms\n",
            "6:\tlearn: 0.3300914\ttotal: 14.3ms\tremaining: 61.5ms\n",
            "7:\tlearn: 0.3229079\ttotal: 19.6ms\tremaining: 71ms\n",
            "8:\tlearn: 0.3148279\ttotal: 25.1ms\tremaining: 78ms\n",
            "9:\tlearn: 0.3054626\ttotal: 27.3ms\tremaining: 73.6ms\n",
            "10:\tlearn: 0.2983658\ttotal: 32.4ms\tremaining: 76.5ms\n",
            "11:\tlearn: 0.2903440\ttotal: 34.8ms\tremaining: 72.6ms\n",
            "12:\tlearn: 0.2852979\ttotal: 36.7ms\tremaining: 67.7ms\n",
            "13:\tlearn: 0.2798563\ttotal: 38.8ms\tremaining: 63.8ms\n",
            "14:\tlearn: 0.2747341\ttotal: 40.5ms\tremaining: 59.4ms\n",
            "15:\tlearn: 0.2702568\ttotal: 42.9ms\tremaining: 56.4ms\n",
            "16:\tlearn: 0.2650537\ttotal: 44.8ms\tremaining: 52.8ms\n",
            "17:\tlearn: 0.2601005\ttotal: 46.9ms\tremaining: 49.5ms\n",
            "18:\tlearn: 0.2560578\ttotal: 48.9ms\tremaining: 46.3ms\n",
            "19:\tlearn: 0.2530381\ttotal: 51.9ms\tremaining: 44.1ms\n",
            "20:\tlearn: 0.2498453\ttotal: 53.8ms\tremaining: 41ms\n",
            "21:\tlearn: 0.2461646\ttotal: 59.1ms\tremaining: 40.3ms\n",
            "22:\tlearn: 0.2424369\ttotal: 61.2ms\tremaining: 37.2ms\n",
            "23:\tlearn: 0.2392835\ttotal: 62.9ms\tremaining: 34.1ms\n",
            "24:\tlearn: 0.2339070\ttotal: 64.7ms\tremaining: 31.1ms\n",
            "25:\tlearn: 0.2301706\ttotal: 66.5ms\tremaining: 28.1ms\n",
            "26:\tlearn: 0.2263007\ttotal: 68.3ms\tremaining: 25.3ms\n",
            "27:\tlearn: 0.2223209\ttotal: 70ms\tremaining: 22.5ms\n",
            "28:\tlearn: 0.2190932\ttotal: 71.9ms\tremaining: 19.8ms\n",
            "29:\tlearn: 0.2159010\ttotal: 73.6ms\tremaining: 17.2ms\n",
            "30:\tlearn: 0.2132954\ttotal: 75.2ms\tremaining: 14.6ms\n",
            "31:\tlearn: 0.2102299\ttotal: 77.1ms\tremaining: 12ms\n",
            "32:\tlearn: 0.2076280\ttotal: 78.9ms\tremaining: 9.56ms\n",
            "33:\tlearn: 0.2043188\ttotal: 80.8ms\tremaining: 7.13ms\n",
            "34:\tlearn: 0.2017849\ttotal: 82.6ms\tremaining: 4.72ms\n",
            "35:\tlearn: 0.1993718\ttotal: 85.1ms\tremaining: 2.36ms\n",
            "36:\tlearn: 0.1972299\ttotal: 87.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.96ms\tremaining: 70.5ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.5ms\tremaining: 43.8ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.78ms\tremaining: 54.2ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.52ms\tremaining: 53.8ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.46ms\tremaining: 47.7ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.65ms\tremaining: 44.7ms\n",
            "6:\tlearn: 0.3158416\ttotal: 11.2ms\tremaining: 48.2ms\n",
            "7:\tlearn: 0.3097739\ttotal: 13ms\tremaining: 47.2ms\n",
            "8:\tlearn: 0.3040041\ttotal: 15.1ms\tremaining: 47.1ms\n",
            "9:\tlearn: 0.2975585\ttotal: 17.2ms\tremaining: 46.6ms\n",
            "10:\tlearn: 0.2898709\ttotal: 21ms\tremaining: 49.5ms\n",
            "11:\tlearn: 0.2845372\ttotal: 23.8ms\tremaining: 49.6ms\n",
            "12:\tlearn: 0.2794184\ttotal: 26.3ms\tremaining: 48.5ms\n",
            "13:\tlearn: 0.2740314\ttotal: 28.3ms\tremaining: 46.5ms\n",
            "14:\tlearn: 0.2705542\ttotal: 30.6ms\tremaining: 44.8ms\n",
            "15:\tlearn: 0.2673919\ttotal: 33.1ms\tremaining: 43.5ms\n",
            "16:\tlearn: 0.2623365\ttotal: 35.8ms\tremaining: 42.1ms\n",
            "17:\tlearn: 0.2595719\ttotal: 37.7ms\tremaining: 39.8ms\n",
            "18:\tlearn: 0.2545713\ttotal: 39.5ms\tremaining: 37.4ms\n",
            "19:\tlearn: 0.2510766\ttotal: 41.3ms\tremaining: 35.1ms\n",
            "20:\tlearn: 0.2477056\ttotal: 44.2ms\tremaining: 33.7ms\n",
            "21:\tlearn: 0.2437884\ttotal: 46.2ms\tremaining: 31.5ms\n",
            "22:\tlearn: 0.2404080\ttotal: 48ms\tremaining: 29.2ms\n",
            "23:\tlearn: 0.2369058\ttotal: 49.8ms\tremaining: 27ms\n",
            "24:\tlearn: 0.2331119\ttotal: 51.6ms\tremaining: 24.8ms\n",
            "25:\tlearn: 0.2293455\ttotal: 53.3ms\tremaining: 22.6ms\n",
            "26:\tlearn: 0.2256418\ttotal: 54.9ms\tremaining: 20.3ms\n",
            "27:\tlearn: 0.2221119\ttotal: 56.9ms\tremaining: 18.3ms\n",
            "28:\tlearn: 0.2190925\ttotal: 59ms\tremaining: 16.3ms\n",
            "29:\tlearn: 0.2161731\ttotal: 61ms\tremaining: 14.2ms\n",
            "30:\tlearn: 0.2135041\ttotal: 63ms\tremaining: 12.2ms\n",
            "31:\tlearn: 0.2113382\ttotal: 65.8ms\tremaining: 10.3ms\n",
            "32:\tlearn: 0.2083485\ttotal: 68ms\tremaining: 8.24ms\n",
            "33:\tlearn: 0.2058588\ttotal: 69.8ms\tremaining: 6.16ms\n",
            "34:\tlearn: 0.2024895\ttotal: 71.6ms\tremaining: 4.09ms\n",
            "35:\tlearn: 0.1997586\ttotal: 74ms\tremaining: 2.06ms\n",
            "36:\tlearn: 0.1976953\ttotal: 75.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.88ms\tremaining: 67.7ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.25ms\tremaining: 39.5ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.85ms\tremaining: 32.2ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.73ms\tremaining: 39ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.84ms\tremaining: 43.8ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.03ms\tremaining: 46.7ms\n",
            "6:\tlearn: 0.3256704\ttotal: 10.9ms\tremaining: 46.7ms\n",
            "7:\tlearn: 0.3174441\ttotal: 12.6ms\tremaining: 45.8ms\n",
            "8:\tlearn: 0.3090762\ttotal: 14.5ms\tremaining: 45.1ms\n",
            "9:\tlearn: 0.3028459\ttotal: 16.5ms\tremaining: 44.6ms\n",
            "10:\tlearn: 0.2958541\ttotal: 19.2ms\tremaining: 45.3ms\n",
            "11:\tlearn: 0.2901166\ttotal: 21.9ms\tremaining: 45.7ms\n",
            "12:\tlearn: 0.2841803\ttotal: 25.4ms\tremaining: 46.9ms\n",
            "13:\tlearn: 0.2789751\ttotal: 37.7ms\tremaining: 61.9ms\n",
            "14:\tlearn: 0.2715599\ttotal: 39.4ms\tremaining: 57.8ms\n",
            "15:\tlearn: 0.2663544\ttotal: 41.2ms\tremaining: 54.1ms\n",
            "16:\tlearn: 0.2615546\ttotal: 43.2ms\tremaining: 50.8ms\n",
            "17:\tlearn: 0.2560079\ttotal: 51ms\tremaining: 53.8ms\n",
            "18:\tlearn: 0.2507480\ttotal: 52.8ms\tremaining: 50.1ms\n",
            "19:\tlearn: 0.2450678\ttotal: 54.5ms\tremaining: 46.3ms\n",
            "20:\tlearn: 0.2413892\ttotal: 56.2ms\tremaining: 42.8ms\n",
            "21:\tlearn: 0.2378437\ttotal: 58.1ms\tremaining: 39.6ms\n",
            "22:\tlearn: 0.2344010\ttotal: 59.9ms\tremaining: 36.5ms\n",
            "23:\tlearn: 0.2304940\ttotal: 61.5ms\tremaining: 33.3ms\n",
            "24:\tlearn: 0.2269540\ttotal: 63.3ms\tremaining: 30.4ms\n",
            "25:\tlearn: 0.2232713\ttotal: 64.9ms\tremaining: 27.4ms\n",
            "26:\tlearn: 0.2208577\ttotal: 66.6ms\tremaining: 24.7ms\n",
            "27:\tlearn: 0.2181825\ttotal: 68.5ms\tremaining: 22ms\n",
            "28:\tlearn: 0.2149071\ttotal: 70.4ms\tremaining: 19.4ms\n",
            "29:\tlearn: 0.2123638\ttotal: 72.3ms\tremaining: 16.9ms\n",
            "30:\tlearn: 0.2094640\ttotal: 74.4ms\tremaining: 14.4ms\n",
            "31:\tlearn: 0.2071716\ttotal: 76.3ms\tremaining: 11.9ms\n",
            "32:\tlearn: 0.2045371\ttotal: 78.2ms\tremaining: 9.48ms\n",
            "33:\tlearn: 0.2018712\ttotal: 80.2ms\tremaining: 7.08ms\n",
            "34:\tlearn: 0.1995442\ttotal: 82.1ms\tremaining: 4.69ms\n",
            "35:\tlearn: 0.1970515\ttotal: 84ms\tremaining: 2.33ms\n",
            "36:\tlearn: 0.1946725\ttotal: 89ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.85ms\tremaining: 66.6ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.23ms\tremaining: 39.1ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.12ms\tremaining: 46.7ms\n",
            "3:\tlearn: 0.3266560\ttotal: 5.99ms\tremaining: 49.4ms\n",
            "4:\tlearn: 0.3080259\ttotal: 7.82ms\tremaining: 50.1ms\n",
            "5:\tlearn: 0.2907443\ttotal: 9.65ms\tremaining: 49.8ms\n",
            "6:\tlearn: 0.2818467\ttotal: 16.7ms\tremaining: 71.5ms\n",
            "7:\tlearn: 0.2691784\ttotal: 19.4ms\tremaining: 70.4ms\n",
            "8:\tlearn: 0.2611618\ttotal: 21.3ms\tremaining: 66.2ms\n",
            "9:\tlearn: 0.2519898\ttotal: 23.1ms\tremaining: 62.3ms\n",
            "10:\tlearn: 0.2462992\ttotal: 25.9ms\tremaining: 61.2ms\n",
            "11:\tlearn: 0.2416348\ttotal: 28.5ms\tremaining: 59.3ms\n",
            "12:\tlearn: 0.2368688\ttotal: 35.3ms\tremaining: 65.2ms\n",
            "13:\tlearn: 0.2320170\ttotal: 37.2ms\tremaining: 61.1ms\n",
            "14:\tlearn: 0.2262186\ttotal: 40.2ms\tremaining: 59ms\n",
            "15:\tlearn: 0.2215380\ttotal: 43.2ms\tremaining: 56.8ms\n",
            "16:\tlearn: 0.2176313\ttotal: 47ms\tremaining: 55.3ms\n",
            "17:\tlearn: 0.2138494\ttotal: 48.8ms\tremaining: 51.6ms\n",
            "18:\tlearn: 0.2100966\ttotal: 50.7ms\tremaining: 48ms\n",
            "19:\tlearn: 0.2068557\ttotal: 52.5ms\tremaining: 44.6ms\n",
            "20:\tlearn: 0.2029945\ttotal: 54.3ms\tremaining: 41.4ms\n",
            "21:\tlearn: 0.2001044\ttotal: 56.1ms\tremaining: 38.2ms\n",
            "22:\tlearn: 0.1970766\ttotal: 59.3ms\tremaining: 36.1ms\n",
            "23:\tlearn: 0.1940285\ttotal: 61.1ms\tremaining: 33.1ms\n",
            "24:\tlearn: 0.1910934\ttotal: 70ms\tremaining: 33.6ms\n",
            "25:\tlearn: 0.1879112\ttotal: 71.7ms\tremaining: 30.3ms\n",
            "26:\tlearn: 0.1852765\ttotal: 73.4ms\tremaining: 27.2ms\n",
            "27:\tlearn: 0.1827068\ttotal: 75ms\tremaining: 24.1ms\n",
            "28:\tlearn: 0.1803359\ttotal: 77.4ms\tremaining: 21.3ms\n",
            "29:\tlearn: 0.1779549\ttotal: 86ms\tremaining: 20.1ms\n",
            "30:\tlearn: 0.1757984\ttotal: 87.8ms\tremaining: 17ms\n",
            "31:\tlearn: 0.1724570\ttotal: 89.6ms\tremaining: 14ms\n",
            "32:\tlearn: 0.1703672\ttotal: 91.6ms\tremaining: 11.1ms\n",
            "33:\tlearn: 0.1685175\ttotal: 93.4ms\tremaining: 8.24ms\n",
            "34:\tlearn: 0.1666049\ttotal: 95ms\tremaining: 5.43ms\n",
            "35:\tlearn: 0.1648374\ttotal: 96.7ms\tremaining: 2.69ms\n",
            "36:\tlearn: 0.1631656\ttotal: 99.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.76ms\tremaining: 63.4ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.13ms\tremaining: 37.4ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.65ms\tremaining: 30ms\n",
            "3:\tlearn: 0.3063743\ttotal: 7.29ms\tremaining: 60.2ms\n",
            "4:\tlearn: 0.2970911\ttotal: 9.74ms\tremaining: 62.4ms\n",
            "5:\tlearn: 0.2891054\ttotal: 12.1ms\tremaining: 62.3ms\n",
            "6:\tlearn: 0.2792409\ttotal: 13.7ms\tremaining: 58.6ms\n",
            "7:\tlearn: 0.2716618\ttotal: 15.3ms\tremaining: 55.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 16.9ms\tremaining: 52.5ms\n",
            "9:\tlearn: 0.2537973\ttotal: 21.8ms\tremaining: 58.8ms\n",
            "10:\tlearn: 0.2473429\ttotal: 27.7ms\tremaining: 65.6ms\n",
            "11:\tlearn: 0.2416695\ttotal: 34.4ms\tremaining: 71.6ms\n",
            "12:\tlearn: 0.2366343\ttotal: 44.2ms\tremaining: 81.6ms\n",
            "13:\tlearn: 0.2298385\ttotal: 48.9ms\tremaining: 80.4ms\n",
            "14:\tlearn: 0.2249545\ttotal: 55.5ms\tremaining: 81.5ms\n",
            "15:\tlearn: 0.2192054\ttotal: 59.7ms\tremaining: 78.3ms\n",
            "16:\tlearn: 0.2150242\ttotal: 64.8ms\tremaining: 76.2ms\n",
            "17:\tlearn: 0.2094516\ttotal: 69.7ms\tremaining: 73.6ms\n",
            "18:\tlearn: 0.2056324\ttotal: 75.3ms\tremaining: 71.4ms\n",
            "19:\tlearn: 0.2021225\ttotal: 78.7ms\tremaining: 66.9ms\n",
            "20:\tlearn: 0.1989042\ttotal: 83.5ms\tremaining: 63.6ms\n",
            "21:\tlearn: 0.1961040\ttotal: 88.3ms\tremaining: 60.2ms\n",
            "22:\tlearn: 0.1934794\ttotal: 93ms\tremaining: 56.6ms\n",
            "23:\tlearn: 0.1902438\ttotal: 97.6ms\tremaining: 52.9ms\n",
            "24:\tlearn: 0.1874921\ttotal: 102ms\tremaining: 49ms\n",
            "25:\tlearn: 0.1829904\ttotal: 107ms\tremaining: 45.1ms\n",
            "26:\tlearn: 0.1804169\ttotal: 112ms\tremaining: 41.4ms\n",
            "27:\tlearn: 0.1776989\ttotal: 114ms\tremaining: 36.7ms\n",
            "28:\tlearn: 0.1751387\ttotal: 119ms\tremaining: 32.9ms\n",
            "29:\tlearn: 0.1727570\ttotal: 124ms\tremaining: 28.9ms\n",
            "30:\tlearn: 0.1693663\ttotal: 129ms\tremaining: 24.9ms\n",
            "31:\tlearn: 0.1661883\ttotal: 134ms\tremaining: 20.9ms\n",
            "32:\tlearn: 0.1641011\ttotal: 139ms\tremaining: 16.8ms\n",
            "33:\tlearn: 0.1616271\ttotal: 144ms\tremaining: 12.7ms\n",
            "34:\tlearn: 0.1593621\ttotal: 152ms\tremaining: 8.7ms\n",
            "35:\tlearn: 0.1576181\ttotal: 163ms\tremaining: 4.53ms\n",
            "36:\tlearn: 0.1557020\ttotal: 168ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 2.91ms\tremaining: 108ms\n",
            "1:\tlearn: 0.4229987\ttotal: 4.3ms\tremaining: 77.4ms\n",
            "2:\tlearn: 0.3843342\ttotal: 7.06ms\tremaining: 82.4ms\n",
            "3:\tlearn: 0.3652888\ttotal: 18.6ms\tremaining: 158ms\n",
            "4:\tlearn: 0.3496343\ttotal: 23.3ms\tremaining: 154ms\n",
            "5:\tlearn: 0.3393969\ttotal: 24.9ms\tremaining: 133ms\n",
            "6:\tlearn: 0.3300914\ttotal: 26.6ms\tremaining: 118ms\n",
            "7:\tlearn: 0.3229079\ttotal: 28.3ms\tremaining: 106ms\n",
            "8:\tlearn: 0.3148279\ttotal: 30.2ms\tremaining: 97.4ms\n",
            "9:\tlearn: 0.3054626\ttotal: 32.2ms\tremaining: 90.1ms\n",
            "10:\tlearn: 0.2983658\ttotal: 34ms\tremaining: 83.4ms\n",
            "11:\tlearn: 0.2903440\ttotal: 35.7ms\tremaining: 77.3ms\n",
            "12:\tlearn: 0.2852979\ttotal: 37.4ms\tremaining: 71.9ms\n",
            "13:\tlearn: 0.2798563\ttotal: 39.2ms\tremaining: 67.1ms\n",
            "14:\tlearn: 0.2747341\ttotal: 40.8ms\tremaining: 62.6ms\n",
            "15:\tlearn: 0.2702568\ttotal: 42.5ms\tremaining: 58.5ms\n",
            "16:\tlearn: 0.2650537\ttotal: 44.8ms\tremaining: 55.3ms\n",
            "17:\tlearn: 0.2601005\ttotal: 47.3ms\tremaining: 52.5ms\n",
            "18:\tlearn: 0.2560578\ttotal: 49.3ms\tremaining: 49.3ms\n",
            "19:\tlearn: 0.2530381\ttotal: 51.3ms\tremaining: 46.2ms\n",
            "20:\tlearn: 0.2498453\ttotal: 53.1ms\tremaining: 43ms\n",
            "21:\tlearn: 0.2461646\ttotal: 55.3ms\tremaining: 40.2ms\n",
            "22:\tlearn: 0.2424369\ttotal: 57.1ms\tremaining: 37.2ms\n",
            "23:\tlearn: 0.2392835\ttotal: 67.1ms\tremaining: 39.2ms\n",
            "24:\tlearn: 0.2339070\ttotal: 68.9ms\tremaining: 35.8ms\n",
            "25:\tlearn: 0.2301706\ttotal: 70.6ms\tremaining: 32.6ms\n",
            "26:\tlearn: 0.2263007\ttotal: 72.4ms\tremaining: 29.5ms\n",
            "27:\tlearn: 0.2223209\ttotal: 74.2ms\tremaining: 26.5ms\n",
            "28:\tlearn: 0.2190932\ttotal: 75.8ms\tremaining: 23.5ms\n",
            "29:\tlearn: 0.2159010\ttotal: 77.4ms\tremaining: 20.6ms\n",
            "30:\tlearn: 0.2132954\ttotal: 80ms\tremaining: 18.1ms\n",
            "31:\tlearn: 0.2102299\ttotal: 81.8ms\tremaining: 15.3ms\n",
            "32:\tlearn: 0.2076280\ttotal: 90.2ms\tremaining: 13.7ms\n",
            "33:\tlearn: 0.2043188\ttotal: 92ms\tremaining: 10.8ms\n",
            "34:\tlearn: 0.2017849\ttotal: 93.8ms\tremaining: 8.04ms\n",
            "35:\tlearn: 0.1993718\ttotal: 95.6ms\tremaining: 5.31ms\n",
            "36:\tlearn: 0.1972299\ttotal: 98.1ms\tremaining: 2.65ms\n",
            "37:\tlearn: 0.1950197\ttotal: 99.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 2.01ms\tremaining: 74.5ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.43ms\tremaining: 43.8ms\n",
            "2:\tlearn: 0.3788145\ttotal: 6.13ms\tremaining: 71.5ms\n",
            "3:\tlearn: 0.3658016\ttotal: 12ms\tremaining: 102ms\n",
            "4:\tlearn: 0.3428474\ttotal: 12.9ms\tremaining: 85.2ms\n",
            "5:\tlearn: 0.3234303\ttotal: 13.8ms\tremaining: 73.8ms\n",
            "6:\tlearn: 0.3158416\ttotal: 16.4ms\tremaining: 72.8ms\n",
            "7:\tlearn: 0.3097739\ttotal: 18.4ms\tremaining: 68.9ms\n",
            "8:\tlearn: 0.3040041\ttotal: 20.2ms\tremaining: 65ms\n",
            "9:\tlearn: 0.2975585\ttotal: 22ms\tremaining: 61.6ms\n",
            "10:\tlearn: 0.2898709\ttotal: 23.8ms\tremaining: 58.4ms\n",
            "11:\tlearn: 0.2845372\ttotal: 25.6ms\tremaining: 55.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 27.4ms\tremaining: 52.8ms\n",
            "13:\tlearn: 0.2740314\ttotal: 30ms\tremaining: 51.4ms\n",
            "14:\tlearn: 0.2705542\ttotal: 31.8ms\tremaining: 48.7ms\n",
            "15:\tlearn: 0.2673919\ttotal: 33.7ms\tremaining: 46.3ms\n",
            "16:\tlearn: 0.2623365\ttotal: 35.7ms\tremaining: 44.1ms\n",
            "17:\tlearn: 0.2595719\ttotal: 37.7ms\tremaining: 41.9ms\n",
            "18:\tlearn: 0.2545713\ttotal: 39.6ms\tremaining: 39.6ms\n",
            "19:\tlearn: 0.2510766\ttotal: 41.5ms\tremaining: 37.4ms\n",
            "20:\tlearn: 0.2477056\ttotal: 43.4ms\tremaining: 35.1ms\n",
            "21:\tlearn: 0.2437884\ttotal: 45.2ms\tremaining: 32.9ms\n",
            "22:\tlearn: 0.2404080\ttotal: 46.9ms\tremaining: 30.6ms\n",
            "23:\tlearn: 0.2369058\ttotal: 48.7ms\tremaining: 28.4ms\n",
            "24:\tlearn: 0.2331119\ttotal: 50.4ms\tremaining: 26.2ms\n",
            "25:\tlearn: 0.2293455\ttotal: 52.1ms\tremaining: 24.1ms\n",
            "26:\tlearn: 0.2256418\ttotal: 54.4ms\tremaining: 22.2ms\n",
            "27:\tlearn: 0.2221119\ttotal: 56.2ms\tremaining: 20.1ms\n",
            "28:\tlearn: 0.2190925\ttotal: 58ms\tremaining: 18ms\n",
            "29:\tlearn: 0.2161731\ttotal: 59.7ms\tremaining: 15.9ms\n",
            "30:\tlearn: 0.2135041\ttotal: 61.6ms\tremaining: 13.9ms\n",
            "31:\tlearn: 0.2113382\ttotal: 63.4ms\tremaining: 11.9ms\n",
            "32:\tlearn: 0.2083485\ttotal: 65.2ms\tremaining: 9.87ms\n",
            "33:\tlearn: 0.2058588\ttotal: 67.2ms\tremaining: 7.9ms\n",
            "34:\tlearn: 0.2024895\ttotal: 69.3ms\tremaining: 5.94ms\n",
            "35:\tlearn: 0.1997586\ttotal: 71.2ms\tremaining: 3.95ms\n",
            "36:\tlearn: 0.1976953\ttotal: 73.1ms\tremaining: 1.97ms\n",
            "37:\tlearn: 0.1949453\ttotal: 75ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.92ms\tremaining: 71ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.31ms\tremaining: 41.7ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.9ms\tremaining: 33.8ms\n",
            "3:\tlearn: 0.3518120\ttotal: 6.68ms\tremaining: 56.8ms\n",
            "4:\tlearn: 0.3441195\ttotal: 9.39ms\tremaining: 62ms\n",
            "5:\tlearn: 0.3328396\ttotal: 11.8ms\tremaining: 62.9ms\n",
            "6:\tlearn: 0.3256704\ttotal: 13.5ms\tremaining: 59.9ms\n",
            "7:\tlearn: 0.3174441\ttotal: 15.3ms\tremaining: 57.4ms\n",
            "8:\tlearn: 0.3090762\ttotal: 17.2ms\tremaining: 55.3ms\n",
            "9:\tlearn: 0.3028459\ttotal: 19ms\tremaining: 53.3ms\n",
            "10:\tlearn: 0.2958541\ttotal: 21ms\tremaining: 51.6ms\n",
            "11:\tlearn: 0.2901166\ttotal: 22.8ms\tremaining: 49.4ms\n",
            "12:\tlearn: 0.2841803\ttotal: 24.6ms\tremaining: 47.4ms\n",
            "13:\tlearn: 0.2789751\ttotal: 26.7ms\tremaining: 45.7ms\n",
            "14:\tlearn: 0.2715599\ttotal: 28.5ms\tremaining: 43.7ms\n",
            "15:\tlearn: 0.2663544\ttotal: 30.6ms\tremaining: 42ms\n",
            "16:\tlearn: 0.2615546\ttotal: 32.4ms\tremaining: 40ms\n",
            "17:\tlearn: 0.2560079\ttotal: 34.2ms\tremaining: 38ms\n",
            "18:\tlearn: 0.2507480\ttotal: 35.8ms\tremaining: 35.8ms\n",
            "19:\tlearn: 0.2450678\ttotal: 37.6ms\tremaining: 33.9ms\n",
            "20:\tlearn: 0.2413892\ttotal: 39.3ms\tremaining: 31.9ms\n",
            "21:\tlearn: 0.2378437\ttotal: 41.6ms\tremaining: 30.2ms\n",
            "22:\tlearn: 0.2344010\ttotal: 43.4ms\tremaining: 28.3ms\n",
            "23:\tlearn: 0.2304940\ttotal: 45.3ms\tremaining: 26.4ms\n",
            "24:\tlearn: 0.2269540\ttotal: 47.2ms\tremaining: 24.5ms\n",
            "25:\tlearn: 0.2232713\ttotal: 48.8ms\tremaining: 22.5ms\n",
            "26:\tlearn: 0.2208577\ttotal: 50.7ms\tremaining: 20.7ms\n",
            "27:\tlearn: 0.2181825\ttotal: 53.3ms\tremaining: 19ms\n",
            "28:\tlearn: 0.2149071\ttotal: 56.2ms\tremaining: 17.4ms\n",
            "29:\tlearn: 0.2123638\ttotal: 58.7ms\tremaining: 15.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 63.5ms\tremaining: 14.3ms\n",
            "31:\tlearn: 0.2071716\ttotal: 66.6ms\tremaining: 12.5ms\n",
            "32:\tlearn: 0.2045371\ttotal: 70.6ms\tremaining: 10.7ms\n",
            "33:\tlearn: 0.2018712\ttotal: 72.3ms\tremaining: 8.51ms\n",
            "34:\tlearn: 0.1995442\ttotal: 74.1ms\tremaining: 6.35ms\n",
            "35:\tlearn: 0.1970515\ttotal: 76.1ms\tremaining: 4.22ms\n",
            "36:\tlearn: 0.1946725\ttotal: 85.4ms\tremaining: 2.31ms\n",
            "37:\tlearn: 0.1924392\ttotal: 87.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 3.46ms\tremaining: 128ms\n",
            "1:\tlearn: 0.3745079\ttotal: 3.94ms\tremaining: 70.8ms\n",
            "2:\tlearn: 0.3383999\ttotal: 5.87ms\tremaining: 68.5ms\n",
            "3:\tlearn: 0.3266560\ttotal: 8.31ms\tremaining: 70.6ms\n",
            "4:\tlearn: 0.3080259\ttotal: 17.2ms\tremaining: 114ms\n",
            "5:\tlearn: 0.2907443\ttotal: 18.9ms\tremaining: 101ms\n",
            "6:\tlearn: 0.2818467\ttotal: 20.4ms\tremaining: 90.5ms\n",
            "7:\tlearn: 0.2691784\ttotal: 21.5ms\tremaining: 80.5ms\n",
            "8:\tlearn: 0.2611618\ttotal: 23.9ms\tremaining: 77.1ms\n",
            "9:\tlearn: 0.2519898\ttotal: 25.7ms\tremaining: 72ms\n",
            "10:\tlearn: 0.2462992\ttotal: 27.4ms\tremaining: 67.4ms\n",
            "11:\tlearn: 0.2416348\ttotal: 29.2ms\tremaining: 63.3ms\n",
            "12:\tlearn: 0.2368688\ttotal: 34.7ms\tremaining: 66.7ms\n",
            "13:\tlearn: 0.2320170\ttotal: 36.4ms\tremaining: 62.4ms\n",
            "14:\tlearn: 0.2262186\ttotal: 38.1ms\tremaining: 58.5ms\n",
            "15:\tlearn: 0.2215380\ttotal: 39.9ms\tremaining: 54.9ms\n",
            "16:\tlearn: 0.2176313\ttotal: 41.7ms\tremaining: 51.6ms\n",
            "17:\tlearn: 0.2138494\ttotal: 43.4ms\tremaining: 48.3ms\n",
            "18:\tlearn: 0.2100966\ttotal: 45.2ms\tremaining: 45.2ms\n",
            "19:\tlearn: 0.2068557\ttotal: 46.9ms\tremaining: 42.2ms\n",
            "20:\tlearn: 0.2029945\ttotal: 49ms\tremaining: 39.6ms\n",
            "21:\tlearn: 0.2001044\ttotal: 50.8ms\tremaining: 37ms\n",
            "22:\tlearn: 0.1970766\ttotal: 52.6ms\tremaining: 34.3ms\n",
            "23:\tlearn: 0.1940285\ttotal: 54.5ms\tremaining: 31.8ms\n",
            "24:\tlearn: 0.1910934\ttotal: 56.3ms\tremaining: 29.3ms\n",
            "25:\tlearn: 0.1879112\ttotal: 58.4ms\tremaining: 26.9ms\n",
            "26:\tlearn: 0.1852765\ttotal: 60.2ms\tremaining: 24.5ms\n",
            "27:\tlearn: 0.1827068\ttotal: 70.2ms\tremaining: 25.1ms\n",
            "28:\tlearn: 0.1803359\ttotal: 71.9ms\tremaining: 22.3ms\n",
            "29:\tlearn: 0.1779549\ttotal: 73.6ms\tremaining: 19.6ms\n",
            "30:\tlearn: 0.1757984\ttotal: 75.5ms\tremaining: 17ms\n",
            "31:\tlearn: 0.1724570\ttotal: 77.9ms\tremaining: 14.6ms\n",
            "32:\tlearn: 0.1703672\ttotal: 82.8ms\tremaining: 12.5ms\n",
            "33:\tlearn: 0.1685175\ttotal: 87.6ms\tremaining: 10.3ms\n",
            "34:\tlearn: 0.1666049\ttotal: 92.3ms\tremaining: 7.91ms\n",
            "35:\tlearn: 0.1648374\ttotal: 97.6ms\tremaining: 5.42ms\n",
            "36:\tlearn: 0.1631656\ttotal: 109ms\tremaining: 2.96ms\n",
            "37:\tlearn: 0.1615072\ttotal: 114ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 2.7ms\tremaining: 99.9ms\n",
            "1:\tlearn: 0.3687510\ttotal: 4.89ms\tremaining: 88ms\n",
            "2:\tlearn: 0.3203557\ttotal: 5.85ms\tremaining: 68.3ms\n",
            "3:\tlearn: 0.3063743\ttotal: 15.6ms\tremaining: 133ms\n",
            "4:\tlearn: 0.2970911\ttotal: 17.3ms\tremaining: 114ms\n",
            "5:\tlearn: 0.2891054\ttotal: 19ms\tremaining: 102ms\n",
            "6:\tlearn: 0.2792409\ttotal: 21.4ms\tremaining: 94.8ms\n",
            "7:\tlearn: 0.2716618\ttotal: 23ms\tremaining: 86.2ms\n",
            "8:\tlearn: 0.2621352\ttotal: 24.7ms\tremaining: 79.5ms\n",
            "9:\tlearn: 0.2537973\ttotal: 31.3ms\tremaining: 87.6ms\n",
            "10:\tlearn: 0.2473429\ttotal: 36.6ms\tremaining: 89.9ms\n",
            "11:\tlearn: 0.2416695\ttotal: 38.6ms\tremaining: 83.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 40.3ms\tremaining: 77.5ms\n",
            "13:\tlearn: 0.2298385\ttotal: 42ms\tremaining: 72ms\n",
            "14:\tlearn: 0.2249545\ttotal: 43.9ms\tremaining: 67.4ms\n",
            "15:\tlearn: 0.2192054\ttotal: 46.3ms\tremaining: 63.6ms\n",
            "16:\tlearn: 0.2150242\ttotal: 47.9ms\tremaining: 59.1ms\n",
            "17:\tlearn: 0.2094516\ttotal: 49.7ms\tremaining: 55.2ms\n",
            "18:\tlearn: 0.2056324\ttotal: 51.5ms\tremaining: 51.5ms\n",
            "19:\tlearn: 0.2021225\ttotal: 53.2ms\tremaining: 47.9ms\n",
            "20:\tlearn: 0.1989042\ttotal: 55ms\tremaining: 44.5ms\n",
            "21:\tlearn: 0.1961040\ttotal: 56.7ms\tremaining: 41.3ms\n",
            "22:\tlearn: 0.1934794\ttotal: 65.4ms\tremaining: 42.7ms\n",
            "23:\tlearn: 0.1902438\ttotal: 67.1ms\tremaining: 39.1ms\n",
            "24:\tlearn: 0.1874921\ttotal: 68.7ms\tremaining: 35.7ms\n",
            "25:\tlearn: 0.1829904\ttotal: 70.3ms\tremaining: 32.4ms\n",
            "26:\tlearn: 0.1804169\ttotal: 72.4ms\tremaining: 29.5ms\n",
            "27:\tlearn: 0.1776989\ttotal: 74.2ms\tremaining: 26.5ms\n",
            "28:\tlearn: 0.1751387\ttotal: 75.9ms\tremaining: 23.6ms\n",
            "29:\tlearn: 0.1727570\ttotal: 77.5ms\tremaining: 20.7ms\n",
            "30:\tlearn: 0.1693663\ttotal: 79.3ms\tremaining: 17.9ms\n",
            "31:\tlearn: 0.1661883\ttotal: 80.9ms\tremaining: 15.2ms\n",
            "32:\tlearn: 0.1641011\ttotal: 82.7ms\tremaining: 12.5ms\n",
            "33:\tlearn: 0.1616271\ttotal: 85.2ms\tremaining: 10ms\n",
            "34:\tlearn: 0.1593621\ttotal: 93.1ms\tremaining: 7.98ms\n",
            "35:\tlearn: 0.1576181\ttotal: 94.7ms\tremaining: 5.26ms\n",
            "36:\tlearn: 0.1557020\ttotal: 96.4ms\tremaining: 2.6ms\n",
            "37:\tlearn: 0.1541003\ttotal: 97.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.8ms\tremaining: 68.4ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.16ms\tremaining: 40ms\n",
            "2:\tlearn: 0.3843342\ttotal: 3.89ms\tremaining: 46.7ms\n",
            "3:\tlearn: 0.3652888\ttotal: 5.63ms\tremaining: 49.3ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.08ms\tremaining: 55ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.1ms\tremaining: 55.5ms\n",
            "6:\tlearn: 0.3300914\ttotal: 11.8ms\tremaining: 53.8ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.2ms\tremaining: 55.1ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.7ms\tremaining: 55.6ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.5ms\tremaining: 53.7ms\n",
            "10:\tlearn: 0.2983658\ttotal: 20.2ms\tremaining: 51.4ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.2ms\tremaining: 50ms\n",
            "12:\tlearn: 0.2852979\ttotal: 24.3ms\tremaining: 48.6ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.9ms\tremaining: 46.3ms\n",
            "14:\tlearn: 0.2747341\ttotal: 28.5ms\tremaining: 45.6ms\n",
            "15:\tlearn: 0.2702568\ttotal: 30.5ms\tremaining: 43.8ms\n",
            "16:\tlearn: 0.2650537\ttotal: 32ms\tremaining: 41.4ms\n",
            "17:\tlearn: 0.2601005\ttotal: 33.7ms\tremaining: 39.3ms\n",
            "18:\tlearn: 0.2560578\ttotal: 35.4ms\tremaining: 37.2ms\n",
            "19:\tlearn: 0.2530381\ttotal: 37.4ms\tremaining: 35.5ms\n",
            "20:\tlearn: 0.2498453\ttotal: 39ms\tremaining: 33.5ms\n",
            "21:\tlearn: 0.2461646\ttotal: 41.8ms\tremaining: 32.3ms\n",
            "22:\tlearn: 0.2424369\ttotal: 43.8ms\tremaining: 30.4ms\n",
            "23:\tlearn: 0.2392835\ttotal: 45.5ms\tremaining: 28.4ms\n",
            "24:\tlearn: 0.2339070\ttotal: 47.2ms\tremaining: 26.4ms\n",
            "25:\tlearn: 0.2301706\ttotal: 49.4ms\tremaining: 24.7ms\n",
            "26:\tlearn: 0.2263007\ttotal: 52ms\tremaining: 23.1ms\n",
            "27:\tlearn: 0.2223209\ttotal: 53.7ms\tremaining: 21.1ms\n",
            "28:\tlearn: 0.2190932\ttotal: 55.3ms\tremaining: 19.1ms\n",
            "29:\tlearn: 0.2159010\ttotal: 57ms\tremaining: 17.1ms\n",
            "30:\tlearn: 0.2132954\ttotal: 59.4ms\tremaining: 15.3ms\n",
            "31:\tlearn: 0.2102299\ttotal: 61.3ms\tremaining: 13.4ms\n",
            "32:\tlearn: 0.2076280\ttotal: 62.9ms\tremaining: 11.4ms\n",
            "33:\tlearn: 0.2043188\ttotal: 64.4ms\tremaining: 9.47ms\n",
            "34:\tlearn: 0.2017849\ttotal: 66.5ms\tremaining: 7.6ms\n",
            "35:\tlearn: 0.1993718\ttotal: 69ms\tremaining: 5.75ms\n",
            "36:\tlearn: 0.1972299\ttotal: 71.1ms\tremaining: 3.84ms\n",
            "37:\tlearn: 0.1950197\ttotal: 72.7ms\tremaining: 1.91ms\n",
            "38:\tlearn: 0.1927135\ttotal: 74.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.81ms\tremaining: 68.9ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.17ms\tremaining: 40.2ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.01ms\tremaining: 48.1ms\n",
            "3:\tlearn: 0.3658016\ttotal: 5.83ms\tremaining: 51ms\n",
            "4:\tlearn: 0.3428474\ttotal: 6.77ms\tremaining: 46ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.51ms\tremaining: 41.3ms\n",
            "6:\tlearn: 0.3158416\ttotal: 9.54ms\tremaining: 43.6ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12ms\tremaining: 46.7ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.9ms\tremaining: 46.3ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.6ms\tremaining: 45.3ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17.3ms\tremaining: 43.9ms\n",
            "11:\tlearn: 0.2845372\ttotal: 18.9ms\tremaining: 42.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 21.1ms\tremaining: 42.1ms\n",
            "13:\tlearn: 0.2740314\ttotal: 23.6ms\tremaining: 42.1ms\n",
            "14:\tlearn: 0.2705542\ttotal: 25.3ms\tremaining: 40.5ms\n",
            "15:\tlearn: 0.2673919\ttotal: 27.1ms\tremaining: 38.9ms\n",
            "16:\tlearn: 0.2623365\ttotal: 28.8ms\tremaining: 37.3ms\n",
            "17:\tlearn: 0.2595719\ttotal: 31ms\tremaining: 36.1ms\n",
            "18:\tlearn: 0.2545713\ttotal: 32.7ms\tremaining: 34.4ms\n",
            "19:\tlearn: 0.2510766\ttotal: 35.1ms\tremaining: 33.4ms\n",
            "20:\tlearn: 0.2477056\ttotal: 37.3ms\tremaining: 32ms\n",
            "21:\tlearn: 0.2437884\ttotal: 39.1ms\tremaining: 30.3ms\n",
            "22:\tlearn: 0.2404080\ttotal: 40.9ms\tremaining: 28.4ms\n",
            "23:\tlearn: 0.2369058\ttotal: 42.8ms\tremaining: 26.8ms\n",
            "24:\tlearn: 0.2331119\ttotal: 45.7ms\tremaining: 25.6ms\n",
            "25:\tlearn: 0.2293455\ttotal: 47.9ms\tremaining: 23.9ms\n",
            "26:\tlearn: 0.2256418\ttotal: 49.7ms\tremaining: 22.1ms\n",
            "27:\tlearn: 0.2221119\ttotal: 51.5ms\tremaining: 20.2ms\n",
            "28:\tlearn: 0.2190925\ttotal: 53.5ms\tremaining: 18.4ms\n",
            "29:\tlearn: 0.2161731\ttotal: 56.2ms\tremaining: 16.9ms\n",
            "30:\tlearn: 0.2135041\ttotal: 58.2ms\tremaining: 15ms\n",
            "31:\tlearn: 0.2113382\ttotal: 60ms\tremaining: 13.1ms\n",
            "32:\tlearn: 0.2083485\ttotal: 61.8ms\tremaining: 11.2ms\n",
            "33:\tlearn: 0.2058588\ttotal: 63.6ms\tremaining: 9.35ms\n",
            "34:\tlearn: 0.2024895\ttotal: 66.1ms\tremaining: 7.55ms\n",
            "35:\tlearn: 0.1997586\ttotal: 68.1ms\tremaining: 5.67ms\n",
            "36:\tlearn: 0.1976953\ttotal: 69.9ms\tremaining: 3.78ms\n",
            "37:\tlearn: 0.1949453\ttotal: 71.7ms\tremaining: 1.89ms\n",
            "38:\tlearn: 0.1931445\ttotal: 73.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.74ms\tremaining: 104ms\n",
            "1:\tlearn: 0.4107278\ttotal: 6.58ms\tremaining: 122ms\n",
            "2:\tlearn: 0.3698157\ttotal: 7.53ms\tremaining: 90.3ms\n",
            "3:\tlearn: 0.3518120\ttotal: 10.8ms\tremaining: 94.9ms\n",
            "4:\tlearn: 0.3441195\ttotal: 15.9ms\tremaining: 108ms\n",
            "5:\tlearn: 0.3328396\ttotal: 20.6ms\tremaining: 113ms\n",
            "6:\tlearn: 0.3256704\ttotal: 25.4ms\tremaining: 116ms\n",
            "7:\tlearn: 0.3174441\ttotal: 30.1ms\tremaining: 117ms\n",
            "8:\tlearn: 0.3090762\ttotal: 35ms\tremaining: 117ms\n",
            "9:\tlearn: 0.3028459\ttotal: 40.3ms\tremaining: 117ms\n",
            "10:\tlearn: 0.2958541\ttotal: 45.7ms\tremaining: 116ms\n",
            "11:\tlearn: 0.2901166\ttotal: 49ms\tremaining: 110ms\n",
            "12:\tlearn: 0.2841803\ttotal: 54.2ms\tremaining: 108ms\n",
            "13:\tlearn: 0.2789751\ttotal: 58.9ms\tremaining: 105ms\n",
            "14:\tlearn: 0.2715599\ttotal: 61.1ms\tremaining: 97.7ms\n",
            "15:\tlearn: 0.2663544\ttotal: 63.5ms\tremaining: 91.3ms\n",
            "16:\tlearn: 0.2615546\ttotal: 65.3ms\tremaining: 84.5ms\n",
            "17:\tlearn: 0.2560079\ttotal: 67.1ms\tremaining: 78.3ms\n",
            "18:\tlearn: 0.2507480\ttotal: 68.8ms\tremaining: 72.4ms\n",
            "19:\tlearn: 0.2450678\ttotal: 70.6ms\tremaining: 67.1ms\n",
            "20:\tlearn: 0.2413892\ttotal: 73.2ms\tremaining: 62.8ms\n",
            "21:\tlearn: 0.2378437\ttotal: 75ms\tremaining: 57.9ms\n",
            "22:\tlearn: 0.2344010\ttotal: 76.6ms\tremaining: 53.3ms\n",
            "23:\tlearn: 0.2304940\ttotal: 79.9ms\tremaining: 50ms\n",
            "24:\tlearn: 0.2269540\ttotal: 81.8ms\tremaining: 45.8ms\n",
            "25:\tlearn: 0.2232713\ttotal: 83.5ms\tremaining: 41.8ms\n",
            "26:\tlearn: 0.2208577\ttotal: 85.8ms\tremaining: 38.1ms\n",
            "27:\tlearn: 0.2181825\ttotal: 87.5ms\tremaining: 34.4ms\n",
            "28:\tlearn: 0.2149071\ttotal: 89.7ms\tremaining: 30.9ms\n",
            "29:\tlearn: 0.2123638\ttotal: 92.6ms\tremaining: 27.8ms\n",
            "30:\tlearn: 0.2094640\ttotal: 94.3ms\tremaining: 24.3ms\n",
            "31:\tlearn: 0.2071716\ttotal: 96.2ms\tremaining: 21ms\n",
            "32:\tlearn: 0.2045371\ttotal: 98.2ms\tremaining: 17.8ms\n",
            "33:\tlearn: 0.2018712\ttotal: 101ms\tremaining: 14.8ms\n",
            "34:\tlearn: 0.1995442\ttotal: 102ms\tremaining: 11.7ms\n",
            "35:\tlearn: 0.1970515\ttotal: 105ms\tremaining: 8.71ms\n",
            "36:\tlearn: 0.1946725\ttotal: 107ms\tremaining: 5.79ms\n",
            "37:\tlearn: 0.1924392\ttotal: 109ms\tremaining: 2.87ms\n",
            "38:\tlearn: 0.1893508\ttotal: 111ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.91ms\tremaining: 72.7ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.33ms\tremaining: 43ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.11ms\tremaining: 49.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 6.21ms\tremaining: 54.3ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.8ms\tremaining: 59.8ms\n",
            "5:\tlearn: 0.2907443\ttotal: 11ms\tremaining: 60.6ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12.7ms\tremaining: 58.3ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.8ms\tremaining: 53.5ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15.6ms\tremaining: 51.9ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.8ms\tremaining: 51.5ms\n",
            "10:\tlearn: 0.2462992\ttotal: 20.3ms\tremaining: 51.6ms\n",
            "11:\tlearn: 0.2416348\ttotal: 22.1ms\tremaining: 49.7ms\n",
            "12:\tlearn: 0.2368688\ttotal: 23.8ms\tremaining: 47.6ms\n",
            "13:\tlearn: 0.2320170\ttotal: 25.6ms\tremaining: 45.6ms\n",
            "14:\tlearn: 0.2262186\ttotal: 27.2ms\tremaining: 43.6ms\n",
            "15:\tlearn: 0.2215380\ttotal: 29.7ms\tremaining: 42.8ms\n",
            "16:\tlearn: 0.2176313\ttotal: 31.6ms\tremaining: 40.9ms\n",
            "17:\tlearn: 0.2138494\ttotal: 33.3ms\tremaining: 38.8ms\n",
            "18:\tlearn: 0.2100966\ttotal: 34.9ms\tremaining: 36.7ms\n",
            "19:\tlearn: 0.2068557\ttotal: 36.6ms\tremaining: 34.8ms\n",
            "20:\tlearn: 0.2029945\ttotal: 39ms\tremaining: 33.4ms\n",
            "21:\tlearn: 0.2001044\ttotal: 52.3ms\tremaining: 40.4ms\n",
            "22:\tlearn: 0.1970766\ttotal: 54.1ms\tremaining: 37.6ms\n",
            "23:\tlearn: 0.1940285\ttotal: 56.3ms\tremaining: 35.2ms\n",
            "24:\tlearn: 0.1910934\ttotal: 58.1ms\tremaining: 32.5ms\n",
            "25:\tlearn: 0.1879112\ttotal: 60.5ms\tremaining: 30.3ms\n",
            "26:\tlearn: 0.1852765\ttotal: 63ms\tremaining: 28ms\n",
            "27:\tlearn: 0.1827068\ttotal: 64.8ms\tremaining: 25.5ms\n",
            "28:\tlearn: 0.1803359\ttotal: 66.6ms\tremaining: 23ms\n",
            "29:\tlearn: 0.1779549\ttotal: 68.4ms\tremaining: 20.5ms\n",
            "30:\tlearn: 0.1757984\ttotal: 70.8ms\tremaining: 18.3ms\n",
            "31:\tlearn: 0.1724570\ttotal: 79.9ms\tremaining: 17.5ms\n",
            "32:\tlearn: 0.1703672\ttotal: 83.6ms\tremaining: 15.2ms\n",
            "33:\tlearn: 0.1685175\ttotal: 85.4ms\tremaining: 12.6ms\n",
            "34:\tlearn: 0.1666049\ttotal: 90.2ms\tremaining: 10.3ms\n",
            "35:\tlearn: 0.1648374\ttotal: 97.4ms\tremaining: 8.12ms\n",
            "36:\tlearn: 0.1631656\ttotal: 99.1ms\tremaining: 5.36ms\n",
            "37:\tlearn: 0.1615072\ttotal: 104ms\tremaining: 2.74ms\n",
            "38:\tlearn: 0.1598928\ttotal: 106ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.92ms\tremaining: 73.1ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.33ms\tremaining: 43.2ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.84ms\tremaining: 34.1ms\n",
            "3:\tlearn: 0.3063743\ttotal: 5.09ms\tremaining: 44.6ms\n",
            "4:\tlearn: 0.2970911\ttotal: 7.55ms\tremaining: 51.4ms\n",
            "5:\tlearn: 0.2891054\ttotal: 9.2ms\tremaining: 50.6ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.8ms\tremaining: 49.6ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.7ms\tremaining: 49ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.9ms\tremaining: 49.6ms\n",
            "9:\tlearn: 0.2537973\ttotal: 17.3ms\tremaining: 50.3ms\n",
            "10:\tlearn: 0.2473429\ttotal: 19.2ms\tremaining: 49ms\n",
            "11:\tlearn: 0.2416695\ttotal: 21.1ms\tremaining: 47.4ms\n",
            "12:\tlearn: 0.2366343\ttotal: 22.9ms\tremaining: 45.7ms\n",
            "13:\tlearn: 0.2298385\ttotal: 24.9ms\tremaining: 44.4ms\n",
            "14:\tlearn: 0.2249545\ttotal: 26.5ms\tremaining: 42.5ms\n",
            "15:\tlearn: 0.2192054\ttotal: 28.6ms\tremaining: 41.1ms\n",
            "16:\tlearn: 0.2150242\ttotal: 31ms\tremaining: 40.1ms\n",
            "17:\tlearn: 0.2094516\ttotal: 32.7ms\tremaining: 38.1ms\n",
            "18:\tlearn: 0.2056324\ttotal: 34.2ms\tremaining: 36ms\n",
            "19:\tlearn: 0.2021225\ttotal: 35.8ms\tremaining: 34ms\n",
            "20:\tlearn: 0.1989042\ttotal: 37.8ms\tremaining: 32.4ms\n",
            "21:\tlearn: 0.1961040\ttotal: 39.5ms\tremaining: 30.5ms\n",
            "22:\tlearn: 0.1934794\ttotal: 41.7ms\tremaining: 29ms\n",
            "23:\tlearn: 0.1902438\ttotal: 44.1ms\tremaining: 27.6ms\n",
            "24:\tlearn: 0.1874921\ttotal: 46.1ms\tremaining: 25.8ms\n",
            "25:\tlearn: 0.1829904\ttotal: 48.4ms\tremaining: 24.2ms\n",
            "26:\tlearn: 0.1804169\ttotal: 50.2ms\tremaining: 22.3ms\n",
            "27:\tlearn: 0.1776989\ttotal: 51.8ms\tremaining: 20.4ms\n",
            "28:\tlearn: 0.1751387\ttotal: 53.4ms\tremaining: 18.4ms\n",
            "29:\tlearn: 0.1727570\ttotal: 55ms\tremaining: 16.5ms\n",
            "30:\tlearn: 0.1693663\ttotal: 57.4ms\tremaining: 14.8ms\n",
            "31:\tlearn: 0.1661883\ttotal: 59.7ms\tremaining: 13.1ms\n",
            "32:\tlearn: 0.1641011\ttotal: 61.3ms\tremaining: 11.1ms\n",
            "33:\tlearn: 0.1616271\ttotal: 63ms\tremaining: 9.27ms\n",
            "34:\tlearn: 0.1593621\ttotal: 64.7ms\tremaining: 7.4ms\n",
            "35:\tlearn: 0.1576181\ttotal: 67ms\tremaining: 5.59ms\n",
            "36:\tlearn: 0.1557020\ttotal: 69.1ms\tremaining: 3.74ms\n",
            "37:\tlearn: 0.1541003\ttotal: 70.8ms\tremaining: 1.86ms\n",
            "38:\tlearn: 0.1522873\ttotal: 72.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 2.24ms\tremaining: 87.4ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.61ms\tremaining: 49.6ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.2ms\tremaining: 51.8ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.32ms\tremaining: 56.9ms\n",
            "4:\tlearn: 0.3496343\ttotal: 7.99ms\tremaining: 55.9ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.4ms\tremaining: 58.7ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.6ms\tremaining: 59.4ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.1ms\tremaining: 56.5ms\n",
            "8:\tlearn: 0.3148279\ttotal: 15.6ms\tremaining: 53.9ms\n",
            "9:\tlearn: 0.3054626\ttotal: 17.3ms\tremaining: 51.9ms\n",
            "10:\tlearn: 0.2983658\ttotal: 19.5ms\tremaining: 51.5ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.1ms\tremaining: 51.5ms\n",
            "12:\tlearn: 0.2852979\ttotal: 23.6ms\tremaining: 49.1ms\n",
            "13:\tlearn: 0.2798563\ttotal: 26ms\tremaining: 48.4ms\n",
            "14:\tlearn: 0.2747341\ttotal: 31.3ms\tremaining: 52.1ms\n",
            "15:\tlearn: 0.2702568\ttotal: 33.8ms\tremaining: 50.8ms\n",
            "16:\tlearn: 0.2650537\ttotal: 36.2ms\tremaining: 49ms\n",
            "17:\tlearn: 0.2601005\ttotal: 37.9ms\tremaining: 46.3ms\n",
            "18:\tlearn: 0.2560578\ttotal: 39.5ms\tremaining: 43.7ms\n",
            "19:\tlearn: 0.2530381\ttotal: 41.3ms\tremaining: 41.3ms\n",
            "20:\tlearn: 0.2498453\ttotal: 43.9ms\tremaining: 39.7ms\n",
            "21:\tlearn: 0.2461646\ttotal: 45.8ms\tremaining: 37.5ms\n",
            "22:\tlearn: 0.2424369\ttotal: 47.5ms\tremaining: 35.1ms\n",
            "23:\tlearn: 0.2392835\ttotal: 49.2ms\tremaining: 32.8ms\n",
            "24:\tlearn: 0.2339070\ttotal: 51.2ms\tremaining: 30.7ms\n",
            "25:\tlearn: 0.2301706\ttotal: 53.8ms\tremaining: 29ms\n",
            "26:\tlearn: 0.2263007\ttotal: 55.5ms\tremaining: 26.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 57.2ms\tremaining: 24.5ms\n",
            "28:\tlearn: 0.2190932\ttotal: 58.8ms\tremaining: 22.3ms\n",
            "29:\tlearn: 0.2159010\ttotal: 61.1ms\tremaining: 20.4ms\n",
            "30:\tlearn: 0.2132954\ttotal: 63.5ms\tremaining: 18.4ms\n",
            "31:\tlearn: 0.2102299\ttotal: 65.2ms\tremaining: 16.3ms\n",
            "32:\tlearn: 0.2076280\ttotal: 66.8ms\tremaining: 14.2ms\n",
            "33:\tlearn: 0.2043188\ttotal: 68.5ms\tremaining: 12.1ms\n",
            "34:\tlearn: 0.2017849\ttotal: 70.8ms\tremaining: 10.1ms\n",
            "35:\tlearn: 0.1993718\ttotal: 75.8ms\tremaining: 8.42ms\n",
            "36:\tlearn: 0.1972299\ttotal: 77.4ms\tremaining: 6.28ms\n",
            "37:\tlearn: 0.1950197\ttotal: 79.8ms\tremaining: 4.2ms\n",
            "38:\tlearn: 0.1927135\ttotal: 81.7ms\tremaining: 2.09ms\n",
            "39:\tlearn: 0.1895038\ttotal: 83.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.79ms\tremaining: 69.7ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.44ms\tremaining: 46.4ms\n",
            "2:\tlearn: 0.3788145\ttotal: 5.18ms\tremaining: 63.9ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.77ms\tremaining: 60.9ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.68ms\tremaining: 53.8ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.53ms\tremaining: 48.4ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10.3ms\tremaining: 48.5ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12.2ms\tremaining: 48.8ms\n",
            "8:\tlearn: 0.3040041\ttotal: 14.1ms\tremaining: 48.5ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.9ms\tremaining: 47.7ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17.6ms\tremaining: 46.5ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.4ms\tremaining: 47.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 23.4ms\tremaining: 48.7ms\n",
            "13:\tlearn: 0.2740314\ttotal: 26.7ms\tremaining: 49.7ms\n",
            "14:\tlearn: 0.2705542\ttotal: 28.7ms\tremaining: 47.8ms\n",
            "15:\tlearn: 0.2673919\ttotal: 30.7ms\tremaining: 46ms\n",
            "16:\tlearn: 0.2623365\ttotal: 32.8ms\tremaining: 44.4ms\n",
            "17:\tlearn: 0.2595719\ttotal: 34.8ms\tremaining: 42.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 36.7ms\tremaining: 40.5ms\n",
            "19:\tlearn: 0.2510766\ttotal: 38.5ms\tremaining: 38.5ms\n",
            "20:\tlearn: 0.2477056\ttotal: 40.3ms\tremaining: 36.5ms\n",
            "21:\tlearn: 0.2437884\ttotal: 42.2ms\tremaining: 34.5ms\n",
            "22:\tlearn: 0.2404080\ttotal: 44.1ms\tremaining: 32.6ms\n",
            "23:\tlearn: 0.2369058\ttotal: 46ms\tremaining: 30.7ms\n",
            "24:\tlearn: 0.2331119\ttotal: 47.8ms\tremaining: 28.7ms\n",
            "25:\tlearn: 0.2293455\ttotal: 49.5ms\tremaining: 26.6ms\n",
            "26:\tlearn: 0.2256418\ttotal: 52.1ms\tremaining: 25.1ms\n",
            "27:\tlearn: 0.2221119\ttotal: 53.8ms\tremaining: 23.1ms\n",
            "28:\tlearn: 0.2190925\ttotal: 55.8ms\tremaining: 21.2ms\n",
            "29:\tlearn: 0.2161731\ttotal: 57.6ms\tremaining: 19.2ms\n",
            "30:\tlearn: 0.2135041\ttotal: 59.6ms\tremaining: 17.3ms\n",
            "31:\tlearn: 0.2113382\ttotal: 61.6ms\tremaining: 15.4ms\n",
            "32:\tlearn: 0.2083485\ttotal: 63.4ms\tremaining: 13.4ms\n",
            "33:\tlearn: 0.2058588\ttotal: 65.4ms\tremaining: 11.5ms\n",
            "34:\tlearn: 0.2024895\ttotal: 68.5ms\tremaining: 9.79ms\n",
            "35:\tlearn: 0.1997586\ttotal: 71.4ms\tremaining: 7.93ms\n",
            "36:\tlearn: 0.1976953\ttotal: 73.3ms\tremaining: 5.94ms\n",
            "37:\tlearn: 0.1949453\ttotal: 75.3ms\tremaining: 3.96ms\n",
            "38:\tlearn: 0.1931445\ttotal: 77.4ms\tremaining: 1.99ms\n",
            "39:\tlearn: 0.1900292\ttotal: 80.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.85ms\tremaining: 72.1ms\n",
            "1:\tlearn: 0.4107278\ttotal: 3.83ms\tremaining: 72.8ms\n",
            "2:\tlearn: 0.3698157\ttotal: 4.32ms\tremaining: 53.3ms\n",
            "3:\tlearn: 0.3518120\ttotal: 6.03ms\tremaining: 54.3ms\n",
            "4:\tlearn: 0.3441195\ttotal: 7.99ms\tremaining: 55.9ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.91ms\tremaining: 56.1ms\n",
            "6:\tlearn: 0.3256704\ttotal: 11.8ms\tremaining: 55.8ms\n",
            "7:\tlearn: 0.3174441\ttotal: 13.9ms\tremaining: 55.6ms\n",
            "8:\tlearn: 0.3090762\ttotal: 15.8ms\tremaining: 54.5ms\n",
            "9:\tlearn: 0.3028459\ttotal: 17.7ms\tremaining: 53.2ms\n",
            "10:\tlearn: 0.2958541\ttotal: 19.7ms\tremaining: 52ms\n",
            "11:\tlearn: 0.2901166\ttotal: 21.6ms\tremaining: 50.5ms\n",
            "12:\tlearn: 0.2841803\ttotal: 23.4ms\tremaining: 48.7ms\n",
            "13:\tlearn: 0.2789751\ttotal: 25.4ms\tremaining: 47.1ms\n",
            "14:\tlearn: 0.2715599\ttotal: 27.3ms\tremaining: 45.5ms\n",
            "15:\tlearn: 0.2663544\ttotal: 29.4ms\tremaining: 44ms\n",
            "16:\tlearn: 0.2615546\ttotal: 31.2ms\tremaining: 42.3ms\n",
            "17:\tlearn: 0.2560079\ttotal: 33.1ms\tremaining: 40.5ms\n",
            "18:\tlearn: 0.2507480\ttotal: 35.1ms\tremaining: 38.8ms\n",
            "19:\tlearn: 0.2450678\ttotal: 37.1ms\tremaining: 37.1ms\n",
            "20:\tlearn: 0.2413892\ttotal: 39ms\tremaining: 35.3ms\n",
            "21:\tlearn: 0.2378437\ttotal: 40.9ms\tremaining: 33.5ms\n",
            "22:\tlearn: 0.2344010\ttotal: 42.9ms\tremaining: 31.7ms\n",
            "23:\tlearn: 0.2304940\ttotal: 44.9ms\tremaining: 29.9ms\n",
            "24:\tlearn: 0.2269540\ttotal: 46.8ms\tremaining: 28.1ms\n",
            "25:\tlearn: 0.2232713\ttotal: 49ms\tremaining: 26.4ms\n",
            "26:\tlearn: 0.2208577\ttotal: 50.9ms\tremaining: 24.5ms\n",
            "27:\tlearn: 0.2181825\ttotal: 52.9ms\tremaining: 22.7ms\n",
            "28:\tlearn: 0.2149071\ttotal: 55ms\tremaining: 20.8ms\n",
            "29:\tlearn: 0.2123638\ttotal: 57ms\tremaining: 19ms\n",
            "30:\tlearn: 0.2094640\ttotal: 59ms\tremaining: 17.1ms\n",
            "31:\tlearn: 0.2071716\ttotal: 60.9ms\tremaining: 15.2ms\n",
            "32:\tlearn: 0.2045371\ttotal: 63ms\tremaining: 13.4ms\n",
            "33:\tlearn: 0.2018712\ttotal: 64.9ms\tremaining: 11.5ms\n",
            "34:\tlearn: 0.1995442\ttotal: 66.9ms\tremaining: 9.55ms\n",
            "35:\tlearn: 0.1970515\ttotal: 68.8ms\tremaining: 7.65ms\n",
            "36:\tlearn: 0.1946725\ttotal: 70.8ms\tremaining: 5.74ms\n",
            "37:\tlearn: 0.1924392\ttotal: 72.7ms\tremaining: 3.83ms\n",
            "38:\tlearn: 0.1893508\ttotal: 74.7ms\tremaining: 1.92ms\n",
            "39:\tlearn: 0.1868097\ttotal: 76.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.81ms\tremaining: 70.5ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.43ms\tremaining: 46.2ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.4ms\tremaining: 54.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 6.41ms\tremaining: 57.7ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.4ms\tremaining: 58.8ms\n",
            "5:\tlearn: 0.2907443\ttotal: 10.3ms\tremaining: 58.4ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12.3ms\tremaining: 57.8ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.5ms\tremaining: 54.1ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15.6ms\tremaining: 53.7ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.6ms\tremaining: 52.7ms\n",
            "10:\tlearn: 0.2462992\ttotal: 19.6ms\tremaining: 51.7ms\n",
            "11:\tlearn: 0.2416348\ttotal: 21.8ms\tremaining: 50.8ms\n",
            "12:\tlearn: 0.2368688\ttotal: 23.7ms\tremaining: 49.2ms\n",
            "13:\tlearn: 0.2320170\ttotal: 25.6ms\tremaining: 47.6ms\n",
            "14:\tlearn: 0.2262186\ttotal: 27.6ms\tremaining: 46ms\n",
            "15:\tlearn: 0.2215380\ttotal: 29.6ms\tremaining: 44.4ms\n",
            "16:\tlearn: 0.2176313\ttotal: 31.4ms\tremaining: 42.5ms\n",
            "17:\tlearn: 0.2138494\ttotal: 33.3ms\tremaining: 40.8ms\n",
            "18:\tlearn: 0.2100966\ttotal: 35.2ms\tremaining: 38.9ms\n",
            "19:\tlearn: 0.2068557\ttotal: 37.1ms\tremaining: 37.1ms\n",
            "20:\tlearn: 0.2029945\ttotal: 39ms\tremaining: 35.3ms\n",
            "21:\tlearn: 0.2001044\ttotal: 41ms\tremaining: 33.6ms\n",
            "22:\tlearn: 0.1970766\ttotal: 43.1ms\tremaining: 31.9ms\n",
            "23:\tlearn: 0.1940285\ttotal: 45.2ms\tremaining: 30.1ms\n",
            "24:\tlearn: 0.1910934\ttotal: 47.2ms\tremaining: 28.3ms\n",
            "25:\tlearn: 0.1879112\ttotal: 49.3ms\tremaining: 26.5ms\n",
            "26:\tlearn: 0.1852765\ttotal: 51.1ms\tremaining: 24.6ms\n",
            "27:\tlearn: 0.1827068\ttotal: 53.1ms\tremaining: 22.7ms\n",
            "28:\tlearn: 0.1803359\ttotal: 54.9ms\tremaining: 20.8ms\n",
            "29:\tlearn: 0.1779549\ttotal: 56.7ms\tremaining: 18.9ms\n",
            "30:\tlearn: 0.1757984\ttotal: 58.5ms\tremaining: 17ms\n",
            "31:\tlearn: 0.1724570\ttotal: 60.4ms\tremaining: 15.1ms\n",
            "32:\tlearn: 0.1703672\ttotal: 62.3ms\tremaining: 13.2ms\n",
            "33:\tlearn: 0.1685175\ttotal: 64.2ms\tremaining: 11.3ms\n",
            "34:\tlearn: 0.1666049\ttotal: 66.9ms\tremaining: 9.56ms\n",
            "35:\tlearn: 0.1648374\ttotal: 70.5ms\tremaining: 7.83ms\n",
            "36:\tlearn: 0.1631656\ttotal: 73.2ms\tremaining: 5.94ms\n",
            "37:\tlearn: 0.1615072\ttotal: 75.9ms\tremaining: 3.99ms\n",
            "38:\tlearn: 0.1598928\ttotal: 79ms\tremaining: 2.02ms\n",
            "39:\tlearn: 0.1584040\ttotal: 83ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.95ms\tremaining: 75.9ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.63ms\tremaining: 49.9ms\n",
            "2:\tlearn: 0.3203557\ttotal: 3.51ms\tremaining: 43.3ms\n",
            "3:\tlearn: 0.3063743\ttotal: 5.32ms\tremaining: 47.9ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.99ms\tremaining: 49ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.98ms\tremaining: 50.9ms\n",
            "6:\tlearn: 0.2792409\ttotal: 11ms\tremaining: 51.7ms\n",
            "7:\tlearn: 0.2716618\ttotal: 13.1ms\tremaining: 52.3ms\n",
            "8:\tlearn: 0.2621352\ttotal: 15.2ms\tremaining: 52.5ms\n",
            "9:\tlearn: 0.2537973\ttotal: 17.4ms\tremaining: 52.2ms\n",
            "10:\tlearn: 0.2473429\ttotal: 19.5ms\tremaining: 51.4ms\n",
            "11:\tlearn: 0.2416695\ttotal: 21.6ms\tremaining: 50.5ms\n",
            "12:\tlearn: 0.2366343\ttotal: 23.7ms\tremaining: 49.1ms\n",
            "13:\tlearn: 0.2298385\ttotal: 25.7ms\tremaining: 47.7ms\n",
            "14:\tlearn: 0.2249545\ttotal: 27.7ms\tremaining: 46.1ms\n",
            "15:\tlearn: 0.2192054\ttotal: 29.7ms\tremaining: 44.6ms\n",
            "16:\tlearn: 0.2150242\ttotal: 31.7ms\tremaining: 42.9ms\n",
            "17:\tlearn: 0.2094516\ttotal: 33.8ms\tremaining: 41.3ms\n",
            "18:\tlearn: 0.2056324\ttotal: 35.8ms\tremaining: 39.6ms\n",
            "19:\tlearn: 0.2021225\ttotal: 37.8ms\tremaining: 37.8ms\n",
            "20:\tlearn: 0.1989042\ttotal: 39.8ms\tremaining: 36ms\n",
            "21:\tlearn: 0.1961040\ttotal: 41.8ms\tremaining: 34.2ms\n",
            "22:\tlearn: 0.1934794\ttotal: 43.9ms\tremaining: 32.4ms\n",
            "23:\tlearn: 0.1902438\ttotal: 45.9ms\tremaining: 30.6ms\n",
            "24:\tlearn: 0.1874921\ttotal: 47.9ms\tremaining: 28.7ms\n",
            "25:\tlearn: 0.1829904\ttotal: 50ms\tremaining: 26.9ms\n",
            "26:\tlearn: 0.1804169\ttotal: 51.9ms\tremaining: 25ms\n",
            "27:\tlearn: 0.1776989\ttotal: 53.9ms\tremaining: 23.1ms\n",
            "28:\tlearn: 0.1751387\ttotal: 56ms\tremaining: 21.2ms\n",
            "29:\tlearn: 0.1727570\ttotal: 58.1ms\tremaining: 19.4ms\n",
            "30:\tlearn: 0.1693663\ttotal: 60.1ms\tremaining: 17.4ms\n",
            "31:\tlearn: 0.1661883\ttotal: 62.1ms\tremaining: 15.5ms\n",
            "32:\tlearn: 0.1641011\ttotal: 64.1ms\tremaining: 13.6ms\n",
            "33:\tlearn: 0.1616271\ttotal: 66.2ms\tremaining: 11.7ms\n",
            "34:\tlearn: 0.1593621\ttotal: 68.3ms\tremaining: 9.75ms\n",
            "35:\tlearn: 0.1576181\ttotal: 70.3ms\tremaining: 7.81ms\n",
            "36:\tlearn: 0.1557020\ttotal: 72.2ms\tremaining: 5.86ms\n",
            "37:\tlearn: 0.1541003\ttotal: 74.3ms\tremaining: 3.91ms\n",
            "38:\tlearn: 0.1522873\ttotal: 76.3ms\tremaining: 1.96ms\n",
            "39:\tlearn: 0.1502740\ttotal: 78.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.69ms\tremaining: 67.8ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.75ms\tremaining: 53.6ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.56ms\tremaining: 57.8ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.51ms\tremaining: 60.3ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.44ms\tremaining: 60.8ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.3ms\tremaining: 60.2ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.3ms\tremaining: 59.6ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.2ms\tremaining: 58.6ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.1ms\tremaining: 57.4ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.2ms\tremaining: 56.5ms\n",
            "10:\tlearn: 0.2983658\ttotal: 20.1ms\tremaining: 54.9ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.3ms\tremaining: 54ms\n",
            "12:\tlearn: 0.2852979\ttotal: 24.4ms\tremaining: 52.5ms\n",
            "13:\tlearn: 0.2798563\ttotal: 26.5ms\tremaining: 51.1ms\n",
            "14:\tlearn: 0.2747341\ttotal: 28.5ms\tremaining: 49.4ms\n",
            "15:\tlearn: 0.2702568\ttotal: 30.7ms\tremaining: 47.9ms\n",
            "16:\tlearn: 0.2650537\ttotal: 32.7ms\tremaining: 46.2ms\n",
            "17:\tlearn: 0.2601005\ttotal: 34.7ms\tremaining: 44.4ms\n",
            "18:\tlearn: 0.2560578\ttotal: 36.8ms\tremaining: 42.6ms\n",
            "19:\tlearn: 0.2530381\ttotal: 38.7ms\tremaining: 40.7ms\n",
            "20:\tlearn: 0.2498453\ttotal: 40.7ms\tremaining: 38.8ms\n",
            "21:\tlearn: 0.2461646\ttotal: 42.8ms\tremaining: 37ms\n",
            "22:\tlearn: 0.2424369\ttotal: 44.9ms\tremaining: 35.1ms\n",
            "23:\tlearn: 0.2392835\ttotal: 46.9ms\tremaining: 33.2ms\n",
            "24:\tlearn: 0.2339070\ttotal: 49.6ms\tremaining: 31.7ms\n",
            "25:\tlearn: 0.2301706\ttotal: 52.3ms\tremaining: 30.2ms\n",
            "26:\tlearn: 0.2263007\ttotal: 55.7ms\tremaining: 28.9ms\n",
            "27:\tlearn: 0.2223209\ttotal: 60.3ms\tremaining: 28ms\n",
            "28:\tlearn: 0.2190932\ttotal: 65ms\tremaining: 26.9ms\n",
            "29:\tlearn: 0.2159010\ttotal: 68.9ms\tremaining: 25.3ms\n",
            "30:\tlearn: 0.2132954\ttotal: 70.7ms\tremaining: 22.8ms\n",
            "31:\tlearn: 0.2102299\ttotal: 72.8ms\tremaining: 20.5ms\n",
            "32:\tlearn: 0.2076280\ttotal: 74.8ms\tremaining: 18.1ms\n",
            "33:\tlearn: 0.2043188\ttotal: 76.8ms\tremaining: 15.8ms\n",
            "34:\tlearn: 0.2017849\ttotal: 78.8ms\tremaining: 13.5ms\n",
            "35:\tlearn: 0.1993718\ttotal: 80.7ms\tremaining: 11.2ms\n",
            "36:\tlearn: 0.1972299\ttotal: 82.6ms\tremaining: 8.93ms\n",
            "37:\tlearn: 0.1950197\ttotal: 84.6ms\tremaining: 6.68ms\n",
            "38:\tlearn: 0.1927135\ttotal: 86.5ms\tremaining: 4.43ms\n",
            "39:\tlearn: 0.1895038\ttotal: 88.5ms\tremaining: 2.21ms\n",
            "40:\tlearn: 0.1867644\ttotal: 90.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.92ms\tremaining: 76.6ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.63ms\tremaining: 51.4ms\n",
            "2:\tlearn: 0.3788145\ttotal: 5.08ms\tremaining: 64.4ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.82ms\tremaining: 63.1ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.8ms\tremaining: 56.1ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.82ms\tremaining: 51.5ms\n",
            "6:\tlearn: 0.3158416\ttotal: 11ms\tremaining: 53.4ms\n",
            "7:\tlearn: 0.3097739\ttotal: 13.1ms\tremaining: 53.9ms\n",
            "8:\tlearn: 0.3040041\ttotal: 15.1ms\tremaining: 53.7ms\n",
            "9:\tlearn: 0.2975585\ttotal: 17.2ms\tremaining: 53.3ms\n",
            "10:\tlearn: 0.2898709\ttotal: 19.3ms\tremaining: 52.7ms\n",
            "11:\tlearn: 0.2845372\ttotal: 21.4ms\tremaining: 51.6ms\n",
            "12:\tlearn: 0.2794184\ttotal: 23.5ms\tremaining: 50.7ms\n",
            "13:\tlearn: 0.2740314\ttotal: 25.6ms\tremaining: 49.3ms\n",
            "14:\tlearn: 0.2705542\ttotal: 27.8ms\tremaining: 48.3ms\n",
            "15:\tlearn: 0.2673919\ttotal: 30ms\tremaining: 46.8ms\n",
            "16:\tlearn: 0.2623365\ttotal: 31.9ms\tremaining: 45.1ms\n",
            "17:\tlearn: 0.2595719\ttotal: 34ms\tremaining: 43.4ms\n",
            "18:\tlearn: 0.2545713\ttotal: 36ms\tremaining: 41.7ms\n",
            "19:\tlearn: 0.2510766\ttotal: 38.1ms\tremaining: 40ms\n",
            "20:\tlearn: 0.2477056\ttotal: 40.1ms\tremaining: 38.2ms\n",
            "21:\tlearn: 0.2437884\ttotal: 42.1ms\tremaining: 36.4ms\n",
            "22:\tlearn: 0.2404080\ttotal: 44.1ms\tremaining: 34.5ms\n",
            "23:\tlearn: 0.2369058\ttotal: 46.1ms\tremaining: 32.7ms\n",
            "24:\tlearn: 0.2331119\ttotal: 48.2ms\tremaining: 30.9ms\n",
            "25:\tlearn: 0.2293455\ttotal: 50.2ms\tremaining: 28.9ms\n",
            "26:\tlearn: 0.2256418\ttotal: 52.1ms\tremaining: 27ms\n",
            "27:\tlearn: 0.2221119\ttotal: 54ms\tremaining: 25.1ms\n",
            "28:\tlearn: 0.2190925\ttotal: 56.3ms\tremaining: 23.3ms\n",
            "29:\tlearn: 0.2161731\ttotal: 58.3ms\tremaining: 21.4ms\n",
            "30:\tlearn: 0.2135041\ttotal: 60.2ms\tremaining: 19.4ms\n",
            "31:\tlearn: 0.2113382\ttotal: 62.2ms\tremaining: 17.5ms\n",
            "32:\tlearn: 0.2083485\ttotal: 64.2ms\tremaining: 15.6ms\n",
            "33:\tlearn: 0.2058588\ttotal: 66.2ms\tremaining: 13.6ms\n",
            "34:\tlearn: 0.2024895\ttotal: 68.2ms\tremaining: 11.7ms\n",
            "35:\tlearn: 0.1997586\ttotal: 70.2ms\tremaining: 9.75ms\n",
            "36:\tlearn: 0.1976953\ttotal: 72.2ms\tremaining: 7.8ms\n",
            "37:\tlearn: 0.1949453\ttotal: 74.2ms\tremaining: 5.86ms\n",
            "38:\tlearn: 0.1931445\ttotal: 76.2ms\tremaining: 3.91ms\n",
            "39:\tlearn: 0.1900292\ttotal: 78.3ms\tremaining: 1.96ms\n",
            "40:\tlearn: 0.1872454\ttotal: 80.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 4.07ms\tremaining: 163ms\n",
            "1:\tlearn: 0.4107278\ttotal: 4.88ms\tremaining: 95.3ms\n",
            "2:\tlearn: 0.3698157\ttotal: 5.71ms\tremaining: 72.3ms\n",
            "3:\tlearn: 0.3518120\ttotal: 9.66ms\tremaining: 89.4ms\n",
            "4:\tlearn: 0.3441195\ttotal: 11.7ms\tremaining: 83.9ms\n",
            "5:\tlearn: 0.3328396\ttotal: 13.6ms\tremaining: 79.5ms\n",
            "6:\tlearn: 0.3256704\ttotal: 15.6ms\tremaining: 75.8ms\n",
            "7:\tlearn: 0.3174441\ttotal: 17.5ms\tremaining: 72.4ms\n",
            "8:\tlearn: 0.3090762\ttotal: 19.5ms\tremaining: 69.2ms\n",
            "9:\tlearn: 0.3028459\ttotal: 21.5ms\tremaining: 66.5ms\n",
            "10:\tlearn: 0.2958541\ttotal: 26.5ms\tremaining: 72.2ms\n",
            "11:\tlearn: 0.2901166\ttotal: 29.2ms\tremaining: 70.5ms\n",
            "12:\tlearn: 0.2841803\ttotal: 30.9ms\tremaining: 66.6ms\n",
            "13:\tlearn: 0.2789751\ttotal: 37.1ms\tremaining: 71.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 40.9ms\tremaining: 70.8ms\n",
            "15:\tlearn: 0.2663544\ttotal: 43.8ms\tremaining: 68.5ms\n",
            "16:\tlearn: 0.2615546\ttotal: 45.8ms\tremaining: 64.6ms\n",
            "17:\tlearn: 0.2560079\ttotal: 47.7ms\tremaining: 60.9ms\n",
            "18:\tlearn: 0.2507480\ttotal: 50.4ms\tremaining: 58.3ms\n",
            "19:\tlearn: 0.2450678\ttotal: 52.6ms\tremaining: 55.2ms\n",
            "20:\tlearn: 0.2413892\ttotal: 55.3ms\tremaining: 52.7ms\n",
            "21:\tlearn: 0.2378437\ttotal: 58.6ms\tremaining: 50.6ms\n",
            "22:\tlearn: 0.2344010\ttotal: 60.6ms\tremaining: 47.4ms\n",
            "23:\tlearn: 0.2304940\ttotal: 62.7ms\tremaining: 44.4ms\n",
            "24:\tlearn: 0.2269540\ttotal: 64.8ms\tremaining: 41.5ms\n",
            "25:\tlearn: 0.2232713\ttotal: 66.9ms\tremaining: 38.6ms\n",
            "26:\tlearn: 0.2208577\ttotal: 69ms\tremaining: 35.8ms\n",
            "27:\tlearn: 0.2181825\ttotal: 71.3ms\tremaining: 33.1ms\n",
            "28:\tlearn: 0.2149071\ttotal: 73.3ms\tremaining: 30.3ms\n",
            "29:\tlearn: 0.2123638\ttotal: 75.5ms\tremaining: 27.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 77.6ms\tremaining: 25ms\n",
            "31:\tlearn: 0.2071716\ttotal: 79.7ms\tremaining: 22.4ms\n",
            "32:\tlearn: 0.2045371\ttotal: 81.8ms\tremaining: 19.8ms\n",
            "33:\tlearn: 0.2018712\ttotal: 83.8ms\tremaining: 17.3ms\n",
            "34:\tlearn: 0.1995442\ttotal: 86.1ms\tremaining: 14.8ms\n",
            "35:\tlearn: 0.1970515\ttotal: 89ms\tremaining: 12.4ms\n",
            "36:\tlearn: 0.1946725\ttotal: 91ms\tremaining: 9.84ms\n",
            "37:\tlearn: 0.1924392\ttotal: 93ms\tremaining: 7.34ms\n",
            "38:\tlearn: 0.1893508\ttotal: 94.9ms\tremaining: 4.87ms\n",
            "39:\tlearn: 0.1868097\ttotal: 97.1ms\tremaining: 2.43ms\n",
            "40:\tlearn: 0.1846310\ttotal: 99.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.87ms\tremaining: 74.6ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.45ms\tremaining: 47.8ms\n",
            "2:\tlearn: 0.3383999\ttotal: 5.86ms\tremaining: 74.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 8.22ms\tremaining: 76.1ms\n",
            "4:\tlearn: 0.3080259\ttotal: 10.3ms\tremaining: 74.4ms\n",
            "5:\tlearn: 0.2907443\ttotal: 12.3ms\tremaining: 71.6ms\n",
            "6:\tlearn: 0.2818467\ttotal: 14.3ms\tremaining: 69.6ms\n",
            "7:\tlearn: 0.2691784\ttotal: 15.7ms\tremaining: 64.8ms\n",
            "8:\tlearn: 0.2611618\ttotal: 17.7ms\tremaining: 62.8ms\n",
            "9:\tlearn: 0.2519898\ttotal: 19.8ms\tremaining: 61.4ms\n",
            "10:\tlearn: 0.2462992\ttotal: 21.9ms\tremaining: 59.7ms\n",
            "11:\tlearn: 0.2416348\ttotal: 24ms\tremaining: 57.9ms\n",
            "12:\tlearn: 0.2368688\ttotal: 26.1ms\tremaining: 56.2ms\n",
            "13:\tlearn: 0.2320170\ttotal: 28.3ms\tremaining: 54.7ms\n",
            "14:\tlearn: 0.2262186\ttotal: 30.4ms\tremaining: 52.7ms\n",
            "15:\tlearn: 0.2215380\ttotal: 32.6ms\tremaining: 51ms\n",
            "16:\tlearn: 0.2176313\ttotal: 34.9ms\tremaining: 49.3ms\n",
            "17:\tlearn: 0.2138494\ttotal: 37ms\tremaining: 47.3ms\n",
            "18:\tlearn: 0.2100966\ttotal: 39ms\tremaining: 45.1ms\n",
            "19:\tlearn: 0.2068557\ttotal: 41.1ms\tremaining: 43.1ms\n",
            "20:\tlearn: 0.2029945\ttotal: 43.1ms\tremaining: 41ms\n",
            "21:\tlearn: 0.2001044\ttotal: 45ms\tremaining: 38.8ms\n",
            "22:\tlearn: 0.1970766\ttotal: 47ms\tremaining: 36.8ms\n",
            "23:\tlearn: 0.1940285\ttotal: 48.9ms\tremaining: 34.6ms\n",
            "24:\tlearn: 0.1910934\ttotal: 51ms\tremaining: 32.6ms\n",
            "25:\tlearn: 0.1879112\ttotal: 53ms\tremaining: 30.6ms\n",
            "26:\tlearn: 0.1852765\ttotal: 54.9ms\tremaining: 28.5ms\n",
            "27:\tlearn: 0.1827068\ttotal: 57.1ms\tremaining: 26.5ms\n",
            "28:\tlearn: 0.1803359\ttotal: 59ms\tremaining: 24.4ms\n",
            "29:\tlearn: 0.1779549\ttotal: 61.1ms\tremaining: 22.4ms\n",
            "30:\tlearn: 0.1757984\ttotal: 63.1ms\tremaining: 20.4ms\n",
            "31:\tlearn: 0.1724570\ttotal: 65.2ms\tremaining: 18.3ms\n",
            "32:\tlearn: 0.1703672\ttotal: 67.6ms\tremaining: 16.4ms\n",
            "33:\tlearn: 0.1685175\ttotal: 70.4ms\tremaining: 14.5ms\n",
            "34:\tlearn: 0.1666049\ttotal: 72.1ms\tremaining: 12.4ms\n",
            "35:\tlearn: 0.1648374\ttotal: 74.2ms\tremaining: 10.3ms\n",
            "36:\tlearn: 0.1631656\ttotal: 76.2ms\tremaining: 8.23ms\n",
            "37:\tlearn: 0.1615072\ttotal: 78.2ms\tremaining: 6.17ms\n",
            "38:\tlearn: 0.1598928\ttotal: 80.3ms\tremaining: 4.12ms\n",
            "39:\tlearn: 0.1584040\ttotal: 82.3ms\tremaining: 2.06ms\n",
            "40:\tlearn: 0.1566573\ttotal: 84.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.82ms\tremaining: 72.7ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.64ms\tremaining: 51.4ms\n",
            "2:\tlearn: 0.3203557\ttotal: 3.35ms\tremaining: 42.4ms\n",
            "3:\tlearn: 0.3063743\ttotal: 5.23ms\tremaining: 48.4ms\n",
            "4:\tlearn: 0.2970911\ttotal: 7.16ms\tremaining: 51.6ms\n",
            "5:\tlearn: 0.2891054\ttotal: 9.08ms\tremaining: 53ms\n",
            "6:\tlearn: 0.2792409\ttotal: 11.1ms\tremaining: 53.7ms\n",
            "7:\tlearn: 0.2716618\ttotal: 13ms\tremaining: 53.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 15ms\tremaining: 53.2ms\n",
            "9:\tlearn: 0.2537973\ttotal: 17ms\tremaining: 52.7ms\n",
            "10:\tlearn: 0.2473429\ttotal: 18.9ms\tremaining: 51.4ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20.7ms\tremaining: 50ms\n",
            "12:\tlearn: 0.2366343\ttotal: 22.8ms\tremaining: 49.1ms\n",
            "13:\tlearn: 0.2298385\ttotal: 24.9ms\tremaining: 47.9ms\n",
            "14:\tlearn: 0.2249545\ttotal: 26.8ms\tremaining: 46.4ms\n",
            "15:\tlearn: 0.2192054\ttotal: 28.7ms\tremaining: 44.9ms\n",
            "16:\tlearn: 0.2150242\ttotal: 30.8ms\tremaining: 43.4ms\n",
            "17:\tlearn: 0.2094516\ttotal: 32.7ms\tremaining: 41.8ms\n",
            "18:\tlearn: 0.2056324\ttotal: 34.7ms\tremaining: 40.2ms\n",
            "19:\tlearn: 0.2021225\ttotal: 36.7ms\tremaining: 38.5ms\n",
            "20:\tlearn: 0.1989042\ttotal: 38.6ms\tremaining: 36.7ms\n",
            "21:\tlearn: 0.1961040\ttotal: 40.4ms\tremaining: 34.9ms\n",
            "22:\tlearn: 0.1934794\ttotal: 42.4ms\tremaining: 33.2ms\n",
            "23:\tlearn: 0.1902438\ttotal: 44.4ms\tremaining: 31.4ms\n",
            "24:\tlearn: 0.1874921\ttotal: 46.3ms\tremaining: 29.6ms\n",
            "25:\tlearn: 0.1829904\ttotal: 48.1ms\tremaining: 27.7ms\n",
            "26:\tlearn: 0.1804169\ttotal: 50ms\tremaining: 25.9ms\n",
            "27:\tlearn: 0.1776989\ttotal: 51.8ms\tremaining: 24.1ms\n",
            "28:\tlearn: 0.1751387\ttotal: 53.8ms\tremaining: 22.3ms\n",
            "29:\tlearn: 0.1727570\ttotal: 55.8ms\tremaining: 20.5ms\n",
            "30:\tlearn: 0.1693663\ttotal: 57.8ms\tremaining: 18.6ms\n",
            "31:\tlearn: 0.1661883\ttotal: 59.7ms\tremaining: 16.8ms\n",
            "32:\tlearn: 0.1641011\ttotal: 61.6ms\tremaining: 14.9ms\n",
            "33:\tlearn: 0.1616271\ttotal: 63.5ms\tremaining: 13.1ms\n",
            "34:\tlearn: 0.1593621\ttotal: 65.5ms\tremaining: 11.2ms\n",
            "35:\tlearn: 0.1576181\ttotal: 67.5ms\tremaining: 9.37ms\n",
            "36:\tlearn: 0.1557020\ttotal: 69.3ms\tremaining: 7.49ms\n",
            "37:\tlearn: 0.1541003\ttotal: 71.2ms\tremaining: 5.62ms\n",
            "38:\tlearn: 0.1522873\ttotal: 73.2ms\tremaining: 3.75ms\n",
            "39:\tlearn: 0.1502740\ttotal: 75.2ms\tremaining: 1.88ms\n",
            "40:\tlearn: 0.1483554\ttotal: 77.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.73ms\tremaining: 70.9ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.98ms\tremaining: 59.6ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.68ms\tremaining: 60.9ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.68ms\tremaining: 63.5ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.63ms\tremaining: 63.8ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.6ms\tremaining: 63.5ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.5ms\tremaining: 62.5ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.3ms\tremaining: 61ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.2ms\tremaining: 59.4ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.2ms\tremaining: 58.3ms\n",
            "10:\tlearn: 0.2983658\ttotal: 20.1ms\tremaining: 56.7ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.1ms\tremaining: 55.3ms\n",
            "12:\tlearn: 0.2852979\ttotal: 24.1ms\tremaining: 53.7ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.9ms\tremaining: 51.8ms\n",
            "14:\tlearn: 0.2747341\ttotal: 27.8ms\tremaining: 50.1ms\n",
            "15:\tlearn: 0.2702568\ttotal: 29.7ms\tremaining: 48.3ms\n",
            "16:\tlearn: 0.2650537\ttotal: 31.6ms\tremaining: 46.5ms\n",
            "17:\tlearn: 0.2601005\ttotal: 33.5ms\tremaining: 44.6ms\n",
            "18:\tlearn: 0.2560578\ttotal: 35.4ms\tremaining: 42.8ms\n",
            "19:\tlearn: 0.2530381\ttotal: 37.5ms\tremaining: 41.3ms\n",
            "20:\tlearn: 0.2498453\ttotal: 39.5ms\tremaining: 39.5ms\n",
            "21:\tlearn: 0.2461646\ttotal: 41.4ms\tremaining: 37.6ms\n",
            "22:\tlearn: 0.2424369\ttotal: 43.4ms\tremaining: 35.8ms\n",
            "23:\tlearn: 0.2392835\ttotal: 45.3ms\tremaining: 34ms\n",
            "24:\tlearn: 0.2339070\ttotal: 47.3ms\tremaining: 32.2ms\n",
            "25:\tlearn: 0.2301706\ttotal: 49.5ms\tremaining: 30.5ms\n",
            "26:\tlearn: 0.2263007\ttotal: 51.5ms\tremaining: 28.6ms\n",
            "27:\tlearn: 0.2223209\ttotal: 53.5ms\tremaining: 26.8ms\n",
            "28:\tlearn: 0.2190932\ttotal: 55.4ms\tremaining: 24.9ms\n",
            "29:\tlearn: 0.2159010\ttotal: 58.2ms\tremaining: 23.3ms\n",
            "30:\tlearn: 0.2132954\ttotal: 61.2ms\tremaining: 21.7ms\n",
            "31:\tlearn: 0.2102299\ttotal: 64ms\tremaining: 20ms\n",
            "32:\tlearn: 0.2076280\ttotal: 69.1ms\tremaining: 18.9ms\n",
            "33:\tlearn: 0.2043188\ttotal: 74ms\tremaining: 17.4ms\n",
            "34:\tlearn: 0.2017849\ttotal: 76.4ms\tremaining: 15.3ms\n",
            "35:\tlearn: 0.1993718\ttotal: 78.3ms\tremaining: 13.1ms\n",
            "36:\tlearn: 0.1972299\ttotal: 80.2ms\tremaining: 10.8ms\n",
            "37:\tlearn: 0.1950197\ttotal: 86.1ms\tremaining: 9.07ms\n",
            "38:\tlearn: 0.1927135\ttotal: 90.2ms\tremaining: 6.94ms\n",
            "39:\tlearn: 0.1895038\ttotal: 93.5ms\tremaining: 4.67ms\n",
            "40:\tlearn: 0.1867644\ttotal: 96.7ms\tremaining: 2.36ms\n",
            "41:\tlearn: 0.1842014\ttotal: 100ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.65ms\tremaining: 67.5ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.21ms\tremaining: 44.2ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.07ms\tremaining: 52.9ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.07ms\tremaining: 57.6ms\n",
            "4:\tlearn: 0.3428474\ttotal: 6.98ms\tremaining: 51.7ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.92ms\tremaining: 47.5ms\n",
            "6:\tlearn: 0.3158416\ttotal: 9.91ms\tremaining: 49.5ms\n",
            "7:\tlearn: 0.3097739\ttotal: 11.9ms\tremaining: 50.5ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.9ms\tremaining: 50.8ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.9ms\tremaining: 51ms\n",
            "10:\tlearn: 0.2898709\ttotal: 18.1ms\tremaining: 50.9ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.2ms\tremaining: 50.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 22.3ms\tremaining: 49.8ms\n",
            "13:\tlearn: 0.2740314\ttotal: 24.4ms\tremaining: 48.9ms\n",
            "14:\tlearn: 0.2705542\ttotal: 26.7ms\tremaining: 48ms\n",
            "15:\tlearn: 0.2673919\ttotal: 28.9ms\tremaining: 47ms\n",
            "16:\tlearn: 0.2623365\ttotal: 31ms\tremaining: 45.5ms\n",
            "17:\tlearn: 0.2595719\ttotal: 33.1ms\tremaining: 44.1ms\n",
            "18:\tlearn: 0.2545713\ttotal: 35.2ms\tremaining: 42.6ms\n",
            "19:\tlearn: 0.2510766\ttotal: 37.3ms\tremaining: 41ms\n",
            "20:\tlearn: 0.2477056\ttotal: 39.3ms\tremaining: 39.3ms\n",
            "21:\tlearn: 0.2437884\ttotal: 41.5ms\tremaining: 37.7ms\n",
            "22:\tlearn: 0.2404080\ttotal: 43.7ms\tremaining: 36.1ms\n",
            "23:\tlearn: 0.2369058\ttotal: 45.8ms\tremaining: 34.4ms\n",
            "24:\tlearn: 0.2331119\ttotal: 48.1ms\tremaining: 32.7ms\n",
            "25:\tlearn: 0.2293455\ttotal: 50.2ms\tremaining: 30.9ms\n",
            "26:\tlearn: 0.2256418\ttotal: 52.3ms\tremaining: 29ms\n",
            "27:\tlearn: 0.2221119\ttotal: 54.3ms\tremaining: 27.2ms\n",
            "28:\tlearn: 0.2190925\ttotal: 56.6ms\tremaining: 25.4ms\n",
            "29:\tlearn: 0.2161731\ttotal: 58.7ms\tremaining: 23.5ms\n",
            "30:\tlearn: 0.2135041\ttotal: 60.8ms\tremaining: 21.6ms\n",
            "31:\tlearn: 0.2113382\ttotal: 63.2ms\tremaining: 19.7ms\n",
            "32:\tlearn: 0.2083485\ttotal: 65.3ms\tremaining: 17.8ms\n",
            "33:\tlearn: 0.2058588\ttotal: 67.4ms\tremaining: 15.9ms\n",
            "34:\tlearn: 0.2024895\ttotal: 69.5ms\tremaining: 13.9ms\n",
            "35:\tlearn: 0.1997586\ttotal: 71.6ms\tremaining: 11.9ms\n",
            "36:\tlearn: 0.1976953\ttotal: 73.7ms\tremaining: 9.95ms\n",
            "37:\tlearn: 0.1949453\ttotal: 75.7ms\tremaining: 7.97ms\n",
            "38:\tlearn: 0.1931445\ttotal: 77.8ms\tremaining: 5.99ms\n",
            "39:\tlearn: 0.1900292\ttotal: 79.9ms\tremaining: 4ms\n",
            "40:\tlearn: 0.1872454\ttotal: 82.1ms\tremaining: 2ms\n",
            "41:\tlearn: 0.1848207\ttotal: 84.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 2.05ms\tremaining: 84.1ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.73ms\tremaining: 54.7ms\n",
            "2:\tlearn: 0.3698157\ttotal: 3.75ms\tremaining: 48.8ms\n",
            "3:\tlearn: 0.3518120\ttotal: 5.82ms\tremaining: 55.3ms\n",
            "4:\tlearn: 0.3441195\ttotal: 7.84ms\tremaining: 58.1ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.96ms\tremaining: 59.7ms\n",
            "6:\tlearn: 0.3256704\ttotal: 12.1ms\tremaining: 60.3ms\n",
            "7:\tlearn: 0.3174441\ttotal: 14ms\tremaining: 59.7ms\n",
            "8:\tlearn: 0.3090762\ttotal: 16.1ms\tremaining: 59.2ms\n",
            "9:\tlearn: 0.3028459\ttotal: 18.2ms\tremaining: 58.3ms\n",
            "10:\tlearn: 0.2958541\ttotal: 20.4ms\tremaining: 57.4ms\n",
            "11:\tlearn: 0.2901166\ttotal: 22.5ms\tremaining: 56.2ms\n",
            "12:\tlearn: 0.2841803\ttotal: 24.7ms\tremaining: 55.2ms\n",
            "13:\tlearn: 0.2789751\ttotal: 27.1ms\tremaining: 54.2ms\n",
            "14:\tlearn: 0.2715599\ttotal: 29.4ms\tremaining: 53ms\n",
            "15:\tlearn: 0.2663544\ttotal: 31.7ms\tremaining: 51.6ms\n",
            "16:\tlearn: 0.2615546\ttotal: 33.9ms\tremaining: 49.8ms\n",
            "17:\tlearn: 0.2560079\ttotal: 36.1ms\tremaining: 48.1ms\n",
            "18:\tlearn: 0.2507480\ttotal: 40.1ms\tremaining: 48.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 43.6ms\tremaining: 48ms\n",
            "20:\tlearn: 0.2413892\ttotal: 46.1ms\tremaining: 46.1ms\n",
            "21:\tlearn: 0.2378437\ttotal: 48.2ms\tremaining: 43.8ms\n",
            "22:\tlearn: 0.2344010\ttotal: 51.1ms\tremaining: 42.2ms\n",
            "23:\tlearn: 0.2304940\ttotal: 54.1ms\tremaining: 40.5ms\n",
            "24:\tlearn: 0.2269540\ttotal: 58.7ms\tremaining: 39.9ms\n",
            "25:\tlearn: 0.2232713\ttotal: 61.5ms\tremaining: 37.8ms\n",
            "26:\tlearn: 0.2208577\ttotal: 63.6ms\tremaining: 35.3ms\n",
            "27:\tlearn: 0.2181825\ttotal: 65.9ms\tremaining: 33ms\n",
            "28:\tlearn: 0.2149071\ttotal: 68.2ms\tremaining: 30.6ms\n",
            "29:\tlearn: 0.2123638\ttotal: 70.4ms\tremaining: 28.2ms\n",
            "30:\tlearn: 0.2094640\ttotal: 72.7ms\tremaining: 25.8ms\n",
            "31:\tlearn: 0.2071716\ttotal: 75ms\tremaining: 23.4ms\n",
            "32:\tlearn: 0.2045371\ttotal: 77.3ms\tremaining: 21.1ms\n",
            "33:\tlearn: 0.2018712\ttotal: 79.5ms\tremaining: 18.7ms\n",
            "34:\tlearn: 0.1995442\ttotal: 81.8ms\tremaining: 16.4ms\n",
            "35:\tlearn: 0.1970515\ttotal: 84ms\tremaining: 14ms\n",
            "36:\tlearn: 0.1946725\ttotal: 86.1ms\tremaining: 11.6ms\n",
            "37:\tlearn: 0.1924392\ttotal: 88.2ms\tremaining: 9.29ms\n",
            "38:\tlearn: 0.1893508\ttotal: 90.7ms\tremaining: 6.98ms\n",
            "39:\tlearn: 0.1868097\ttotal: 93ms\tremaining: 4.65ms\n",
            "40:\tlearn: 0.1846310\ttotal: 95.3ms\tremaining: 2.32ms\n",
            "41:\tlearn: 0.1820837\ttotal: 97.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 2.03ms\tremaining: 83.2ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.45ms\tremaining: 49ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.78ms\tremaining: 62.1ms\n",
            "3:\tlearn: 0.3266560\ttotal: 7.16ms\tremaining: 68ms\n",
            "4:\tlearn: 0.3080259\ttotal: 9.45ms\tremaining: 69.9ms\n",
            "5:\tlearn: 0.2907443\ttotal: 11.7ms\tremaining: 70.4ms\n",
            "6:\tlearn: 0.2818467\ttotal: 14ms\tremaining: 69.9ms\n",
            "7:\tlearn: 0.2691784\ttotal: 15.5ms\tremaining: 65.9ms\n",
            "8:\tlearn: 0.2611618\ttotal: 17.8ms\tremaining: 65.1ms\n",
            "9:\tlearn: 0.2519898\ttotal: 20ms\tremaining: 64.1ms\n",
            "10:\tlearn: 0.2462992\ttotal: 22.3ms\tremaining: 62.8ms\n",
            "11:\tlearn: 0.2416348\ttotal: 24.5ms\tremaining: 61.3ms\n",
            "12:\tlearn: 0.2368688\ttotal: 26.7ms\tremaining: 59.5ms\n",
            "13:\tlearn: 0.2320170\ttotal: 29ms\tremaining: 58ms\n",
            "14:\tlearn: 0.2262186\ttotal: 31.3ms\tremaining: 56.3ms\n",
            "15:\tlearn: 0.2215380\ttotal: 33.7ms\tremaining: 54.7ms\n",
            "16:\tlearn: 0.2176313\ttotal: 36ms\tremaining: 52.9ms\n",
            "17:\tlearn: 0.2138494\ttotal: 38.2ms\tremaining: 51ms\n",
            "18:\tlearn: 0.2100966\ttotal: 40.4ms\tremaining: 48.9ms\n",
            "19:\tlearn: 0.2068557\ttotal: 42.6ms\tremaining: 46.9ms\n",
            "20:\tlearn: 0.2029945\ttotal: 45ms\tremaining: 45ms\n",
            "21:\tlearn: 0.2001044\ttotal: 47.2ms\tremaining: 42.9ms\n",
            "22:\tlearn: 0.1970766\ttotal: 49.5ms\tremaining: 40.9ms\n",
            "23:\tlearn: 0.1940285\ttotal: 51.8ms\tremaining: 38.8ms\n",
            "24:\tlearn: 0.1910934\ttotal: 54.1ms\tremaining: 36.8ms\n",
            "25:\tlearn: 0.1879112\ttotal: 56.3ms\tremaining: 34.7ms\n",
            "26:\tlearn: 0.1852765\ttotal: 58.6ms\tremaining: 32.5ms\n",
            "27:\tlearn: 0.1827068\ttotal: 60.8ms\tremaining: 30.4ms\n",
            "28:\tlearn: 0.1803359\ttotal: 63ms\tremaining: 28.2ms\n",
            "29:\tlearn: 0.1779549\ttotal: 65.2ms\tremaining: 26.1ms\n",
            "30:\tlearn: 0.1757984\ttotal: 67.4ms\tremaining: 23.9ms\n",
            "31:\tlearn: 0.1724570\ttotal: 69.6ms\tremaining: 21.8ms\n",
            "32:\tlearn: 0.1703672\ttotal: 71.8ms\tremaining: 19.6ms\n",
            "33:\tlearn: 0.1685175\ttotal: 74ms\tremaining: 17.4ms\n",
            "34:\tlearn: 0.1666049\ttotal: 76.2ms\tremaining: 15.2ms\n",
            "35:\tlearn: 0.1648374\ttotal: 78.4ms\tremaining: 13.1ms\n",
            "36:\tlearn: 0.1631656\ttotal: 80.3ms\tremaining: 10.9ms\n",
            "37:\tlearn: 0.1615072\ttotal: 82.5ms\tremaining: 8.69ms\n",
            "38:\tlearn: 0.1598928\ttotal: 84.7ms\tremaining: 6.51ms\n",
            "39:\tlearn: 0.1584040\ttotal: 86.9ms\tremaining: 4.34ms\n",
            "40:\tlearn: 0.1566573\ttotal: 89ms\tremaining: 2.17ms\n",
            "41:\tlearn: 0.1544748\ttotal: 91.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 2.12ms\tremaining: 87ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.76ms\tremaining: 55.2ms\n",
            "2:\tlearn: 0.3203557\ttotal: 3.51ms\tremaining: 45.7ms\n",
            "3:\tlearn: 0.3063743\ttotal: 5.54ms\tremaining: 52.6ms\n",
            "4:\tlearn: 0.2970911\ttotal: 7.65ms\tremaining: 56.6ms\n",
            "5:\tlearn: 0.2891054\ttotal: 9.68ms\tremaining: 58.1ms\n",
            "6:\tlearn: 0.2792409\ttotal: 11.7ms\tremaining: 58.5ms\n",
            "7:\tlearn: 0.2716618\ttotal: 13.8ms\tremaining: 58.5ms\n",
            "8:\tlearn: 0.2621352\ttotal: 15.8ms\tremaining: 57.8ms\n",
            "9:\tlearn: 0.2537973\ttotal: 19.3ms\tremaining: 61.6ms\n",
            "10:\tlearn: 0.2473429\ttotal: 23.1ms\tremaining: 65.2ms\n",
            "11:\tlearn: 0.2416695\ttotal: 26.7ms\tremaining: 66.7ms\n",
            "12:\tlearn: 0.2366343\ttotal: 29.4ms\tremaining: 65.6ms\n",
            "13:\tlearn: 0.2298385\ttotal: 32.8ms\tremaining: 65.5ms\n",
            "14:\tlearn: 0.2249545\ttotal: 34.6ms\tremaining: 62.2ms\n",
            "15:\tlearn: 0.2192054\ttotal: 36.5ms\tremaining: 59.2ms\n",
            "16:\tlearn: 0.2150242\ttotal: 38.2ms\tremaining: 56.2ms\n",
            "17:\tlearn: 0.2094516\ttotal: 40.2ms\tremaining: 53.6ms\n",
            "18:\tlearn: 0.2056324\ttotal: 42.3ms\tremaining: 51.2ms\n",
            "19:\tlearn: 0.2021225\ttotal: 44.3ms\tremaining: 48.7ms\n",
            "20:\tlearn: 0.1989042\ttotal: 46.4ms\tremaining: 46.4ms\n",
            "21:\tlearn: 0.1961040\ttotal: 48.4ms\tremaining: 44ms\n",
            "22:\tlearn: 0.1934794\ttotal: 50.5ms\tremaining: 41.7ms\n",
            "23:\tlearn: 0.1902438\ttotal: 52.6ms\tremaining: 39.4ms\n",
            "24:\tlearn: 0.1874921\ttotal: 54.6ms\tremaining: 37.1ms\n",
            "25:\tlearn: 0.1829904\ttotal: 56.6ms\tremaining: 34.8ms\n",
            "26:\tlearn: 0.1804169\ttotal: 58.6ms\tremaining: 32.6ms\n",
            "27:\tlearn: 0.1776989\ttotal: 60.6ms\tremaining: 30.3ms\n",
            "28:\tlearn: 0.1751387\ttotal: 62.6ms\tremaining: 28.1ms\n",
            "29:\tlearn: 0.1727570\ttotal: 64.5ms\tremaining: 25.8ms\n",
            "30:\tlearn: 0.1693663\ttotal: 66.5ms\tremaining: 23.6ms\n",
            "31:\tlearn: 0.1661883\ttotal: 68.4ms\tremaining: 21.4ms\n",
            "32:\tlearn: 0.1641011\ttotal: 70.3ms\tremaining: 19.2ms\n",
            "33:\tlearn: 0.1616271\ttotal: 72.3ms\tremaining: 17ms\n",
            "34:\tlearn: 0.1593621\ttotal: 74.3ms\tremaining: 14.9ms\n",
            "35:\tlearn: 0.1576181\ttotal: 76.3ms\tremaining: 12.7ms\n",
            "36:\tlearn: 0.1557020\ttotal: 78.2ms\tremaining: 10.6ms\n",
            "37:\tlearn: 0.1541003\ttotal: 80.1ms\tremaining: 8.43ms\n",
            "38:\tlearn: 0.1522873\ttotal: 82ms\tremaining: 6.31ms\n",
            "39:\tlearn: 0.1502740\ttotal: 84ms\tremaining: 4.2ms\n",
            "40:\tlearn: 0.1483554\ttotal: 85.9ms\tremaining: 2.1ms\n",
            "41:\tlearn: 0.1465885\ttotal: 87.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.71ms\tremaining: 71.9ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.88ms\tremaining: 59ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.54ms\tremaining: 60.6ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.48ms\tremaining: 63.2ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.41ms\tremaining: 63.9ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.2ms\tremaining: 63.2ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.1ms\tremaining: 62.5ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14ms\tremaining: 61.3ms\n",
            "8:\tlearn: 0.3148279\ttotal: 15.9ms\tremaining: 59.9ms\n",
            "9:\tlearn: 0.3054626\ttotal: 17.9ms\tremaining: 59ms\n",
            "10:\tlearn: 0.2983658\ttotal: 19.7ms\tremaining: 57.4ms\n",
            "11:\tlearn: 0.2903440\ttotal: 21.7ms\tremaining: 56ms\n",
            "12:\tlearn: 0.2852979\ttotal: 23.7ms\tremaining: 54.6ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.6ms\tremaining: 53.1ms\n",
            "14:\tlearn: 0.2747341\ttotal: 27.6ms\tremaining: 51.6ms\n",
            "15:\tlearn: 0.2702568\ttotal: 30.6ms\tremaining: 51.6ms\n",
            "16:\tlearn: 0.2650537\ttotal: 32.5ms\tremaining: 49.8ms\n",
            "17:\tlearn: 0.2601005\ttotal: 34.5ms\tremaining: 48ms\n",
            "18:\tlearn: 0.2560578\ttotal: 36.5ms\tremaining: 46.1ms\n",
            "19:\tlearn: 0.2530381\ttotal: 38.5ms\tremaining: 44.3ms\n",
            "20:\tlearn: 0.2498453\ttotal: 40.4ms\tremaining: 42.3ms\n",
            "21:\tlearn: 0.2461646\ttotal: 42.5ms\tremaining: 40.6ms\n",
            "22:\tlearn: 0.2424369\ttotal: 45.7ms\tremaining: 39.8ms\n",
            "23:\tlearn: 0.2392835\ttotal: 47.5ms\tremaining: 37.6ms\n",
            "24:\tlearn: 0.2339070\ttotal: 49.6ms\tremaining: 35.7ms\n",
            "25:\tlearn: 0.2301706\ttotal: 51.6ms\tremaining: 33.7ms\n",
            "26:\tlearn: 0.2263007\ttotal: 53.6ms\tremaining: 31.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 55.6ms\tremaining: 29.8ms\n",
            "28:\tlearn: 0.2190932\ttotal: 57.5ms\tremaining: 27.8ms\n",
            "29:\tlearn: 0.2159010\ttotal: 59.4ms\tremaining: 25.7ms\n",
            "30:\tlearn: 0.2132954\ttotal: 61.3ms\tremaining: 23.7ms\n",
            "31:\tlearn: 0.2102299\ttotal: 63.4ms\tremaining: 21.8ms\n",
            "32:\tlearn: 0.2076280\ttotal: 65.4ms\tremaining: 19.8ms\n",
            "33:\tlearn: 0.2043188\ttotal: 67.3ms\tremaining: 17.8ms\n",
            "34:\tlearn: 0.2017849\ttotal: 69.6ms\tremaining: 15.9ms\n",
            "35:\tlearn: 0.1993718\ttotal: 72.1ms\tremaining: 14ms\n",
            "36:\tlearn: 0.1972299\ttotal: 73.9ms\tremaining: 12ms\n",
            "37:\tlearn: 0.1950197\ttotal: 75.8ms\tremaining: 9.97ms\n",
            "38:\tlearn: 0.1927135\ttotal: 77.7ms\tremaining: 7.97ms\n",
            "39:\tlearn: 0.1895038\ttotal: 79.5ms\tremaining: 5.96ms\n",
            "40:\tlearn: 0.1867644\ttotal: 81.4ms\tremaining: 3.97ms\n",
            "41:\tlearn: 0.1842014\ttotal: 83.3ms\tremaining: 1.98ms\n",
            "42:\tlearn: 0.1821212\ttotal: 85.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 3.45ms\tremaining: 145ms\n",
            "1:\tlearn: 0.4049315\ttotal: 4.32ms\tremaining: 88.6ms\n",
            "2:\tlearn: 0.3788145\ttotal: 6.37ms\tremaining: 84.9ms\n",
            "3:\tlearn: 0.3658016\ttotal: 8.41ms\tremaining: 82ms\n",
            "4:\tlearn: 0.3428474\ttotal: 9.1ms\tremaining: 69.2ms\n",
            "5:\tlearn: 0.3234303\ttotal: 10.1ms\tremaining: 62.6ms\n",
            "6:\tlearn: 0.3158416\ttotal: 12.1ms\tremaining: 62.1ms\n",
            "7:\tlearn: 0.3097739\ttotal: 13.9ms\tremaining: 60.9ms\n",
            "8:\tlearn: 0.3040041\ttotal: 15.8ms\tremaining: 59.8ms\n",
            "9:\tlearn: 0.2975585\ttotal: 17.7ms\tremaining: 58.4ms\n",
            "10:\tlearn: 0.2898709\ttotal: 19.5ms\tremaining: 56.7ms\n",
            "11:\tlearn: 0.2845372\ttotal: 21.4ms\tremaining: 55.2ms\n",
            "12:\tlearn: 0.2794184\ttotal: 23.2ms\tremaining: 53.5ms\n",
            "13:\tlearn: 0.2740314\ttotal: 25.1ms\tremaining: 52ms\n",
            "14:\tlearn: 0.2705542\ttotal: 27.1ms\tremaining: 50.5ms\n",
            "15:\tlearn: 0.2673919\ttotal: 28.8ms\tremaining: 48.6ms\n",
            "16:\tlearn: 0.2623365\ttotal: 31.8ms\tremaining: 48.6ms\n",
            "17:\tlearn: 0.2595719\ttotal: 35ms\tremaining: 48.6ms\n",
            "18:\tlearn: 0.2545713\ttotal: 38.4ms\tremaining: 48.5ms\n",
            "19:\tlearn: 0.2510766\ttotal: 40.3ms\tremaining: 46.4ms\n",
            "20:\tlearn: 0.2477056\ttotal: 42.3ms\tremaining: 44.3ms\n",
            "21:\tlearn: 0.2437884\ttotal: 44.1ms\tremaining: 42.1ms\n",
            "22:\tlearn: 0.2404080\ttotal: 46.1ms\tremaining: 40.1ms\n",
            "23:\tlearn: 0.2369058\ttotal: 47.9ms\tremaining: 37.9ms\n",
            "24:\tlearn: 0.2331119\ttotal: 49.8ms\tremaining: 35.9ms\n",
            "25:\tlearn: 0.2293455\ttotal: 51.7ms\tremaining: 33.8ms\n",
            "26:\tlearn: 0.2256418\ttotal: 53.5ms\tremaining: 31.7ms\n",
            "27:\tlearn: 0.2221119\ttotal: 55.4ms\tremaining: 29.7ms\n",
            "28:\tlearn: 0.2190925\ttotal: 57.2ms\tremaining: 27.6ms\n",
            "29:\tlearn: 0.2161731\ttotal: 59.1ms\tremaining: 25.6ms\n",
            "30:\tlearn: 0.2135041\ttotal: 61ms\tremaining: 23.6ms\n",
            "31:\tlearn: 0.2113382\ttotal: 62.9ms\tremaining: 21.6ms\n",
            "32:\tlearn: 0.2083485\ttotal: 64.9ms\tremaining: 19.7ms\n",
            "33:\tlearn: 0.2058588\ttotal: 67ms\tremaining: 17.7ms\n",
            "34:\tlearn: 0.2024895\ttotal: 69ms\tremaining: 15.8ms\n",
            "35:\tlearn: 0.1997586\ttotal: 71.2ms\tremaining: 13.8ms\n",
            "36:\tlearn: 0.1976953\ttotal: 74.9ms\tremaining: 12.1ms\n",
            "37:\tlearn: 0.1949453\ttotal: 76.6ms\tremaining: 10.1ms\n",
            "38:\tlearn: 0.1931445\ttotal: 78.7ms\tremaining: 8.07ms\n",
            "39:\tlearn: 0.1900292\ttotal: 80.6ms\tremaining: 6.04ms\n",
            "40:\tlearn: 0.1872454\ttotal: 82.5ms\tremaining: 4.02ms\n",
            "41:\tlearn: 0.1848207\ttotal: 84.5ms\tremaining: 2.01ms\n",
            "42:\tlearn: 0.1823519\ttotal: 86.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 4.8ms\tremaining: 202ms\n",
            "1:\tlearn: 0.4107278\ttotal: 5.39ms\tremaining: 111ms\n",
            "2:\tlearn: 0.3698157\ttotal: 6.1ms\tremaining: 81.3ms\n",
            "3:\tlearn: 0.3518120\ttotal: 8.2ms\tremaining: 79.9ms\n",
            "4:\tlearn: 0.3441195\ttotal: 10.2ms\tremaining: 77.6ms\n",
            "5:\tlearn: 0.3328396\ttotal: 12.2ms\tremaining: 75.3ms\n",
            "6:\tlearn: 0.3256704\ttotal: 14ms\tremaining: 71.9ms\n",
            "7:\tlearn: 0.3174441\ttotal: 15.9ms\tremaining: 69.4ms\n",
            "8:\tlearn: 0.3090762\ttotal: 17.7ms\tremaining: 67ms\n",
            "9:\tlearn: 0.3028459\ttotal: 19.7ms\tremaining: 64.9ms\n",
            "10:\tlearn: 0.2958541\ttotal: 21.5ms\tremaining: 62.5ms\n",
            "11:\tlearn: 0.2901166\ttotal: 23.4ms\tremaining: 60.4ms\n",
            "12:\tlearn: 0.2841803\ttotal: 25.3ms\tremaining: 58.4ms\n",
            "13:\tlearn: 0.2789751\ttotal: 27.3ms\tremaining: 56.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 29.3ms\tremaining: 54.7ms\n",
            "15:\tlearn: 0.2663544\ttotal: 31.3ms\tremaining: 52.9ms\n",
            "16:\tlearn: 0.2615546\ttotal: 33.4ms\tremaining: 51.1ms\n",
            "17:\tlearn: 0.2560079\ttotal: 35.4ms\tremaining: 49.2ms\n",
            "18:\tlearn: 0.2507480\ttotal: 37.3ms\tremaining: 47.2ms\n",
            "19:\tlearn: 0.2450678\ttotal: 39.3ms\tremaining: 45.2ms\n",
            "20:\tlearn: 0.2413892\ttotal: 41.2ms\tremaining: 43.2ms\n",
            "21:\tlearn: 0.2378437\ttotal: 43.2ms\tremaining: 41.2ms\n",
            "22:\tlearn: 0.2344010\ttotal: 45.2ms\tremaining: 39.3ms\n",
            "23:\tlearn: 0.2304940\ttotal: 47.1ms\tremaining: 37.3ms\n",
            "24:\tlearn: 0.2269540\ttotal: 49.2ms\tremaining: 35.4ms\n",
            "25:\tlearn: 0.2232713\ttotal: 51.1ms\tremaining: 33.4ms\n",
            "26:\tlearn: 0.2208577\ttotal: 53.1ms\tremaining: 31.5ms\n",
            "27:\tlearn: 0.2181825\ttotal: 55.2ms\tremaining: 29.6ms\n",
            "28:\tlearn: 0.2149071\ttotal: 57.3ms\tremaining: 27.7ms\n",
            "29:\tlearn: 0.2123638\ttotal: 59.3ms\tremaining: 25.7ms\n",
            "30:\tlearn: 0.2094640\ttotal: 61.3ms\tremaining: 23.7ms\n",
            "31:\tlearn: 0.2071716\ttotal: 63.3ms\tremaining: 21.7ms\n",
            "32:\tlearn: 0.2045371\ttotal: 65.4ms\tremaining: 19.8ms\n",
            "33:\tlearn: 0.2018712\ttotal: 67.4ms\tremaining: 17.8ms\n",
            "34:\tlearn: 0.1995442\ttotal: 69.3ms\tremaining: 15.8ms\n",
            "35:\tlearn: 0.1970515\ttotal: 71.3ms\tremaining: 13.9ms\n",
            "36:\tlearn: 0.1946725\ttotal: 73.3ms\tremaining: 11.9ms\n",
            "37:\tlearn: 0.1924392\ttotal: 75.3ms\tremaining: 9.9ms\n",
            "38:\tlearn: 0.1893508\ttotal: 77.2ms\tremaining: 7.92ms\n",
            "39:\tlearn: 0.1868097\ttotal: 79.2ms\tremaining: 5.94ms\n",
            "40:\tlearn: 0.1846310\ttotal: 81.2ms\tremaining: 3.96ms\n",
            "41:\tlearn: 0.1820837\ttotal: 83.2ms\tremaining: 1.98ms\n",
            "42:\tlearn: 0.1795780\ttotal: 88.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.82ms\tremaining: 76.7ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.47ms\tremaining: 50.7ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.37ms\tremaining: 58.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 6.4ms\tremaining: 62.4ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.33ms\tremaining: 63.3ms\n",
            "5:\tlearn: 0.2907443\ttotal: 10.3ms\tremaining: 63.3ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12ms\tremaining: 61.9ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.3ms\tremaining: 58.3ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15.3ms\tremaining: 57.7ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.2ms\tremaining: 56.9ms\n",
            "10:\tlearn: 0.2462992\ttotal: 19.1ms\tremaining: 55.7ms\n",
            "11:\tlearn: 0.2416348\ttotal: 21ms\tremaining: 54.3ms\n",
            "12:\tlearn: 0.2368688\ttotal: 22.9ms\tremaining: 52.8ms\n",
            "13:\tlearn: 0.2320170\ttotal: 24.9ms\tremaining: 51.6ms\n",
            "14:\tlearn: 0.2262186\ttotal: 27.1ms\tremaining: 50.6ms\n",
            "15:\tlearn: 0.2215380\ttotal: 29.1ms\tremaining: 49.1ms\n",
            "16:\tlearn: 0.2176313\ttotal: 31ms\tremaining: 47.5ms\n",
            "17:\tlearn: 0.2138494\ttotal: 32.9ms\tremaining: 45.6ms\n",
            "18:\tlearn: 0.2100966\ttotal: 34.6ms\tremaining: 43.7ms\n",
            "19:\tlearn: 0.2068557\ttotal: 36.8ms\tremaining: 42.3ms\n",
            "20:\tlearn: 0.2029945\ttotal: 39.1ms\tremaining: 41ms\n",
            "21:\tlearn: 0.2001044\ttotal: 43.1ms\tremaining: 41.1ms\n",
            "22:\tlearn: 0.1970766\ttotal: 45.5ms\tremaining: 39.5ms\n",
            "23:\tlearn: 0.1940285\ttotal: 49.4ms\tremaining: 39.1ms\n",
            "24:\tlearn: 0.1910934\ttotal: 52.6ms\tremaining: 37.8ms\n",
            "25:\tlearn: 0.1879112\ttotal: 54.6ms\tremaining: 35.7ms\n",
            "26:\tlearn: 0.1852765\ttotal: 56.8ms\tremaining: 33.7ms\n",
            "27:\tlearn: 0.1827068\ttotal: 58.9ms\tremaining: 31.5ms\n",
            "28:\tlearn: 0.1803359\ttotal: 60.8ms\tremaining: 29.4ms\n",
            "29:\tlearn: 0.1779549\ttotal: 62.8ms\tremaining: 27.2ms\n",
            "30:\tlearn: 0.1757984\ttotal: 64.8ms\tremaining: 25.1ms\n",
            "31:\tlearn: 0.1724570\ttotal: 66.9ms\tremaining: 23ms\n",
            "32:\tlearn: 0.1703672\ttotal: 68.9ms\tremaining: 20.9ms\n",
            "33:\tlearn: 0.1685175\ttotal: 70.9ms\tremaining: 18.8ms\n",
            "34:\tlearn: 0.1666049\ttotal: 73ms\tremaining: 16.7ms\n",
            "35:\tlearn: 0.1648374\ttotal: 75ms\tremaining: 14.6ms\n",
            "36:\tlearn: 0.1631656\ttotal: 77.1ms\tremaining: 12.5ms\n",
            "37:\tlearn: 0.1615072\ttotal: 79.1ms\tremaining: 10.4ms\n",
            "38:\tlearn: 0.1598928\ttotal: 81.1ms\tremaining: 8.32ms\n",
            "39:\tlearn: 0.1584040\ttotal: 83.3ms\tremaining: 6.24ms\n",
            "40:\tlearn: 0.1566573\ttotal: 85.2ms\tremaining: 4.16ms\n",
            "41:\tlearn: 0.1544748\ttotal: 87.1ms\tremaining: 2.07ms\n",
            "42:\tlearn: 0.1525493\ttotal: 89ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.63ms\tremaining: 68.6ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.22ms\tremaining: 45.6ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.94ms\tremaining: 39.1ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.82ms\tremaining: 47ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.73ms\tremaining: 51.2ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.57ms\tremaining: 52.9ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.4ms\tremaining: 53.3ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.4ms\tremaining: 54.3ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.5ms\tremaining: 54.6ms\n",
            "9:\tlearn: 0.2537973\ttotal: 16.6ms\tremaining: 54.7ms\n",
            "10:\tlearn: 0.2473429\ttotal: 18.6ms\tremaining: 54.2ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20.6ms\tremaining: 53.3ms\n",
            "12:\tlearn: 0.2366343\ttotal: 22.3ms\tremaining: 51.5ms\n",
            "13:\tlearn: 0.2298385\ttotal: 24.3ms\tremaining: 50.3ms\n",
            "14:\tlearn: 0.2249545\ttotal: 26.2ms\tremaining: 48.8ms\n",
            "15:\tlearn: 0.2192054\ttotal: 28.1ms\tremaining: 47.3ms\n",
            "16:\tlearn: 0.2150242\ttotal: 30.2ms\tremaining: 46.2ms\n",
            "17:\tlearn: 0.2094516\ttotal: 32.1ms\tremaining: 44.7ms\n",
            "18:\tlearn: 0.2056324\ttotal: 34ms\tremaining: 43ms\n",
            "19:\tlearn: 0.2021225\ttotal: 36ms\tremaining: 41.5ms\n",
            "20:\tlearn: 0.1989042\ttotal: 37.9ms\tremaining: 39.7ms\n",
            "21:\tlearn: 0.1961040\ttotal: 39.8ms\tremaining: 38ms\n",
            "22:\tlearn: 0.1934794\ttotal: 41.7ms\tremaining: 36.2ms\n",
            "23:\tlearn: 0.1902438\ttotal: 43.6ms\tremaining: 34.5ms\n",
            "24:\tlearn: 0.1874921\ttotal: 45.2ms\tremaining: 32.6ms\n",
            "25:\tlearn: 0.1829904\ttotal: 47.2ms\tremaining: 30.9ms\n",
            "26:\tlearn: 0.1804169\ttotal: 51ms\tremaining: 30.2ms\n",
            "27:\tlearn: 0.1776989\ttotal: 54.2ms\tremaining: 29ms\n",
            "28:\tlearn: 0.1751387\ttotal: 57.9ms\tremaining: 28ms\n",
            "29:\tlearn: 0.1727570\ttotal: 61ms\tremaining: 26.4ms\n",
            "30:\tlearn: 0.1693663\ttotal: 63ms\tremaining: 24.4ms\n",
            "31:\tlearn: 0.1661883\ttotal: 64.9ms\tremaining: 22.3ms\n",
            "32:\tlearn: 0.1641011\ttotal: 66.7ms\tremaining: 20.2ms\n",
            "33:\tlearn: 0.1616271\ttotal: 68.6ms\tremaining: 18.1ms\n",
            "34:\tlearn: 0.1593621\ttotal: 70.6ms\tremaining: 16.1ms\n",
            "35:\tlearn: 0.1576181\ttotal: 72.5ms\tremaining: 14.1ms\n",
            "36:\tlearn: 0.1557020\ttotal: 74.3ms\tremaining: 12ms\n",
            "37:\tlearn: 0.1541003\ttotal: 76.2ms\tremaining: 10ms\n",
            "38:\tlearn: 0.1522873\ttotal: 78.1ms\tremaining: 8.01ms\n",
            "39:\tlearn: 0.1502740\ttotal: 80.1ms\tremaining: 6ms\n",
            "40:\tlearn: 0.1483554\ttotal: 82ms\tremaining: 4ms\n",
            "41:\tlearn: 0.1465885\ttotal: 84.1ms\tremaining: 2ms\n",
            "42:\tlearn: 0.1443271\ttotal: 86.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.83ms\tremaining: 78.9ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.19ms\tremaining: 46ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.21ms\tremaining: 57.6ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.16ms\tremaining: 61.6ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.11ms\tremaining: 63.3ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.1ms\tremaining: 63.7ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.1ms\tremaining: 63.9ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14ms\tremaining: 62.9ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16ms\tremaining: 62.1ms\n",
            "9:\tlearn: 0.3054626\ttotal: 17.9ms\tremaining: 60.9ms\n",
            "10:\tlearn: 0.2983658\ttotal: 19.9ms\tremaining: 59.6ms\n",
            "11:\tlearn: 0.2903440\ttotal: 21.8ms\tremaining: 58.1ms\n",
            "12:\tlearn: 0.2852979\ttotal: 23.7ms\tremaining: 56.5ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.7ms\tremaining: 55.1ms\n",
            "14:\tlearn: 0.2747341\ttotal: 27.5ms\tremaining: 53.3ms\n",
            "15:\tlearn: 0.2702568\ttotal: 29.5ms\tremaining: 51.7ms\n",
            "16:\tlearn: 0.2650537\ttotal: 31.5ms\tremaining: 50ms\n",
            "17:\tlearn: 0.2601005\ttotal: 33.5ms\tremaining: 48.3ms\n",
            "18:\tlearn: 0.2560578\ttotal: 35.4ms\tremaining: 46.6ms\n",
            "19:\tlearn: 0.2530381\ttotal: 37.2ms\tremaining: 44.7ms\n",
            "20:\tlearn: 0.2498453\ttotal: 39.1ms\tremaining: 42.8ms\n",
            "21:\tlearn: 0.2461646\ttotal: 41.3ms\tremaining: 41.3ms\n",
            "22:\tlearn: 0.2424369\ttotal: 43.4ms\tremaining: 39.6ms\n",
            "23:\tlearn: 0.2392835\ttotal: 45.2ms\tremaining: 37.7ms\n",
            "24:\tlearn: 0.2339070\ttotal: 47.2ms\tremaining: 35.9ms\n",
            "25:\tlearn: 0.2301706\ttotal: 49ms\tremaining: 33.9ms\n",
            "26:\tlearn: 0.2263007\ttotal: 50.9ms\tremaining: 32.1ms\n",
            "27:\tlearn: 0.2223209\ttotal: 52.8ms\tremaining: 30.2ms\n",
            "28:\tlearn: 0.2190932\ttotal: 54.7ms\tremaining: 28.3ms\n",
            "29:\tlearn: 0.2159010\ttotal: 56.6ms\tremaining: 26.4ms\n",
            "30:\tlearn: 0.2132954\ttotal: 58.5ms\tremaining: 24.5ms\n",
            "31:\tlearn: 0.2102299\ttotal: 60.5ms\tremaining: 22.7ms\n",
            "32:\tlearn: 0.2076280\ttotal: 62.4ms\tremaining: 20.8ms\n",
            "33:\tlearn: 0.2043188\ttotal: 64.2ms\tremaining: 18.9ms\n",
            "34:\tlearn: 0.2017849\ttotal: 66.3ms\tremaining: 17ms\n",
            "35:\tlearn: 0.1993718\ttotal: 68.2ms\tremaining: 15.2ms\n",
            "36:\tlearn: 0.1972299\ttotal: 70.1ms\tremaining: 13.3ms\n",
            "37:\tlearn: 0.1950197\ttotal: 72ms\tremaining: 11.4ms\n",
            "38:\tlearn: 0.1927135\ttotal: 74ms\tremaining: 9.48ms\n",
            "39:\tlearn: 0.1895038\ttotal: 75.6ms\tremaining: 7.55ms\n",
            "40:\tlearn: 0.1867644\ttotal: 77.4ms\tremaining: 5.66ms\n",
            "41:\tlearn: 0.1842014\ttotal: 79.3ms\tremaining: 3.77ms\n",
            "42:\tlearn: 0.1821212\ttotal: 81ms\tremaining: 1.88ms\n",
            "43:\tlearn: 0.1794173\ttotal: 82.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 2.03ms\tremaining: 87.2ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.66ms\tremaining: 55.9ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.79ms\tremaining: 65.5ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.97ms\tremaining: 69.7ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.92ms\tremaining: 61.8ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.87ms\tremaining: 56.2ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10.8ms\tremaining: 57.3ms\n",
            "7:\tlearn: 0.3097739\ttotal: 13ms\tremaining: 58.5ms\n",
            "8:\tlearn: 0.3040041\ttotal: 15.1ms\tremaining: 58.6ms\n",
            "9:\tlearn: 0.2975585\ttotal: 17.2ms\tremaining: 58.4ms\n",
            "10:\tlearn: 0.2898709\ttotal: 19.3ms\tremaining: 57.8ms\n",
            "11:\tlearn: 0.2845372\ttotal: 21.3ms\tremaining: 56.9ms\n",
            "12:\tlearn: 0.2794184\ttotal: 23.4ms\tremaining: 55.9ms\n",
            "13:\tlearn: 0.2740314\ttotal: 25.5ms\tremaining: 54.7ms\n",
            "14:\tlearn: 0.2705542\ttotal: 27.7ms\tremaining: 53.6ms\n",
            "15:\tlearn: 0.2673919\ttotal: 29.9ms\tremaining: 52.3ms\n",
            "16:\tlearn: 0.2623365\ttotal: 32.9ms\tremaining: 52.3ms\n",
            "17:\tlearn: 0.2595719\ttotal: 36.3ms\tremaining: 52.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 42.5ms\tremaining: 55.9ms\n",
            "19:\tlearn: 0.2510766\ttotal: 45.3ms\tremaining: 54.4ms\n",
            "20:\tlearn: 0.2477056\ttotal: 47.2ms\tremaining: 51.7ms\n",
            "21:\tlearn: 0.2437884\ttotal: 49.3ms\tremaining: 49.3ms\n",
            "22:\tlearn: 0.2404080\ttotal: 51.4ms\tremaining: 47ms\n",
            "23:\tlearn: 0.2369058\ttotal: 53.5ms\tremaining: 44.6ms\n",
            "24:\tlearn: 0.2331119\ttotal: 55.7ms\tremaining: 42.3ms\n",
            "25:\tlearn: 0.2293455\ttotal: 57.9ms\tremaining: 40.1ms\n",
            "26:\tlearn: 0.2256418\ttotal: 59.9ms\tremaining: 37.7ms\n",
            "27:\tlearn: 0.2221119\ttotal: 62ms\tremaining: 35.4ms\n",
            "28:\tlearn: 0.2190925\ttotal: 64ms\tremaining: 33.1ms\n",
            "29:\tlearn: 0.2161731\ttotal: 66.1ms\tremaining: 30.9ms\n",
            "30:\tlearn: 0.2135041\ttotal: 68.4ms\tremaining: 28.7ms\n",
            "31:\tlearn: 0.2113382\ttotal: 70.5ms\tremaining: 26.5ms\n",
            "32:\tlearn: 0.2083485\ttotal: 72.7ms\tremaining: 24.2ms\n",
            "33:\tlearn: 0.2058588\ttotal: 74.8ms\tremaining: 22ms\n",
            "34:\tlearn: 0.2024895\ttotal: 76.8ms\tremaining: 19.8ms\n",
            "35:\tlearn: 0.1997586\ttotal: 78.8ms\tremaining: 17.5ms\n",
            "36:\tlearn: 0.1976953\ttotal: 80.9ms\tremaining: 15.3ms\n",
            "37:\tlearn: 0.1949453\ttotal: 83ms\tremaining: 13.1ms\n",
            "38:\tlearn: 0.1931445\ttotal: 85.2ms\tremaining: 10.9ms\n",
            "39:\tlearn: 0.1900292\ttotal: 87.4ms\tremaining: 8.74ms\n",
            "40:\tlearn: 0.1872454\ttotal: 89.7ms\tremaining: 6.56ms\n",
            "41:\tlearn: 0.1848207\ttotal: 91.9ms\tremaining: 4.37ms\n",
            "42:\tlearn: 0.1823519\ttotal: 94ms\tremaining: 2.19ms\n",
            "43:\tlearn: 0.1801956\ttotal: 96.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.88ms\tremaining: 80.6ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.3ms\tremaining: 48.3ms\n",
            "2:\tlearn: 0.3698157\ttotal: 3.1ms\tremaining: 42.4ms\n",
            "3:\tlearn: 0.3518120\ttotal: 5.23ms\tremaining: 52.3ms\n",
            "4:\tlearn: 0.3441195\ttotal: 7.29ms\tremaining: 56.9ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.34ms\tremaining: 59.2ms\n",
            "6:\tlearn: 0.3256704\ttotal: 11.4ms\tremaining: 60.3ms\n",
            "7:\tlearn: 0.3174441\ttotal: 13.5ms\tremaining: 60.6ms\n",
            "8:\tlearn: 0.3090762\ttotal: 15.7ms\tremaining: 61.2ms\n",
            "9:\tlearn: 0.3028459\ttotal: 17.9ms\tremaining: 60.7ms\n",
            "10:\tlearn: 0.2958541\ttotal: 20ms\tremaining: 59.9ms\n",
            "11:\tlearn: 0.2901166\ttotal: 22.1ms\tremaining: 59ms\n",
            "12:\tlearn: 0.2841803\ttotal: 24.4ms\tremaining: 58.1ms\n",
            "13:\tlearn: 0.2789751\ttotal: 26.7ms\tremaining: 57.2ms\n",
            "14:\tlearn: 0.2715599\ttotal: 29.1ms\tremaining: 56.2ms\n",
            "15:\tlearn: 0.2663544\ttotal: 31.5ms\tremaining: 55.1ms\n",
            "16:\tlearn: 0.2615546\ttotal: 33.9ms\tremaining: 53.8ms\n",
            "17:\tlearn: 0.2560079\ttotal: 36.3ms\tremaining: 52.4ms\n",
            "18:\tlearn: 0.2507480\ttotal: 38.5ms\tremaining: 50.7ms\n",
            "19:\tlearn: 0.2450678\ttotal: 40.8ms\tremaining: 49ms\n",
            "20:\tlearn: 0.2413892\ttotal: 43.1ms\tremaining: 47.2ms\n",
            "21:\tlearn: 0.2378437\ttotal: 45.4ms\tremaining: 45.4ms\n",
            "22:\tlearn: 0.2344010\ttotal: 47.7ms\tremaining: 43.6ms\n",
            "23:\tlearn: 0.2304940\ttotal: 50ms\tremaining: 41.7ms\n",
            "24:\tlearn: 0.2269540\ttotal: 52.4ms\tremaining: 39.8ms\n",
            "25:\tlearn: 0.2232713\ttotal: 54.7ms\tremaining: 37.8ms\n",
            "26:\tlearn: 0.2208577\ttotal: 57.1ms\tremaining: 36ms\n",
            "27:\tlearn: 0.2181825\ttotal: 59.5ms\tremaining: 34ms\n",
            "28:\tlearn: 0.2149071\ttotal: 61.9ms\tremaining: 32ms\n",
            "29:\tlearn: 0.2123638\ttotal: 64.2ms\tremaining: 30ms\n",
            "30:\tlearn: 0.2094640\ttotal: 66.5ms\tremaining: 27.9ms\n",
            "31:\tlearn: 0.2071716\ttotal: 68.8ms\tremaining: 25.8ms\n",
            "32:\tlearn: 0.2045371\ttotal: 71.2ms\tremaining: 23.7ms\n",
            "33:\tlearn: 0.2018712\ttotal: 73.5ms\tremaining: 21.6ms\n",
            "34:\tlearn: 0.1995442\ttotal: 75.9ms\tremaining: 19.5ms\n",
            "35:\tlearn: 0.1970515\ttotal: 78.2ms\tremaining: 17.4ms\n",
            "36:\tlearn: 0.1946725\ttotal: 80.5ms\tremaining: 15.2ms\n",
            "37:\tlearn: 0.1924392\ttotal: 82.8ms\tremaining: 13.1ms\n",
            "38:\tlearn: 0.1893508\ttotal: 85ms\tremaining: 10.9ms\n",
            "39:\tlearn: 0.1868097\ttotal: 87.3ms\tremaining: 8.73ms\n",
            "40:\tlearn: 0.1846310\ttotal: 89.6ms\tremaining: 6.55ms\n",
            "41:\tlearn: 0.1820837\ttotal: 91.9ms\tremaining: 4.37ms\n",
            "42:\tlearn: 0.1795780\ttotal: 94.3ms\tremaining: 2.19ms\n",
            "43:\tlearn: 0.1777006\ttotal: 96.6ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.8ms\tremaining: 77.6ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.64ms\tremaining: 55.5ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.67ms\tremaining: 63.9ms\n",
            "3:\tlearn: 0.3266560\ttotal: 6.79ms\tremaining: 67.9ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.92ms\tremaining: 69.6ms\n",
            "5:\tlearn: 0.2907443\ttotal: 11.1ms\tremaining: 70.4ms\n",
            "6:\tlearn: 0.2818467\ttotal: 13.1ms\tremaining: 69ms\n",
            "7:\tlearn: 0.2691784\ttotal: 14.5ms\tremaining: 65.2ms\n",
            "8:\tlearn: 0.2611618\ttotal: 16.6ms\tremaining: 64.4ms\n",
            "9:\tlearn: 0.2519898\ttotal: 18.7ms\tremaining: 63.5ms\n",
            "10:\tlearn: 0.2462992\ttotal: 20.7ms\tremaining: 62.2ms\n",
            "11:\tlearn: 0.2416348\ttotal: 22.7ms\tremaining: 60.6ms\n",
            "12:\tlearn: 0.2368688\ttotal: 24.7ms\tremaining: 58.9ms\n",
            "13:\tlearn: 0.2320170\ttotal: 26.8ms\tremaining: 57.5ms\n",
            "14:\tlearn: 0.2262186\ttotal: 28.8ms\tremaining: 55.8ms\n",
            "15:\tlearn: 0.2215380\ttotal: 31ms\tremaining: 54.2ms\n",
            "16:\tlearn: 0.2176313\ttotal: 33ms\tremaining: 52.5ms\n",
            "17:\tlearn: 0.2138494\ttotal: 36.1ms\tremaining: 52.2ms\n",
            "18:\tlearn: 0.2100966\ttotal: 38ms\tremaining: 50ms\n",
            "19:\tlearn: 0.2068557\ttotal: 39.9ms\tremaining: 47.9ms\n",
            "20:\tlearn: 0.2029945\ttotal: 42ms\tremaining: 46ms\n",
            "21:\tlearn: 0.2001044\ttotal: 44ms\tremaining: 44ms\n",
            "22:\tlearn: 0.1970766\ttotal: 46ms\tremaining: 42ms\n",
            "23:\tlearn: 0.1940285\ttotal: 48ms\tremaining: 40ms\n",
            "24:\tlearn: 0.1910934\ttotal: 50.1ms\tremaining: 38.1ms\n",
            "25:\tlearn: 0.1879112\ttotal: 52.1ms\tremaining: 36.1ms\n",
            "26:\tlearn: 0.1852765\ttotal: 54.3ms\tremaining: 34.2ms\n",
            "27:\tlearn: 0.1827068\ttotal: 56.3ms\tremaining: 32.2ms\n",
            "28:\tlearn: 0.1803359\ttotal: 58.3ms\tremaining: 30.2ms\n",
            "29:\tlearn: 0.1779549\ttotal: 60.4ms\tremaining: 28.2ms\n",
            "30:\tlearn: 0.1757984\ttotal: 62.4ms\tremaining: 26.2ms\n",
            "31:\tlearn: 0.1724570\ttotal: 64.4ms\tremaining: 24.2ms\n",
            "32:\tlearn: 0.1703672\ttotal: 66.3ms\tremaining: 22.1ms\n",
            "33:\tlearn: 0.1685175\ttotal: 68.4ms\tremaining: 20.1ms\n",
            "34:\tlearn: 0.1666049\ttotal: 70.4ms\tremaining: 18.1ms\n",
            "35:\tlearn: 0.1648374\ttotal: 72.3ms\tremaining: 16.1ms\n",
            "36:\tlearn: 0.1631656\ttotal: 74.2ms\tremaining: 14ms\n",
            "37:\tlearn: 0.1615072\ttotal: 76.1ms\tremaining: 12ms\n",
            "38:\tlearn: 0.1598928\ttotal: 78.9ms\tremaining: 10.1ms\n",
            "39:\tlearn: 0.1584040\ttotal: 81ms\tremaining: 8.1ms\n",
            "40:\tlearn: 0.1566573\ttotal: 82.8ms\tremaining: 6.06ms\n",
            "41:\tlearn: 0.1544748\ttotal: 84.7ms\tremaining: 4.03ms\n",
            "42:\tlearn: 0.1525493\ttotal: 86.6ms\tremaining: 2.01ms\n",
            "43:\tlearn: 0.1506610\ttotal: 88.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.67ms\tremaining: 71.6ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.3ms\tremaining: 48.3ms\n",
            "2:\tlearn: 0.3203557\ttotal: 3ms\tremaining: 41ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.85ms\tremaining: 48.5ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.76ms\tremaining: 52.7ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.61ms\tremaining: 54.5ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.5ms\tremaining: 55.7ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.5ms\tremaining: 56.3ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.4ms\tremaining: 56.2ms\n",
            "9:\tlearn: 0.2537973\ttotal: 16.4ms\tremaining: 55.8ms\n",
            "10:\tlearn: 0.2473429\ttotal: 18.4ms\tremaining: 55.2ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20.2ms\tremaining: 54ms\n",
            "12:\tlearn: 0.2366343\ttotal: 22.1ms\tremaining: 52.8ms\n",
            "13:\tlearn: 0.2298385\ttotal: 24.1ms\tremaining: 51.7ms\n",
            "14:\tlearn: 0.2249545\ttotal: 26.1ms\tremaining: 50.5ms\n",
            "15:\tlearn: 0.2192054\ttotal: 28.1ms\tremaining: 49.2ms\n",
            "16:\tlearn: 0.2150242\ttotal: 30ms\tremaining: 47.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 32.1ms\tremaining: 46.4ms\n",
            "18:\tlearn: 0.2056324\ttotal: 34.3ms\tremaining: 45.2ms\n",
            "19:\tlearn: 0.2021225\ttotal: 36ms\tremaining: 43.3ms\n",
            "20:\tlearn: 0.1989042\ttotal: 37.9ms\tremaining: 41.5ms\n",
            "21:\tlearn: 0.1961040\ttotal: 41ms\tremaining: 41ms\n",
            "22:\tlearn: 0.1934794\ttotal: 43.7ms\tremaining: 39.9ms\n",
            "23:\tlearn: 0.1902438\ttotal: 48.7ms\tremaining: 40.6ms\n",
            "24:\tlearn: 0.1874921\ttotal: 53.4ms\tremaining: 40.6ms\n",
            "25:\tlearn: 0.1829904\ttotal: 58.3ms\tremaining: 40.4ms\n",
            "26:\tlearn: 0.1804169\ttotal: 61.5ms\tremaining: 38.7ms\n",
            "27:\tlearn: 0.1776989\ttotal: 63.5ms\tremaining: 36.3ms\n",
            "28:\tlearn: 0.1751387\ttotal: 65.2ms\tremaining: 33.7ms\n",
            "29:\tlearn: 0.1727570\ttotal: 67ms\tremaining: 31.3ms\n",
            "30:\tlearn: 0.1693663\ttotal: 68.9ms\tremaining: 28.9ms\n",
            "31:\tlearn: 0.1661883\ttotal: 70.8ms\tremaining: 26.5ms\n",
            "32:\tlearn: 0.1641011\ttotal: 72.7ms\tremaining: 24.2ms\n",
            "33:\tlearn: 0.1616271\ttotal: 74.6ms\tremaining: 21.9ms\n",
            "34:\tlearn: 0.1593621\ttotal: 76.5ms\tremaining: 19.7ms\n",
            "35:\tlearn: 0.1576181\ttotal: 79.1ms\tremaining: 17.6ms\n",
            "36:\tlearn: 0.1557020\ttotal: 82.9ms\tremaining: 15.7ms\n",
            "37:\tlearn: 0.1541003\ttotal: 85.8ms\tremaining: 13.5ms\n",
            "38:\tlearn: 0.1522873\ttotal: 88.5ms\tremaining: 11.3ms\n",
            "39:\tlearn: 0.1502740\ttotal: 92.4ms\tremaining: 9.24ms\n",
            "40:\tlearn: 0.1483554\ttotal: 96.4ms\tremaining: 7.05ms\n",
            "41:\tlearn: 0.1465885\ttotal: 98.3ms\tremaining: 4.68ms\n",
            "42:\tlearn: 0.1443271\ttotal: 100ms\tremaining: 2.33ms\n",
            "43:\tlearn: 0.1425567\ttotal: 102ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.68ms\tremaining: 74ms\n",
            "1:\tlearn: 0.4229987\ttotal: 3.1ms\tremaining: 66.7ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.76ms\tremaining: 66.7ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.69ms\tremaining: 68.6ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.62ms\tremaining: 69ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.7ms\tremaining: 69.3ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.6ms\tremaining: 68.6ms\n",
            "7:\tlearn: 0.3229079\ttotal: 15.7ms\tremaining: 72.8ms\n",
            "8:\tlearn: 0.3148279\ttotal: 17.9ms\tremaining: 71.7ms\n",
            "9:\tlearn: 0.3054626\ttotal: 19.9ms\tremaining: 69.6ms\n",
            "10:\tlearn: 0.2983658\ttotal: 21.8ms\tremaining: 67.5ms\n",
            "11:\tlearn: 0.2903440\ttotal: 24.2ms\tremaining: 66.5ms\n",
            "12:\tlearn: 0.2852979\ttotal: 27ms\tremaining: 66.5ms\n",
            "13:\tlearn: 0.2798563\ttotal: 28.7ms\tremaining: 63.5ms\n",
            "14:\tlearn: 0.2747341\ttotal: 30.4ms\tremaining: 60.9ms\n",
            "15:\tlearn: 0.2702568\ttotal: 32.4ms\tremaining: 58.7ms\n",
            "16:\tlearn: 0.2650537\ttotal: 34.3ms\tremaining: 56.4ms\n",
            "17:\tlearn: 0.2601005\ttotal: 36.3ms\tremaining: 54.4ms\n",
            "18:\tlearn: 0.2560578\ttotal: 38.2ms\tremaining: 52.2ms\n",
            "19:\tlearn: 0.2530381\ttotal: 40ms\tremaining: 50ms\n",
            "20:\tlearn: 0.2498453\ttotal: 41.9ms\tremaining: 47.9ms\n",
            "21:\tlearn: 0.2461646\ttotal: 43.8ms\tremaining: 45.8ms\n",
            "22:\tlearn: 0.2424369\ttotal: 46ms\tremaining: 44ms\n",
            "23:\tlearn: 0.2392835\ttotal: 47.9ms\tremaining: 41.9ms\n",
            "24:\tlearn: 0.2339070\ttotal: 49.9ms\tremaining: 39.9ms\n",
            "25:\tlearn: 0.2301706\ttotal: 52ms\tremaining: 38ms\n",
            "26:\tlearn: 0.2263007\ttotal: 55ms\tremaining: 36.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 57.1ms\tremaining: 34.7ms\n",
            "28:\tlearn: 0.2190932\ttotal: 59.1ms\tremaining: 32.6ms\n",
            "29:\tlearn: 0.2159010\ttotal: 61.1ms\tremaining: 30.5ms\n",
            "30:\tlearn: 0.2132954\ttotal: 63.1ms\tremaining: 28.5ms\n",
            "31:\tlearn: 0.2102299\ttotal: 65.2ms\tremaining: 26.5ms\n",
            "32:\tlearn: 0.2076280\ttotal: 67.2ms\tremaining: 24.4ms\n",
            "33:\tlearn: 0.2043188\ttotal: 69.2ms\tremaining: 22.4ms\n",
            "34:\tlearn: 0.2017849\ttotal: 71.2ms\tremaining: 20.3ms\n",
            "35:\tlearn: 0.1993718\ttotal: 73.1ms\tremaining: 18.3ms\n",
            "36:\tlearn: 0.1972299\ttotal: 75.1ms\tremaining: 16.2ms\n",
            "37:\tlearn: 0.1950197\ttotal: 77.1ms\tremaining: 14.2ms\n",
            "38:\tlearn: 0.1927135\ttotal: 79ms\tremaining: 12.2ms\n",
            "39:\tlearn: 0.1895038\ttotal: 80.9ms\tremaining: 10.1ms\n",
            "40:\tlearn: 0.1867644\ttotal: 83ms\tremaining: 8.1ms\n",
            "41:\tlearn: 0.1842014\ttotal: 84.8ms\tremaining: 6.06ms\n",
            "42:\tlearn: 0.1821212\ttotal: 86.8ms\tremaining: 4.04ms\n",
            "43:\tlearn: 0.1794173\ttotal: 88.8ms\tremaining: 2.02ms\n",
            "44:\tlearn: 0.1766213\ttotal: 90.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.77ms\tremaining: 77.7ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.39ms\tremaining: 51.4ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.38ms\tremaining: 61.3ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.1ms\tremaining: 62.5ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.03ms\tremaining: 56.3ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.99ms\tremaining: 51.9ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10ms\tremaining: 54.5ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12ms\tremaining: 55.4ms\n",
            "8:\tlearn: 0.3040041\ttotal: 14ms\tremaining: 55.9ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.9ms\tremaining: 55.7ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17.7ms\tremaining: 54.8ms\n",
            "11:\tlearn: 0.2845372\ttotal: 19.7ms\tremaining: 54.3ms\n",
            "12:\tlearn: 0.2794184\ttotal: 21.9ms\tremaining: 53.9ms\n",
            "13:\tlearn: 0.2740314\ttotal: 23.9ms\tremaining: 52.8ms\n",
            "14:\tlearn: 0.2705542\ttotal: 25.8ms\tremaining: 51.7ms\n",
            "15:\tlearn: 0.2673919\ttotal: 27.8ms\tremaining: 50.3ms\n",
            "16:\tlearn: 0.2623365\ttotal: 30.2ms\tremaining: 49.7ms\n",
            "17:\tlearn: 0.2595719\ttotal: 34.3ms\tremaining: 51.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 37.4ms\tremaining: 51.2ms\n",
            "19:\tlearn: 0.2510766\ttotal: 40.3ms\tremaining: 50.3ms\n",
            "20:\tlearn: 0.2477056\ttotal: 42.2ms\tremaining: 48.2ms\n",
            "21:\tlearn: 0.2437884\ttotal: 44.2ms\tremaining: 46.3ms\n",
            "22:\tlearn: 0.2404080\ttotal: 46.2ms\tremaining: 44.2ms\n",
            "23:\tlearn: 0.2369058\ttotal: 48.2ms\tremaining: 42.2ms\n",
            "24:\tlearn: 0.2331119\ttotal: 50.1ms\tremaining: 40.1ms\n",
            "25:\tlearn: 0.2293455\ttotal: 52ms\tremaining: 38ms\n",
            "26:\tlearn: 0.2256418\ttotal: 54.1ms\tremaining: 36ms\n",
            "27:\tlearn: 0.2221119\ttotal: 56ms\tremaining: 34ms\n",
            "28:\tlearn: 0.2190925\ttotal: 58ms\tremaining: 32ms\n",
            "29:\tlearn: 0.2161731\ttotal: 60ms\tremaining: 30ms\n",
            "30:\tlearn: 0.2135041\ttotal: 62ms\tremaining: 28ms\n",
            "31:\tlearn: 0.2113382\ttotal: 64ms\tremaining: 26ms\n",
            "32:\tlearn: 0.2083485\ttotal: 66ms\tremaining: 24ms\n",
            "33:\tlearn: 0.2058588\ttotal: 68ms\tremaining: 22ms\n",
            "34:\tlearn: 0.2024895\ttotal: 69.9ms\tremaining: 20ms\n",
            "35:\tlearn: 0.1997586\ttotal: 71.8ms\tremaining: 17.9ms\n",
            "36:\tlearn: 0.1976953\ttotal: 73.7ms\tremaining: 15.9ms\n",
            "37:\tlearn: 0.1949453\ttotal: 75.6ms\tremaining: 13.9ms\n",
            "38:\tlearn: 0.1931445\ttotal: 77.6ms\tremaining: 11.9ms\n",
            "39:\tlearn: 0.1900292\ttotal: 79.6ms\tremaining: 9.95ms\n",
            "40:\tlearn: 0.1872454\ttotal: 81.5ms\tremaining: 7.95ms\n",
            "41:\tlearn: 0.1848207\ttotal: 83.6ms\tremaining: 5.97ms\n",
            "42:\tlearn: 0.1823519\ttotal: 85.5ms\tremaining: 3.98ms\n",
            "43:\tlearn: 0.1801956\ttotal: 87.5ms\tremaining: 1.99ms\n",
            "44:\tlearn: 0.1784734\ttotal: 89.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.57ms\tremaining: 69.3ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.19ms\tremaining: 47.2ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.92ms\tremaining: 40.9ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.87ms\tremaining: 49.9ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.9ms\tremaining: 55.2ms\n",
            "5:\tlearn: 0.3328396\ttotal: 8.84ms\tremaining: 57.5ms\n",
            "6:\tlearn: 0.3256704\ttotal: 10.7ms\tremaining: 58ms\n",
            "7:\tlearn: 0.3174441\ttotal: 12.5ms\tremaining: 57.8ms\n",
            "8:\tlearn: 0.3090762\ttotal: 14.3ms\tremaining: 57.3ms\n",
            "9:\tlearn: 0.3028459\ttotal: 16.4ms\tremaining: 57.2ms\n",
            "10:\tlearn: 0.2958541\ttotal: 19.3ms\tremaining: 59.6ms\n",
            "11:\tlearn: 0.2901166\ttotal: 21.5ms\tremaining: 59.1ms\n",
            "12:\tlearn: 0.2841803\ttotal: 23.2ms\tremaining: 57.1ms\n",
            "13:\tlearn: 0.2789751\ttotal: 25.1ms\tremaining: 55.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 27.2ms\tremaining: 54.4ms\n",
            "15:\tlearn: 0.2663544\ttotal: 29.1ms\tremaining: 52.7ms\n",
            "16:\tlearn: 0.2615546\ttotal: 31ms\tremaining: 51.1ms\n",
            "17:\tlearn: 0.2560079\ttotal: 33ms\tremaining: 49.6ms\n",
            "18:\tlearn: 0.2507480\ttotal: 35ms\tremaining: 47.8ms\n",
            "19:\tlearn: 0.2450678\ttotal: 36.9ms\tremaining: 46.1ms\n",
            "20:\tlearn: 0.2413892\ttotal: 38.7ms\tremaining: 44.3ms\n",
            "21:\tlearn: 0.2378437\ttotal: 40.7ms\tremaining: 42.5ms\n",
            "22:\tlearn: 0.2344010\ttotal: 42.5ms\tremaining: 40.6ms\n",
            "23:\tlearn: 0.2304940\ttotal: 44.3ms\tremaining: 38.8ms\n",
            "24:\tlearn: 0.2269540\ttotal: 46.3ms\tremaining: 37.1ms\n",
            "25:\tlearn: 0.2232713\ttotal: 48.1ms\tremaining: 35.2ms\n",
            "26:\tlearn: 0.2208577\ttotal: 50.1ms\tremaining: 33.4ms\n",
            "27:\tlearn: 0.2181825\ttotal: 52.2ms\tremaining: 31.7ms\n",
            "28:\tlearn: 0.2149071\ttotal: 54.2ms\tremaining: 29.9ms\n",
            "29:\tlearn: 0.2123638\ttotal: 56.2ms\tremaining: 28.1ms\n",
            "30:\tlearn: 0.2094640\ttotal: 58.2ms\tremaining: 26.3ms\n",
            "31:\tlearn: 0.2071716\ttotal: 60.1ms\tremaining: 24.4ms\n",
            "32:\tlearn: 0.2045371\ttotal: 62ms\tremaining: 22.5ms\n",
            "33:\tlearn: 0.2018712\ttotal: 63.9ms\tremaining: 20.7ms\n",
            "34:\tlearn: 0.1995442\ttotal: 66ms\tremaining: 18.9ms\n",
            "35:\tlearn: 0.1970515\ttotal: 68ms\tremaining: 17ms\n",
            "36:\tlearn: 0.1946725\ttotal: 69.9ms\tremaining: 15.1ms\n",
            "37:\tlearn: 0.1924392\ttotal: 71.9ms\tremaining: 13.2ms\n",
            "38:\tlearn: 0.1893508\ttotal: 74ms\tremaining: 11.4ms\n",
            "39:\tlearn: 0.1868097\ttotal: 76ms\tremaining: 9.5ms\n",
            "40:\tlearn: 0.1846310\ttotal: 77.9ms\tremaining: 7.6ms\n",
            "41:\tlearn: 0.1820837\ttotal: 79.8ms\tremaining: 5.7ms\n",
            "42:\tlearn: 0.1795780\ttotal: 81.8ms\tremaining: 3.81ms\n",
            "43:\tlearn: 0.1777006\ttotal: 83.8ms\tremaining: 1.91ms\n",
            "44:\tlearn: 0.1761110\ttotal: 85.7ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 4.81ms\tremaining: 212ms\n",
            "1:\tlearn: 0.3745079\ttotal: 5.55ms\tremaining: 119ms\n",
            "2:\tlearn: 0.3383999\ttotal: 8.59ms\tremaining: 120ms\n",
            "3:\tlearn: 0.3266560\ttotal: 10.9ms\tremaining: 112ms\n",
            "4:\tlearn: 0.3080259\ttotal: 13.1ms\tremaining: 105ms\n",
            "5:\tlearn: 0.2907443\ttotal: 15.1ms\tremaining: 98.1ms\n",
            "6:\tlearn: 0.2818467\ttotal: 17.1ms\tremaining: 92.6ms\n",
            "7:\tlearn: 0.2691784\ttotal: 18.4ms\tremaining: 84.9ms\n",
            "8:\tlearn: 0.2611618\ttotal: 20.4ms\tremaining: 81.4ms\n",
            "9:\tlearn: 0.2519898\ttotal: 22.4ms\tremaining: 78.4ms\n",
            "10:\tlearn: 0.2462992\ttotal: 24.5ms\tremaining: 75.6ms\n",
            "11:\tlearn: 0.2416348\ttotal: 28.6ms\tremaining: 78.8ms\n",
            "12:\tlearn: 0.2368688\ttotal: 31ms\tremaining: 76.4ms\n",
            "13:\tlearn: 0.2320170\ttotal: 33.1ms\tremaining: 73.3ms\n",
            "14:\tlearn: 0.2262186\ttotal: 35.1ms\tremaining: 70.2ms\n",
            "15:\tlearn: 0.2215380\ttotal: 37.1ms\tremaining: 67.3ms\n",
            "16:\tlearn: 0.2176313\ttotal: 39.3ms\tremaining: 64.6ms\n",
            "17:\tlearn: 0.2138494\ttotal: 41.2ms\tremaining: 61.8ms\n",
            "18:\tlearn: 0.2100966\ttotal: 43.1ms\tremaining: 59ms\n",
            "19:\tlearn: 0.2068557\ttotal: 45ms\tremaining: 56.3ms\n",
            "20:\tlearn: 0.2029945\ttotal: 47.1ms\tremaining: 53.8ms\n",
            "21:\tlearn: 0.2001044\ttotal: 49ms\tremaining: 51.2ms\n",
            "22:\tlearn: 0.1970766\ttotal: 51ms\tremaining: 48.7ms\n",
            "23:\tlearn: 0.1940285\ttotal: 52.9ms\tremaining: 46.3ms\n",
            "24:\tlearn: 0.1910934\ttotal: 54.9ms\tremaining: 43.9ms\n",
            "25:\tlearn: 0.1879112\ttotal: 56.9ms\tremaining: 41.6ms\n",
            "26:\tlearn: 0.1852765\ttotal: 59.1ms\tremaining: 39.4ms\n",
            "27:\tlearn: 0.1827068\ttotal: 61.2ms\tremaining: 37.2ms\n",
            "28:\tlearn: 0.1803359\ttotal: 63.1ms\tremaining: 34.8ms\n",
            "29:\tlearn: 0.1779549\ttotal: 65ms\tremaining: 32.5ms\n",
            "30:\tlearn: 0.1757984\ttotal: 66.8ms\tremaining: 30.2ms\n",
            "31:\tlearn: 0.1724570\ttotal: 68.8ms\tremaining: 28ms\n",
            "32:\tlearn: 0.1703672\ttotal: 70.8ms\tremaining: 25.7ms\n",
            "33:\tlearn: 0.1685175\ttotal: 72.6ms\tremaining: 23.5ms\n",
            "34:\tlearn: 0.1666049\ttotal: 74.5ms\tremaining: 21.3ms\n",
            "35:\tlearn: 0.1648374\ttotal: 76.3ms\tremaining: 19.1ms\n",
            "36:\tlearn: 0.1631656\ttotal: 78.2ms\tremaining: 16.9ms\n",
            "37:\tlearn: 0.1615072\ttotal: 80.2ms\tremaining: 14.8ms\n",
            "38:\tlearn: 0.1598928\ttotal: 82.1ms\tremaining: 12.6ms\n",
            "39:\tlearn: 0.1584040\ttotal: 84ms\tremaining: 10.5ms\n",
            "40:\tlearn: 0.1566573\ttotal: 86ms\tremaining: 8.39ms\n",
            "41:\tlearn: 0.1544748\ttotal: 87.9ms\tremaining: 6.28ms\n",
            "42:\tlearn: 0.1525493\ttotal: 89.9ms\tremaining: 4.18ms\n",
            "43:\tlearn: 0.1506610\ttotal: 91.8ms\tremaining: 2.09ms\n",
            "44:\tlearn: 0.1483410\ttotal: 93.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.75ms\tremaining: 76.9ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.11ms\tremaining: 45.4ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.74ms\tremaining: 38.4ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.45ms\tremaining: 45.7ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.23ms\tremaining: 49.9ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.09ms\tremaining: 52.6ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10ms\tremaining: 54.5ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12ms\tremaining: 55.6ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14.1ms\tremaining: 56.5ms\n",
            "9:\tlearn: 0.2537973\ttotal: 16.2ms\tremaining: 56.6ms\n",
            "10:\tlearn: 0.2473429\ttotal: 18.3ms\tremaining: 56.6ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20.2ms\tremaining: 55.6ms\n",
            "12:\tlearn: 0.2366343\ttotal: 22.2ms\tremaining: 54.6ms\n",
            "13:\tlearn: 0.2298385\ttotal: 23.9ms\tremaining: 52.9ms\n",
            "14:\tlearn: 0.2249545\ttotal: 25.8ms\tremaining: 51.6ms\n",
            "15:\tlearn: 0.2192054\ttotal: 27.9ms\tremaining: 50.5ms\n",
            "16:\tlearn: 0.2150242\ttotal: 29.8ms\tremaining: 49ms\n",
            "17:\tlearn: 0.2094516\ttotal: 31.7ms\tremaining: 47.5ms\n",
            "18:\tlearn: 0.2056324\ttotal: 33.6ms\tremaining: 46ms\n",
            "19:\tlearn: 0.2021225\ttotal: 35.5ms\tremaining: 44.3ms\n",
            "20:\tlearn: 0.1989042\ttotal: 37.4ms\tremaining: 42.7ms\n",
            "21:\tlearn: 0.1961040\ttotal: 39.4ms\tremaining: 41.2ms\n",
            "22:\tlearn: 0.1934794\ttotal: 41.3ms\tremaining: 39.5ms\n",
            "23:\tlearn: 0.1902438\ttotal: 43.2ms\tremaining: 37.8ms\n",
            "24:\tlearn: 0.1874921\ttotal: 45ms\tremaining: 36ms\n",
            "25:\tlearn: 0.1829904\ttotal: 47ms\tremaining: 34.4ms\n",
            "26:\tlearn: 0.1804169\ttotal: 48.9ms\tremaining: 32.6ms\n",
            "27:\tlearn: 0.1776989\ttotal: 50.7ms\tremaining: 30.8ms\n",
            "28:\tlearn: 0.1751387\ttotal: 52.6ms\tremaining: 29ms\n",
            "29:\tlearn: 0.1727570\ttotal: 54.4ms\tremaining: 27.2ms\n",
            "30:\tlearn: 0.1693663\ttotal: 56.4ms\tremaining: 25.5ms\n",
            "31:\tlearn: 0.1661883\ttotal: 58.2ms\tremaining: 23.7ms\n",
            "32:\tlearn: 0.1641011\ttotal: 60.1ms\tremaining: 21.9ms\n",
            "33:\tlearn: 0.1616271\ttotal: 62.3ms\tremaining: 20.1ms\n",
            "34:\tlearn: 0.1593621\ttotal: 64.2ms\tremaining: 18.3ms\n",
            "35:\tlearn: 0.1576181\ttotal: 66.2ms\tremaining: 16.6ms\n",
            "36:\tlearn: 0.1557020\ttotal: 68.1ms\tremaining: 14.7ms\n",
            "37:\tlearn: 0.1541003\ttotal: 70ms\tremaining: 12.9ms\n",
            "38:\tlearn: 0.1522873\ttotal: 72ms\tremaining: 11.1ms\n",
            "39:\tlearn: 0.1502740\ttotal: 74ms\tremaining: 9.25ms\n",
            "40:\tlearn: 0.1483554\ttotal: 76ms\tremaining: 7.41ms\n",
            "41:\tlearn: 0.1465885\ttotal: 79.7ms\tremaining: 5.69ms\n",
            "42:\tlearn: 0.1443271\ttotal: 82.9ms\tremaining: 3.86ms\n",
            "43:\tlearn: 0.1425567\ttotal: 86.6ms\tremaining: 1.97ms\n",
            "44:\tlearn: 0.1409543\ttotal: 90.1ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.81ms\tremaining: 81.7ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.19ms\tremaining: 48.1ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.21ms\tremaining: 60.4ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.18ms\tremaining: 64.9ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.21ms\tremaining: 67.3ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.4ms\tremaining: 69ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.4ms\tremaining: 69ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.4ms\tremaining: 68.2ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.3ms\tremaining: 66.9ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.5ms\tremaining: 66.7ms\n",
            "10:\tlearn: 0.2983658\ttotal: 20.3ms\tremaining: 64.5ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.3ms\tremaining: 63.2ms\n",
            "12:\tlearn: 0.2852979\ttotal: 24.4ms\tremaining: 62ms\n",
            "13:\tlearn: 0.2798563\ttotal: 26.4ms\tremaining: 60.3ms\n",
            "14:\tlearn: 0.2747341\ttotal: 28.4ms\tremaining: 58.6ms\n",
            "15:\tlearn: 0.2702568\ttotal: 30.3ms\tremaining: 56.9ms\n",
            "16:\tlearn: 0.2650537\ttotal: 32.3ms\tremaining: 55.2ms\n",
            "17:\tlearn: 0.2601005\ttotal: 34.3ms\tremaining: 53.4ms\n",
            "18:\tlearn: 0.2560578\ttotal: 36.4ms\tremaining: 51.7ms\n",
            "19:\tlearn: 0.2530381\ttotal: 38.4ms\tremaining: 50ms\n",
            "20:\tlearn: 0.2498453\ttotal: 40.5ms\tremaining: 48.2ms\n",
            "21:\tlearn: 0.2461646\ttotal: 42.6ms\tremaining: 46.4ms\n",
            "22:\tlearn: 0.2424369\ttotal: 44.7ms\tremaining: 44.7ms\n",
            "23:\tlearn: 0.2392835\ttotal: 46.7ms\tremaining: 42.8ms\n",
            "24:\tlearn: 0.2339070\ttotal: 48.7ms\tremaining: 40.9ms\n",
            "25:\tlearn: 0.2301706\ttotal: 50.8ms\tremaining: 39.1ms\n",
            "26:\tlearn: 0.2263007\ttotal: 52.9ms\tremaining: 37.3ms\n",
            "27:\tlearn: 0.2223209\ttotal: 55ms\tremaining: 35.3ms\n",
            "28:\tlearn: 0.2190932\ttotal: 57.1ms\tremaining: 33.4ms\n",
            "29:\tlearn: 0.2159010\ttotal: 59.1ms\tremaining: 31.5ms\n",
            "30:\tlearn: 0.2132954\ttotal: 61.1ms\tremaining: 29.6ms\n",
            "31:\tlearn: 0.2102299\ttotal: 63.2ms\tremaining: 27.6ms\n",
            "32:\tlearn: 0.2076280\ttotal: 65.2ms\tremaining: 25.7ms\n",
            "33:\tlearn: 0.2043188\ttotal: 67.2ms\tremaining: 23.7ms\n",
            "34:\tlearn: 0.2017849\ttotal: 69.2ms\tremaining: 21.8ms\n",
            "35:\tlearn: 0.1993718\ttotal: 71.2ms\tremaining: 19.8ms\n",
            "36:\tlearn: 0.1972299\ttotal: 73.1ms\tremaining: 17.8ms\n",
            "37:\tlearn: 0.1950197\ttotal: 75.2ms\tremaining: 15.8ms\n",
            "38:\tlearn: 0.1927135\ttotal: 77.2ms\tremaining: 13.9ms\n",
            "39:\tlearn: 0.1895038\ttotal: 79.2ms\tremaining: 11.9ms\n",
            "40:\tlearn: 0.1867644\ttotal: 81.4ms\tremaining: 9.93ms\n",
            "41:\tlearn: 0.1842014\ttotal: 83.4ms\tremaining: 7.95ms\n",
            "42:\tlearn: 0.1821212\ttotal: 85.4ms\tremaining: 5.96ms\n",
            "43:\tlearn: 0.1794173\ttotal: 87.5ms\tremaining: 3.98ms\n",
            "44:\tlearn: 0.1766213\ttotal: 89.5ms\tremaining: 1.99ms\n",
            "45:\tlearn: 0.1742184\ttotal: 91.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.8ms\tremaining: 81.3ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.42ms\tremaining: 53.3ms\n",
            "2:\tlearn: 0.3788145\ttotal: 5.2ms\tremaining: 74.5ms\n",
            "3:\tlearn: 0.3658016\ttotal: 7.04ms\tremaining: 74ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.92ms\tremaining: 65ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.85ms\tremaining: 59ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10.6ms\tremaining: 59.2ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12.5ms\tremaining: 59.3ms\n",
            "8:\tlearn: 0.3040041\ttotal: 14.4ms\tremaining: 59.1ms\n",
            "9:\tlearn: 0.2975585\ttotal: 16.3ms\tremaining: 58.8ms\n",
            "10:\tlearn: 0.2898709\ttotal: 18.2ms\tremaining: 57.8ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.1ms\tremaining: 57ms\n",
            "12:\tlearn: 0.2794184\ttotal: 22.2ms\tremaining: 56.5ms\n",
            "13:\tlearn: 0.2740314\ttotal: 24.3ms\tremaining: 55.6ms\n",
            "14:\tlearn: 0.2705542\ttotal: 26.2ms\tremaining: 54.2ms\n",
            "15:\tlearn: 0.2673919\ttotal: 28.3ms\tremaining: 53ms\n",
            "16:\tlearn: 0.2623365\ttotal: 30.2ms\tremaining: 51.5ms\n",
            "17:\tlearn: 0.2595719\ttotal: 32.1ms\tremaining: 49.9ms\n",
            "18:\tlearn: 0.2545713\ttotal: 33.9ms\tremaining: 48.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 35.9ms\tremaining: 46.6ms\n",
            "20:\tlearn: 0.2477056\ttotal: 37.7ms\tremaining: 44.9ms\n",
            "21:\tlearn: 0.2437884\ttotal: 39.6ms\tremaining: 43.2ms\n",
            "22:\tlearn: 0.2404080\ttotal: 41.4ms\tremaining: 41.4ms\n",
            "23:\tlearn: 0.2369058\ttotal: 43.3ms\tremaining: 39.7ms\n",
            "24:\tlearn: 0.2331119\ttotal: 45.1ms\tremaining: 37.9ms\n",
            "25:\tlearn: 0.2293455\ttotal: 47ms\tremaining: 36.1ms\n",
            "26:\tlearn: 0.2256418\ttotal: 48.9ms\tremaining: 34.4ms\n",
            "27:\tlearn: 0.2221119\ttotal: 52.5ms\tremaining: 33.7ms\n",
            "28:\tlearn: 0.2190925\ttotal: 55.1ms\tremaining: 32.3ms\n",
            "29:\tlearn: 0.2161731\ttotal: 57.6ms\tremaining: 30.7ms\n",
            "30:\tlearn: 0.2135041\ttotal: 59.8ms\tremaining: 28.9ms\n",
            "31:\tlearn: 0.2113382\ttotal: 61.7ms\tremaining: 27ms\n",
            "32:\tlearn: 0.2083485\ttotal: 64.1ms\tremaining: 25.2ms\n",
            "33:\tlearn: 0.2058588\ttotal: 65.9ms\tremaining: 23.3ms\n",
            "34:\tlearn: 0.2024895\ttotal: 68.1ms\tremaining: 21.4ms\n",
            "35:\tlearn: 0.1997586\ttotal: 69.9ms\tremaining: 19.4ms\n",
            "36:\tlearn: 0.1976953\ttotal: 71.9ms\tremaining: 17.5ms\n",
            "37:\tlearn: 0.1949453\ttotal: 74ms\tremaining: 15.6ms\n",
            "38:\tlearn: 0.1931445\ttotal: 75.9ms\tremaining: 13.6ms\n",
            "39:\tlearn: 0.1900292\ttotal: 77.9ms\tremaining: 11.7ms\n",
            "40:\tlearn: 0.1872454\ttotal: 79.9ms\tremaining: 9.74ms\n",
            "41:\tlearn: 0.1848207\ttotal: 81.8ms\tremaining: 7.79ms\n",
            "42:\tlearn: 0.1823519\ttotal: 83.9ms\tremaining: 5.85ms\n",
            "43:\tlearn: 0.1801956\ttotal: 85.8ms\tremaining: 3.9ms\n",
            "44:\tlearn: 0.1784734\ttotal: 87.7ms\tremaining: 1.95ms\n",
            "45:\tlearn: 0.1765592\ttotal: 89.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.59ms\tremaining: 71.6ms\n",
            "1:\tlearn: 0.4107278\ttotal: 1.94ms\tremaining: 42.7ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.38ms\tremaining: 34.1ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.33ms\tremaining: 45.4ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.39ms\tremaining: 52.4ms\n",
            "5:\tlearn: 0.3328396\ttotal: 8.65ms\tremaining: 57.7ms\n",
            "6:\tlearn: 0.3256704\ttotal: 10.6ms\tremaining: 59.2ms\n",
            "7:\tlearn: 0.3174441\ttotal: 12.6ms\tremaining: 59.8ms\n",
            "8:\tlearn: 0.3090762\ttotal: 15ms\tremaining: 61.6ms\n",
            "9:\tlearn: 0.3028459\ttotal: 17ms\tremaining: 61.2ms\n",
            "10:\tlearn: 0.2958541\ttotal: 18.8ms\tremaining: 59.8ms\n",
            "11:\tlearn: 0.2901166\ttotal: 20.8ms\tremaining: 58.9ms\n",
            "12:\tlearn: 0.2841803\ttotal: 22.8ms\tremaining: 57.8ms\n",
            "13:\tlearn: 0.2789751\ttotal: 24.8ms\tremaining: 56.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 26.7ms\tremaining: 55.3ms\n",
            "15:\tlearn: 0.2663544\ttotal: 28.8ms\tremaining: 53.9ms\n",
            "16:\tlearn: 0.2615546\ttotal: 30.8ms\tremaining: 52.6ms\n",
            "17:\tlearn: 0.2560079\ttotal: 32.8ms\tremaining: 51ms\n",
            "18:\tlearn: 0.2507480\ttotal: 34.8ms\tremaining: 49.5ms\n",
            "19:\tlearn: 0.2450678\ttotal: 36.6ms\tremaining: 47.6ms\n",
            "20:\tlearn: 0.2413892\ttotal: 38.5ms\tremaining: 45.9ms\n",
            "21:\tlearn: 0.2378437\ttotal: 40.5ms\tremaining: 44.1ms\n",
            "22:\tlearn: 0.2344010\ttotal: 42.4ms\tremaining: 42.4ms\n",
            "23:\tlearn: 0.2304940\ttotal: 44.4ms\tremaining: 40.7ms\n",
            "24:\tlearn: 0.2269540\ttotal: 46.4ms\tremaining: 39ms\n",
            "25:\tlearn: 0.2232713\ttotal: 48.3ms\tremaining: 37.2ms\n",
            "26:\tlearn: 0.2208577\ttotal: 50.5ms\tremaining: 35.5ms\n",
            "27:\tlearn: 0.2181825\ttotal: 52.5ms\tremaining: 33.8ms\n",
            "28:\tlearn: 0.2149071\ttotal: 54.5ms\tremaining: 31.9ms\n",
            "29:\tlearn: 0.2123638\ttotal: 56.5ms\tremaining: 30.1ms\n",
            "30:\tlearn: 0.2094640\ttotal: 58.5ms\tremaining: 28.3ms\n",
            "31:\tlearn: 0.2071716\ttotal: 60.5ms\tremaining: 26.5ms\n",
            "32:\tlearn: 0.2045371\ttotal: 62.7ms\tremaining: 24.7ms\n",
            "33:\tlearn: 0.2018712\ttotal: 64.8ms\tremaining: 22.9ms\n",
            "34:\tlearn: 0.1995442\ttotal: 66.8ms\tremaining: 21ms\n",
            "35:\tlearn: 0.1970515\ttotal: 68.8ms\tremaining: 19.1ms\n",
            "36:\tlearn: 0.1946725\ttotal: 70.8ms\tremaining: 17.2ms\n",
            "37:\tlearn: 0.1924392\ttotal: 73.8ms\tremaining: 15.5ms\n",
            "38:\tlearn: 0.1893508\ttotal: 75.5ms\tremaining: 13.5ms\n",
            "39:\tlearn: 0.1868097\ttotal: 77.4ms\tremaining: 11.6ms\n",
            "40:\tlearn: 0.1846310\ttotal: 79.4ms\tremaining: 9.68ms\n",
            "41:\tlearn: 0.1820837\ttotal: 81.5ms\tremaining: 7.76ms\n",
            "42:\tlearn: 0.1795780\ttotal: 83.6ms\tremaining: 5.83ms\n",
            "43:\tlearn: 0.1777006\ttotal: 85.9ms\tremaining: 3.9ms\n",
            "44:\tlearn: 0.1761110\ttotal: 88.4ms\tremaining: 1.97ms\n",
            "45:\tlearn: 0.1739210\ttotal: 92.8ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 2.62ms\tremaining: 118ms\n",
            "1:\tlearn: 0.3745079\ttotal: 3.21ms\tremaining: 70.6ms\n",
            "2:\tlearn: 0.3383999\ttotal: 5.18ms\tremaining: 74.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 7.06ms\tremaining: 74.2ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.97ms\tremaining: 73.6ms\n",
            "5:\tlearn: 0.2907443\ttotal: 13ms\tremaining: 86.6ms\n",
            "6:\tlearn: 0.2818467\ttotal: 15.8ms\tremaining: 88.3ms\n",
            "7:\tlearn: 0.2691784\ttotal: 17.6ms\tremaining: 83.5ms\n",
            "8:\tlearn: 0.2611618\ttotal: 19.9ms\tremaining: 82ms\n",
            "9:\tlearn: 0.2519898\ttotal: 21.8ms\tremaining: 78.5ms\n",
            "10:\tlearn: 0.2462992\ttotal: 24.2ms\tremaining: 77.1ms\n",
            "11:\tlearn: 0.2416348\ttotal: 26.2ms\tremaining: 74.1ms\n",
            "12:\tlearn: 0.2368688\ttotal: 28.5ms\tremaining: 72.4ms\n",
            "13:\tlearn: 0.2320170\ttotal: 30.4ms\tremaining: 69.6ms\n",
            "14:\tlearn: 0.2262186\ttotal: 32.5ms\tremaining: 67.1ms\n",
            "15:\tlearn: 0.2215380\ttotal: 34.2ms\tremaining: 64.2ms\n",
            "16:\tlearn: 0.2176313\ttotal: 36.2ms\tremaining: 61.8ms\n",
            "17:\tlearn: 0.2138494\ttotal: 38.2ms\tremaining: 59.5ms\n",
            "18:\tlearn: 0.2100966\ttotal: 40.2ms\tremaining: 57.1ms\n",
            "19:\tlearn: 0.2068557\ttotal: 42.1ms\tremaining: 54.8ms\n",
            "20:\tlearn: 0.2029945\ttotal: 44.1ms\tremaining: 52.5ms\n",
            "21:\tlearn: 0.2001044\ttotal: 46.1ms\tremaining: 50.3ms\n",
            "22:\tlearn: 0.1970766\ttotal: 48.2ms\tremaining: 48.2ms\n",
            "23:\tlearn: 0.1940285\ttotal: 50.3ms\tremaining: 46.1ms\n",
            "24:\tlearn: 0.1910934\ttotal: 52.3ms\tremaining: 43.9ms\n",
            "25:\tlearn: 0.1879112\ttotal: 54.3ms\tremaining: 41.7ms\n",
            "26:\tlearn: 0.1852765\ttotal: 56.3ms\tremaining: 39.6ms\n",
            "27:\tlearn: 0.1827068\ttotal: 58.6ms\tremaining: 37.7ms\n",
            "28:\tlearn: 0.1803359\ttotal: 61.8ms\tremaining: 36.2ms\n",
            "29:\tlearn: 0.1779549\ttotal: 63.7ms\tremaining: 34ms\n",
            "30:\tlearn: 0.1757984\ttotal: 65.7ms\tremaining: 31.8ms\n",
            "31:\tlearn: 0.1724570\ttotal: 67.7ms\tremaining: 29.6ms\n",
            "32:\tlearn: 0.1703672\ttotal: 69.6ms\tremaining: 27.4ms\n",
            "33:\tlearn: 0.1685175\ttotal: 71.4ms\tremaining: 25.2ms\n",
            "34:\tlearn: 0.1666049\ttotal: 73.4ms\tremaining: 23.1ms\n",
            "35:\tlearn: 0.1648374\ttotal: 75.4ms\tremaining: 20.9ms\n",
            "36:\tlearn: 0.1631656\ttotal: 77.3ms\tremaining: 18.8ms\n",
            "37:\tlearn: 0.1615072\ttotal: 79.4ms\tremaining: 16.7ms\n",
            "38:\tlearn: 0.1598928\ttotal: 81.3ms\tremaining: 14.6ms\n",
            "39:\tlearn: 0.1584040\ttotal: 83.2ms\tremaining: 12.5ms\n",
            "40:\tlearn: 0.1566573\ttotal: 85.2ms\tremaining: 10.4ms\n",
            "41:\tlearn: 0.1544748\ttotal: 87.1ms\tremaining: 8.29ms\n",
            "42:\tlearn: 0.1525493\ttotal: 89ms\tremaining: 6.21ms\n",
            "43:\tlearn: 0.1506610\ttotal: 91ms\tremaining: 4.13ms\n",
            "44:\tlearn: 0.1483410\ttotal: 92.9ms\tremaining: 2.06ms\n",
            "45:\tlearn: 0.1468477\ttotal: 94.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.66ms\tremaining: 74.6ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.01ms\tremaining: 44.2ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.69ms\tremaining: 38.5ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.55ms\tremaining: 47.8ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.45ms\tremaining: 52.9ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.26ms\tremaining: 55.1ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.2ms\tremaining: 57ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.1ms\tremaining: 57.6ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14ms\tremaining: 57.6ms\n",
            "9:\tlearn: 0.2537973\ttotal: 15.9ms\tremaining: 57.3ms\n",
            "10:\tlearn: 0.2473429\ttotal: 17.8ms\tremaining: 56.5ms\n",
            "11:\tlearn: 0.2416695\ttotal: 19.5ms\tremaining: 55.1ms\n",
            "12:\tlearn: 0.2366343\ttotal: 21.2ms\tremaining: 53.8ms\n",
            "13:\tlearn: 0.2298385\ttotal: 22.9ms\tremaining: 52.4ms\n",
            "14:\tlearn: 0.2249545\ttotal: 24.8ms\tremaining: 51.2ms\n",
            "15:\tlearn: 0.2192054\ttotal: 26.6ms\tremaining: 49.9ms\n",
            "16:\tlearn: 0.2150242\ttotal: 28.5ms\tremaining: 48.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 30.4ms\tremaining: 47.3ms\n",
            "18:\tlearn: 0.2056324\ttotal: 32.3ms\tremaining: 45.9ms\n",
            "19:\tlearn: 0.2021225\ttotal: 34.2ms\tremaining: 44.4ms\n",
            "20:\tlearn: 0.1989042\ttotal: 36ms\tremaining: 42.9ms\n",
            "21:\tlearn: 0.1961040\ttotal: 37.7ms\tremaining: 41.2ms\n",
            "22:\tlearn: 0.1934794\ttotal: 39.4ms\tremaining: 39.4ms\n",
            "23:\tlearn: 0.1902438\ttotal: 41.2ms\tremaining: 37.7ms\n",
            "24:\tlearn: 0.1874921\ttotal: 43.1ms\tremaining: 36.2ms\n",
            "25:\tlearn: 0.1829904\ttotal: 44.9ms\tremaining: 34.5ms\n",
            "26:\tlearn: 0.1804169\ttotal: 46.7ms\tremaining: 32.8ms\n",
            "27:\tlearn: 0.1776989\ttotal: 48.7ms\tremaining: 31.3ms\n",
            "28:\tlearn: 0.1751387\ttotal: 50.5ms\tremaining: 29.6ms\n",
            "29:\tlearn: 0.1727570\ttotal: 52.3ms\tremaining: 27.9ms\n",
            "30:\tlearn: 0.1693663\ttotal: 54.3ms\tremaining: 26.3ms\n",
            "31:\tlearn: 0.1661883\ttotal: 56ms\tremaining: 24.5ms\n",
            "32:\tlearn: 0.1641011\ttotal: 57.9ms\tremaining: 22.8ms\n",
            "33:\tlearn: 0.1616271\ttotal: 59.9ms\tremaining: 21.1ms\n",
            "34:\tlearn: 0.1593621\ttotal: 61.7ms\tremaining: 19.4ms\n",
            "35:\tlearn: 0.1576181\ttotal: 63.6ms\tremaining: 17.7ms\n",
            "36:\tlearn: 0.1557020\ttotal: 65.4ms\tremaining: 15.9ms\n",
            "37:\tlearn: 0.1541003\ttotal: 67.3ms\tremaining: 14.2ms\n",
            "38:\tlearn: 0.1522873\ttotal: 69.2ms\tremaining: 12.4ms\n",
            "39:\tlearn: 0.1502740\ttotal: 70.9ms\tremaining: 10.6ms\n",
            "40:\tlearn: 0.1483554\ttotal: 72.8ms\tremaining: 8.88ms\n",
            "41:\tlearn: 0.1465885\ttotal: 74.8ms\tremaining: 7.12ms\n",
            "42:\tlearn: 0.1443271\ttotal: 76.6ms\tremaining: 5.34ms\n",
            "43:\tlearn: 0.1425567\ttotal: 78.5ms\tremaining: 3.57ms\n",
            "44:\tlearn: 0.1409543\ttotal: 80.4ms\tremaining: 1.79ms\n",
            "45:\tlearn: 0.1393691\ttotal: 82.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.72ms\tremaining: 79ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.56ms\tremaining: 57.6ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.38ms\tremaining: 64.2ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.33ms\tremaining: 68.1ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.2ms\tremaining: 68.9ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.1ms\tremaining: 69.3ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.2ms\tremaining: 69.9ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.5ms\tremaining: 70.8ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.5ms\tremaining: 69.5ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.4ms\tremaining: 68.1ms\n",
            "10:\tlearn: 0.2983658\ttotal: 20.2ms\tremaining: 66.2ms\n",
            "11:\tlearn: 0.2903440\ttotal: 22.2ms\tremaining: 64.7ms\n",
            "12:\tlearn: 0.2852979\ttotal: 24.1ms\tremaining: 63ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.9ms\tremaining: 61.1ms\n",
            "14:\tlearn: 0.2747341\ttotal: 27.8ms\tremaining: 59.4ms\n",
            "15:\tlearn: 0.2702568\ttotal: 29.8ms\tremaining: 57.7ms\n",
            "16:\tlearn: 0.2650537\ttotal: 31.6ms\tremaining: 55.7ms\n",
            "17:\tlearn: 0.2601005\ttotal: 33.5ms\tremaining: 53.9ms\n",
            "18:\tlearn: 0.2560578\ttotal: 35.3ms\tremaining: 52ms\n",
            "19:\tlearn: 0.2530381\ttotal: 37.2ms\tremaining: 50.2ms\n",
            "20:\tlearn: 0.2498453\ttotal: 39ms\tremaining: 48.3ms\n",
            "21:\tlearn: 0.2461646\ttotal: 40.9ms\tremaining: 46.5ms\n",
            "22:\tlearn: 0.2424369\ttotal: 43.1ms\tremaining: 45ms\n",
            "23:\tlearn: 0.2392835\ttotal: 45.1ms\tremaining: 43.2ms\n",
            "24:\tlearn: 0.2339070\ttotal: 46.9ms\tremaining: 41.2ms\n",
            "25:\tlearn: 0.2301706\ttotal: 48.8ms\tremaining: 39.4ms\n",
            "26:\tlearn: 0.2263007\ttotal: 50.9ms\tremaining: 37.7ms\n",
            "27:\tlearn: 0.2223209\ttotal: 54.3ms\tremaining: 36.8ms\n",
            "28:\tlearn: 0.2190932\ttotal: 56.4ms\tremaining: 35ms\n",
            "29:\tlearn: 0.2159010\ttotal: 58.1ms\tremaining: 32.9ms\n",
            "30:\tlearn: 0.2132954\ttotal: 60.1ms\tremaining: 31ms\n",
            "31:\tlearn: 0.2102299\ttotal: 62ms\tremaining: 29.1ms\n",
            "32:\tlearn: 0.2076280\ttotal: 64ms\tremaining: 27.2ms\n",
            "33:\tlearn: 0.2043188\ttotal: 66ms\tremaining: 25.2ms\n",
            "34:\tlearn: 0.2017849\ttotal: 67.9ms\tremaining: 23.3ms\n",
            "35:\tlearn: 0.1993718\ttotal: 70.1ms\tremaining: 21.4ms\n",
            "36:\tlearn: 0.1972299\ttotal: 72.1ms\tremaining: 19.5ms\n",
            "37:\tlearn: 0.1950197\ttotal: 74ms\tremaining: 17.5ms\n",
            "38:\tlearn: 0.1927135\ttotal: 76ms\tremaining: 15.6ms\n",
            "39:\tlearn: 0.1895038\ttotal: 77.8ms\tremaining: 13.6ms\n",
            "40:\tlearn: 0.1867644\ttotal: 79.9ms\tremaining: 11.7ms\n",
            "41:\tlearn: 0.1842014\ttotal: 81.8ms\tremaining: 9.74ms\n",
            "42:\tlearn: 0.1821212\ttotal: 83.7ms\tremaining: 7.78ms\n",
            "43:\tlearn: 0.1794173\ttotal: 85.6ms\tremaining: 5.83ms\n",
            "44:\tlearn: 0.1766213\ttotal: 87.6ms\tremaining: 3.89ms\n",
            "45:\tlearn: 0.1742184\ttotal: 89.5ms\tremaining: 1.95ms\n",
            "46:\tlearn: 0.1725620\ttotal: 91.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.74ms\tremaining: 80.1ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.33ms\tremaining: 52.4ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.19ms\tremaining: 61.4ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.18ms\tremaining: 66.5ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.08ms\tremaining: 59.5ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.99ms\tremaining: 54.6ms\n",
            "6:\tlearn: 0.3158416\ttotal: 9.94ms\tremaining: 56.8ms\n",
            "7:\tlearn: 0.3097739\ttotal: 11.9ms\tremaining: 58.1ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.9ms\tremaining: 58.5ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.8ms\tremaining: 58.5ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17.9ms\tremaining: 58.5ms\n",
            "11:\tlearn: 0.2845372\ttotal: 19.8ms\tremaining: 57.7ms\n",
            "12:\tlearn: 0.2794184\ttotal: 21.8ms\tremaining: 57.1ms\n",
            "13:\tlearn: 0.2740314\ttotal: 23.7ms\tremaining: 56ms\n",
            "14:\tlearn: 0.2705542\ttotal: 25.9ms\tremaining: 55.3ms\n",
            "15:\tlearn: 0.2673919\ttotal: 28.1ms\tremaining: 54.5ms\n",
            "16:\tlearn: 0.2623365\ttotal: 30.1ms\tremaining: 53.2ms\n",
            "17:\tlearn: 0.2595719\ttotal: 32.4ms\tremaining: 52.1ms\n",
            "18:\tlearn: 0.2545713\ttotal: 34.5ms\tremaining: 50.9ms\n",
            "19:\tlearn: 0.2510766\ttotal: 36.5ms\tremaining: 49.3ms\n",
            "20:\tlearn: 0.2477056\ttotal: 38.6ms\tremaining: 47.8ms\n",
            "21:\tlearn: 0.2437884\ttotal: 40.7ms\tremaining: 46.2ms\n",
            "22:\tlearn: 0.2404080\ttotal: 42.9ms\tremaining: 44.7ms\n",
            "23:\tlearn: 0.2369058\ttotal: 45ms\tremaining: 43.1ms\n",
            "24:\tlearn: 0.2331119\ttotal: 47.1ms\tremaining: 41.5ms\n",
            "25:\tlearn: 0.2293455\ttotal: 49.2ms\tremaining: 39.7ms\n",
            "26:\tlearn: 0.2256418\ttotal: 51.1ms\tremaining: 37.9ms\n",
            "27:\tlearn: 0.2221119\ttotal: 53ms\tremaining: 36ms\n",
            "28:\tlearn: 0.2190925\ttotal: 55ms\tremaining: 34.1ms\n",
            "29:\tlearn: 0.2161731\ttotal: 57ms\tremaining: 32.3ms\n",
            "30:\tlearn: 0.2135041\ttotal: 59ms\tremaining: 30.4ms\n",
            "31:\tlearn: 0.2113382\ttotal: 61ms\tremaining: 28.6ms\n",
            "32:\tlearn: 0.2083485\ttotal: 63ms\tremaining: 26.7ms\n",
            "33:\tlearn: 0.2058588\ttotal: 65ms\tremaining: 24.9ms\n",
            "34:\tlearn: 0.2024895\ttotal: 67ms\tremaining: 23ms\n",
            "35:\tlearn: 0.1997586\ttotal: 69ms\tremaining: 21.1ms\n",
            "36:\tlearn: 0.1976953\ttotal: 71ms\tremaining: 19.2ms\n",
            "37:\tlearn: 0.1949453\ttotal: 73ms\tremaining: 17.3ms\n",
            "38:\tlearn: 0.1931445\ttotal: 75.1ms\tremaining: 15.4ms\n",
            "39:\tlearn: 0.1900292\ttotal: 77.1ms\tremaining: 13.5ms\n",
            "40:\tlearn: 0.1872454\ttotal: 80.9ms\tremaining: 11.8ms\n",
            "41:\tlearn: 0.1848207\ttotal: 83.5ms\tremaining: 9.94ms\n",
            "42:\tlearn: 0.1823519\ttotal: 87.7ms\tremaining: 8.16ms\n",
            "43:\tlearn: 0.1801956\ttotal: 91.1ms\tremaining: 6.21ms\n",
            "44:\tlearn: 0.1784734\ttotal: 93.1ms\tremaining: 4.14ms\n",
            "45:\tlearn: 0.1765592\ttotal: 95.1ms\tremaining: 2.07ms\n",
            "46:\tlearn: 0.1747084\ttotal: 97ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.59ms\tremaining: 73.3ms\n",
            "1:\tlearn: 0.4107278\ttotal: 1.96ms\tremaining: 44ms\n",
            "2:\tlearn: 0.3698157\ttotal: 2.4ms\tremaining: 35.2ms\n",
            "3:\tlearn: 0.3518120\ttotal: 4.32ms\tremaining: 46.4ms\n",
            "4:\tlearn: 0.3441195\ttotal: 6.14ms\tremaining: 51.6ms\n",
            "5:\tlearn: 0.3328396\ttotal: 7.97ms\tremaining: 54.5ms\n",
            "6:\tlearn: 0.3256704\ttotal: 9.88ms\tremaining: 56.5ms\n",
            "7:\tlearn: 0.3174441\ttotal: 11.8ms\tremaining: 57.6ms\n",
            "8:\tlearn: 0.3090762\ttotal: 13.7ms\tremaining: 57.9ms\n",
            "9:\tlearn: 0.3028459\ttotal: 15.7ms\tremaining: 58.1ms\n",
            "10:\tlearn: 0.2958541\ttotal: 17.5ms\tremaining: 57.4ms\n",
            "11:\tlearn: 0.2901166\ttotal: 19.4ms\tremaining: 56.5ms\n",
            "12:\tlearn: 0.2841803\ttotal: 21.4ms\tremaining: 55.9ms\n",
            "13:\tlearn: 0.2789751\ttotal: 23.3ms\tremaining: 54.9ms\n",
            "14:\tlearn: 0.2715599\ttotal: 25.3ms\tremaining: 54ms\n",
            "15:\tlearn: 0.2663544\ttotal: 27.4ms\tremaining: 53ms\n",
            "16:\tlearn: 0.2615546\ttotal: 29.6ms\tremaining: 52.2ms\n",
            "17:\tlearn: 0.2560079\ttotal: 31.5ms\tremaining: 50.8ms\n",
            "18:\tlearn: 0.2507480\ttotal: 33.4ms\tremaining: 49.2ms\n",
            "19:\tlearn: 0.2450678\ttotal: 35.3ms\tremaining: 47.6ms\n",
            "20:\tlearn: 0.2413892\ttotal: 37.1ms\tremaining: 45.9ms\n",
            "21:\tlearn: 0.2378437\ttotal: 39.3ms\tremaining: 44.7ms\n",
            "22:\tlearn: 0.2344010\ttotal: 41.3ms\tremaining: 43.1ms\n",
            "23:\tlearn: 0.2304940\ttotal: 43.2ms\tremaining: 41.4ms\n",
            "24:\tlearn: 0.2269540\ttotal: 45.3ms\tremaining: 39.8ms\n",
            "25:\tlearn: 0.2232713\ttotal: 47ms\tremaining: 38ms\n",
            "26:\tlearn: 0.2208577\ttotal: 49ms\tremaining: 36.3ms\n",
            "27:\tlearn: 0.2181825\ttotal: 51ms\tremaining: 34.6ms\n",
            "28:\tlearn: 0.2149071\ttotal: 53.2ms\tremaining: 33ms\n",
            "29:\tlearn: 0.2123638\ttotal: 55.2ms\tremaining: 31.3ms\n",
            "30:\tlearn: 0.2094640\ttotal: 57.2ms\tremaining: 29.5ms\n",
            "31:\tlearn: 0.2071716\ttotal: 59.3ms\tremaining: 27.8ms\n",
            "32:\tlearn: 0.2045371\ttotal: 61.3ms\tremaining: 26ms\n",
            "33:\tlearn: 0.2018712\ttotal: 63.2ms\tremaining: 24.2ms\n",
            "34:\tlearn: 0.1995442\ttotal: 65.5ms\tremaining: 22.4ms\n",
            "35:\tlearn: 0.1970515\ttotal: 67.3ms\tremaining: 20.6ms\n",
            "36:\tlearn: 0.1946725\ttotal: 69.2ms\tremaining: 18.7ms\n",
            "37:\tlearn: 0.1924392\ttotal: 71.1ms\tremaining: 16.8ms\n",
            "38:\tlearn: 0.1893508\ttotal: 73ms\tremaining: 15ms\n",
            "39:\tlearn: 0.1868097\ttotal: 74.9ms\tremaining: 13.1ms\n",
            "40:\tlearn: 0.1846310\ttotal: 76.8ms\tremaining: 11.2ms\n",
            "41:\tlearn: 0.1820837\ttotal: 78.8ms\tremaining: 9.38ms\n",
            "42:\tlearn: 0.1795780\ttotal: 80.7ms\tremaining: 7.5ms\n",
            "43:\tlearn: 0.1777006\ttotal: 82.6ms\tremaining: 5.63ms\n",
            "44:\tlearn: 0.1761110\ttotal: 84.4ms\tremaining: 3.75ms\n",
            "45:\tlearn: 0.1739210\ttotal: 86.3ms\tremaining: 1.88ms\n",
            "46:\tlearn: 0.1717247\ttotal: 90.2ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.79ms\tremaining: 82.6ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.43ms\tremaining: 54.8ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.32ms\tremaining: 63.3ms\n",
            "3:\tlearn: 0.3266560\ttotal: 6.44ms\tremaining: 69.3ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.44ms\tremaining: 70.9ms\n",
            "5:\tlearn: 0.2907443\ttotal: 10.4ms\tremaining: 70.9ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12.2ms\tremaining: 69.8ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.5ms\tremaining: 65.8ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15.4ms\tremaining: 65.1ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.4ms\tremaining: 64.5ms\n",
            "10:\tlearn: 0.2462992\ttotal: 19.4ms\tremaining: 63.4ms\n",
            "11:\tlearn: 0.2416348\ttotal: 21.2ms\tremaining: 61.8ms\n",
            "12:\tlearn: 0.2368688\ttotal: 23ms\tremaining: 60.3ms\n",
            "13:\tlearn: 0.2320170\ttotal: 24.9ms\tremaining: 58.7ms\n",
            "14:\tlearn: 0.2262186\ttotal: 26.7ms\tremaining: 56.9ms\n",
            "15:\tlearn: 0.2215380\ttotal: 28.6ms\tremaining: 55.4ms\n",
            "16:\tlearn: 0.2176313\ttotal: 30.6ms\tremaining: 53.9ms\n",
            "17:\tlearn: 0.2138494\ttotal: 32.4ms\tremaining: 52.2ms\n",
            "18:\tlearn: 0.2100966\ttotal: 34.3ms\tremaining: 50.5ms\n",
            "19:\tlearn: 0.2068557\ttotal: 36.1ms\tremaining: 48.7ms\n",
            "20:\tlearn: 0.2029945\ttotal: 38.6ms\tremaining: 47.8ms\n",
            "21:\tlearn: 0.2001044\ttotal: 41.3ms\tremaining: 46.9ms\n",
            "22:\tlearn: 0.1970766\ttotal: 44.7ms\tremaining: 46.6ms\n",
            "23:\tlearn: 0.1940285\ttotal: 47.6ms\tremaining: 45.6ms\n",
            "24:\tlearn: 0.1910934\ttotal: 49.4ms\tremaining: 43.5ms\n",
            "25:\tlearn: 0.1879112\ttotal: 51ms\tremaining: 41.2ms\n",
            "26:\tlearn: 0.1852765\ttotal: 52.9ms\tremaining: 39.2ms\n",
            "27:\tlearn: 0.1827068\ttotal: 54.9ms\tremaining: 37.3ms\n",
            "28:\tlearn: 0.1803359\ttotal: 56.8ms\tremaining: 35.3ms\n",
            "29:\tlearn: 0.1779549\ttotal: 58.6ms\tremaining: 33.2ms\n",
            "30:\tlearn: 0.1757984\ttotal: 60.3ms\tremaining: 31.1ms\n",
            "31:\tlearn: 0.1724570\ttotal: 62.2ms\tremaining: 29.2ms\n",
            "32:\tlearn: 0.1703672\ttotal: 64.1ms\tremaining: 27.2ms\n",
            "33:\tlearn: 0.1685175\ttotal: 65.8ms\tremaining: 25.2ms\n",
            "34:\tlearn: 0.1666049\ttotal: 67.6ms\tremaining: 23.2ms\n",
            "35:\tlearn: 0.1648374\ttotal: 69.4ms\tremaining: 21.2ms\n",
            "36:\tlearn: 0.1631656\ttotal: 71.1ms\tremaining: 19.2ms\n",
            "37:\tlearn: 0.1615072\ttotal: 73ms\tremaining: 17.3ms\n",
            "38:\tlearn: 0.1598928\ttotal: 74.9ms\tremaining: 15.4ms\n",
            "39:\tlearn: 0.1584040\ttotal: 76.8ms\tremaining: 13.4ms\n",
            "40:\tlearn: 0.1566573\ttotal: 78.7ms\tremaining: 11.5ms\n",
            "41:\tlearn: 0.1544748\ttotal: 80.6ms\tremaining: 9.59ms\n",
            "42:\tlearn: 0.1525493\ttotal: 82.4ms\tremaining: 7.67ms\n",
            "43:\tlearn: 0.1506610\ttotal: 84.3ms\tremaining: 5.75ms\n",
            "44:\tlearn: 0.1483410\ttotal: 86.2ms\tremaining: 3.83ms\n",
            "45:\tlearn: 0.1468477\ttotal: 88ms\tremaining: 1.91ms\n",
            "46:\tlearn: 0.1454975\ttotal: 89.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.74ms\tremaining: 79.9ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.3ms\tremaining: 51.8ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.93ms\tremaining: 43ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.8ms\tremaining: 51.6ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.77ms\tremaining: 56.9ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.6ms\tremaining: 58.8ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.4ms\tremaining: 59.6ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.4ms\tremaining: 60.6ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14ms\tremaining: 59.3ms\n",
            "9:\tlearn: 0.2537973\ttotal: 16ms\tremaining: 59.2ms\n",
            "10:\tlearn: 0.2473429\ttotal: 18.1ms\tremaining: 59.1ms\n",
            "11:\tlearn: 0.2416695\ttotal: 20ms\tremaining: 58.2ms\n",
            "12:\tlearn: 0.2366343\ttotal: 21.8ms\tremaining: 57ms\n",
            "13:\tlearn: 0.2298385\ttotal: 23.6ms\tremaining: 55.7ms\n",
            "14:\tlearn: 0.2249545\ttotal: 25.8ms\tremaining: 55ms\n",
            "15:\tlearn: 0.2192054\ttotal: 27.8ms\tremaining: 53.9ms\n",
            "16:\tlearn: 0.2150242\ttotal: 29.8ms\tremaining: 52.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 31.9ms\tremaining: 51.4ms\n",
            "18:\tlearn: 0.2056324\ttotal: 33.8ms\tremaining: 49.7ms\n",
            "19:\tlearn: 0.2021225\ttotal: 35.6ms\tremaining: 48.1ms\n",
            "20:\tlearn: 0.1989042\ttotal: 37.5ms\tremaining: 46.5ms\n",
            "21:\tlearn: 0.1961040\ttotal: 39.5ms\tremaining: 44.9ms\n",
            "22:\tlearn: 0.1934794\ttotal: 41.3ms\tremaining: 43.1ms\n",
            "23:\tlearn: 0.1902438\ttotal: 43.2ms\tremaining: 41.4ms\n",
            "24:\tlearn: 0.1874921\ttotal: 45.1ms\tremaining: 39.7ms\n",
            "25:\tlearn: 0.1829904\ttotal: 47.1ms\tremaining: 38ms\n",
            "26:\tlearn: 0.1804169\ttotal: 49ms\tremaining: 36.3ms\n",
            "27:\tlearn: 0.1776989\ttotal: 50.8ms\tremaining: 34.5ms\n",
            "28:\tlearn: 0.1751387\ttotal: 52.8ms\tremaining: 32.7ms\n",
            "29:\tlearn: 0.1727570\ttotal: 54.7ms\tremaining: 31ms\n",
            "30:\tlearn: 0.1693663\ttotal: 56.5ms\tremaining: 29.2ms\n",
            "31:\tlearn: 0.1661883\ttotal: 58.3ms\tremaining: 27.3ms\n",
            "32:\tlearn: 0.1641011\ttotal: 60.1ms\tremaining: 25.5ms\n",
            "33:\tlearn: 0.1616271\ttotal: 62ms\tremaining: 23.7ms\n",
            "34:\tlearn: 0.1593621\ttotal: 63.8ms\tremaining: 21.9ms\n",
            "35:\tlearn: 0.1576181\ttotal: 65.7ms\tremaining: 20.1ms\n",
            "36:\tlearn: 0.1557020\ttotal: 67.6ms\tremaining: 18.3ms\n",
            "37:\tlearn: 0.1541003\ttotal: 69.4ms\tremaining: 16.4ms\n",
            "38:\tlearn: 0.1522873\ttotal: 71.1ms\tremaining: 14.6ms\n",
            "39:\tlearn: 0.1502740\ttotal: 73ms\tremaining: 12.8ms\n",
            "40:\tlearn: 0.1483554\ttotal: 74.9ms\tremaining: 11ms\n",
            "41:\tlearn: 0.1465885\ttotal: 76.8ms\tremaining: 9.14ms\n",
            "42:\tlearn: 0.1443271\ttotal: 78.6ms\tremaining: 7.31ms\n",
            "43:\tlearn: 0.1425567\ttotal: 80.3ms\tremaining: 5.48ms\n",
            "44:\tlearn: 0.1409543\ttotal: 82.1ms\tremaining: 3.65ms\n",
            "45:\tlearn: 0.1393691\ttotal: 84ms\tremaining: 1.83ms\n",
            "46:\tlearn: 0.1378187\ttotal: 86ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.68ms\tremaining: 79.1ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.31ms\tremaining: 53.1ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.28ms\tremaining: 64.2ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.2ms\tremaining: 68.2ms\n",
            "4:\tlearn: 0.3496343\ttotal: 9.57ms\tremaining: 82.3ms\n",
            "5:\tlearn: 0.3393969\ttotal: 12.1ms\tremaining: 84.4ms\n",
            "6:\tlearn: 0.3300914\ttotal: 16.9ms\tremaining: 99.1ms\n",
            "7:\tlearn: 0.3229079\ttotal: 19.1ms\tremaining: 95.3ms\n",
            "8:\tlearn: 0.3148279\ttotal: 20.9ms\tremaining: 90.6ms\n",
            "9:\tlearn: 0.3054626\ttotal: 22.5ms\tremaining: 85.6ms\n",
            "10:\tlearn: 0.2983658\ttotal: 24.4ms\tremaining: 82.1ms\n",
            "11:\tlearn: 0.2903440\ttotal: 26.3ms\tremaining: 79ms\n",
            "12:\tlearn: 0.2852979\ttotal: 28.7ms\tremaining: 77.3ms\n",
            "13:\tlearn: 0.2798563\ttotal: 30.4ms\tremaining: 73.9ms\n",
            "14:\tlearn: 0.2747341\ttotal: 32.2ms\tremaining: 70.8ms\n",
            "15:\tlearn: 0.2702568\ttotal: 34ms\tremaining: 68ms\n",
            "16:\tlearn: 0.2650537\ttotal: 35.9ms\tremaining: 65.4ms\n",
            "17:\tlearn: 0.2601005\ttotal: 37.8ms\tremaining: 63ms\n",
            "18:\tlearn: 0.2560578\ttotal: 39.7ms\tremaining: 60.6ms\n",
            "19:\tlearn: 0.2530381\ttotal: 41.5ms\tremaining: 58.1ms\n",
            "20:\tlearn: 0.2498453\ttotal: 43.3ms\tremaining: 55.7ms\n",
            "21:\tlearn: 0.2461646\ttotal: 45.2ms\tremaining: 53.4ms\n",
            "22:\tlearn: 0.2424369\ttotal: 47.9ms\tremaining: 52ms\n",
            "23:\tlearn: 0.2392835\ttotal: 49.8ms\tremaining: 49.8ms\n",
            "24:\tlearn: 0.2339070\ttotal: 51.8ms\tremaining: 47.7ms\n",
            "25:\tlearn: 0.2301706\ttotal: 54.8ms\tremaining: 46.4ms\n",
            "26:\tlearn: 0.2263007\ttotal: 56.4ms\tremaining: 43.9ms\n",
            "27:\tlearn: 0.2223209\ttotal: 58.3ms\tremaining: 41.7ms\n",
            "28:\tlearn: 0.2190932\ttotal: 60.2ms\tremaining: 39.4ms\n",
            "29:\tlearn: 0.2159010\ttotal: 62ms\tremaining: 37.2ms\n",
            "30:\tlearn: 0.2132954\ttotal: 63.9ms\tremaining: 35ms\n",
            "31:\tlearn: 0.2102299\ttotal: 65.8ms\tremaining: 32.9ms\n",
            "32:\tlearn: 0.2076280\ttotal: 67.7ms\tremaining: 30.8ms\n",
            "33:\tlearn: 0.2043188\ttotal: 69.6ms\tremaining: 28.6ms\n",
            "34:\tlearn: 0.2017849\ttotal: 71.5ms\tremaining: 26.6ms\n",
            "35:\tlearn: 0.1993718\ttotal: 73.5ms\tremaining: 24.5ms\n",
            "36:\tlearn: 0.1972299\ttotal: 75.3ms\tremaining: 22.4ms\n",
            "37:\tlearn: 0.1950197\ttotal: 77.1ms\tremaining: 20.3ms\n",
            "38:\tlearn: 0.1927135\ttotal: 79.1ms\tremaining: 18.2ms\n",
            "39:\tlearn: 0.1895038\ttotal: 81ms\tremaining: 16.2ms\n",
            "40:\tlearn: 0.1867644\ttotal: 83ms\tremaining: 14.2ms\n",
            "41:\tlearn: 0.1842014\ttotal: 84.8ms\tremaining: 12.1ms\n",
            "42:\tlearn: 0.1821212\ttotal: 86.7ms\tremaining: 10.1ms\n",
            "43:\tlearn: 0.1794173\ttotal: 88.6ms\tremaining: 8.05ms\n",
            "44:\tlearn: 0.1766213\ttotal: 90.4ms\tremaining: 6.03ms\n",
            "45:\tlearn: 0.1742184\ttotal: 92.4ms\tremaining: 4.01ms\n",
            "46:\tlearn: 0.1725620\ttotal: 94.4ms\tremaining: 2.01ms\n",
            "47:\tlearn: 0.1705090\ttotal: 96.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.6ms\tremaining: 75.2ms\n",
            "1:\tlearn: 0.4049315\ttotal: 1.95ms\tremaining: 44.8ms\n",
            "2:\tlearn: 0.3788145\ttotal: 3.91ms\tremaining: 58.6ms\n",
            "3:\tlearn: 0.3658016\ttotal: 5.9ms\tremaining: 64.9ms\n",
            "4:\tlearn: 0.3428474\ttotal: 6.83ms\tremaining: 58.8ms\n",
            "5:\tlearn: 0.3234303\ttotal: 7.65ms\tremaining: 53.6ms\n",
            "6:\tlearn: 0.3158416\ttotal: 9.55ms\tremaining: 55.9ms\n",
            "7:\tlearn: 0.3097739\ttotal: 11.6ms\tremaining: 57.8ms\n",
            "8:\tlearn: 0.3040041\ttotal: 13.5ms\tremaining: 58.5ms\n",
            "9:\tlearn: 0.2975585\ttotal: 15.5ms\tremaining: 58.8ms\n",
            "10:\tlearn: 0.2898709\ttotal: 17.6ms\tremaining: 59.2ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.2ms\tremaining: 60.5ms\n",
            "12:\tlearn: 0.2794184\ttotal: 23.7ms\tremaining: 63.8ms\n",
            "13:\tlearn: 0.2740314\ttotal: 28.8ms\tremaining: 70ms\n",
            "14:\tlearn: 0.2705542\ttotal: 33.6ms\tremaining: 74ms\n",
            "15:\tlearn: 0.2673919\ttotal: 38.8ms\tremaining: 77.5ms\n",
            "16:\tlearn: 0.2623365\ttotal: 40.5ms\tremaining: 73.8ms\n",
            "17:\tlearn: 0.2595719\ttotal: 42.7ms\tremaining: 71.1ms\n",
            "18:\tlearn: 0.2545713\ttotal: 44.7ms\tremaining: 68.3ms\n",
            "19:\tlearn: 0.2510766\ttotal: 46.7ms\tremaining: 65.4ms\n",
            "20:\tlearn: 0.2477056\ttotal: 48.6ms\tremaining: 62.5ms\n",
            "21:\tlearn: 0.2437884\ttotal: 50.6ms\tremaining: 59.8ms\n",
            "22:\tlearn: 0.2404080\ttotal: 52.6ms\tremaining: 57.1ms\n",
            "23:\tlearn: 0.2369058\ttotal: 54.6ms\tremaining: 54.6ms\n",
            "24:\tlearn: 0.2331119\ttotal: 56.5ms\tremaining: 51.9ms\n",
            "25:\tlearn: 0.2293455\ttotal: 58.3ms\tremaining: 49.3ms\n",
            "26:\tlearn: 0.2256418\ttotal: 60.2ms\tremaining: 46.8ms\n",
            "27:\tlearn: 0.2221119\ttotal: 62.2ms\tremaining: 44.4ms\n",
            "28:\tlearn: 0.2190925\ttotal: 64ms\tremaining: 42ms\n",
            "29:\tlearn: 0.2161731\ttotal: 65.9ms\tremaining: 39.5ms\n",
            "30:\tlearn: 0.2135041\ttotal: 67.8ms\tremaining: 37.2ms\n",
            "31:\tlearn: 0.2113382\ttotal: 69.8ms\tremaining: 34.9ms\n",
            "32:\tlearn: 0.2083485\ttotal: 71.7ms\tremaining: 32.6ms\n",
            "33:\tlearn: 0.2058588\ttotal: 73.5ms\tremaining: 30.3ms\n",
            "34:\tlearn: 0.2024895\ttotal: 75.4ms\tremaining: 28ms\n",
            "35:\tlearn: 0.1997586\ttotal: 77.3ms\tremaining: 25.8ms\n",
            "36:\tlearn: 0.1976953\ttotal: 81ms\tremaining: 24.1ms\n",
            "37:\tlearn: 0.1949453\ttotal: 84.6ms\tremaining: 22.3ms\n",
            "38:\tlearn: 0.1931445\ttotal: 87.8ms\tremaining: 20.3ms\n",
            "39:\tlearn: 0.1900292\ttotal: 89.8ms\tremaining: 18ms\n",
            "40:\tlearn: 0.1872454\ttotal: 91.8ms\tremaining: 15.7ms\n",
            "41:\tlearn: 0.1848207\ttotal: 93.9ms\tremaining: 13.4ms\n",
            "42:\tlearn: 0.1823519\ttotal: 96.6ms\tremaining: 11.2ms\n",
            "43:\tlearn: 0.1801956\ttotal: 99.1ms\tremaining: 9.01ms\n",
            "44:\tlearn: 0.1784734\ttotal: 101ms\tremaining: 6.71ms\n",
            "45:\tlearn: 0.1765592\ttotal: 103ms\tremaining: 4.46ms\n",
            "46:\tlearn: 0.1747084\ttotal: 105ms\tremaining: 2.23ms\n",
            "47:\tlearn: 0.1724770\ttotal: 107ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.83ms\tremaining: 86.1ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.48ms\tremaining: 56.9ms\n",
            "2:\tlearn: 0.3698157\ttotal: 3.22ms\tremaining: 48.3ms\n",
            "3:\tlearn: 0.3518120\ttotal: 5.15ms\tremaining: 56.7ms\n",
            "4:\tlearn: 0.3441195\ttotal: 7.06ms\tremaining: 60.7ms\n",
            "5:\tlearn: 0.3328396\ttotal: 8.85ms\tremaining: 61.9ms\n",
            "6:\tlearn: 0.3256704\ttotal: 10.7ms\tremaining: 62.9ms\n",
            "7:\tlearn: 0.3174441\ttotal: 12.7ms\tremaining: 63.3ms\n",
            "8:\tlearn: 0.3090762\ttotal: 14.5ms\tremaining: 62.8ms\n",
            "9:\tlearn: 0.3028459\ttotal: 16.5ms\tremaining: 62.9ms\n",
            "10:\tlearn: 0.2958541\ttotal: 18.4ms\tremaining: 61.8ms\n",
            "11:\tlearn: 0.2901166\ttotal: 20.2ms\tremaining: 60.6ms\n",
            "12:\tlearn: 0.2841803\ttotal: 22.1ms\tremaining: 59.5ms\n",
            "13:\tlearn: 0.2789751\ttotal: 24ms\tremaining: 58.4ms\n",
            "14:\tlearn: 0.2715599\ttotal: 26ms\tremaining: 57.1ms\n",
            "15:\tlearn: 0.2663544\ttotal: 28ms\tremaining: 56ms\n",
            "16:\tlearn: 0.2615546\ttotal: 29.9ms\tremaining: 54.6ms\n",
            "17:\tlearn: 0.2560079\ttotal: 31.9ms\tremaining: 53.2ms\n",
            "18:\tlearn: 0.2507480\ttotal: 33.8ms\tremaining: 51.7ms\n",
            "19:\tlearn: 0.2450678\ttotal: 35.8ms\tremaining: 50.1ms\n",
            "20:\tlearn: 0.2413892\ttotal: 37.6ms\tremaining: 48.3ms\n",
            "21:\tlearn: 0.2378437\ttotal: 39.4ms\tremaining: 46.6ms\n",
            "22:\tlearn: 0.2344010\ttotal: 41.3ms\tremaining: 44.9ms\n",
            "23:\tlearn: 0.2304940\ttotal: 43.1ms\tremaining: 43.1ms\n",
            "24:\tlearn: 0.2269540\ttotal: 45ms\tremaining: 41.4ms\n",
            "25:\tlearn: 0.2232713\ttotal: 47ms\tremaining: 39.8ms\n",
            "26:\tlearn: 0.2208577\ttotal: 48.7ms\tremaining: 37.9ms\n",
            "27:\tlearn: 0.2181825\ttotal: 50.6ms\tremaining: 36.2ms\n",
            "28:\tlearn: 0.2149071\ttotal: 52.6ms\tremaining: 34.5ms\n",
            "29:\tlearn: 0.2123638\ttotal: 54.6ms\tremaining: 32.8ms\n",
            "30:\tlearn: 0.2094640\ttotal: 56.6ms\tremaining: 31ms\n",
            "31:\tlearn: 0.2071716\ttotal: 58.5ms\tremaining: 29.2ms\n",
            "32:\tlearn: 0.2045371\ttotal: 60.5ms\tremaining: 27.5ms\n",
            "33:\tlearn: 0.2018712\ttotal: 62.5ms\tremaining: 25.7ms\n",
            "34:\tlearn: 0.1995442\ttotal: 64.4ms\tremaining: 23.9ms\n",
            "35:\tlearn: 0.1970515\ttotal: 66.4ms\tremaining: 22.1ms\n",
            "36:\tlearn: 0.1946725\ttotal: 68.3ms\tremaining: 20.3ms\n",
            "37:\tlearn: 0.1924392\ttotal: 70.3ms\tremaining: 18.5ms\n",
            "38:\tlearn: 0.1893508\ttotal: 72.3ms\tremaining: 16.7ms\n",
            "39:\tlearn: 0.1868097\ttotal: 74.2ms\tremaining: 14.8ms\n",
            "40:\tlearn: 0.1846310\ttotal: 76.3ms\tremaining: 13ms\n",
            "41:\tlearn: 0.1820837\ttotal: 79.8ms\tremaining: 11.4ms\n",
            "42:\tlearn: 0.1795780\ttotal: 82.4ms\tremaining: 9.59ms\n",
            "43:\tlearn: 0.1777006\ttotal: 84.4ms\tremaining: 7.67ms\n",
            "44:\tlearn: 0.1761110\ttotal: 86.3ms\tremaining: 5.75ms\n",
            "45:\tlearn: 0.1739210\ttotal: 88.3ms\tremaining: 3.84ms\n",
            "46:\tlearn: 0.1717247\ttotal: 90.2ms\tremaining: 1.92ms\n",
            "47:\tlearn: 0.1694785\ttotal: 92.3ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.72ms\tremaining: 80.7ms\n",
            "1:\tlearn: 0.3745079\ttotal: 2.34ms\tremaining: 53.8ms\n",
            "2:\tlearn: 0.3383999\ttotal: 4.34ms\tremaining: 65.1ms\n",
            "3:\tlearn: 0.3266560\ttotal: 6.45ms\tremaining: 70.9ms\n",
            "4:\tlearn: 0.3080259\ttotal: 8.24ms\tremaining: 70.9ms\n",
            "5:\tlearn: 0.2907443\ttotal: 10.2ms\tremaining: 71.4ms\n",
            "6:\tlearn: 0.2818467\ttotal: 12.1ms\tremaining: 70.9ms\n",
            "7:\tlearn: 0.2691784\ttotal: 13.6ms\tremaining: 68ms\n",
            "8:\tlearn: 0.2611618\ttotal: 15.7ms\tremaining: 67.9ms\n",
            "9:\tlearn: 0.2519898\ttotal: 17.7ms\tremaining: 67.1ms\n",
            "10:\tlearn: 0.2462992\ttotal: 19.6ms\tremaining: 65.9ms\n",
            "11:\tlearn: 0.2416348\ttotal: 21.6ms\tremaining: 64.9ms\n",
            "12:\tlearn: 0.2368688\ttotal: 23.6ms\tremaining: 63.4ms\n",
            "13:\tlearn: 0.2320170\ttotal: 25.6ms\tremaining: 62.1ms\n",
            "14:\tlearn: 0.2262186\ttotal: 28.9ms\tremaining: 63.6ms\n",
            "15:\tlearn: 0.2215380\ttotal: 32.8ms\tremaining: 65.7ms\n",
            "16:\tlearn: 0.2176313\ttotal: 35.6ms\tremaining: 64.9ms\n",
            "17:\tlearn: 0.2138494\ttotal: 37.9ms\tremaining: 63.2ms\n",
            "18:\tlearn: 0.2100966\ttotal: 42.8ms\tremaining: 65.4ms\n",
            "19:\tlearn: 0.2068557\ttotal: 44.4ms\tremaining: 62.2ms\n",
            "20:\tlearn: 0.2029945\ttotal: 46.3ms\tremaining: 59.6ms\n",
            "21:\tlearn: 0.2001044\ttotal: 48.1ms\tremaining: 56.8ms\n",
            "22:\tlearn: 0.1970766\ttotal: 49.9ms\tremaining: 54.3ms\n",
            "23:\tlearn: 0.1940285\ttotal: 52ms\tremaining: 52ms\n",
            "24:\tlearn: 0.1910934\ttotal: 54.1ms\tremaining: 49.7ms\n",
            "25:\tlearn: 0.1879112\ttotal: 56.1ms\tremaining: 47.5ms\n",
            "26:\tlearn: 0.1852765\ttotal: 58ms\tremaining: 45.1ms\n",
            "27:\tlearn: 0.1827068\ttotal: 60.1ms\tremaining: 42.9ms\n",
            "28:\tlearn: 0.1803359\ttotal: 63.1ms\tremaining: 41.4ms\n",
            "29:\tlearn: 0.1779549\ttotal: 65ms\tremaining: 39ms\n",
            "30:\tlearn: 0.1757984\ttotal: 66.7ms\tremaining: 36.6ms\n",
            "31:\tlearn: 0.1724570\ttotal: 68.5ms\tremaining: 34.3ms\n",
            "32:\tlearn: 0.1703672\ttotal: 70.5ms\tremaining: 32ms\n",
            "33:\tlearn: 0.1685175\ttotal: 72.4ms\tremaining: 29.8ms\n",
            "34:\tlearn: 0.1666049\ttotal: 74.2ms\tremaining: 27.6ms\n",
            "35:\tlearn: 0.1648374\ttotal: 76.1ms\tremaining: 25.4ms\n",
            "36:\tlearn: 0.1631656\ttotal: 78.1ms\tremaining: 23.2ms\n",
            "37:\tlearn: 0.1615072\ttotal: 80.4ms\tremaining: 21.1ms\n",
            "38:\tlearn: 0.1598928\ttotal: 82.3ms\tremaining: 19ms\n",
            "39:\tlearn: 0.1584040\ttotal: 84.3ms\tremaining: 16.9ms\n",
            "40:\tlearn: 0.1566573\ttotal: 86.3ms\tremaining: 14.7ms\n",
            "41:\tlearn: 0.1544748\ttotal: 88.2ms\tremaining: 12.6ms\n",
            "42:\tlearn: 0.1525493\ttotal: 90.3ms\tremaining: 10.5ms\n",
            "43:\tlearn: 0.1506610\ttotal: 92.1ms\tremaining: 8.37ms\n",
            "44:\tlearn: 0.1483410\ttotal: 94.1ms\tremaining: 6.27ms\n",
            "45:\tlearn: 0.1468477\ttotal: 96.1ms\tremaining: 4.18ms\n",
            "46:\tlearn: 0.1454975\ttotal: 98ms\tremaining: 2.08ms\n",
            "47:\tlearn: 0.1439431\ttotal: 100ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.65ms\tremaining: 77.4ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.26ms\tremaining: 52ms\n",
            "2:\tlearn: 0.3203557\ttotal: 2.95ms\tremaining: 44.2ms\n",
            "3:\tlearn: 0.3063743\ttotal: 4.79ms\tremaining: 52.7ms\n",
            "4:\tlearn: 0.2970911\ttotal: 6.61ms\tremaining: 56.9ms\n",
            "5:\tlearn: 0.2891054\ttotal: 8.47ms\tremaining: 59.3ms\n",
            "6:\tlearn: 0.2792409\ttotal: 10.3ms\tremaining: 60.4ms\n",
            "7:\tlearn: 0.2716618\ttotal: 12.2ms\tremaining: 60.8ms\n",
            "8:\tlearn: 0.2621352\ttotal: 14ms\tremaining: 60.6ms\n",
            "9:\tlearn: 0.2537973\ttotal: 15.9ms\tremaining: 60.4ms\n",
            "10:\tlearn: 0.2473429\ttotal: 17.6ms\tremaining: 59.3ms\n",
            "11:\tlearn: 0.2416695\ttotal: 19.7ms\tremaining: 59ms\n",
            "12:\tlearn: 0.2366343\ttotal: 21.6ms\tremaining: 58.2ms\n",
            "13:\tlearn: 0.2298385\ttotal: 23.8ms\tremaining: 57.7ms\n",
            "14:\tlearn: 0.2249545\ttotal: 25.6ms\tremaining: 56.3ms\n",
            "15:\tlearn: 0.2192054\ttotal: 27.5ms\tremaining: 55ms\n",
            "16:\tlearn: 0.2150242\ttotal: 29.4ms\tremaining: 53.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 31.2ms\tremaining: 51.9ms\n",
            "18:\tlearn: 0.2056324\ttotal: 32.9ms\tremaining: 50.2ms\n",
            "19:\tlearn: 0.2021225\ttotal: 34.7ms\tremaining: 48.6ms\n",
            "20:\tlearn: 0.1989042\ttotal: 36.6ms\tremaining: 47ms\n",
            "21:\tlearn: 0.1961040\ttotal: 38.5ms\tremaining: 45.5ms\n",
            "22:\tlearn: 0.1934794\ttotal: 40.4ms\tremaining: 43.9ms\n",
            "23:\tlearn: 0.1902438\ttotal: 42.3ms\tremaining: 42.3ms\n",
            "24:\tlearn: 0.1874921\ttotal: 44.3ms\tremaining: 40.7ms\n",
            "25:\tlearn: 0.1829904\ttotal: 46.3ms\tremaining: 39.2ms\n",
            "26:\tlearn: 0.1804169\ttotal: 48.3ms\tremaining: 37.6ms\n",
            "27:\tlearn: 0.1776989\ttotal: 50.2ms\tremaining: 35.8ms\n",
            "28:\tlearn: 0.1751387\ttotal: 52.1ms\tremaining: 34.1ms\n",
            "29:\tlearn: 0.1727570\ttotal: 54ms\tremaining: 32.4ms\n",
            "30:\tlearn: 0.1693663\ttotal: 56ms\tremaining: 30.7ms\n",
            "31:\tlearn: 0.1661883\ttotal: 57.9ms\tremaining: 29ms\n",
            "32:\tlearn: 0.1641011\ttotal: 59.9ms\tremaining: 27.2ms\n",
            "33:\tlearn: 0.1616271\ttotal: 61.8ms\tremaining: 25.5ms\n",
            "34:\tlearn: 0.1593621\ttotal: 63.7ms\tremaining: 23.7ms\n",
            "35:\tlearn: 0.1576181\ttotal: 65.9ms\tremaining: 22ms\n",
            "36:\tlearn: 0.1557020\ttotal: 67.9ms\tremaining: 20.2ms\n",
            "37:\tlearn: 0.1541003\ttotal: 70ms\tremaining: 18.4ms\n",
            "38:\tlearn: 0.1522873\ttotal: 72ms\tremaining: 16.6ms\n",
            "39:\tlearn: 0.1502740\ttotal: 74.1ms\tremaining: 14.8ms\n",
            "40:\tlearn: 0.1483554\ttotal: 76.1ms\tremaining: 13ms\n",
            "41:\tlearn: 0.1465885\ttotal: 78.2ms\tremaining: 11.2ms\n",
            "42:\tlearn: 0.1443271\ttotal: 80.3ms\tremaining: 9.34ms\n",
            "43:\tlearn: 0.1425567\ttotal: 82.1ms\tremaining: 7.46ms\n",
            "44:\tlearn: 0.1409543\ttotal: 84.1ms\tremaining: 5.6ms\n",
            "45:\tlearn: 0.1393691\ttotal: 86.2ms\tremaining: 3.75ms\n",
            "46:\tlearn: 0.1378187\ttotal: 88.2ms\tremaining: 1.88ms\n",
            "47:\tlearn: 0.1364367\ttotal: 90.4ms\tremaining: 0us\n",
            "0:\tlearn: 0.5271443\ttotal: 1.77ms\tremaining: 85.1ms\n",
            "1:\tlearn: 0.4229987\ttotal: 2.6ms\tremaining: 61.1ms\n",
            "2:\tlearn: 0.3843342\ttotal: 4.54ms\tremaining: 69.7ms\n",
            "3:\tlearn: 0.3652888\ttotal: 6.45ms\tremaining: 72.5ms\n",
            "4:\tlearn: 0.3496343\ttotal: 8.47ms\tremaining: 74.5ms\n",
            "5:\tlearn: 0.3393969\ttotal: 10.4ms\tremaining: 74.5ms\n",
            "6:\tlearn: 0.3300914\ttotal: 12.4ms\tremaining: 74.2ms\n",
            "7:\tlearn: 0.3229079\ttotal: 14.2ms\tremaining: 72.9ms\n",
            "8:\tlearn: 0.3148279\ttotal: 16.2ms\tremaining: 71.9ms\n",
            "9:\tlearn: 0.3054626\ttotal: 18.1ms\tremaining: 70.6ms\n",
            "10:\tlearn: 0.2983658\ttotal: 20ms\tremaining: 69.1ms\n",
            "11:\tlearn: 0.2903440\ttotal: 21.8ms\tremaining: 67.2ms\n",
            "12:\tlearn: 0.2852979\ttotal: 23.8ms\tremaining: 65.8ms\n",
            "13:\tlearn: 0.2798563\ttotal: 25.6ms\tremaining: 63.9ms\n",
            "14:\tlearn: 0.2747341\ttotal: 27.6ms\tremaining: 62.5ms\n",
            "15:\tlearn: 0.2702568\ttotal: 29.8ms\tremaining: 61.5ms\n",
            "16:\tlearn: 0.2650537\ttotal: 31.8ms\tremaining: 59.9ms\n",
            "17:\tlearn: 0.2601005\ttotal: 33.7ms\tremaining: 58ms\n",
            "18:\tlearn: 0.2560578\ttotal: 35.5ms\tremaining: 56.1ms\n",
            "19:\tlearn: 0.2530381\ttotal: 37.3ms\tremaining: 54.1ms\n",
            "20:\tlearn: 0.2498453\ttotal: 39.2ms\tremaining: 52.2ms\n",
            "21:\tlearn: 0.2461646\ttotal: 41ms\tremaining: 50.3ms\n",
            "22:\tlearn: 0.2424369\ttotal: 43.2ms\tremaining: 48.9ms\n",
            "23:\tlearn: 0.2392835\ttotal: 45.2ms\tremaining: 47.1ms\n",
            "24:\tlearn: 0.2339070\ttotal: 47.4ms\tremaining: 45.5ms\n",
            "25:\tlearn: 0.2301706\ttotal: 49.4ms\tremaining: 43.7ms\n",
            "26:\tlearn: 0.2263007\ttotal: 51.3ms\tremaining: 41.8ms\n",
            "27:\tlearn: 0.2223209\ttotal: 53.4ms\tremaining: 40ms\n",
            "28:\tlearn: 0.2190932\ttotal: 55.2ms\tremaining: 38.1ms\n",
            "29:\tlearn: 0.2159010\ttotal: 57.2ms\tremaining: 36.2ms\n",
            "30:\tlearn: 0.2132954\ttotal: 59.2ms\tremaining: 34.4ms\n",
            "31:\tlearn: 0.2102299\ttotal: 61.1ms\tremaining: 32.5ms\n",
            "32:\tlearn: 0.2076280\ttotal: 63.1ms\tremaining: 30.6ms\n",
            "33:\tlearn: 0.2043188\ttotal: 65.1ms\tremaining: 28.7ms\n",
            "34:\tlearn: 0.2017849\ttotal: 67.3ms\tremaining: 26.9ms\n",
            "35:\tlearn: 0.1993718\ttotal: 69.2ms\tremaining: 25ms\n",
            "36:\tlearn: 0.1972299\ttotal: 71.2ms\tremaining: 23.1ms\n",
            "37:\tlearn: 0.1950197\ttotal: 73.2ms\tremaining: 21.2ms\n",
            "38:\tlearn: 0.1927135\ttotal: 75.1ms\tremaining: 19.3ms\n",
            "39:\tlearn: 0.1895038\ttotal: 77.1ms\tremaining: 17.4ms\n",
            "40:\tlearn: 0.1867644\ttotal: 79.2ms\tremaining: 15.4ms\n",
            "41:\tlearn: 0.1842014\ttotal: 81.1ms\tremaining: 13.5ms\n",
            "42:\tlearn: 0.1821212\ttotal: 82.9ms\tremaining: 11.6ms\n",
            "43:\tlearn: 0.1794173\ttotal: 84.9ms\tremaining: 9.65ms\n",
            "44:\tlearn: 0.1766213\ttotal: 86.8ms\tremaining: 7.71ms\n",
            "45:\tlearn: 0.1742184\ttotal: 88.6ms\tremaining: 5.78ms\n",
            "46:\tlearn: 0.1725620\ttotal: 90.5ms\tremaining: 3.85ms\n",
            "47:\tlearn: 0.1705090\ttotal: 92.5ms\tremaining: 1.93ms\n",
            "48:\tlearn: 0.1688721\ttotal: 94.5ms\tremaining: 0us\n",
            "0:\tlearn: 0.5328005\ttotal: 1.76ms\tremaining: 84.6ms\n",
            "1:\tlearn: 0.4049315\ttotal: 2.37ms\tremaining: 55.7ms\n",
            "2:\tlearn: 0.3788145\ttotal: 4.29ms\tremaining: 65.8ms\n",
            "3:\tlearn: 0.3658016\ttotal: 6.29ms\tremaining: 70.8ms\n",
            "4:\tlearn: 0.3428474\ttotal: 7.27ms\tremaining: 64ms\n",
            "5:\tlearn: 0.3234303\ttotal: 8.29ms\tremaining: 59.4ms\n",
            "6:\tlearn: 0.3158416\ttotal: 10.2ms\tremaining: 61.3ms\n",
            "7:\tlearn: 0.3097739\ttotal: 12.2ms\tremaining: 62.4ms\n",
            "8:\tlearn: 0.3040041\ttotal: 14.1ms\tremaining: 62.9ms\n",
            "9:\tlearn: 0.2975585\ttotal: 16.2ms\tremaining: 63ms\n",
            "10:\tlearn: 0.2898709\ttotal: 18.1ms\tremaining: 62.5ms\n",
            "11:\tlearn: 0.2845372\ttotal: 20.1ms\tremaining: 62.1ms\n",
            "12:\tlearn: 0.2794184\ttotal: 22.2ms\tremaining: 61.5ms\n",
            "13:\tlearn: 0.2740314\ttotal: 24.2ms\tremaining: 60.4ms\n",
            "14:\tlearn: 0.2705542\ttotal: 26ms\tremaining: 59ms\n",
            "15:\tlearn: 0.2673919\ttotal: 27.9ms\tremaining: 57.5ms\n",
            "16:\tlearn: 0.2623365\ttotal: 29.7ms\tremaining: 55.9ms\n",
            "17:\tlearn: 0.2595719\ttotal: 31.7ms\tremaining: 54.5ms\n",
            "18:\tlearn: 0.2545713\ttotal: 33.6ms\tremaining: 53.1ms\n",
            "19:\tlearn: 0.2510766\ttotal: 35.7ms\tremaining: 51.7ms\n",
            "20:\tlearn: 0.2477056\ttotal: 37.6ms\tremaining: 50.2ms\n",
            "21:\tlearn: 0.2437884\ttotal: 39.6ms\tremaining: 48.6ms\n",
            "22:\tlearn: 0.2404080\ttotal: 41.5ms\tremaining: 47ms\n",
            "23:\tlearn: 0.2369058\ttotal: 43.4ms\tremaining: 45.2ms\n",
            "24:\tlearn: 0.2331119\ttotal: 45.5ms\tremaining: 43.6ms\n",
            "25:\tlearn: 0.2293455\ttotal: 47.4ms\tremaining: 41.9ms\n",
            "26:\tlearn: 0.2256418\ttotal: 49.4ms\tremaining: 40.2ms\n",
            "27:\tlearn: 0.2221119\ttotal: 51.3ms\tremaining: 38.5ms\n",
            "28:\tlearn: 0.2190925\ttotal: 53.1ms\tremaining: 36.6ms\n",
            "29:\tlearn: 0.2161731\ttotal: 55.2ms\tremaining: 35ms\n",
            "30:\tlearn: 0.2135041\ttotal: 57.2ms\tremaining: 33.2ms\n",
            "31:\tlearn: 0.2113382\ttotal: 59.3ms\tremaining: 31.5ms\n",
            "32:\tlearn: 0.2083485\ttotal: 61.3ms\tremaining: 29.7ms\n",
            "33:\tlearn: 0.2058588\ttotal: 63.3ms\tremaining: 27.9ms\n",
            "34:\tlearn: 0.2024895\ttotal: 65.2ms\tremaining: 26.1ms\n",
            "35:\tlearn: 0.1997586\ttotal: 67.3ms\tremaining: 24.3ms\n",
            "36:\tlearn: 0.1976953\ttotal: 69.4ms\tremaining: 22.5ms\n",
            "37:\tlearn: 0.1949453\ttotal: 71.5ms\tremaining: 20.7ms\n",
            "38:\tlearn: 0.1931445\ttotal: 73.6ms\tremaining: 18.9ms\n",
            "39:\tlearn: 0.1900292\ttotal: 77.1ms\tremaining: 17.4ms\n",
            "40:\tlearn: 0.1872454\ttotal: 80ms\tremaining: 15.6ms\n",
            "41:\tlearn: 0.1848207\ttotal: 83.6ms\tremaining: 13.9ms\n",
            "42:\tlearn: 0.1823519\ttotal: 86ms\tremaining: 12ms\n",
            "43:\tlearn: 0.1801956\ttotal: 87.9ms\tremaining: 9.98ms\n",
            "44:\tlearn: 0.1784734\ttotal: 89.6ms\tremaining: 7.96ms\n",
            "45:\tlearn: 0.1765592\ttotal: 91.6ms\tremaining: 5.97ms\n",
            "46:\tlearn: 0.1747084\ttotal: 93.6ms\tremaining: 3.98ms\n",
            "47:\tlearn: 0.1724770\ttotal: 95.8ms\tremaining: 2ms\n",
            "48:\tlearn: 0.1708807\ttotal: 97.9ms\tremaining: 0us\n",
            "0:\tlearn: 0.5205269\ttotal: 1.88ms\tremaining: 90.4ms\n",
            "1:\tlearn: 0.4107278\ttotal: 2.23ms\tremaining: 52.5ms\n",
            "2:\tlearn: 0.3698157\ttotal: 3.34ms\tremaining: 51.2ms\n",
            "3:\tlearn: 0.3518120\ttotal: 5.44ms\tremaining: 61.2ms\n",
            "4:\tlearn: 0.3441195\ttotal: 7.41ms\tremaining: 65.2ms\n",
            "5:\tlearn: 0.3328396\ttotal: 9.37ms\tremaining: 67.1ms\n",
            "6:\tlearn: 0.3256704\ttotal: 11.4ms\tremaining: 68.5ms\n",
            "7:\tlearn: 0.3174441\ttotal: 13.7ms\tremaining: 70.4ms\n",
            "8:\tlearn: 0.3090762\ttotal: 15.9ms\tremaining: 70.6ms\n",
            "9:\tlearn: 0.3028459\ttotal: 18.1ms\tremaining: 70.7ms\n",
            "10:\tlearn: 0.2958541\ttotal: 20.4ms\tremaining: 70.4ms\n",
            "11:\tlearn: 0.2901166\ttotal: 22.4ms\tremaining: 69.2ms\n",
            "12:\tlearn: 0.2841803\ttotal: 24.4ms\tremaining: 67.7ms\n",
            "13:\tlearn: 0.2789751\ttotal: 26.6ms\tremaining: 66.6ms\n",
            "14:\tlearn: 0.2715599\ttotal: 28.7ms\tremaining: 65ms\n",
            "15:\tlearn: 0.2663544\ttotal: 32.1ms\tremaining: 66.3ms\n",
            "16:\tlearn: 0.2615546\ttotal: 35.5ms\tremaining: 66.9ms\n",
            "17:\tlearn: 0.2560079\ttotal: 37.3ms\tremaining: 64.2ms\n",
            "18:\tlearn: 0.2507480\ttotal: 39.2ms\tremaining: 61.9ms\n",
            "19:\tlearn: 0.2450678\ttotal: 41.2ms\tremaining: 59.8ms\n",
            "20:\tlearn: 0.2413892\ttotal: 43.3ms\tremaining: 57.8ms\n",
            "21:\tlearn: 0.2378437\ttotal: 45.3ms\tremaining: 55.6ms\n",
            "22:\tlearn: 0.2344010\ttotal: 47.6ms\tremaining: 53.8ms\n",
            "23:\tlearn: 0.2304940\ttotal: 49.6ms\tremaining: 51.7ms\n",
            "24:\tlearn: 0.2269540\ttotal: 51.7ms\tremaining: 49.6ms\n",
            "25:\tlearn: 0.2232713\ttotal: 53.6ms\tremaining: 47.5ms\n",
            "26:\tlearn: 0.2208577\ttotal: 55.7ms\tremaining: 45.4ms\n",
            "27:\tlearn: 0.2181825\ttotal: 57.7ms\tremaining: 43.3ms\n",
            "28:\tlearn: 0.2149071\ttotal: 59.7ms\tremaining: 41.2ms\n",
            "29:\tlearn: 0.2123638\ttotal: 61.7ms\tremaining: 39.1ms\n",
            "30:\tlearn: 0.2094640\ttotal: 63.7ms\tremaining: 37ms\n",
            "31:\tlearn: 0.2071716\ttotal: 65.6ms\tremaining: 34.9ms\n",
            "32:\tlearn: 0.2045371\ttotal: 67.6ms\tremaining: 32.8ms\n",
            "33:\tlearn: 0.2018712\ttotal: 69.6ms\tremaining: 30.7ms\n",
            "34:\tlearn: 0.1995442\ttotal: 71.6ms\tremaining: 28.7ms\n",
            "35:\tlearn: 0.1970515\ttotal: 73.8ms\tremaining: 26.7ms\n",
            "36:\tlearn: 0.1946725\ttotal: 75.9ms\tremaining: 24.6ms\n",
            "37:\tlearn: 0.1924392\ttotal: 78ms\tremaining: 22.6ms\n",
            "38:\tlearn: 0.1893508\ttotal: 80.1ms\tremaining: 20.5ms\n",
            "39:\tlearn: 0.1868097\ttotal: 82.1ms\tremaining: 18.5ms\n",
            "40:\tlearn: 0.1846310\ttotal: 84ms\tremaining: 16.4ms\n",
            "41:\tlearn: 0.1820837\ttotal: 86.1ms\tremaining: 14.3ms\n",
            "42:\tlearn: 0.1795780\ttotal: 88.1ms\tremaining: 12.3ms\n",
            "43:\tlearn: 0.1777006\ttotal: 90.2ms\tremaining: 10.2ms\n",
            "44:\tlearn: 0.1761110\ttotal: 92.2ms\tremaining: 8.2ms\n",
            "45:\tlearn: 0.1739210\ttotal: 94.3ms\tremaining: 6.15ms\n",
            "46:\tlearn: 0.1717247\ttotal: 96.4ms\tremaining: 4.1ms\n",
            "47:\tlearn: 0.1694785\ttotal: 98.5ms\tremaining: 2.05ms\n",
            "48:\tlearn: 0.1675220\ttotal: 101ms\tremaining: 0us\n",
            "0:\tlearn: 0.4885102\ttotal: 1.73ms\tremaining: 82.8ms\n",
            "1:\tlearn: 0.3745079\ttotal: 3.18ms\tremaining: 74.8ms\n",
            "2:\tlearn: 0.3383999\ttotal: 5.33ms\tremaining: 81.7ms\n",
            "3:\tlearn: 0.3266560\ttotal: 7.18ms\tremaining: 80.8ms\n",
            "4:\tlearn: 0.3080259\ttotal: 9.31ms\tremaining: 81.9ms\n",
            "5:\tlearn: 0.2907443\ttotal: 11.4ms\tremaining: 81.5ms\n",
            "6:\tlearn: 0.2818467\ttotal: 13.4ms\tremaining: 80.3ms\n",
            "7:\tlearn: 0.2691784\ttotal: 14.7ms\tremaining: 75.5ms\n",
            "8:\tlearn: 0.2611618\ttotal: 16.7ms\tremaining: 74.4ms\n",
            "9:\tlearn: 0.2519898\ttotal: 21.8ms\tremaining: 85ms\n",
            "10:\tlearn: 0.2462992\ttotal: 24.6ms\tremaining: 85ms\n",
            "11:\tlearn: 0.2416348\ttotal: 27.7ms\tremaining: 85.3ms\n",
            "12:\tlearn: 0.2368688\ttotal: 30.2ms\tremaining: 83.6ms\n",
            "13:\tlearn: 0.2320170\ttotal: 32.4ms\tremaining: 81.1ms\n",
            "14:\tlearn: 0.2262186\ttotal: 34.1ms\tremaining: 77.3ms\n",
            "15:\tlearn: 0.2215380\ttotal: 36.1ms\tremaining: 74.4ms\n",
            "16:\tlearn: 0.2176313\ttotal: 37.9ms\tremaining: 71.3ms\n",
            "17:\tlearn: 0.2138494\ttotal: 39.8ms\tremaining: 68.6ms\n",
            "18:\tlearn: 0.2100966\ttotal: 41.8ms\tremaining: 66ms\n",
            "19:\tlearn: 0.2068557\ttotal: 43.7ms\tremaining: 63.4ms\n",
            "20:\tlearn: 0.2029945\ttotal: 45.7ms\tremaining: 60.9ms\n",
            "21:\tlearn: 0.2001044\ttotal: 47.7ms\tremaining: 58.5ms\n",
            "22:\tlearn: 0.1970766\ttotal: 49.6ms\tremaining: 56.1ms\n",
            "23:\tlearn: 0.1940285\ttotal: 51.5ms\tremaining: 53.7ms\n",
            "24:\tlearn: 0.1910934\ttotal: 53.5ms\tremaining: 51.4ms\n",
            "25:\tlearn: 0.1879112\ttotal: 55.6ms\tremaining: 49.2ms\n",
            "26:\tlearn: 0.1852765\ttotal: 57.5ms\tremaining: 46.9ms\n",
            "27:\tlearn: 0.1827068\ttotal: 59.5ms\tremaining: 44.6ms\n",
            "28:\tlearn: 0.1803359\ttotal: 61.4ms\tremaining: 42.3ms\n",
            "29:\tlearn: 0.1779549\ttotal: 63.3ms\tremaining: 40.1ms\n",
            "30:\tlearn: 0.1757984\ttotal: 65.1ms\tremaining: 37.8ms\n",
            "31:\tlearn: 0.1724570\ttotal: 67.1ms\tremaining: 35.6ms\n",
            "32:\tlearn: 0.1703672\ttotal: 69ms\tremaining: 33.5ms\n",
            "33:\tlearn: 0.1685175\ttotal: 71ms\tremaining: 31.3ms\n",
            "34:\tlearn: 0.1666049\ttotal: 73ms\tremaining: 29.2ms\n",
            "35:\tlearn: 0.1648374\ttotal: 74.8ms\tremaining: 27ms\n",
            "36:\tlearn: 0.1631656\ttotal: 76.8ms\tremaining: 24.9ms\n",
            "37:\tlearn: 0.1615072\ttotal: 78.8ms\tremaining: 22.8ms\n",
            "38:\tlearn: 0.1598928\ttotal: 80.8ms\tremaining: 20.7ms\n",
            "39:\tlearn: 0.1584040\ttotal: 82.8ms\tremaining: 18.6ms\n",
            "40:\tlearn: 0.1566573\ttotal: 84.9ms\tremaining: 16.6ms\n",
            "41:\tlearn: 0.1544748\ttotal: 86.6ms\tremaining: 14.4ms\n",
            "42:\tlearn: 0.1525493\ttotal: 88.6ms\tremaining: 12.4ms\n",
            "43:\tlearn: 0.1506610\ttotal: 90.4ms\tremaining: 10.3ms\n",
            "44:\tlearn: 0.1483410\ttotal: 92.4ms\tremaining: 8.21ms\n",
            "45:\tlearn: 0.1468477\ttotal: 94.3ms\tremaining: 6.15ms\n",
            "46:\tlearn: 0.1454975\ttotal: 96.3ms\tremaining: 4.09ms\n",
            "47:\tlearn: 0.1439431\ttotal: 98.2ms\tremaining: 2.05ms\n",
            "48:\tlearn: 0.1425078\ttotal: 100ms\tremaining: 0us\n",
            "0:\tlearn: 0.4849523\ttotal: 1.91ms\tremaining: 91.5ms\n",
            "1:\tlearn: 0.3687510\ttotal: 2.56ms\tremaining: 60.1ms\n",
            "2:\tlearn: 0.3203557\ttotal: 3.57ms\tremaining: 54.7ms\n",
            "3:\tlearn: 0.3063743\ttotal: 5.34ms\tremaining: 60.1ms\n",
            "4:\tlearn: 0.2970911\ttotal: 7.61ms\tremaining: 66.9ms\n",
            "5:\tlearn: 0.2891054\ttotal: 12.8ms\tremaining: 91.8ms\n",
            "6:\tlearn: 0.2792409\ttotal: 15ms\tremaining: 90.3ms\n",
            "7:\tlearn: 0.2716618\ttotal: 17.1ms\tremaining: 87.6ms\n",
            "8:\tlearn: 0.2621352\ttotal: 19.4ms\tremaining: 86.1ms\n",
            "9:\tlearn: 0.2537973\ttotal: 21.6ms\tremaining: 84.4ms\n",
            "10:\tlearn: 0.2473429\ttotal: 23.4ms\tremaining: 80.7ms\n",
            "11:\tlearn: 0.2416695\ttotal: 25.4ms\tremaining: 78.3ms\n",
            "12:\tlearn: 0.2366343\ttotal: 27.5ms\tremaining: 76.2ms\n",
            "13:\tlearn: 0.2298385\ttotal: 30.2ms\tremaining: 75.5ms\n",
            "14:\tlearn: 0.2249545\ttotal: 32.9ms\tremaining: 74.5ms\n",
            "15:\tlearn: 0.2192054\ttotal: 36.1ms\tremaining: 74.5ms\n",
            "16:\tlearn: 0.2150242\ttotal: 38ms\tremaining: 71.6ms\n",
            "17:\tlearn: 0.2094516\ttotal: 39.9ms\tremaining: 68.7ms\n",
            "18:\tlearn: 0.2056324\ttotal: 42.1ms\tremaining: 66.4ms\n",
            "19:\tlearn: 0.2021225\ttotal: 44.1ms\tremaining: 63.9ms\n",
            "20:\tlearn: 0.1989042\ttotal: 46.1ms\tremaining: 61.4ms\n",
            "21:\tlearn: 0.1961040\ttotal: 48ms\tremaining: 58.9ms\n",
            "22:\tlearn: 0.1934794\ttotal: 50ms\tremaining: 56.5ms\n",
            "23:\tlearn: 0.1902438\ttotal: 52.9ms\tremaining: 55.1ms\n",
            "24:\tlearn: 0.1874921\ttotal: 54.9ms\tremaining: 52.7ms\n",
            "25:\tlearn: 0.1829904\ttotal: 56.9ms\tremaining: 50.3ms\n",
            "26:\tlearn: 0.1804169\ttotal: 58.9ms\tremaining: 48ms\n",
            "27:\tlearn: 0.1776989\ttotal: 60.9ms\tremaining: 45.7ms\n",
            "28:\tlearn: 0.1751387\ttotal: 62.9ms\tremaining: 43.4ms\n",
            "29:\tlearn: 0.1727570\ttotal: 64.9ms\tremaining: 41.1ms\n",
            "30:\tlearn: 0.1693663\ttotal: 68.1ms\tremaining: 39.5ms\n",
            "31:\tlearn: 0.1661883\ttotal: 70.2ms\tremaining: 37.3ms\n",
            "32:\tlearn: 0.1641011\ttotal: 72ms\tremaining: 34.9ms\n",
            "33:\tlearn: 0.1616271\ttotal: 74.1ms\tremaining: 32.7ms\n",
            "34:\tlearn: 0.1593621\ttotal: 76.1ms\tremaining: 30.4ms\n",
            "35:\tlearn: 0.1576181\ttotal: 78.1ms\tremaining: 28.2ms\n",
            "36:\tlearn: 0.1557020\ttotal: 80.2ms\tremaining: 26ms\n",
            "37:\tlearn: 0.1541003\ttotal: 82.2ms\tremaining: 23.8ms\n",
            "38:\tlearn: 0.1522873\ttotal: 84.2ms\tremaining: 21.6ms\n",
            "39:\tlearn: 0.1502740\ttotal: 88.8ms\tremaining: 20ms\n",
            "40:\tlearn: 0.1483554\ttotal: 91.9ms\tremaining: 17.9ms\n",
            "41:\tlearn: 0.1465885\ttotal: 95.4ms\tremaining: 15.9ms\n",
            "42:\tlearn: 0.1443271\ttotal: 98.8ms\tremaining: 13.8ms\n",
            "43:\tlearn: 0.1425567\ttotal: 101ms\tremaining: 11.4ms\n",
            "44:\tlearn: 0.1409543\ttotal: 102ms\tremaining: 9.11ms\n",
            "45:\tlearn: 0.1393691\ttotal: 105ms\tremaining: 6.82ms\n",
            "46:\tlearn: 0.1378187\ttotal: 107ms\tremaining: 4.53ms\n",
            "47:\tlearn: 0.1364367\ttotal: 108ms\tremaining: 2.26ms\n",
            "48:\tlearn: 0.1348338\ttotal: 111ms\tremaining: 0us\n",
            "0:\tlearn: 0.4953901\ttotal: 1.84ms\tremaining: 75.5ms\n",
            "1:\tlearn: 0.3913884\ttotal: 2.23ms\tremaining: 44.6ms\n",
            "2:\tlearn: 0.3448150\ttotal: 2.97ms\tremaining: 38.6ms\n",
            "3:\tlearn: 0.3239941\ttotal: 4.98ms\tremaining: 47.3ms\n",
            "4:\tlearn: 0.3154324\ttotal: 7.12ms\tremaining: 52.7ms\n",
            "5:\tlearn: 0.3071855\ttotal: 9.32ms\tremaining: 55.9ms\n",
            "6:\tlearn: 0.3008926\ttotal: 11.4ms\tremaining: 57.1ms\n",
            "7:\tlearn: 0.2917474\ttotal: 13.7ms\tremaining: 58.4ms\n",
            "8:\tlearn: 0.2839959\ttotal: 15.9ms\tremaining: 58.5ms\n",
            "9:\tlearn: 0.2764479\ttotal: 18.2ms\tremaining: 58.1ms\n",
            "10:\tlearn: 0.2697878\ttotal: 20.3ms\tremaining: 57.3ms\n",
            "11:\tlearn: 0.2637910\ttotal: 22.5ms\tremaining: 56.2ms\n",
            "12:\tlearn: 0.2584595\ttotal: 24.6ms\tremaining: 54.9ms\n",
            "13:\tlearn: 0.2536803\ttotal: 26.7ms\tremaining: 53.5ms\n",
            "14:\tlearn: 0.2488450\ttotal: 28.7ms\tremaining: 51.7ms\n",
            "15:\tlearn: 0.2453522\ttotal: 30.9ms\tremaining: 50.1ms\n",
            "16:\tlearn: 0.2409862\ttotal: 32.9ms\tremaining: 48.3ms\n",
            "17:\tlearn: 0.2362795\ttotal: 35ms\tremaining: 46.6ms\n",
            "18:\tlearn: 0.2316987\ttotal: 37.1ms\tremaining: 44.9ms\n",
            "19:\tlearn: 0.2278794\ttotal: 39.3ms\tremaining: 43.2ms\n",
            "20:\tlearn: 0.2240923\ttotal: 41.3ms\tremaining: 41.3ms\n",
            "21:\tlearn: 0.2210944\ttotal: 43.4ms\tremaining: 39.5ms\n",
            "22:\tlearn: 0.2178475\ttotal: 45.6ms\tremaining: 37.7ms\n",
            "23:\tlearn: 0.2144264\ttotal: 47.7ms\tremaining: 35.8ms\n",
            "24:\tlearn: 0.2113675\ttotal: 49.8ms\tremaining: 33.8ms\n",
            "25:\tlearn: 0.2087050\ttotal: 51.8ms\tremaining: 31.9ms\n",
            "26:\tlearn: 0.2056571\ttotal: 53.9ms\tremaining: 29.9ms\n",
            "27:\tlearn: 0.2027725\ttotal: 56ms\tremaining: 28ms\n",
            "28:\tlearn: 0.1994675\ttotal: 58.1ms\tremaining: 26ms\n",
            "29:\tlearn: 0.1972468\ttotal: 60.1ms\tremaining: 24.1ms\n",
            "30:\tlearn: 0.1946726\ttotal: 62.2ms\tremaining: 22.1ms\n",
            "31:\tlearn: 0.1921813\ttotal: 64.4ms\tremaining: 20.1ms\n",
            "32:\tlearn: 0.1898599\ttotal: 66.6ms\tremaining: 18.2ms\n",
            "33:\tlearn: 0.1882285\ttotal: 68.6ms\tremaining: 16.1ms\n",
            "34:\tlearn: 0.1858728\ttotal: 70.7ms\tremaining: 14.1ms\n",
            "35:\tlearn: 0.1839323\ttotal: 72.9ms\tremaining: 12.1ms\n",
            "36:\tlearn: 0.1816561\ttotal: 77.4ms\tremaining: 10.5ms\n",
            "37:\tlearn: 0.1793649\ttotal: 79.8ms\tremaining: 8.39ms\n",
            "38:\tlearn: 0.1773369\ttotal: 82.6ms\tremaining: 6.36ms\n",
            "39:\tlearn: 0.1759663\ttotal: 86.1ms\tremaining: 4.3ms\n",
            "40:\tlearn: 0.1739234\ttotal: 90.4ms\tremaining: 2.21ms\n",
            "41:\tlearn: 0.1720694\ttotal: 93.4ms\tremaining: 0us\n",
            "Best set of hyperparameters:  {'iterations': 42}\n",
            "Best score:  0.8666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6QE0oxEn4Xs",
        "outputId": "73f9d4fb-afa2-4802-cd8f-676ee0b9c709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6879775\ttotal: 3.74ms\tremaining: 153ms\n",
            "1:\tlearn: 0.6813871\ttotal: 12.3ms\tremaining: 246ms\n",
            "2:\tlearn: 0.6762891\ttotal: 22.7ms\tremaining: 294ms\n",
            "3:\tlearn: 0.6703790\ttotal: 33ms\tremaining: 313ms\n",
            "4:\tlearn: 0.6642745\ttotal: 36.3ms\tremaining: 269ms\n",
            "5:\tlearn: 0.6594751\ttotal: 42.7ms\tremaining: 256ms\n",
            "6:\tlearn: 0.6536367\ttotal: 47.7ms\tremaining: 239ms\n",
            "7:\tlearn: 0.6494343\ttotal: 56ms\tremaining: 238ms\n",
            "8:\tlearn: 0.6445585\ttotal: 58.2ms\tremaining: 213ms\n",
            "9:\tlearn: 0.6394792\ttotal: 62.2ms\tremaining: 199ms\n",
            "10:\tlearn: 0.6337802\ttotal: 64.2ms\tremaining: 181ms\n",
            "11:\tlearn: 0.6284016\ttotal: 66.2ms\tremaining: 166ms\n",
            "12:\tlearn: 0.6245699\ttotal: 69.6ms\tremaining: 155ms\n",
            "13:\tlearn: 0.6199771\ttotal: 74.8ms\tremaining: 150ms\n",
            "14:\tlearn: 0.6147096\ttotal: 75.6ms\tremaining: 136ms\n",
            "15:\tlearn: 0.6107561\ttotal: 78.8ms\tremaining: 128ms\n",
            "16:\tlearn: 0.6069749\ttotal: 83.9ms\tremaining: 123ms\n",
            "17:\tlearn: 0.6023983\ttotal: 85.8ms\tremaining: 114ms\n",
            "18:\tlearn: 0.5983896\ttotal: 89ms\tremaining: 108ms\n",
            "19:\tlearn: 0.5947854\ttotal: 95ms\tremaining: 104ms\n",
            "20:\tlearn: 0.5906842\ttotal: 104ms\tremaining: 104ms\n",
            "21:\tlearn: 0.5862427\ttotal: 109ms\tremaining: 99.5ms\n",
            "22:\tlearn: 0.5816636\ttotal: 111ms\tremaining: 91.6ms\n",
            "23:\tlearn: 0.5778533\ttotal: 117ms\tremaining: 87.9ms\n",
            "24:\tlearn: 0.5748501\ttotal: 126ms\tremaining: 85.7ms\n",
            "25:\tlearn: 0.5706014\ttotal: 135ms\tremaining: 82.8ms\n",
            "26:\tlearn: 0.5667167\ttotal: 140ms\tremaining: 77.8ms\n",
            "27:\tlearn: 0.5633451\ttotal: 147ms\tremaining: 73.6ms\n",
            "28:\tlearn: 0.5593710\ttotal: 151ms\tremaining: 67.9ms\n",
            "29:\tlearn: 0.5561919\ttotal: 157ms\tremaining: 62.8ms\n",
            "30:\tlearn: 0.5525580\ttotal: 166ms\tremaining: 58.9ms\n",
            "31:\tlearn: 0.5494994\ttotal: 171ms\tremaining: 53.5ms\n",
            "32:\tlearn: 0.5455363\ttotal: 175ms\tremaining: 47.7ms\n",
            "33:\tlearn: 0.5421483\ttotal: 181ms\tremaining: 42.6ms\n",
            "34:\tlearn: 0.5391124\ttotal: 191ms\tremaining: 38.1ms\n",
            "35:\tlearn: 0.5363076\ttotal: 203ms\tremaining: 33.8ms\n",
            "36:\tlearn: 0.5332932\ttotal: 210ms\tremaining: 28.4ms\n",
            "37:\tlearn: 0.5301799\ttotal: 219ms\tremaining: 23ms\n",
            "38:\tlearn: 0.5271623\ttotal: 229ms\tremaining: 17.6ms\n",
            "39:\tlearn: 0.5240516\ttotal: 236ms\tremaining: 11.8ms\n",
            "40:\tlearn: 0.5220403\ttotal: 245ms\tremaining: 5.99ms\n",
            "41:\tlearn: 0.5195521\ttotal: 250ms\tremaining: 0us\n",
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91        82\n",
            "           1       0.92      0.93      0.93       102\n",
            "\n",
            "    accuracy                           0.92       184\n",
            "   macro avg       0.92      0.92      0.92       184\n",
            "weighted avg       0.92      0.92      0.92       184\n",
            "\n",
            "The accuracy for 1 : 0.9169057867049258\n",
            "0:\tlearn: 0.6877873\ttotal: 7.17ms\tremaining: 294ms\n",
            "1:\tlearn: 0.6806987\ttotal: 11.6ms\tremaining: 233ms\n",
            "2:\tlearn: 0.6753932\ttotal: 15.7ms\tremaining: 204ms\n",
            "3:\tlearn: 0.6696816\ttotal: 18.9ms\tremaining: 179ms\n",
            "4:\tlearn: 0.6627844\ttotal: 20ms\tremaining: 148ms\n",
            "5:\tlearn: 0.6566318\ttotal: 23ms\tremaining: 138ms\n",
            "6:\tlearn: 0.6499372\ttotal: 25ms\tremaining: 125ms\n",
            "7:\tlearn: 0.6450065\ttotal: 28.3ms\tremaining: 120ms\n",
            "8:\tlearn: 0.6404303\ttotal: 31.5ms\tremaining: 116ms\n",
            "9:\tlearn: 0.6355537\ttotal: 34.8ms\tremaining: 111ms\n",
            "10:\tlearn: 0.6295572\ttotal: 36.7ms\tremaining: 103ms\n",
            "11:\tlearn: 0.6244016\ttotal: 41.1ms\tremaining: 103ms\n",
            "12:\tlearn: 0.6194015\ttotal: 42.4ms\tremaining: 94.5ms\n",
            "13:\tlearn: 0.6141964\ttotal: 43.7ms\tremaining: 87.4ms\n",
            "14:\tlearn: 0.6100358\ttotal: 48.6ms\tremaining: 87.6ms\n",
            "15:\tlearn: 0.6065897\ttotal: 49.3ms\tremaining: 80.1ms\n",
            "16:\tlearn: 0.6013474\ttotal: 50.3ms\tremaining: 73.9ms\n",
            "17:\tlearn: 0.5971880\ttotal: 51.5ms\tremaining: 68.7ms\n",
            "18:\tlearn: 0.5938637\ttotal: 52.3ms\tremaining: 63.3ms\n",
            "19:\tlearn: 0.5888974\ttotal: 53.3ms\tremaining: 58.6ms\n",
            "20:\tlearn: 0.5853994\ttotal: 58.5ms\tremaining: 58.5ms\n",
            "21:\tlearn: 0.5812671\ttotal: 61.9ms\tremaining: 56.2ms\n",
            "22:\tlearn: 0.5776084\ttotal: 66.5ms\tremaining: 54.9ms\n",
            "23:\tlearn: 0.5737436\ttotal: 69ms\tremaining: 51.8ms\n",
            "24:\tlearn: 0.5697787\ttotal: 72.4ms\tremaining: 49.3ms\n",
            "25:\tlearn: 0.5658628\ttotal: 73.3ms\tremaining: 45.1ms\n",
            "26:\tlearn: 0.5626702\ttotal: 83.1ms\tremaining: 46.2ms\n",
            "27:\tlearn: 0.5595225\ttotal: 87.5ms\tremaining: 43.7ms\n",
            "28:\tlearn: 0.5558039\ttotal: 88.5ms\tremaining: 39.7ms\n",
            "29:\tlearn: 0.5518784\ttotal: 89.3ms\tremaining: 35.7ms\n",
            "30:\tlearn: 0.5484490\ttotal: 92.6ms\tremaining: 32.9ms\n",
            "31:\tlearn: 0.5450944\ttotal: 96.1ms\tremaining: 30ms\n",
            "32:\tlearn: 0.5418053\ttotal: 99.6ms\tremaining: 27.2ms\n",
            "33:\tlearn: 0.5384887\ttotal: 101ms\tremaining: 23.7ms\n",
            "34:\tlearn: 0.5346277\ttotal: 104ms\tremaining: 20.7ms\n",
            "35:\tlearn: 0.5316471\ttotal: 105ms\tremaining: 17.4ms\n",
            "36:\tlearn: 0.5283597\ttotal: 107ms\tremaining: 14.4ms\n",
            "37:\tlearn: 0.5256538\ttotal: 110ms\tremaining: 11.6ms\n",
            "38:\tlearn: 0.5227654\ttotal: 116ms\tremaining: 8.9ms\n",
            "39:\tlearn: 0.5200527\ttotal: 119ms\tremaining: 5.96ms\n",
            "40:\tlearn: 0.5176495\ttotal: 124ms\tremaining: 3.03ms\n",
            "41:\tlearn: 0.5147132\ttotal: 128ms\tremaining: 0us\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.90      0.81        82\n",
            "           1       0.90      0.74      0.81       102\n",
            "\n",
            "    accuracy                           0.81       184\n",
            "   macro avg       0.82      0.82      0.81       184\n",
            "weighted avg       0.83      0.81      0.81       184\n",
            "\n",
            "The accuracy for 2 : 0.8188665710186515\n",
            "0:\tlearn: 0.6872573\ttotal: 14.1ms\tremaining: 579ms\n",
            "1:\tlearn: 0.6800990\ttotal: 26.1ms\tremaining: 521ms\n",
            "2:\tlearn: 0.6736594\ttotal: 30.5ms\tremaining: 397ms\n",
            "3:\tlearn: 0.6683790\ttotal: 37.7ms\tremaining: 358ms\n",
            "4:\tlearn: 0.6613427\ttotal: 42.7ms\tremaining: 316ms\n",
            "5:\tlearn: 0.6560488\ttotal: 55.1ms\tremaining: 331ms\n",
            "6:\tlearn: 0.6486992\ttotal: 57.3ms\tremaining: 286ms\n",
            "7:\tlearn: 0.6438714\ttotal: 60.9ms\tremaining: 259ms\n",
            "8:\tlearn: 0.6387936\ttotal: 64.1ms\tremaining: 235ms\n",
            "9:\tlearn: 0.6331552\ttotal: 68ms\tremaining: 218ms\n",
            "10:\tlearn: 0.6280763\ttotal: 71.4ms\tremaining: 201ms\n",
            "11:\tlearn: 0.6215360\ttotal: 72.9ms\tremaining: 182ms\n",
            "12:\tlearn: 0.6154097\ttotal: 76.9ms\tremaining: 172ms\n",
            "13:\tlearn: 0.6092712\ttotal: 78.2ms\tremaining: 156ms\n",
            "14:\tlearn: 0.6036992\ttotal: 78.9ms\tremaining: 142ms\n",
            "15:\tlearn: 0.5985824\ttotal: 85ms\tremaining: 138ms\n",
            "16:\tlearn: 0.5936884\ttotal: 89.3ms\tremaining: 131ms\n",
            "17:\tlearn: 0.5877181\ttotal: 90.6ms\tremaining: 121ms\n",
            "18:\tlearn: 0.5827902\ttotal: 95.4ms\tremaining: 116ms\n",
            "19:\tlearn: 0.5771141\ttotal: 97ms\tremaining: 107ms\n",
            "20:\tlearn: 0.5722149\ttotal: 100ms\tremaining: 100ms\n",
            "21:\tlearn: 0.5676736\ttotal: 110ms\tremaining: 99.9ms\n",
            "22:\tlearn: 0.5623654\ttotal: 111ms\tremaining: 91.5ms\n",
            "23:\tlearn: 0.5588111\ttotal: 114ms\tremaining: 85.6ms\n",
            "24:\tlearn: 0.5544429\ttotal: 120ms\tremaining: 81.3ms\n",
            "25:\tlearn: 0.5505852\ttotal: 123ms\tremaining: 75.7ms\n",
            "26:\tlearn: 0.5467490\ttotal: 128ms\tremaining: 71.1ms\n",
            "27:\tlearn: 0.5424746\ttotal: 129ms\tremaining: 64.5ms\n",
            "28:\tlearn: 0.5388218\ttotal: 132ms\tremaining: 59.2ms\n",
            "29:\tlearn: 0.5344286\ttotal: 137ms\tremaining: 54.9ms\n",
            "30:\tlearn: 0.5310294\ttotal: 140ms\tremaining: 49.8ms\n",
            "31:\tlearn: 0.5272517\ttotal: 142ms\tremaining: 44.5ms\n",
            "32:\tlearn: 0.5233053\ttotal: 145ms\tremaining: 39.5ms\n",
            "33:\tlearn: 0.5199713\ttotal: 147ms\tremaining: 34.6ms\n",
            "34:\tlearn: 0.5165779\ttotal: 151ms\tremaining: 30.2ms\n",
            "35:\tlearn: 0.5136363\ttotal: 158ms\tremaining: 26.3ms\n",
            "36:\tlearn: 0.5103292\ttotal: 161ms\tremaining: 21.8ms\n",
            "37:\tlearn: 0.5072890\ttotal: 166ms\tremaining: 17.5ms\n",
            "38:\tlearn: 0.5040553\ttotal: 170ms\tremaining: 13ms\n",
            "39:\tlearn: 0.5008687\ttotal: 173ms\tremaining: 8.65ms\n",
            "40:\tlearn: 0.4986748\ttotal: 178ms\tremaining: 4.35ms\n",
            "41:\tlearn: 0.4956965\ttotal: 179ms\tremaining: 0us\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.73      0.82        82\n",
            "           1       0.82      0.96      0.88       102\n",
            "\n",
            "    accuracy                           0.86       184\n",
            "   macro avg       0.88      0.85      0.85       184\n",
            "weighted avg       0.87      0.86      0.86       184\n",
            "\n",
            "The accuracy for 3 : 0.8462458153993305\n",
            "0:\tlearn: 0.6868869\ttotal: 10.2ms\tremaining: 419ms\n",
            "1:\tlearn: 0.6797941\ttotal: 14ms\tremaining: 280ms\n",
            "2:\tlearn: 0.6732013\ttotal: 19.1ms\tremaining: 249ms\n",
            "3:\tlearn: 0.6663592\ttotal: 22.3ms\tremaining: 212ms\n",
            "4:\tlearn: 0.6589335\ttotal: 23.4ms\tremaining: 173ms\n",
            "5:\tlearn: 0.6522149\ttotal: 26.5ms\tremaining: 159ms\n",
            "6:\tlearn: 0.6448850\ttotal: 28.4ms\tremaining: 142ms\n",
            "7:\tlearn: 0.6399756\ttotal: 31.7ms\tremaining: 135ms\n",
            "8:\tlearn: 0.6340433\ttotal: 34.7ms\tremaining: 127ms\n",
            "9:\tlearn: 0.6286292\ttotal: 38.1ms\tremaining: 122ms\n",
            "10:\tlearn: 0.6219645\ttotal: 39.4ms\tremaining: 111ms\n",
            "11:\tlearn: 0.6168900\ttotal: 40.2ms\tremaining: 101ms\n",
            "12:\tlearn: 0.6113078\ttotal: 44.8ms\tremaining: 99.8ms\n",
            "13:\tlearn: 0.6069359\ttotal: 51.5ms\tremaining: 103ms\n",
            "14:\tlearn: 0.6019136\ttotal: 56.9ms\tremaining: 102ms\n",
            "15:\tlearn: 0.5972852\ttotal: 58.4ms\tremaining: 94.9ms\n",
            "16:\tlearn: 0.5910408\ttotal: 60.2ms\tremaining: 88.6ms\n",
            "17:\tlearn: 0.5855650\ttotal: 69ms\tremaining: 92ms\n",
            "18:\tlearn: 0.5812015\ttotal: 72.5ms\tremaining: 87.7ms\n",
            "19:\tlearn: 0.5767557\ttotal: 80.4ms\tremaining: 88.5ms\n",
            "20:\tlearn: 0.5716123\ttotal: 84ms\tremaining: 84ms\n",
            "21:\tlearn: 0.5674911\ttotal: 92.4ms\tremaining: 84ms\n",
            "22:\tlearn: 0.5627353\ttotal: 97.9ms\tremaining: 80.9ms\n",
            "23:\tlearn: 0.5580224\ttotal: 107ms\tremaining: 80.4ms\n",
            "24:\tlearn: 0.5529885\ttotal: 117ms\tremaining: 79.7ms\n",
            "25:\tlearn: 0.5497621\ttotal: 127ms\tremaining: 78.4ms\n",
            "26:\tlearn: 0.5452621\ttotal: 133ms\tremaining: 74ms\n",
            "27:\tlearn: 0.5412593\ttotal: 143ms\tremaining: 71.7ms\n",
            "28:\tlearn: 0.5367707\ttotal: 147ms\tremaining: 66ms\n",
            "29:\tlearn: 0.5332544\ttotal: 156ms\tremaining: 62.4ms\n",
            "30:\tlearn: 0.5292160\ttotal: 158ms\tremaining: 56.1ms\n",
            "31:\tlearn: 0.5252746\ttotal: 166ms\tremaining: 52ms\n",
            "32:\tlearn: 0.5212535\ttotal: 171ms\tremaining: 46.6ms\n",
            "33:\tlearn: 0.5169347\ttotal: 175ms\tremaining: 41.3ms\n",
            "34:\tlearn: 0.5134679\ttotal: 181ms\tremaining: 36.2ms\n",
            "35:\tlearn: 0.5096512\ttotal: 184ms\tremaining: 30.7ms\n",
            "36:\tlearn: 0.5064491\ttotal: 193ms\tremaining: 26ms\n",
            "37:\tlearn: 0.5035870\ttotal: 204ms\tremaining: 21.4ms\n",
            "38:\tlearn: 0.5007376\ttotal: 212ms\tremaining: 16.3ms\n",
            "39:\tlearn: 0.4977909\ttotal: 221ms\tremaining: 11.1ms\n",
            "40:\tlearn: 0.4949339\ttotal: 230ms\tremaining: 5.6ms\n",
            "41:\tlearn: 0.4915173\ttotal: 233ms\tremaining: 0us\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.66      0.74        82\n",
            "           1       0.77      0.91      0.83       101\n",
            "\n",
            "    accuracy                           0.80       183\n",
            "   macro avg       0.81      0.78      0.79       183\n",
            "weighted avg       0.81      0.80      0.79       183\n",
            "\n",
            "The accuracy for 4 : 0.7847138372373822\n",
            "0:\tlearn: 0.6865403\ttotal: 8.79ms\tremaining: 361ms\n",
            "1:\tlearn: 0.6789988\ttotal: 16.8ms\tremaining: 335ms\n",
            "2:\tlearn: 0.6717637\ttotal: 26.4ms\tremaining: 343ms\n",
            "3:\tlearn: 0.6643128\ttotal: 40.5ms\tremaining: 385ms\n",
            "4:\tlearn: 0.6568472\ttotal: 41.7ms\tremaining: 308ms\n",
            "5:\tlearn: 0.6497989\ttotal: 49.9ms\tremaining: 299ms\n",
            "6:\tlearn: 0.6426625\ttotal: 52.1ms\tremaining: 260ms\n",
            "7:\tlearn: 0.6363674\ttotal: 62.4ms\tremaining: 265ms\n",
            "8:\tlearn: 0.6302382\ttotal: 66.8ms\tremaining: 245ms\n",
            "9:\tlearn: 0.6239763\ttotal: 79.8ms\tremaining: 255ms\n",
            "10:\tlearn: 0.6184783\ttotal: 83.5ms\tremaining: 235ms\n",
            "11:\tlearn: 0.6121642\ttotal: 85.4ms\tremaining: 213ms\n",
            "12:\tlearn: 0.6081686\ttotal: 92.8ms\tremaining: 207ms\n",
            "13:\tlearn: 0.6020552\ttotal: 100ms\tremaining: 201ms\n",
            "14:\tlearn: 0.5970665\ttotal: 118ms\tremaining: 213ms\n",
            "15:\tlearn: 0.5919844\ttotal: 121ms\tremaining: 196ms\n",
            "16:\tlearn: 0.5865742\ttotal: 127ms\tremaining: 187ms\n",
            "17:\tlearn: 0.5810007\ttotal: 132ms\tremaining: 176ms\n",
            "18:\tlearn: 0.5754176\ttotal: 133ms\tremaining: 161ms\n",
            "19:\tlearn: 0.5711045\ttotal: 141ms\tremaining: 155ms\n",
            "20:\tlearn: 0.5664042\ttotal: 149ms\tremaining: 149ms\n",
            "21:\tlearn: 0.5623788\ttotal: 153ms\tremaining: 139ms\n",
            "22:\tlearn: 0.5581387\ttotal: 177ms\tremaining: 146ms\n",
            "23:\tlearn: 0.5530145\ttotal: 187ms\tremaining: 140ms\n",
            "24:\tlearn: 0.5481365\ttotal: 196ms\tremaining: 133ms\n",
            "25:\tlearn: 0.5433304\ttotal: 205ms\tremaining: 126ms\n",
            "26:\tlearn: 0.5383829\ttotal: 208ms\tremaining: 115ms\n",
            "27:\tlearn: 0.5337644\ttotal: 211ms\tremaining: 105ms\n",
            "28:\tlearn: 0.5302474\ttotal: 216ms\tremaining: 96.9ms\n",
            "29:\tlearn: 0.5256254\ttotal: 223ms\tremaining: 89.1ms\n",
            "30:\tlearn: 0.5216241\ttotal: 229ms\tremaining: 81.3ms\n",
            "31:\tlearn: 0.5175612\ttotal: 235ms\tremaining: 73.3ms\n",
            "32:\tlearn: 0.5129887\ttotal: 240ms\tremaining: 65.4ms\n",
            "33:\tlearn: 0.5086833\ttotal: 245ms\tremaining: 57.8ms\n",
            "34:\tlearn: 0.5046702\ttotal: 253ms\tremaining: 50.7ms\n",
            "35:\tlearn: 0.5016249\ttotal: 263ms\tremaining: 43.9ms\n",
            "36:\tlearn: 0.4982530\ttotal: 273ms\tremaining: 36.9ms\n",
            "37:\tlearn: 0.4946518\ttotal: 285ms\tremaining: 30ms\n",
            "38:\tlearn: 0.4910228\ttotal: 298ms\tremaining: 22.9ms\n",
            "39:\tlearn: 0.4871997\ttotal: 311ms\tremaining: 15.6ms\n",
            "40:\tlearn: 0.4841495\ttotal: 320ms\tremaining: 7.81ms\n",
            "41:\tlearn: 0.4803815\ttotal: 321ms\tremaining: 0us\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.65      0.67        82\n",
            "           1       0.73      0.76      0.74       101\n",
            "\n",
            "    accuracy                           0.71       183\n",
            "   macro avg       0.71      0.70      0.71       183\n",
            "weighted avg       0.71      0.71      0.71       183\n",
            "\n",
            "The accuracy for 5 : 0.7043588505191983\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "acc_catBoost = []\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold, (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "  X_train = df_nontree.loc[trn_,feature_col_nontree]\n",
        "  y_train = df_nontree.loc[trn_,target]\n",
        "\n",
        "  X_valid = df_nontree.loc[val_,feature_col_nontree]\n",
        "  y_valid = df_nontree.loc[val_,target]\n",
        "\n",
        "  clf = CatBoostClassifier(depth =  8, iterations = 42, learning_rate = 0.01,\n",
        "        l2_leaf_reg = 24)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_valid)\n",
        "  print(f\"The fold is : {fold} : \")\n",
        "  print(classification_report(y_valid,y_pred))\n",
        "  acc = roc_auc_score(y_valid,y_pred)\n",
        "  acc_catBoost.append(acc)\n",
        "  print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Average(acc_catBoost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgsv-QmgIGhB",
        "outputId": "1c01b23a-1898-4cf5-bace-3e6c19a926ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8142181721758976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snvCi11rrcaI"
      },
      "source": [
        "# LightGBM\n",
        "LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be efficient and scalable for large-scale machine learning tasks, such as classification and regression. It is particularly well suited for working with large datasets, due to its fast training speed, low memory usage, and ability to handle missing values.\n",
        "\n",
        "LightGBM uses a novel gradient-based one-side sampling technique to handle large datasets, which allows it to achieve high training speeds while still maintaining accuracy. It also includes advanced features for model tuning, such as support for parallel and GPU-based computing, as well as various objective functions for both binary and multiclass classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter tuning**"
      ],
      "metadata": {
        "id": "Fn_J-ezPIbFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_test1 = { 'max_depth' : [1,2,3,4,5,6,7,8,9,10],\n",
        "                'learning_rate' : [0.1,0.01,0.001],\n",
        "                'num_leaves' : [i for i in range(1,10)],\n",
        "                'n_estimators' : [i for i in range(1,100)]\n",
        "}\n",
        "X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "clf=LGBMClassifier(max_depth = 2,num_leaves = 4,learning_rate = 0.1)\n",
        "grid_search = GridSearchCV(clf, param_test1, cv=5, scoring='accuracy')\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAiEd0QTIdmo",
        "outputId": "81f68e4d-bce6-4b17-d22b-e29227862152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 326, number of negative: 262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 337\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554422 -> initscore=0.218553\n",
            "[LightGBM] [Info] Start training from score 0.218553\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 320\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 325, number of negative: 263\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 302\n",
            "[LightGBM] [Info] Number of data points in the train set: 588, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552721 -> initscore=0.211671\n",
            "[LightGBM] [Info] Start training from score 0.211671\n",
            "[LightGBM] [Info] Number of positive: 407, number of negative: 328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 358\n",
            "[LightGBM] [Info] Number of data points in the train set: 735, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553741 -> initscore=0.215800\n",
            "[LightGBM] [Info] Start training from score 0.215800\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Best set of hyperparameters:  {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 92, 'num_leaves': 4}\n",
            "Best score:  0.8734693877551021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYwdVXgBtPXx",
        "outputId": "a2d25fd6-1916-4c0a-93fc-4663a9dfd341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 406, number of negative: 328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 386\n",
            "[LightGBM] [Info] Number of data points in the train set: 734, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553134 -> initscore=0.213340\n",
            "[LightGBM] [Info] Start training from score 0.213340\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89        82\n",
            "           1       0.94      0.87      0.90       102\n",
            "\n",
            "    accuracy                           0.90       184\n",
            "   macro avg       0.90      0.90      0.90       184\n",
            "weighted avg       0.90      0.90      0.90       184\n",
            "\n",
            "The accuracy for 1 : 0.899689143950263\n",
            "[LightGBM] [Info] Number of positive: 406, number of negative: 328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 395\n",
            "[LightGBM] [Info] Number of data points in the train set: 734, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553134 -> initscore=0.213340\n",
            "[LightGBM] [Info] Start training from score 0.213340\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83        82\n",
            "           1       0.93      0.75      0.83       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.84      0.84      0.83       184\n",
            "weighted avg       0.85      0.83      0.83       184\n",
            "\n",
            "The accuracy for 2 : 0.8408656145384983\n",
            "[LightGBM] [Info] Number of positive: 406, number of negative: 328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 382\n",
            "[LightGBM] [Info] Number of data points in the train set: 734, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553134 -> initscore=0.213340\n",
            "[LightGBM] [Info] Start training from score 0.213340\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.63      0.77        82\n",
            "           1       0.77      0.99      0.87       102\n",
            "\n",
            "    accuracy                           0.83       184\n",
            "   macro avg       0.88      0.81      0.82       184\n",
            "weighted avg       0.86      0.83      0.82       184\n",
            "\n",
            "The accuracy for 3 : 0.8121712099473937\n",
            "[LightGBM] [Info] Number of positive: 407, number of negative: 328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 735, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553741 -> initscore=0.215800\n",
            "[LightGBM] [Info] Start training from score 0.215800\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81        82\n",
            "           1       0.83      0.88      0.86       101\n",
            "\n",
            "    accuracy                           0.84       183\n",
            "   macro avg       0.84      0.83      0.83       183\n",
            "weighted avg       0.84      0.84      0.84       183\n",
            "\n",
            "The accuracy for 4 : 0.830837961844965\n",
            "[LightGBM] [Info] Number of positive: 407, number of negative: 328\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 735, number of used features: 20\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553741 -> initscore=0.215800\n",
            "[LightGBM] [Info] Start training from score 0.215800\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.84      0.76        82\n",
            "           1       0.85      0.70      0.77       101\n",
            "\n",
            "    accuracy                           0.77       183\n",
            "   macro avg       0.77      0.77      0.76       183\n",
            "weighted avg       0.78      0.77      0.77       183\n",
            "\n",
            "The accuracy for 5 : 0.7722168558319247\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "\n",
        "acc_LightGBM = []\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold, (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "  X_train = df_nontree.loc[trn_,feature_col_nontree]\n",
        "  y_train = df_nontree.loc[trn_,target]\n",
        "\n",
        "  X_valid = df_nontree.loc[val_,feature_col_nontree]\n",
        "  y_valid = df_nontree.loc[val_,target]\n",
        "\n",
        "  clf = LGBMClassifier(max_depth = 2, learning_rate = 0.1,\n",
        "                       num_leaves = 4, n_estimators = 92)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_valid)\n",
        "  print(f\"The fold is : {fold} : \")\n",
        "  print(classification_report(y_valid,y_pred))\n",
        "  acc = roc_auc_score(y_valid,y_pred)\n",
        "  acc_LightGBM.append(acc)\n",
        "  print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGKrKmuDyUU4"
      },
      "source": [
        "**Average Accuracy of LightGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t_b-qOEyYu6",
        "outputId": "06b714f3-ab50-4d40-bd64-62797f7bcf4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8311561572226089\n"
          ]
        }
      ],
      "source": [
        "print(Average(acc_LightGBM))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y1CNLb3sq6E"
      },
      "source": [
        "# AdaBoost\n",
        "AdaBoost (Adaptive Boosting) is a machine learning technique used for classification and regression problems. It is an ensemble learning method that combines the predictions of multiple weak models to produce a strong overall prediction. The weak models are typically decision trees with a shallow depth, and the predictions are combined through a weighted average, where more weight is given to the trees that produce a better result on the training data.\n",
        "\n",
        "AdaBoost works by iteratively fitting weak models to the training data and adjusting the weights of the samples in each iteration to focus on the samples that are misclassified in the previous iteration. The final prediction is made by taking a weighted majority vote of all the trees in the ensemble."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_test1 = {\n",
        "                'learning_rate' : [0.1,0.01,0.001],\n",
        "                'n_estimators' : [i for i in range(1,100)]\n",
        "}\n",
        "X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "clf=AdaBoostClassifier()\n",
        "grid_search = GridSearchCV(clf, param_test1, cv=5, scoring='accuracy')\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLn1YQbRL2Wh",
        "outputId": "82caf47c-af37-49ef-80df-ef61aa6515ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best set of hyperparameters:  {'learning_rate': 0.1, 'n_estimators': 68}\n",
            "Best score:  0.8639455782312926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ri9a4T_6KM",
        "outputId": "909f1c92-d21a-419d-b0c0-f6f81cccd34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88        82\n",
            "           1       0.93      0.87      0.90       102\n",
            "\n",
            "    accuracy                           0.89       184\n",
            "   macro avg       0.89      0.89      0.89       184\n",
            "weighted avg       0.89      0.89      0.89       184\n",
            "\n",
            "The accuracy for 1 : 0.8935915829746534\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.84        82\n",
            "           1       0.92      0.78      0.85       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.85      0.85      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n",
            "The accuracy for 2 : 0.8494739359158296\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.65      0.78        82\n",
            "           1       0.78      0.99      0.87       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.88      0.82      0.83       184\n",
            "weighted avg       0.87      0.84      0.83       184\n",
            "\n",
            "The accuracy for 3 : 0.8182687709230033\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84        82\n",
            "           1       0.87      0.86      0.87       101\n",
            "\n",
            "    accuracy                           0.85       183\n",
            "   macro avg       0.85      0.85      0.85       183\n",
            "weighted avg       0.85      0.85      0.85       183\n",
            "\n",
            "The accuracy for 4 : 0.8514247766240037\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.77      0.72        82\n",
            "           1       0.79      0.70      0.74       101\n",
            "\n",
            "    accuracy                           0.73       183\n",
            "   macro avg       0.73      0.74      0.73       183\n",
            "weighted avg       0.74      0.73      0.73       183\n",
            "\n",
            "The accuracy for 5 : 0.7356314899782661\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "\n",
        "acc_AdaBoost = []\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold, (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "  X_train = df_nontree.loc[trn_,feature_col_nontree]\n",
        "  y_train = df_nontree.loc[trn_,target]\n",
        "\n",
        "  X_valid = df_nontree.loc[val_,feature_col_nontree]\n",
        "  y_valid = df_nontree.loc[val_,target]\n",
        "\n",
        "  clf = AdaBoostClassifier(learning_rate = 0.1, n_estimators = 68)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_valid)\n",
        "  print(f\"The fold is : {fold} : \")\n",
        "  print(classification_report(y_valid,y_pred))\n",
        "  acc = roc_auc_score(y_valid,y_pred)\n",
        "  acc_AdaBoost.append(acc)\n",
        "  print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08vSsuJSylM4"
      },
      "source": [
        "**Average Accuracy of AdaBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzje6vHxyraa",
        "outputId": "c0d2f8e3-515a-44b2-a939-4ab2ffdf2214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8296781112831514\n"
          ]
        }
      ],
      "source": [
        "print(Average(acc_AdaBoost))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkLroIyus4fc"
      },
      "source": [
        "# Gradient Boosting\n",
        "Gradient Boosting is the boosting algorithm that works on the principle of the stagewise addition method, where multiple weak learning algorithms are trained and a strong learner algorithm is used as a final model from the addition of multiple weak learning algorithms trained on the same dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_test1 = {\n",
        "                'learning_rate' : [0.1,0.01,0.001],\n",
        "                'n_estimators' : [i for i in range(1,100)],\n",
        "                'subsample' : [i/10 for i in range(1,10)]\n",
        "}\n",
        "X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "clf=GradientBoostingClassifier()\n",
        "grid_search = GridSearchCV(clf, param_test1, cv=5, scoring='accuracy')\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyweVmXIZ0pn",
        "outputId": "d070cee5-971c-4ba8-8145-093b10849a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best set of hyperparameters:  {'learning_rate': 0.01, 'n_estimators': 37, 'subsample': 0.1}\n",
            "Best score:  0.8734693877551021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EoLppsmITNO",
        "outputId": "255f2d7e-34f3-451d-beda-0ffac59434e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fold is : 0 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.82      0.86        82\n",
            "           1       0.86      0.93      0.90       102\n",
            "\n",
            "    accuracy                           0.88       184\n",
            "   macro avg       0.88      0.87      0.88       184\n",
            "weighted avg       0.88      0.88      0.88       184\n",
            "\n",
            "The accuracy for 1 : 0.8742228598756576\n",
            "The fold is : 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87        82\n",
            "           1       0.90      0.89      0.90       102\n",
            "\n",
            "    accuracy                           0.89       184\n",
            "   macro avg       0.88      0.89      0.88       184\n",
            "weighted avg       0.89      0.89      0.89       184\n",
            "\n",
            "The accuracy for 2 : 0.8851028216164515\n",
            "The fold is : 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.63      0.78        82\n",
            "           1       0.77      1.00      0.87       102\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.89      0.82      0.82       184\n",
            "weighted avg       0.87      0.84      0.83       184\n",
            "\n",
            "The accuracy for 3 : 0.8170731707317074\n",
            "The fold is : 3 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.59      0.70        82\n",
            "           1       0.73      0.92      0.82       101\n",
            "\n",
            "    accuracy                           0.77       183\n",
            "   macro avg       0.79      0.75      0.76       183\n",
            "weighted avg       0.79      0.77      0.76       183\n",
            "\n",
            "The accuracy for 4 : 0.7530789664332287\n",
            "The fold is : 4 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.61      0.65        82\n",
            "           1       0.71      0.79      0.75       101\n",
            "\n",
            "    accuracy                           0.71       183\n",
            "   macro avg       0.71      0.70      0.70       183\n",
            "weighted avg       0.71      0.71      0.71       183\n",
            "\n",
            "The accuracy for 5 : 0.7009176527408839\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "\n",
        "acc_GradientBoosting = []\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold, (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "  X_train = df_nontree.loc[trn_,feature_col_nontree]\n",
        "  y_train = df_nontree.loc[trn_,target]\n",
        "\n",
        "  X_valid = df_nontree.loc[val_,feature_col_nontree]\n",
        "  y_valid = df_nontree.loc[val_,target]\n",
        "\n",
        "  clf = GradientBoostingClassifier(learning_rate = 0.01\n",
        "              , n_estimators = 37, subsample = 0.1)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_valid)\n",
        "  print(f\"The fold is : {fold} : \")\n",
        "  print(classification_report(y_valid,y_pred))\n",
        "  acc = roc_auc_score(y_valid,y_pred)\n",
        "  acc_GradientBoosting.append(acc)\n",
        "  print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TXXT4Gxyzab"
      },
      "source": [
        "**Average Accuracy of Gradient Boosting**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00FIX4suy6Yh",
        "outputId": "1ff874c4-60d3-457e-c77b-e0720e20ea66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8060790942795858\n"
          ]
        }
      ],
      "source": [
        "print(Average(acc_GradientBoosting))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8y4HI2EjdOt"
      },
      "source": [
        "# Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCStFd4QjcLT"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df,y=\"Age\",x=\"HeartDisease\",title=f\"Distrubution of Age\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvHa4D6e-L-N"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df,y=\"RestingBP\",x=\"HeartDisease\",title=f\"Distrubution of RestingBP\",color=\"Sex\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A8l0eKF-O1S"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df,y=\"Cholesterol\",x=\"HeartDisease\",title=f\"Distrubution of Cholesterol\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAgQsrmF-PrH"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df,y=\"Oldpeak\",x=\"HeartDisease\",title=f\"Distrubution of Oldpeak\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATTeW3RF-TTS"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df,y=\"MaxHR\",x=\"HeartDisease\",title=f\"Distrubution of MaxHR\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPGTnYYFASg7"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "# Copy the dataframe\n",
        "df_outliers = df.copy()\n",
        "\n",
        "#List of column that we need to check outliers\n",
        "check = ['Age','RestingBP','Cholesterol','Oldpeak','MaxHR']\n",
        "threshold = 3\n",
        "for string in check:\n",
        "  z = np.abs(stats.zscore(df[string]))\n",
        "\n",
        "  # Identify outliers  with a z-score greater than 3\n",
        "  outliers = df[z > threshold]\n",
        "\n",
        "  #Remove outliers row\n",
        "  df_outliers.drop(outliers.index, inplace = True)\n",
        "\n",
        "#Reset the index of dataframe\n",
        "df_outliers.reset_index(drop=True, inplace=True)\n",
        "df_outliers.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp_hpaEXgI3k"
      },
      "source": [
        "# Process Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmw9DDDDgLmz"
      },
      "outputs": [],
      "source": [
        "# As we will be using both types of approches for demonstration lets do First Label Ecoding\n",
        "# which will be used with Tree Based Algorthms\n",
        "df_tree = df_outliers.apply(LabelEncoder().fit_transform)\n",
        "df_tree.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSeF9eT-go6B"
      },
      "outputs": [],
      "source": [
        "## Creaeting one hot encoded features for working with non tree based algorithms\n",
        "df_nontree=pd.get_dummies(df_outliers,columns=string_col,drop_first=False)\n",
        "df_nontree.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tnHiirgjH_7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb6xoFTliuaT"
      },
      "outputs": [],
      "source": [
        "# Getting the target column at the end\n",
        "target=\"HeartDisease\"\n",
        "y=df_nontree[target].values\n",
        "df_nontree.drop(\"HeartDisease\",axis=1,inplace=True)\n",
        "df_nontree=pd.concat([df_nontree,df_outliers[target]],axis=1)\n",
        "df_nontree.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqK4skZhg3zI"
      },
      "outputs": [],
      "source": [
        "feature_col_nontree=df_nontree.columns.to_list()\n",
        "feature_col_nontree.remove(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1-tapQMhB6I"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score\n",
        "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
        "acc_log=[]\n",
        "\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    #print(pd.DataFrame(X_valid).head())\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=LogisticRegression()\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_log.append(acc)\n",
        "    print(f\"The accuracy for Fold {fold+1} : {acc}\")\n",
        "    pass\n",
        "print(Average(acc_log))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlNMMKh2lEhO"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "acc_Gauss=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=GaussianNB()\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_Gauss.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_Gauss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sXdOJoVlXeu"
      },
      "outputs": [],
      "source": [
        "# Using Linear Kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"linear\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTsWtuYwlh3U"
      },
      "outputs": [],
      "source": [
        "## Using Sigmoid Kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm_sig=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"sigmoid\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm_sig.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "    pass\n",
        "\n",
        "print(Average(acc_svm_sig))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e3e0IPTlu6-"
      },
      "outputs": [],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm_rbf=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"rbf\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm_rbf.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_svm_rbf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzdVkEaHmLFX"
      },
      "outputs": [],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.svm import SVC\n",
        "acc_svm_poly=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=SVC(kernel=\"poly\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_svm_poly.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_svm_poly))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds4f9lbGmQOi"
      },
      "outputs": [],
      "source": [
        "## Using RBF kernel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "acc_KNN=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_nontree,y=y)):\n",
        "\n",
        "    X_train=df_nontree.loc[trn_,feature_col_nontree]\n",
        "    y_train=df_nontree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_nontree.loc[val_,feature_col_nontree]\n",
        "    y_valid=df_nontree.loc[val_,target]\n",
        "\n",
        "    ro_scaler=MinMaxScaler()\n",
        "    X_train=ro_scaler.fit_transform(X_train)\n",
        "    X_valid=ro_scaler.transform(X_valid)\n",
        "\n",
        "    clf=KNeighborsClassifier(n_neighbors=32)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_KNN.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "\n",
        "    pass\n",
        "print(Average(acc_KNN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjILhs94mYjC"
      },
      "outputs": [],
      "source": [
        "feature_col_tree=df_tree.columns.to_list()\n",
        "feature_col_tree.remove(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHeI5vZJmcXp"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "acc_Dtree=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "    X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "    y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "    y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "    clf=DecisionTreeClassifier(criterion=\"entropy\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_Dtree.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "print(Average(acc_Dtree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNr7HOuPmm2P"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "acc_RandF=[]\n",
        "kf=model_selection.StratifiedKFold(n_splits=5)\n",
        "for fold , (trn_,val_) in enumerate(kf.split(X=df_tree,y=y)):\n",
        "\n",
        "    X_train=df_tree.loc[trn_,feature_col_tree]\n",
        "    y_train=df_tree.loc[trn_,target]\n",
        "\n",
        "    X_valid=df_tree.loc[val_,feature_col_tree]\n",
        "    y_valid=df_tree.loc[val_,target]\n",
        "\n",
        "    clf=RandomForestClassifier(n_estimators=200,criterion=\"entropy\")\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_valid)\n",
        "    print(f\"The fold is : {fold} : \")\n",
        "    print(classification_report(y_valid,y_pred))\n",
        "    acc=roc_auc_score(y_valid,y_pred)\n",
        "    acc_RandF.append(acc)\n",
        "    print(f\"The accuracy for {fold+1} : {acc}\")\n",
        "print(Average(acc_RandF))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}